{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import retriever\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset_file = '../data/training/order_train_data.bin'\n",
    "testset_file = '../data/training/order_test_data.bin'\n",
    "vocab_file =  '../data/metadata/w2v_vocab.json'\n",
    "params_dir_tmp = '../data/training/models/All/'\n",
    "embed_path =  '../data/metadata/w2v.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Each entry in this list has the following structure:</h3>\n",
    "<ul>\n",
    "<li>entry[0]: query indexes </li>\n",
    "<li>entry[1:n]: n items where each item is [bounding box vector, bounding box spaital features]. Note that different enteries might have different number of possible  bounding boxes (i.e. different n) </li>\n",
    "<li>entry[n+1]: integer, entry[ 1 + entry[n+1]] is the ture bbox </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set batches #: 297\n",
      "Train batch size: 200\n",
      "Train set data size: 59400\n",
      "Test set batches #: 297\n",
      "Test Batch size: 200\n",
      "Test set data size: 59400\n"
     ]
    }
   ],
   "source": [
    "# A data point is taken from the dataset only if the query length is \n",
    "# bigger than zero and it has more than two possible bounding boxes\n",
    "# to choose from\n",
    "\n",
    "trainset = np.load(open(trainset_file, 'rb'))\n",
    "trainset = [item for item in trainset if len(item)>2 and len(item[0])>0]\n",
    "print('Train set batches #:', len(trainset))\n",
    "print('Train batch size:', len(trainset[0]))\n",
    "print('Train set data size:', len(trainset)*len(trainset[0]))\n",
    "\n",
    "testset = np.load(open(testset_file, 'rb'))\n",
    "testset = [item for item in testset if len(item)>2 and len(item[0])>0]\n",
    "print('Test set batches #:', len(trainset))\n",
    "print('Test Batch size:', len(trainset[0]))\n",
    "print('Test set data size:', len(trainset)*len(trainset[0]))\n",
    "\n",
    "\n",
    "with open(vocab_file, 'r') as f:\n",
    "    vocab = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab['<unk>'] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8242, 8241)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab), vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w2c words vectors\n",
    "embed_vecs = np.load(open(embed_path, 'rb')).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> augment_data function </h3>\n",
    "<br>We try sevral regularization methods. One of the things I've tried is to add data points where for each data I pick a query from a random data point and a set of bbox from a different random point. We build the labels (bboxes) distribution by giving an equal probability to each label. <br><br>\n",
    "The augment_data function does just that but the label of each added poind is writen as -1*number of bboxes. When we build the batch it self (function build_data in class Model), if we see a negative label index, we know its an added point and we know the number of bboxes so we can build the correct distribution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_data(data, ratio=0.5, addNoise=False):\n",
    "        '''\n",
    "        The function add data points. \n",
    "        We pick a query from a random data point,\n",
    "        and a set of bbox from a different random point and we join them\n",
    "        to build a new data point. The label distribution of the new data point will \n",
    "        uniform, that is, all labels will have equal probability. \n",
    "        \n",
    "        \n",
    "        Params:\n",
    "            data: a list of data entries\n",
    "                                                \n",
    "        Returns: a list of augmented data\n",
    "            \n",
    "                        \n",
    "        '''\n",
    "                          \n",
    "        q_idx = np.random.choice(range(len(data)), int(len(data)*ratio), replace=False)\n",
    "        im_idx = np.random.choice([i for i in range(len(data)) if i not in q_idx], int(len(data)*ratio))\n",
    "        for i in range(len(q_idx)):\n",
    "            q, im = data[q_idx[i]][0], data[im_idx[i]][1:-1]\n",
    "            item = [q]\n",
    "            for im_tmp in im:\n",
    "                item.append(im_tmp)\n",
    "            item.append(-len(im))\n",
    "            data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stats(test, train, ephocs=100, title=None, params=[50, 100, 150, 200]):\n",
    "    '''\n",
    "    Plot metrics graphs and print some stats.\n",
    "    \n",
    "    Params:\n",
    "        test: list. \n",
    "              Each item is a tuple, [test accuracy, test IOU, test loss]\n",
    "        \n",
    "        train: list. \n",
    "               Each item is a tuple, [train accuracy, train IOU, train loss, 0]\n",
    "               For now we can ignore the last part in the tuple (zero)\n",
    "               \n",
    "        params: The hyper-parameters to iterate over, defult to number of rnn's hidden units.\n",
    "    '''\n",
    "    \n",
    "    ephocs = range(ephocs)\n",
    "    test_res = np.array(test)\n",
    "    train_res = np.array(train)\n",
    "    test_Glabels = ['test accuracy', 'test IOU', 'test loss']\n",
    "    train_Glabels = ['train accuracy', 'train IOU', 'train loss']\n",
    "\n",
    "    for j, param in enumerate(params):\n",
    "        print('num_hidden:', param)\n",
    "        print('='*(len('num_hidden:')+3))\n",
    "        for i in range(len(train_Glabels)):\n",
    "            plt.plot(ephocs, test_res[j][:,i])\n",
    "            plt.plot(ephocs, train_res[j][:,i])\n",
    "            plt.legend([test_Glabels[i], train_Glabels[i]], loc='upper left')\n",
    "            if title is not None:\n",
    "                plt.title('%s: %d'%(title, param))\n",
    "            plt.show()\n",
    "\n",
    "            metric = ''.join(train_Glabels[i][len('train')+1:])\n",
    "            if metric=='loss':\n",
    "                print('Train min %s:%.3f'%(metric, min(train_res[j][:,i])))\n",
    "                print('Test min %s:%.3f'%(metric, min(test_res[j][:,i])))\n",
    "            else:\n",
    "                print('Train max %s:%.3f'%(metric, max(train_res[j][:,i])))\n",
    "                print('Test max %s:%.3f'%(metric, max(test_res[j][:,i])))\n",
    "        print('-'*100,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALSTM\n",
    "\n",
    "After running B with no edited words we use this RNN cell which has two LSTM cells, Bcell (for player B) and Acell (for Player A). If is Edit is False, we just run B's cell else it works as follow:\n",
    "<ol> \n",
    "<li>We run B's cells with the true query input word, getting the un-edited state. If use_worsAttn=True we add attention on the images vectors for each word.</li>\n",
    "<li>We run B's cells with the edited input word - 'unk', getting the edited state. If use_worsAttn=True we add attention on the images vectors for each word.</li>\n",
    "<li>A uses attention mechanism over all B's outputs on the unedited words (which we got before using this cell).</li>\n",
    "<li>A's input are:\n",
    "<ul><li>B's unedited state</li><li>The reward for editing a word</li><li>B's loss having no edited words.</li></ul></li>\n",
    "<br><li>A's output is then goes throw a transformation which yields two values, one for editing a word and another for not:\n",
    "<ul>\n",
    "    <li>With probability of editRandomlyProb we ignore A and decide whether to edit or not with probability of rnn_editProb</li>\n",
    "    <li>With probability of 1-editRandomlyProb A chooses an action: edit only if the value for edit the word is higher (i.e. we pass B's edited state to the next time step), else we pass B's unedited state.</li></ul>.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ALSTM(tf.nn.rnn_cell.LSTMCell):\n",
    "    def __init__(self, \n",
    "                 batch_size, \n",
    "                 num_units, \n",
    "                 \n",
    "                 # Size of A's attention vector.\n",
    "                 words_attn_dim, \n",
    "                 # B's outputs (for each time step).\n",
    "                 words_attn_states, \n",
    "                 # Inicates whether attentionvec is a padding (0) or not (1).\n",
    "                 words_attn_idx, \n",
    "                 \n",
    "                 # Size of B's attention vector ([image vector, spital features] size) .\n",
    "                 img_attn_dim, \n",
    "                 # B's outputs (for each time step).\n",
    "                 img_attn_states, \n",
    "                 \n",
    "                 \n",
    "                 # Inicates whether attentionvec is a padding (0) or not (1).\n",
    "                 img_attn_idx, \n",
    "                 \n",
    "                 unk, #'unk' word vector\n",
    "                 \n",
    "                 # Probabilty for choosing an action (edit or not) randomly, \n",
    "                 editRandomlyProb, \n",
    "                 # Probabilty for edit a word in rnn, when decision are taken randomly.\n",
    "                 rnn_editProb, \n",
    "                 \n",
    "                 \n",
    "                 # Whehter to edit the query or not.\n",
    "                 isEdit, \n",
    "                 \n",
    "                 # Whether B uses words levlel attention or not.\n",
    "                 use_wordAttn,\n",
    "                 \n",
    "                 # qeuries_length[i]=length of the i'th query in the batch\n",
    "                 qeuries_length,\n",
    "                 \n",
    "                 # If (qeuries_length[i]-1)-current_timestamp>MIXER_delta\n",
    "                 # don't edit.\n",
    "                 MIXER_delta,\n",
    "                 \n",
    "                 # If isIDX is True then use the decisions in set_actions.\n",
    "                 isIDX,\n",
    "                 set_actions=None,\n",
    "                 \n",
    "                 # If True add noise instead of using 'unk'\n",
    "                 useNoise=False,\n",
    "                 \n",
    "                 # If useNoise is true word vec = alpha*word_vector+(1-alpha)*noise\n",
    "                 alpha=.3,\n",
    "                 \n",
    "                 # Dropout ratio for rnn's inputs and outpouts\n",
    "                 dropout_in=1.,\n",
    "                 dropout_out=1.,\n",
    "                 \n",
    "                 #this holds A's rewards and B's losses to\n",
    "                 # be add to A's feature vectors.\n",
    "                 reward_loss=None,\n",
    "                 state_is_tuple=True,):\n",
    "        \n",
    "        \n",
    "        # When useing A, the cell state will contain the concatenation \n",
    "        # of both B and A states. Therefore we set the unit number to be\n",
    "        # 2*(A and B unit size).\n",
    "        super().__init__(2*num_units+1, state_is_tuple=state_is_tuple)\n",
    "    \n",
    "        self.words_attn_states = words_attn_states\n",
    "        self.words_attn_idx = words_attn_idx\n",
    "        self.words_attn_dim = words_attn_dim\n",
    "        \n",
    "        self.img_attn_states = img_attn_states\n",
    "        self.img_attn_idx = img_attn_idx\n",
    "        self.img_attn_dim = img_attn_dim\n",
    "                \n",
    "        self.num_units = num_units\n",
    "        self.batch_size = batch_size\n",
    "        self.unk = unk \n",
    "        self.isEdit = isEdit\n",
    "        self.use_wordAttn=use_wordAttn\n",
    "        \n",
    "        # To avoide using dropout twice on the same input, if isEdit is true\n",
    "        # Bcell will only use dropout for its inputs. We'll add dropout to B's outputs\n",
    "        # only after A's action was taken.\n",
    "        self.Acell = tf.contrib.rnn.DropoutWrapper(\n",
    "            tf.nn.rnn_cell.LSTMCell(self.num_units, state_is_tuple=True), \n",
    "            input_keep_prob=dropout_in, \n",
    "            output_keep_prob=dropout_out\n",
    "        )\n",
    "      \n",
    "        self.Bcell_tmp = tf.nn.rnn_cell.LSTMCell(self.num_units, state_is_tuple=True)\n",
    "            \n",
    "        \n",
    "        self.rnn_editProb = rnn_editProb\n",
    "        self.reward_loss = reward_loss\n",
    "        self.useNoise=useNoise\n",
    "        self.alpha=alpha\n",
    "        \n",
    "        self.isIDX=isIDX\n",
    "        self.set_actions=set_actions\n",
    "        self.editRandomlyProb = editRandomlyProb\n",
    "        self.dropout_in = dropout_in\n",
    "        self.dropout_out = dropout_out\n",
    "        \n",
    "        self.MIXER_delta=MIXER_delta\n",
    "        self.qeuries_length = qeuries_length\n",
    "        \n",
    "\n",
    "    def call(self, inputs, state):\n",
    "        '''\n",
    "        Params:\n",
    "            inputs: word embadding.\n",
    "            state:  [B's state form privious state, A's state form privious state]\n",
    "        '''\n",
    "        # takse B's state from state[:self.num_units]\n",
    "        Bstate_c = tf.slice(state[0], [0, 0], [-1, self.num_units])\n",
    "        Bstate_h = tf.slice(state[1], [0, 0], [-1, self.num_units])\n",
    "        self.Bstate =  tf.nn.rnn_cell.LSTMStateTuple(c=Bstate_c, h=Bstate_h)\n",
    "\n",
    "        \n",
    "        # If isEdit==True \n",
    "        def f1(): \n",
    "            # If B's cell uses attention\n",
    "            self.Bcell = tf.contrib.rnn.DropoutWrapper(\n",
    "                    self.Bcell_tmp, input_keep_prob=self.dropout_in)\n",
    "            \n",
    "            # If B uses words level attention over BBOXes.\n",
    "            if self.use_wordAttn:\n",
    "                words_attn = self.attention(Bstate_h, self.img_attn_states, self.img_attn_dim, self.img_attn_idx)\n",
    "                new_input = tf.concat([inputs, words_attn], -1)\n",
    "                Boutputs, Bnew_state =  self.Bcell(new_input, self.Bstate, 'Bcell')\n",
    "            else:\n",
    "                Boutputs, Bnew_state =  self.Bcell(inputs, self.Bstate, 'Bcell')\n",
    "            \n",
    "            # takse A's state from state[self.num_units: 2*self.num_units]\n",
    "            Astate_c = tf.slice(state[0], [0, self.num_units], [-1, self.num_units])\n",
    "            Astate_h = tf.slice(state[1], [0, self.num_units], [-1, self.num_units])\n",
    "            self.Astate =  tf.nn.rnn_cell.LSTMStateTuple(c=Astate_c, h=Astate_h)\n",
    "            \n",
    "            #Current time step is in the state[-1]\n",
    "            self.timesteps = tf.slice(state[1], [0, 2*self.num_units], [-1, 1])\n",
    "            self.timestep = tf.cast(self.timesteps[0][0], tf.int32)\n",
    "            \n",
    "            # If timestep_delta[i]=0, don't edit the i'th word in the batch\n",
    "            self.timestep_delta = tf.cast(tf.less_equal(\n",
    "                tf.expand_dims(self.qeuries_length-1, 1)-tf.cast(self.timesteps, tf.int32), self.MIXER_delta), tf.float32)\n",
    "            \n",
    "            if self.useNoise: # just add noise to the edited words\n",
    "                new_unk_vecs = self.alpha*inputs + (1-alpha)*tf.random_normal(shape=inputs.get_shape(), stddev=0.1)\n",
    "            else: # change the edited words by 'unk'\n",
    "                unk_vecs = tf.concat([self.unk for _ in range(self.batch_size)], 0) # shape: self.batch_size x 1 x embed_size\n",
    "                new_unk_vecs = tf.squeeze(unk_vecs) # shape: self.batch_size x embed_size\n",
    "            \n",
    "            # run B's cell with unk_batch\n",
    "            if self.use_wordAttn:\n",
    "                new_unk = tf.concat([new_unk_vecs, words_attn], -1)\n",
    "            else:\n",
    "                new_unk = new_unk_vecs\n",
    "            edit_output, edit_new_state = self.Bcell(new_unk, self.Bstate, 'Bcell')  \n",
    "            out1, state1 = self.runCell(Boutputs, Bnew_state, edit_new_state)\n",
    "            return out1, state1\n",
    "        \n",
    "        def f2(): #If we don't edit\n",
    "            # If B's cell uses attention\n",
    "            self.Bcell = tf.contrib.rnn.DropoutWrapper(\n",
    "                    self.Bcell_tmp, output_keep_prob=self.dropout_out, input_keep_prob=self.dropout_in)\n",
    "            \n",
    "            if self.use_wordAttn:\n",
    "                words_attn = self.attention(Bstate_h, self.img_attn_states, self.img_attn_dim, self.img_attn_idx)\n",
    "                new_input = tf.concat([inputs, words_attn], -1)\n",
    "                Boutputs, Bnew_state =  self.Bcell(new_input, self.Bstate, 'Bcell')\n",
    "            else:\n",
    "                Boutputs, Bnew_state =  self.Bcell(inputs, self.Bstate, 'Bcell')\n",
    "                \n",
    "            outs = tf.concat([Boutputs, tf.zeros((self.batch_size, self.num_units+1))], 1)\n",
    "            new_state_c = tf.concat([Bnew_state[0], tf.zeros((self.batch_size, self.num_units+1))], 1)\n",
    "            new_state_h = tf.concat([Bnew_state[1], tf.zeros((self.batch_size, self.num_units+1))], 1)\n",
    "            return outs, tf.nn.rnn_cell.LSTMStateTuple(c=new_state_c, h=new_state_h)\n",
    "        \n",
    "        new_output, new_state = tf.cond(self.isEdit, f1, f2)\n",
    "        \n",
    "        return new_output, new_state\n",
    "    \n",
    "    def runCell(self, Boutputs, Bnew_state, edit_new_state):\n",
    "        '''\n",
    "        Run B's cell after editing.\n",
    "        \n",
    "        params:\n",
    "            Boutputs: output vector without editing.\n",
    "            Bnew_state: state vector without editing.\n",
    "            edit_new_state: state vector after editing the input word to 'unk'. \n",
    "        '''\n",
    "        \n",
    "        with tf.variable_scope('runcell'):\n",
    "            # get action values according to B's hidden state\n",
    "            Aout, Anew_state, actions_vals = self.action_vals(Boutputs) \n",
    "            \n",
    "            def g1():\n",
    "                '''\n",
    "                If isIDX use the decisions in self.action_idx\n",
    "                '''\n",
    "                return tf.slice(self.set_actions, [0,self.timestep], [-1, 1])\n",
    "            \n",
    "            def g2():\n",
    "                # A choose to edit a word if actions_vals[0]<actions_vals[1].\n",
    "                # Note: if we edit the word cond=1, else cond=0.\n",
    "                a1, a2 = tf.split(value=actions_vals, num_or_size_splits=2, axis=1)\n",
    "                A_choice = tf.cast(tf.less(a1, a2), tf.float32)\n",
    "\n",
    "                # If action is chosen randomly, edit word with probability self.rnn_editProb\n",
    "                # Note: if we edit the word cond=1, else cond=0.\n",
    "                rand = tf.multinomial(tf.log([[self.rnn_editProb, 1-self.rnn_editProb]]), self.batch_size)\n",
    "                rand_choice = tf.cast(tf.less(tf.transpose(rand), 1), tf.float32) \n",
    "\n",
    "                # Choose whether to edit a word randomly with probability of editRandomlyProb\n",
    "                editRandomly = tf.multinomial(tf.log([[self.editRandomlyProb, 1-self.editRandomlyProb]]), self.batch_size)\n",
    "                editRandomly_choice = tf.cast(tf.less(tf.transpose(editRandomly), 1), tf.float32)\n",
    "\n",
    "                # A list of decisions for each word in the batch. actions_idx[i] = 1->edit word in query i (at this time step), 0->do not edit.\n",
    "                return self.timestep_delta*(editRandomly_choice*rand_choice + (1-editRandomly_choice)*A_choice)\n",
    "\n",
    "            \n",
    "            # a list of A's decisions for each batch.  1->edit, 0-> do not edit.\n",
    "            cond = tf.cast(tf.cond(self.isIDX, g1, g2), tf.float32)\n",
    "\n",
    "            # We'd like to know the action values and decision for each word,\n",
    "            # therefore theses info are placed on the first 3 dimensions of the \n",
    "            # output vector. Note that this vector is not passed to the \n",
    "            # next tiee step so it won't affect the model. \n",
    "            outs = tf.concat([actions_vals, cond], 1)\n",
    "\n",
    "            # B's i state is replaced by the edited state if cond[i]=1 (i =1, 2, ..., batch_size)\n",
    "            new_edit_state_c = (1-cond)*Bnew_state[0] + cond*edit_new_state[0]\n",
    "            new_edit_state_h = (1-cond)*Bnew_state[1] + cond*edit_new_state[1]\n",
    "\n",
    "\n",
    "            new_outs = tf.concat([outs, tf.zeros((self.batch_size, 2*self.num_units-3)), self.timesteps+1], 1)\n",
    "            new_state_c = tf.concat([new_edit_state_c, Anew_state[0], self.timesteps+1], 1)\n",
    "            new_state_h = tf.concat([new_edit_state_h, Anew_state[1], self.timesteps+1], 1)\n",
    "            return new_outs, tf.nn.rnn_cell.LSTMStateTuple(c=new_state_c, h=new_state_h)\n",
    "    \n",
    "    \n",
    "    def action_vals(self, Boutputs):\n",
    "        '''\n",
    "        Get values for editing/not editing the input word.\n",
    "        \n",
    "        Params:\n",
    "            Boutputs: output vector without editing.\n",
    "            \n",
    "        Returns vals where:\n",
    "            Aout: A's cell output\n",
    "            Anew_state: A's cell state\n",
    "            vals: Tensor where vals[0] is the value for not editing the word \n",
    "                    and vals[1] is the value for editing the word.\n",
    "        '''\n",
    "        \n",
    "        with tf.variable_scope('action_vals') as scope:\n",
    "            Aattn = self.attention(self.Astate[1], self.words_attn_states, self.words_attn_dim, self.words_attn_idx)\n",
    "            \n",
    "            # A's input: [input, B's output, attntion state, reward, B's loss with no edits]\n",
    "            Anew_inputs = tf.concat([Boutputs, Aattn, self.reward_loss], 1)\n",
    "            \n",
    "            Aout, Anew_state = self.Acell(Anew_inputs, self.Astate, 'Acell')\n",
    "            vals = tf.nn.relu(self.linear(Aout, 2))\n",
    "\n",
    "            # Save the variables that only A uses. \n",
    "            # These variables will be trained separately from B's model.\n",
    "            self.Avars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
    "            \n",
    "            return Aout, Anew_state, vals\n",
    "            \n",
    "        \n",
    "    def linear(self, inputs, output_dim, scope='linear', bias=True, reuse=False):\n",
    "        with tf.variable_scope(scope, reuse=False):\n",
    "            W = tf.get_variable('W', initializer=tf.random_uniform_initializer(maxval=1., minval=-1.),\n",
    "                                shape=(inputs.get_shape()[-1], output_dim))\n",
    "            if bias:\n",
    "                b = tf.get_variable('b', initializer=tf.constant_initializer(0.1),\n",
    "                               shape=[1, output_dim])\n",
    "                return tf.matmul(inputs, W) + b\n",
    "\n",
    "        return tf.matmul(inputs, W)\n",
    "    \n",
    "    \n",
    "    def attention(self, state, attn_states, attn_dim, attn_idx, relu=False):\n",
    "        '''\n",
    "        Attention mechanism (see https://arxiv.org/pdf/1409.0473.pdf)\n",
    "        \n",
    "        state: State from previous time step.\n",
    "        attn_states: Attetntion states. \n",
    "                     Tensor of shape (batch_size x max([len(attention_vectors[i]) for i in range(bach_size)]) x attn_dim)\n",
    "        attn_dim: Attention vector size.\n",
    "        attn_idx,: Tensor used for masking of shape (batch_size x max([len(attention_vectors[i]) for i in range(bach_size)]). \n",
    "                   attn_idx[i, j]=1 if the j's attention vcctior of sample i  is not padding, else its equat to 0.\n",
    "        '''\n",
    "        \n",
    "        self.attn_length = tf.shape(attn_states)[1]  \n",
    "        \n",
    "        # Computing... hidden_attn = W*v_att (use tf.nn.conv2d for efficiency)\n",
    "        attn_vecs = tf.reshape(attn_states, [self.batch_size, self.attn_length, 1, attn_dim])\n",
    "        W = tf.get_variable(\"attn_W\", [1, 1, attn_dim, self.num_units])\n",
    "        hidden_attn = tf.nn.conv2d(attn_vecs, W, [1, 1, 1, 1], \"SAME\")\n",
    "\n",
    "        # Computing... hidden_s = U*v_state\n",
    "        hidden_s = tf.reshape(\n",
    "            self.linear(\n",
    "                tf.cast(state, tf.float32), output_dim=self.num_units, scope='hidden_s_linear'), [-1, 1, 1,  self.num_units], name='hidden_s')\n",
    "\n",
    "        # Computing alpha\n",
    "        v = tf.get_variable(\"attn_v\", [self.num_units])\n",
    "        if relu:\n",
    "            logits = tf.reduce_sum(v * tf.nn.relu(hidden_attn + hidden_s), [2, 3])\n",
    "        else:\n",
    "            logits = tf.reduce_sum(v * tf.nn.tanh(hidden_attn + hidden_s), [2, 3])\n",
    "\n",
    "        # Masked softmax\n",
    "        max_logits = tf.reduce_max(logits, axis=-1)\n",
    "        masked_logits = tf.exp(logits-tf.expand_dims(max_logits, axis=1))*attn_idx\n",
    "        alpha = masked_logits/tf.reduce_sum(masked_logits, axis=-1, keep_dims=True)\n",
    "\n",
    "        a = tf.reduce_sum(tf.reshape(alpha, [-1, self.attn_length, 1, 1]) * attn_vecs, [1, 2])\n",
    "        b = tf.contrib.layers.fully_connected(a, num_outputs=self.num_units)\n",
    "                                               \n",
    "\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "When A joins the game, each iteration is completed via three steps:\n",
    "<ul>\n",
    "<li>We feed the query as it is to B and run it alone (no optimization nor training is done at this step)</li>\n",
    "<li>We calculate B's loss per query and use it to calculate the reward for query i as follow: <br> <br><b>edit_reard*Bloss_i/length_of_query_i</b><br>\n",
    "<li>We run A and B together (no optimization nor training is done at this step). At this step we get A's decition and B's loss on the edited query. We use B's loss to calculate the Bellman's value for each time step. </li>\n",
    "<li>We again run A and B together, forcing A to make the same actions it did as in the previous run. Since now we know the real value, action and reward for each time step (these will be the same as in the previous step since we did not train optimize the parameters yet), we finaly train the model</li>\n",
    "</ul>\n",
    "<br>\n",
    "But first we check the model's performance with out A. Class Model has a set of conditioning variables that set a different ragularization methods in the model. We start by checking them with out A's interference. We can also make the model RNN become bidirectional (by setting useBidirectionalRnn to True) and use words level attention (by setting use_wordAttn to True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self,\n",
    "                 batch_size, \n",
    "                 num_hidden, \n",
    "                 \n",
    "                 #Image's vector size.\n",
    "                 img_dims, \n",
    "                 \n",
    "                 #Spaital features length.\n",
    "                 bbox_dims, \n",
    "                 vocab, \n",
    "                 lr, #  B's learning rate.\n",
    "                 decay_steps, \n",
    "                 decay_rate, \n",
    "                 \n",
    "                 # A's leanring rate = B's learning rate x coefAlr.\n",
    "                 coefAlr,\n",
    "                 \n",
    "                 # whether to use bach normaliztion for the last attention layer\n",
    "                 bnorm,\n",
    "                 embed_size=embed_vecs.shape[1],\n",
    "                 \n",
    "                 # Whether B uses words levlel attention or not.\n",
    "                 use_wordAttn=False,\n",
    "                 \n",
    "                 # Whther to use bidirectional rnn\n",
    "                 useBidirectionalRnn=False,\n",
    "                 \n",
    "                 # Urnn_norm: Whether to use batch normalization for the queries.\n",
    "                 # Uatt_norm: Whether to use batch normalization for the VGG outputs.\n",
    "                 Urnn_norm=True, \n",
    "                 Uatt_norm=True,\n",
    "                 \n",
    "                 # If useNoise, A add Normal noise to a word \n",
    "                 # instead of editing it: word_vec = alpha*word_vec+(1-alpha)*noise\n",
    "                 useNoise=False,\n",
    "                 alpha=.5,\n",
    "                \n",
    "                 # Whether to scale and normelize queries \n",
    "                 # embedding to have zero mean and QSTD std\n",
    "                 toQscale = False,\n",
    "                 Qstd = 0.1):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.img_dims = img_dims\n",
    "        self.bbox_dims = bbox_dims \n",
    "        self.num_hidden = num_hidden\n",
    "        self.embed_size = embed_size\n",
    "        self.vocab = vocab\n",
    "        self.lr = lr\n",
    "        self.toQscale=toQscale\n",
    "        self.Qstd=Qstd\n",
    "\n",
    "        # Probabilty for choosing an action (edit or not) randomly, \n",
    "        self.editRandomlyProb = tf.placeholder(tf.float32, name='editRandomlyProb_holder')\n",
    "        # If the action is chosen randomly. edit with probability of rnn_editProb\n",
    "        self.rnn_editProb = tf.placeholder(tf.float32, name='rnn_editProb_holder')\n",
    "\n",
    "        self.queries = tf.placeholder(tf.int32, [None, None], name='queries')\n",
    "        self.img  = tf.placeholder(tf.float32, [None, None, self.img_dims], name='img')# VGG output vectors\n",
    "        self.bboxes = tf.placeholder(tf.float32, [None, None, self.bbox_dims], name='bboxes')# spatial bbox's features.\n",
    "\n",
    "        # attn_idx: inicates whether attention box is a dummy (0) or not (1).\n",
    "        self.attn_idx = tf.placeholder(tf.float32, [None, None], name='attn_idx')\n",
    "        \n",
    "        # If isIDX is True then use the decisions in set_actions instead of A's decisions.\n",
    "        # We use it to force A to take the decitions it made while we calculated the bellman values.\n",
    "        self.isIDX = tf.placeholder(tf.bool, name='isIDX_holder')\n",
    "        self.set_actions = tf.placeholder(tf.float32, [None, None], name='actions_idx_holder')\n",
    "\n",
    "        self.labels = tf.placeholder(tf.float32, [None, None], name='labels')\n",
    "        self.isEdit = tf.placeholder(tf.bool, name='isEdit') # whehter to edit the query or not.\n",
    "        \n",
    "        self.MIXER_delta = tf.placeholder(tf.int32, name='mixer_delta_place_holder')\n",
    "\n",
    "\n",
    "\n",
    "        # this holds A's rewards and B losses per query, to be add to A's feature vectors.\n",
    "        self.reward_loss = tf.placeholder(tf.float32, [None,2], name='rewards_loss')\n",
    "\n",
    "        # Dropout ratio for rnn's inputs and outpouts\n",
    "        self.dropout_in = tf.placeholder(tf.float32, name='dropoutIn_holder')\n",
    "        self.dropout_out = tf.placeholder(tf.float32, name='dropoutOut_holder')\n",
    "\n",
    "        # Dropout ratio for attention vector (for the final attention layer before the loss function)\n",
    "        self.dropout_img = tf.placeholder(tf.float32, name='dropoutImg_holder')\n",
    "        # Dropout ratio for query vector (for the final attention layer before the loss function)\n",
    "        self.dropout_q = tf.placeholder(tf.float32, name='dropoutImg_holder')\n",
    "\n",
    "        # B outputs vectors (with no words edits), These are A's attention vectors\n",
    "        # which it uses to decide whter to edit a word.\n",
    "        self.Aattn_vecs = tf.placeholder(tf.float32, [None, None, None], name='Aattn_vecs_holder')    \n",
    "        self.unk = tf.constant([[vocab['<unk>']]], tf.int32)\n",
    "\n",
    "        self.isTrain = tf.placeholder(tf.bool, name='isTrain_holder') \n",
    "        self.queries_lens = self.length(self.queries) # list of all the lengths of the batch's queriey \n",
    "\n",
    "        # Concatinate images vectors and their spaital features. \n",
    "        # These vectors wlll be used for attenionn when \n",
    "        # we calculate the loss function.\n",
    "        attn_vecs = tf.concat([self.img, self.bboxes], 2) \n",
    "        voc_size = len(self.vocab)\n",
    "\n",
    "        # Load pre-trained word imaddings.\n",
    "        # w2v_embed is not trainable.\n",
    "        with tf.variable_scope('w2v'):\n",
    "            w2v_embed = tf.get_variable('w2v_embed', initializer=embed_vecs, trainable=False)\n",
    "            w2v_queries = tf.nn.embedding_lookup(w2v_embed, self.queries, name='w2v_queries')\n",
    "\n",
    "        with tf.variable_scope('embed'):\n",
    "            embed = tf.get_variable('embed', shape=[voc_size, self.embed_size], \n",
    "                                    initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1))\n",
    "            embed_queries_tmp = tf.nn.embedding_lookup(embed, self.queries, name='embed_queries')\n",
    "\n",
    "        embed_queries = embed_queries_tmp+w2v_queries\n",
    "\n",
    "        with tf.variable_scope('rnn'):\n",
    "            Aattn_idx = tf.cast(tf.abs(tf.sign(self.queries)), tf.float32)\n",
    "\n",
    "\n",
    "            cell = ALSTM(num_units=self.num_hidden, \n",
    "                            words_attn_dim=self.num_hidden, \n",
    "                            words_attn_states=self.Aattn_vecs, \n",
    "                            words_attn_idx=Aattn_idx,\n",
    "                            img_attn_dim=self.img_dims+self.bbox_dims,\n",
    "                            img_attn_states=attn_vecs,\n",
    "                            img_attn_idx=self.attn_idx,\n",
    "                            batch_size=self.batch_size, \n",
    "                            unk=tf.nn.embedding_lookup(embed, self.unk), rnn_editProb=self.rnn_editProb,\n",
    "                            isEdit=self.isEdit, dropout_in=self.dropout_in, dropout_out=self.dropout_out,\n",
    "                            reward_loss=self.reward_loss, use_wordAttn=use_wordAttn,\n",
    "                            isIDX=self.isIDX, set_actions=self.set_actions, editRandomlyProb=self.editRandomlyProb,\n",
    "                            useNoise=useNoise, alpha=alpha, MIXER_delta=self.MIXER_delta, qeuries_length=self.queries_lens)\n",
    "\n",
    "            if useBidirectionalRnn:\n",
    "                self.outputs, self.last_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "                    cell_fw=cell,\n",
    "                    cell_bw=cell,\n",
    "                    dtype=tf.float32,\n",
    "                    sequence_length=self.queries_lens,\n",
    "                    inputs=embed_queries)\n",
    "\n",
    "                # self.last_states contain both forward state\n",
    "                # and backward state.\n",
    "                # We don't use A with bidirectional rnn\n",
    "                # so no need for self.values (action values as calculated by A)\n",
    "                Bstate = tf.concat(\n",
    "                    [tf.slice(self.last_states[0][1], [0,0], [-1, self.num_hidden]), \n",
    "                     tf.slice(self.last_states[1][1], [0,0], [-1, self.num_hidden])], -1)\n",
    "            else:\n",
    "                self.outputs, self.last_states = tf.nn.dynamic_rnn(\n",
    "                    cell=cell,\n",
    "                    dtype=tf.float32,\n",
    "                    sequence_length=self.queries_lens,\n",
    "                    inputs=embed_queries)\n",
    "\n",
    "                # self.values[0]=value for not editing, self.values[1]=value for editing\n",
    "                self.values = tf.slice(self.outputs, [0,0,0], [-1,-1,2])\n",
    "                Bstate = tf.slice(self.last_states[1], [0,0], [-1, self.num_hidden])  \n",
    "\n",
    "\n",
    "        # The variable A uses\n",
    "        Avars = cell.Avars\n",
    "\n",
    "        if bnorm: # If using batch normalization \n",
    "            self.scores = self.bnorm_attention(Bstate, Urnn_norm=Urnn_norm, Uatt_norm=Uatt_norm) \n",
    "        else:\n",
    "            self.scores = self.attention(Bstate) \n",
    "\n",
    "\n",
    "        # Cross entophy loss for each of the queries in the batch.\n",
    "        self.B_ce = -tf.reduce_sum(\n",
    "                        self.labels*tf.log(self.scores+0.00000001)+\n",
    "                            (1-self.labels)*tf.log((1-self.scores)+0.00000001), \n",
    "                            axis=-1)\n",
    "\n",
    "\n",
    "        # We don't use A with bidirectional rnn\n",
    "        if not useBidirectionalRnn:\n",
    "            # A's decision for each word.\n",
    "            self.idx = tf.squeeze(tf.slice(self.outputs, [0,0,2], [-1,-1,1]))\n",
    "\n",
    "            self.edit_num = tf.reduce_mean(tf.reduce_sum(\n",
    "                tf.cast(self.idx, tf.float32)*tf.expand_dims(\n",
    "                        1/tf.cast(self.queries_lens, tf.float32), axis=1), axis=1))\n",
    "\n",
    "            # After running A for the first time, we get A's decisions and their values.\n",
    "            # we then calulate the following tensors:\n",
    "            # actions_idx[j,i] = 1 if the word i in query j was edited or 0 otherwise.     \n",
    "            # bell_vall holds the values for each decision by the bellman function. \n",
    "\n",
    "            # self.actions_idx will be used to get the values of the action that were taken by A.                 \n",
    "            self.actions_idx = tf.placeholder(shape=[None, None], dtype=tf.int32, name=\"actions_idx\")\n",
    "            self.bell_val = tf.placeholder(shape=[None, None], dtype=tf.float32, name=\"bell_val\")\n",
    "\n",
    "            # pyrite_val: holds the values for each of A's decisions, claculated by A. \n",
    "            # see https://en.wikipedia.org/wiki/Pyrite.\n",
    "            self.pyrite_val = tf.reshape(tf.gather_nd(tf.reshape(self.values, (-1,2)), self.actions_idx), (self.batch_size, -1))\n",
    "\n",
    "            # RMSE loss (adding smoothing factor so the gradient won't divide by zero)\n",
    "            self.A_loss = tf.reduce_mean(tf.reduce_sum(\n",
    "                tf.sqrt(tf.square((self.bell_val-self.pyrite_val+0.000001)*tf.cast(\n",
    "                    tf.sign(tf.abs(self.queries)), tf.float32)))/tf.expand_dims(\n",
    "                                                    tf.cast(self.queries_lens, tf.float32), axis=1), axis=-1))\n",
    "\n",
    "        self.B_loss = tf.reduce_mean(self.B_ce)\n",
    "\n",
    "        ##############\n",
    "        # Optimizers #\n",
    "        ##############\n",
    "\n",
    "        starter_learning_rate = self.lr\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.learning_rate = tf.train.exponential_decay(starter_learning_rate, self.global_step,\n",
    "                                                       decay_steps=decay_steps, decay_rate=decay_rate, staircase=True)\n",
    "\n",
    "        if not useBidirectionalRnn:\n",
    "            # Train only A variables \n",
    "            self.A_optimizer =  tf.train.GradientDescentOptimizer(\n",
    "                    learning_rate=coefAlr*self.learning_rate).minimize(self.A_loss, var_list=Avars)  \n",
    "\n",
    "        # Train only B variables \n",
    "        Bvars = [var for var in tf.trainable_variables() if var not in Avars]\n",
    "        self.B_optimizer =  tf.train.GradientDescentOptimizer(\n",
    "                    learning_rate=self.learning_rate).minimize(self.B_loss, global_step=self.global_step, var_list=Bvars)  \n",
    "\n",
    "        if not os.path.exists(params_dir):\n",
    "                os.makedirs(params_dir)\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "        \n",
    "    def length(self, seq):\n",
    "        '''\n",
    "        Retruns real lengths (before addings) of all queries in seq  .\n",
    "        '''\n",
    "        return tf.cast(tf.reduce_sum(tf.sign(tf.abs(seq)), reduction_indices=1), tf.int32)\n",
    "       \n",
    "\n",
    "    def linear(self, inputs, output_dim, scope='linear', bias=True, reuse=False):\n",
    "\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            W = tf.get_variable('W', initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                shape=(inputs.get_shape()[-1], output_dim))\n",
    "            if bias:\n",
    "                b = tf.get_variable('b', initializer=tf.constant_initializer(0.1),\n",
    "                               shape=[1, output_dim])\n",
    "                return tf.matmul(inputs, W) + b\n",
    "            \n",
    "            return tf.matmul(inputs, W)\n",
    "\n",
    "            \n",
    "    def Qscale(self, qVecs):\n",
    "        '''\n",
    "        Scale queries embedding vectors to have zero mean and std STD.\n",
    "        \n",
    "        Params:\n",
    "            qVecs: Tensor (shape: batch_size x number_of_hidden_units) \n",
    "                   holding the queries vectors, \n",
    "        '''\n",
    "        qVecs_min = tf.reduce_min(qVecs, axis=-1, keep_dims=True)\n",
    "        qVecs_max = tf.reduce_max(qVecs, axis=-1, keep_dims=True)\n",
    "        qVecs_scale = (qVecs-qVecs_min)/(qVecs_max-qVecs_min) # Scale to 0-1\n",
    "        s = tf.contrib.keras.backend.std(qVecs_scale, axis=-1, keepdims=True)\n",
    "        tmp = self.Qstd * qVecs_scale/s #Scale to have self.Qstd std\n",
    "        new_qVecs = tmp - tf.reduce_mean(tmp, axis=-1, keep_dims=True) # zero mean\n",
    "        \n",
    "        return new_qVecs\n",
    "    \n",
    "    def attention(self, q_embed):\n",
    "        '''\n",
    "        Given B's output vector, calculate the attention over \n",
    "        all the query's bounding boxes vectors, That is, calculate:\n",
    "        \n",
    "        probs = softmax(relu(context(Sq+Satt+b)))\n",
    "        \n",
    "        Where:\n",
    "        Sq = <Wq, queries_states>\n",
    "        Sattn = <Wattn, attention_bboxes_vectors>\n",
    "        \n",
    "        The  bounding box with the highest attention score will be chosen as the correct bounding box.\n",
    "        \n",
    "        Params:\n",
    "            q_embed: Tensor of shape (batch size x num_hidden)B's outputs. \n",
    "            \n",
    "        Returns:\n",
    "            probs: Tensor of shape (batch_size x max bbox number for query).\n",
    "                   Attention score for each bbox.\n",
    "        '''\n",
    "        # concatenate img vectors with spaical features\n",
    "        attn_vecs = tf.concat([self.img, self.bboxes], 2)\n",
    "        \n",
    "        # B's outputs, shape: (batch size x num_hidden)\n",
    "        if self.toQscale:\n",
    "            Urnn = self.Qscale(q_embed)\n",
    "        else:\n",
    "            Urnn = q_embed\n",
    "        \n",
    "        # Attention vectors, \n",
    "        # shape: (batch size x max bbox number for query x attention vector size)\n",
    "        Uatt = attn_vecs\n",
    "           \n",
    "        with tf.variable_scope('l1'):\n",
    "            b = tf.get_variable(\n",
    "                    'b', \n",
    "                    initializer=tf.constant_initializer(0.1), \n",
    "                    shape=[1, self.num_hidden])\n",
    "\n",
    "            context = tf.get_variable(\n",
    "                    'context', \n",
    "                    initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1), \n",
    "                    shape=[self.num_hidden, 1])\n",
    "\n",
    "\n",
    "            Sq = tf.nn.dropout(\n",
    "                self.linear(Urnn, self.num_hidden, bias=False, scope='Sq'), \n",
    "                self.dropout_q)\n",
    "            \n",
    "            Sattn = tf.nn.dropout(\n",
    "                tf.reshape(\n",
    "                    self.linear(\n",
    "                        tf.reshape(Uatt, (-1, self.img_dims+self.bbox_dims)), \n",
    "                        self.num_hidden, \n",
    "                        bias=False, scope='Sattn'), \n",
    "                    [self.batch_size, -1, self.num_hidden]),\n",
    "                self.dropout_img)\n",
    "\n",
    "        out = tf.nn.relu(tf.expand_dims(Sq, 1) + Sattn + b)\n",
    "        logits = tf.reshape(tf.matmul(tf.reshape(out, (-1, tf.shape(out)[-1])),  context), (tf.shape(out)[0], -1))\n",
    "\n",
    "        # Calculate logits's masked softmax (we use self.attn_idx to mas\n",
    "        max_logits = tf.reduce_max(logits, axis=-1)\n",
    "        masked_logits = tf.exp(logits-tf.expand_dims(max_logits, axis=1))*self.attn_idx\n",
    "        probs = self.attn_idx*masked_logits/tf.reduce_sum(masked_logits, axis=-1, keep_dims=True)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    \n",
    "    def bnorm_attention(self, q_embed, Urnn_norm=True, Uatt_norm=True):\n",
    "        '''\n",
    "        Given B's output vector, calculate the attention over \n",
    "        all the query's bounding boxes vectors using batch normalization. , That is, calculate:\n",
    "        \n",
    "        probs = softmax(relu(context(Sq+Satt+b)))\n",
    "        \n",
    "        Where:\n",
    "        Sq = <Wq, queries_states>\n",
    "        Sattn = <Wattn, attention_bboxes_vectors>\n",
    "        \n",
    "        The  bounding box with the highest attention score will be chosen as the correct bounding box.\n",
    "        This function uses batch normalization. \n",
    "        \n",
    "        Params:\n",
    "            q_embed: Tensor of shape (batch size x num_hidden)B's outputs. \n",
    "            Urnn_norm: Whether to use batch normalization for the queries.\n",
    "            Uatt_norm: Whether to use batch normalization for the VGG outputs.\n",
    "            \n",
    "        Returns:\n",
    "            probs: Tensor of shape (batch_size x max bbox number for query).\n",
    "                   Attention score for each bbox.\n",
    "        '''\n",
    "        # concatenate img vectors with with spaical features\n",
    "        attn_vecs = tf.concat([self.img, self.bboxes], 2)\n",
    "        Urnn = q_embed\n",
    "        Uatt = attn_vecs\n",
    "        \n",
    "        if Urnn_norm:\n",
    "            # B's outputs with bath normalization. \n",
    "            # shape: (batch size x num_hidden)\n",
    "            Urnn = tf.contrib.layers.batch_norm(\n",
    "                q_embed, center=True, scale=True, is_training=self.isTrain) \n",
    "        \n",
    "        if Uatt_norm:\n",
    "            # Attention vectors with bath normalization. \n",
    "            # shape: (batch size x max bbox number for query x attention vector size)\n",
    "            Uatt = tf.contrib.layers.batch_norm(\n",
    "                attn_vecs, center=True, scale=True, is_training=self.isTrain)\n",
    "           \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            with tf.variable_scope('bnorm_l1'):\n",
    "                b = tf.get_variable(\n",
    "                        'b', \n",
    "                        initializer=tf.constant_initializer(0.1), \n",
    "                        shape=[1, self.num_hidden])\n",
    "\n",
    "                context = tf.get_variable(\n",
    "                        'context', \n",
    "                        initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1), \n",
    "                        shape=[self.num_hidden, 1])\n",
    "\n",
    "\n",
    "                Sq = tf.nn.dropout(\n",
    "                    self.linear(Urnn, self.num_hidden, bias=False, scope='Sq'), \n",
    "                    self.dropout_q)\n",
    "                \n",
    "                Sattn = tf.nn.dropout(\n",
    "                            tf.reshape(\n",
    "                                self.linear(\n",
    "                                    tf.reshape(Uatt, (-1, self.img_dims+self.bbox_dims)), \n",
    "                                    self.num_hidden, \n",
    "                                    bias=False, scope='Sattn'), \n",
    "                                 [self.batch_size, -1, self.num_hidden]),\n",
    "                            self.dropout_img)\n",
    "                    \n",
    "                   \n",
    "            out = tf.nn.relu(tf.expand_dims(Sq, 1) + Sattn + b)\n",
    "            logits = tf.reshape(tf.matmul(tf.reshape(out, (-1, tf.shape(out)[-1])),  context), (tf.shape(out)[0], -1))\n",
    "\n",
    "            # Calculate logits's masked softmax (we use self.attn_idx to mas\n",
    "            max_logits = tf.reduce_max(logits, axis=-1)\n",
    "            masked_logits = tf.exp(logits-tf.expand_dims(max_logits, axis=1))*self.attn_idx\n",
    "            probs = self.attn_idx*masked_logits/tf.reduce_sum(masked_logits, axis=-1, keep_dims=True)\n",
    "\n",
    "            return probs\n",
    "  \n",
    "        \n",
    "    def q_padding(self, seq, max_length):\n",
    "        '''\n",
    "        Pad  seq with vocab['<pad>'] (0) to max_length length.\n",
    "        '''                  \n",
    "        return seq + [self.vocab['<pad>']]*(max_length-len(seq))\n",
    "\n",
    "    \n",
    "    def build_data(self, data, start, end, imScale, addNoise=False):\n",
    "        '''\n",
    "        Build batch.\n",
    "        ------------\n",
    "        \n",
    "        Params:\n",
    "            data: each entry in this list has the following structure:\n",
    "                  [query indexes, [bounding box vector (VGG), bounding box spaital features], ..., \n",
    "                  [bounding box vector (VGG), bounding box spaital features], index of the true label]\n",
    "                  \n",
    "            start/end: batch data is built from data[start:end]\n",
    "            \n",
    "        Returns:\n",
    "            attn_idx: attn_idx[i, j]=1 if the j'th bbox in the i'th query is not padding, else equals to 0. \n",
    "            \n",
    "            padded_queries: list of queries, padded to the length of the longest query in the batch.\n",
    "                            Note: vocab['pad']=0\n",
    "                            \n",
    "            padded_im: list of bounding boxes vectors, padded to the maximum number of bbox per query.\n",
    "                       Note: padded vector is vector of zeros. \n",
    "                            \n",
    "            padded_bbox: list of bounding boxes spatial features, padded to the maximum number of bbox per query.\n",
    "                         Note: padded vector is vector of zeros.  \n",
    "        \n",
    "            onehot_labels: onehot_labels[i][j]=1 if j is the true bbox for query i, else  onehot_labels[i][j]=0\n",
    "            \n",
    "            addNoise: Boolean. Whether to add normal noise to the images.\n",
    "            \n",
    "            imScale: If not None, scale the image vectors (VGG16 outputs) to have 0 mean and 1imScale std\n",
    "                        \n",
    "        '''\n",
    "                          \n",
    "        qlen = max([len(data[i][0]) for i in range(start, end)]) # Length fo the longest query\n",
    "        imlen = max([len(data[i]) for i in range(start, end)])-2 # Maximum number of bbox per query.\n",
    "        padded_queries, padded_im, padded_bbox, attn_idx = [], [], [], []\n",
    "        \n",
    "        # Build one hot labels from the labels index, given in the data.                  \n",
    "        labels = [item[-1] for item in data[start:end]] #data[i][-1]=index of the true bbox of query i\n",
    "        dist_labels = np.zeros((end-start, imlen)) #label distribution\n",
    "        \n",
    "        # Real data points\n",
    "        dist_labels[[i for i in np.arange(end-start) if labels[i]>=0], [l for l in labels if l>=0]]=1\n",
    "        \n",
    "        # augmented data points\n",
    "        # the label of each added poind is writen as -1*number of bboxes. \n",
    "        # When we build the batch it self (function build_data in class Model), \n",
    "        # if we see a negative label index, we know its an added point and we know the \n",
    "        # number of bboxes so we can build the correct distribution.\n",
    "        for i in np.arange(end-start):\n",
    "            if labels[i]<0:\n",
    "                dist_labels[i] = [-1/labels[i] for _ in range(-labels[i])]+[0. for _ in range(imlen+labels[i])]\n",
    "                          \n",
    "        im_dim, bbox_dim = data[0][1][0].shape[1], data[0][1][1].shape[1]\n",
    "        for i in range(start, end):\n",
    "            padded_queries.append(self.q_padding(data[i][0], qlen))\n",
    "            \n",
    "            attn_idx.append([1 for _ in range(len(data[i])-2)]+[0 for _ in range(imlen-(len(data[i])-2))])\n",
    "            \n",
    "            padded_im.append(np.concatenate([data[i][j][0] for j in range(1, len(data[i])-1)] + \n",
    "                                       [np.full((imlen-(len(data[i])-2), im_dim), vocab['<pad>'], dtype=np.float32)], axis=0))\n",
    "            \n",
    "            padded_bbox.append(np.concatenate([data[i][j][1] for j in range(1, len(data[i])-1)] + \n",
    "                                       [np.full((imlen-(len(data[i])-2),bbox_dim), vocab['<pad>'], dtype=np.float32)], axis=0))\n",
    "           \n",
    "        \n",
    "        \n",
    "        if addNoise:\n",
    "            padded_im+=(padded_im+np.random.normal(0, .1, np.array(padded_im).shape))*np.expand_dims(attn_idx, 2)\n",
    "        else:\n",
    "            padded_im=np.array(padded_im)\n",
    "            \n",
    "        if imScale is not None:\n",
    "            # Smoothing factor\n",
    "            halper = (1-np.expand_dims(np.array(attn_idx).astype(np.float32), 2))\n",
    "            img_min = np.min(padded_im, axis=-1, keepdims=True)\n",
    "            img_max = np.max(padded_im, axis=-1, keepdims=True)\n",
    "            img_scale = (padded_im-img_min)/((img_max-img_min)+halper) # Scale to 0-1\n",
    "            s = np.std(img_scale, axis=-1, keepdims=True)\n",
    "            padded_im = img_scale/(imScale*s+halper)  #Scale to have 1/imScale std\n",
    "            padded_im = padded_im - np.mean(padded_im, axis=-1, keepdims=True) # scale to zero mean\n",
    "            \n",
    "        return np.array(attn_idx), np.array(padded_queries, dtype=np.int32), padded_im, np.array(padded_bbox), np.array(dist_labels)\n",
    "            \n",
    "   \n",
    "    def ground(self, data=None, start=None, end=None, \n",
    "               sess=None, feed_dict = None, isEdit=True, \n",
    "               imScale=False, MIXER_delta=None):\n",
    "        '''\n",
    "        Given a query and a list of bboxes, the function returns the index of the chosen bbox and the ground truth bbox.\n",
    "        \n",
    "        Params:\n",
    "            data: A numpy array with datasat's data points\n",
    "            start/end: The function only take data points from data[start:end]\n",
    "            imScale: whether to scale the images vectors\n",
    "        '''\n",
    "        isSess = (sess==None)\n",
    "        if isSess:\n",
    "            sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            if isSess:\n",
    "                tf.global_variables_initializer().run()\n",
    "                ckpt = tf.train.get_checkpoint_state(params_dir)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    self.saver.restore(sess, ckpt.model_checkpoint_path) # restore all variables\n",
    "                else:\n",
    "                    print('Initializing variables')\n",
    "            if feed_dict is None:\n",
    "                attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(data, start, end, imScale=imScale)\n",
    "                feed_dict = {\n",
    "                        self.queries:padded_queries,\n",
    "                        self.img:padded_im,\n",
    "                        self.bboxes:padded_bbox,\n",
    "                        self.labels:labels,\n",
    "                        self.attn_idx:attn_idx,\n",
    "                        self.MIXER_delta:MIXER_delta\n",
    "                    }\n",
    "                \n",
    "            feed_dict[self.isTrain]=False\n",
    "            feed_dict[self.isEdit] = isEdit\n",
    "            feed_dict[self.dropout_in]=1.\n",
    "            feed_dict[self.dropout_out]=1.\n",
    "            feed_dict[self.dropout_img]=1.\n",
    "            feed_dict[self.dropout_q]=1.\n",
    "            scores = sess.run(self.scores, feed_dict=feed_dict) # get score for each bbox\n",
    "\n",
    "        return np.argmax(scores, axis=1), np.argmax(feed_dict[self.labels], axis=1)\n",
    "        \n",
    "        \n",
    "    def iou_accuracy(self, data, start, end, imScale, sess=None, \n",
    "                     feed_dict = None, threshold=0.5, test=False, \n",
    "                     isEdit=True, MIXER_delta=None):\n",
    "        '''\n",
    "        Calculate the IOU score between the Model bbox and the true bbox.\n",
    "        \n",
    "         Params:\n",
    "            data: A numpy array with datasat's data points\n",
    "            start/end: The function only take data points from data[start:end]\n",
    "            imScale: whether to scale the images vectors\n",
    "            threshold: If IOU>0.5 this is a true positive\n",
    "        ''' \n",
    "                          \n",
    "        # Get score for each bbox (labels) and th true bbox index (gt_idx)                  \n",
    "        if feed_dict is None:\n",
    "            labels, gt_idx = self.ground(data, start, end, sess=sess, feed_dict=feed_dict, \n",
    "                                         isEdit=isEdit, imScale=imScale, MIXER_delta=MIXER_delta)\n",
    "        else: labels, gt_idx = self.ground(sess=sess, feed_dict=feed_dict, \n",
    "                                           isEdit=isEdit, imScale=imScale, MIXER_delta=MIXER_delta)\n",
    "        acc = 0\n",
    "        \n",
    "        for i in range(start, end):\n",
    "            gt = data[i][gt_idx[i-start]+1][1][0] # ground truth bbox. Note that len(data)!=len(gt_idx)=batch_size\n",
    "            crops = np.expand_dims(data[i][labels[i-start]+1][1][0], axis=0) #Model chosen bbox. Note that len(data)!=len(labels)=batch_size\n",
    "            acc += (retriever.compute_iou(crops, gt)[0]>threshold) #IOU for the i sample.\n",
    "            \n",
    "        return acc/(end-start)\n",
    "        \n",
    "    def accuracy(self, imScale, data=None, start=None, end=None, \n",
    "                 sess=None, feed_dict = None, isEdit=True, MIXER_delta=None):\n",
    "        isSess = (sess==None)\n",
    "        if isSess:\n",
    "            print('Building sess')\n",
    "            sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            if isSess:\n",
    "                print('Building sess used')\n",
    "                tf.global_variables_initializer().run()\n",
    "                ckpt = tf.train.get_checkpoint_state(params_dir)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    print('3')\n",
    "                    self.saver.restore(sess, ckpt.model_checkpoint_path) # restore all variables\n",
    "                else:\n",
    "                    print('Initializing variables')\n",
    "            if feed_dict is None:\n",
    "                print('Building feed_dict')\n",
    "                attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(data, start, end, imScale=imScale)\n",
    "                feed_dict = {\n",
    "                        self.queries:padded_queries,\n",
    "                        self.img:padded_im,\n",
    "                        self.bboxes:padded_bbox,\n",
    "                        self.attn_idx:attn_idx,\n",
    "                        self.labels:labels,\n",
    "                        self.MIXER_delta:MIXER_delta\n",
    "                    }\n",
    "                \n",
    "            feed_dict[self.isTrain]=False\n",
    "            feed_dict[self.isEdit] = isEdit\n",
    "            feed_dict[self.dropout_in]=1.\n",
    "            feed_dict[self.dropout_out]=1.\n",
    "            feed_dict[self.dropout_img]=1.\n",
    "            feed_dict[self.dropout_q]=1.\n",
    "            scores = sess.run(self.scores, feed_dict=feed_dict)\n",
    "            acc = sum(np.equal(np.argmax(scores, axis=1), np.argmax(feed_dict[self.labels], axis=1))/len(feed_dict[self.labels]))\n",
    "\n",
    "                    \n",
    "        return acc\n",
    "    \n",
    "    def discount_rewards(self, r, last_r, gamma=1.0):\n",
    "        \"\"\" \n",
    "        take 1D float array of rewards and compute discounted reward \n",
    "        using bellman function.\n",
    "        \n",
    "        params:\n",
    "            r: r[i,j]=1 reward of action A did on word j at query i.\n",
    "            last_r: B's loss for query i with no edits. This is the final reward.\n",
    "            gamma: discount factor.\n",
    "        \"\"\"\n",
    "                          \n",
    "        discounted_r = np.zeros(r.shape)\n",
    "        running_add = last_r # B loss\n",
    "        discounted_r = [i for i in range(r.shape[-1])]\n",
    "        for t in reversed(range(0, r.shape[-1])):\n",
    "            running_add = running_add * gamma + r[:,t]\n",
    "            discounted_r[t] = running_add\n",
    "        return np.array(discounted_r).T\n",
    "        \n",
    "    def train(self, trn_data, tst_data, ephocs_num, edit_reward, rnn_editProb, startA=3, \n",
    "              activation_ephoc=10, muteB=3, start_ephoc=0, dropout_in=1., onlyB=False,\n",
    "              dropout_out=1., dropout_img=1., dropout_q=1., editProb=0.5,\n",
    "              addNoise=False, imScale=None):\n",
    "                          \n",
    "        '''\n",
    "        Params:\n",
    "             trn_data: list, train set. \n",
    "             \n",
    "             tst_data: list, test set. \n",
    "             \n",
    "             ephocs_num: number of ephocs\n",
    "             \n",
    "             start_ephoc: number of first ephoc.\n",
    "             \n",
    "             edit_reward: int, coefficient to multiply the reward by when editing a word.\n",
    "             \n",
    "             startA: int, Start competition only at ephoc # startA.\n",
    "             \n",
    "             activation_ephoc: at ephoc numer \"activation_ephoc\", A will be activate.\n",
    "                               That is, for (activation_ephoc-startA) number of ephocs, \n",
    "                               A will chooce an action randomly.\n",
    "             \n",
    "            muteB: After A starts, for each ephoc which A & B trains, \n",
    "                   only A will be trained for this amount of ephocs.\n",
    "                   \n",
    "            editProb: robabilty for editing a query.\n",
    "            \n",
    "            rnn_editProb: Probabilty for edit a word in rnn, when decision are taken randomly.  \n",
    "            \n",
    "            dropout_in: dropout ratio of B's rnn inputs.\n",
    "            \n",
    "            dropout_output: dropout ratio of B's rnn output.\n",
    "            \n",
    "            dropout_img: dropout ratio of images vectors before the last attention layer .\n",
    "            \n",
    "            addNoise: Boolean. Whether to add normal noise to the images (see build_data).\n",
    "            \n",
    "            imScale: If not None, scale the image vectors (VGG16 outputs) to have 0 mean and 1imScale std\n",
    "            \n",
    "            onlyB: boolean, Wheter to train only B. By setting startA and acctivation_ephoc larger than ephocs_num\n",
    "                   and setting onlyB to True, we get A out of the game \n",
    "                               \n",
    "        '''                  \n",
    "        \n",
    "        trn_nbatch = len(trn_data)\n",
    "        tst_nbatch = len(tst_data)\n",
    "        print('# Train set size:', len([len(batch) for batch in trn_data]))\n",
    "        print('# Training batches:', trn_nbatch)\n",
    "        print('# Test set size:', len([len(batch) for batch in tst_data]))\n",
    "        print('# Testing batches:', tst_nbatch)\n",
    "        self.test_res, self.train_res = [], [] #list to hold accuracy of test and train sets\n",
    "        \n",
    "        # When activating A, the probability to choose an action randomly is 1/delta, we increase delta during training.\n",
    "        # After activation_ephoc number of ephocs, A may only edit the last word (mixer_delta=1). \n",
    "        MIXER_delta, delta = 1, 1\n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            tf.global_variables_initializer().run()\n",
    "            ckpt = tf.train.get_checkpoint_state(params_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                print('Loading parameters from', ckpt.model_checkpoint_path)\n",
    "                self.saver.restore(sess, ckpt.model_checkpoint_path) # restore all variables\n",
    "            else:\n",
    "                print('Initializing variables')\n",
    "                \n",
    "            for ephoc in range(start_ephoc, ephocs_num):\n",
    "                startTime = datetime.now().replace(microsecond=0)\n",
    "                          \n",
    "                # Train B only after competition start (ephoc<startA). \n",
    "                # Each time we train B, we train only B for muteB ephocs.\n",
    "                toTrainB = ephoc<startA or (ephoc-(startA-1))%(muteB+1)==0 # Whether to train only B \n",
    "                \n",
    "                # Every 2 times we train B and A (+ only A for muteB ephocs), we increase\n",
    "                # delta by one\n",
    "                if (ephoc-activation_ephoc)%((muteB+1)*2)==0 and ephoc>=activation_ephoc:\n",
    "                    delta+=1\n",
    "                    MIXER_delta+=1\n",
    "                \n",
    "                # * If ephoc<startA, train A with no word edits\n",
    "                #   by setting editRandomlyProb to one and rnn_editProb to 0 (always \n",
    "                #   choose an action randomly with zero probability for edit). \n",
    "                # * If we train B in this ephoc, set editRandomlyProb to zero.\n",
    "                if ephoc<startA:\n",
    "                    rnn_editProb_holder = 0.\n",
    "                    editRandomlyProb=1.\n",
    "                elif toTrainB==False:\n",
    "                    rnn_editProb_holder = rnn_editProb\n",
    "                    editRandomlyProb=1/delta\n",
    "                else:\n",
    "                    rnn_editProb_holder= 0.\n",
    "                    editRandomlyProb=0.\n",
    "                        \n",
    "                # When we train B with edited words (itrInEphoc=2), we show B results without editing (on train set).\n",
    "                # Note the we train B with edited words only if delta>2.\n",
    "                itrInEphoc=1\n",
    "                if onlyB==False and delta>2 and toTrainB:\n",
    "                    itrInEphoc=2\n",
    "                    \n",
    "                print('='*50,'\\nTrain, ephoc:',ephoc, '; Training B:', toTrainB)\n",
    "                np.random.shuffle(trn_data)\n",
    "                for ep in range(itrInEphoc):\n",
    "                    trn_ce_loss, A_trn_loss, B_trn_loss = 0, 0, 0\n",
    "                    trn_acc, trn_iou, edits_count = 0, 0, 0\n",
    "                    tst_ce_loss, tst_loss, tst_acc, tst_iou = 0, 0, 0, 0\n",
    "                    if ep==1:\n",
    "                        print('No Edit')\n",
    "                        print('ooooooo')\n",
    "                    edit_num = 0 # average number of edited words per query\n",
    "                    editRount_count = 0 # number of iterations with competition.\n",
    "                    \n",
    "                    for b in range(trn_nbatch):\n",
    "                        if ep==1:\n",
    "                            '''\n",
    "                            If ep=1, we're in round 2 in which we only show B's \n",
    "                            results with out editing (on the train set).\n",
    "                            '''\n",
    "                            isEdit=False\n",
    "                        else:\n",
    "                            # If ephoc<startA we train B and A with no edits\n",
    "                            # then, if B is trained, only if delta>2 (which mean A was trained with un-random choices)\n",
    "                            # we can train B with A edits.\n",
    "                            isEdit = onlyB==False and ephoc<startA or toTrainB==False or (delta>2 and np.random.rand(1)[0]<editProb)\n",
    "                            \n",
    "                        attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(trn_data[b], \n",
    "                                                                                            0, \n",
    "                                                                                            self.batch_size, \n",
    "                                                                                            addNoise=addNoise,\n",
    "                                                                                            imScale=imScale)\n",
    "                \n",
    "                        reward_loss = np.array([[0., 0.] for _ in range(self.batch_size)]) # dummy holder \n",
    "                    \n",
    "\n",
    "                        feed_dict = {\n",
    "                            self.queries:padded_queries,\n",
    "                            self.img:padded_im,\n",
    "                            self.bboxes:padded_bbox,\n",
    "                            self.attn_idx:attn_idx,\n",
    "                            self.labels: labels,\n",
    "                            self.unk:np.array([[vocab['<unk>']]]),\n",
    "                            self.isEdit:isEdit,\n",
    "                            self.reward_loss:reward_loss,\n",
    "                            self.Aattn_vecs:[[[]]],# dummy holder \n",
    "                            self.dropout_in:dropout_in,\n",
    "                            self.dropout_out:dropout_out,\n",
    "                            self.dropout_img:dropout_img,\n",
    "                            self.dropout_q:dropout_q,\n",
    "                            self.isTrain:True,\n",
    "                            self.isIDX:False,\n",
    "                            self.set_actions:[[]],# dummy holder \n",
    "                            self.rnn_editProb:rnn_editProb_holder,\n",
    "                            self.editRandomlyProb:editRandomlyProb,\n",
    "                            self.MIXER_delta:MIXER_delta\n",
    "                        }\n",
    "                        \n",
    "                        \n",
    "                        if isEdit==True:\n",
    "                            editRount_count+=1\n",
    "                          \n",
    "                            '''We first run B with no edit in order to get it's loss and outputs.'''\n",
    "                            feed_dict[self.isEdit] = False\n",
    "                            queries_lens, B_ce, outputs = sess.run([self.queries_lens, self.B_ce, self.outputs], feed_dict=feed_dict)\n",
    "                            feed_dict[self.isEdit] = True\n",
    "                            # B_ce contain the loss for each query.\n",
    "                            # We scale all the losses to have mean 1 and std 0.3.\n",
    "                            Bce_min = min(B_ce)\n",
    "                            Bce_max = max(B_ce)\n",
    "                            Bce_scale = (B_ce-Bce_min)/(Bce_max-Bce_min)\n",
    "                            s = np.std(Bce_scale)\n",
    "                            BCE = 0.3*Bce_scale/s\n",
    "                            BCE = 1 + BCE - np.mean(BCE)\n",
    "                          \n",
    "                            # reward for edit a word = edit_reward*BCE/queries_lens.\n",
    "                            # A's get the reward and loss per query  as 2 of its features.\n",
    "                            rewards_loss = np.concatenate(\n",
    "                                [np.expand_dims(edit_reward*BCE/queries_lens, 1), np.expand_dims(BCE, 1)], 1)\n",
    "                            \n",
    "                            feed_dict[self.reward_loss]=rewards_loss\n",
    "                            \n",
    "                            # A's attention vectors are B's outputs with no edited words.\n",
    "                            Aattn_vecs = outputs[:,:,:self.num_hidden]\n",
    "                            feed_dict[self.Aattn_vecs]=Aattn_vecs\n",
    "                           \n",
    "                            '''\n",
    "                            We then run B with A's edits. \n",
    "                            We get idx (A's decision [0,1] for each words).\n",
    "                            edit_num: the ratio of edited words per query \n",
    "                            B_ce, B_loss: B's loss per query and B overall mean.\n",
    "                            '''\n",
    "                           \n",
    "                            idx, B_ce1, B_loss, edit_num = sess.run(\n",
    "                                [self.idx, self.B_ce, self.B_loss, self.edit_num], \n",
    "                                 feed_dict=feed_dict)\n",
    "\n",
    "                            # Get reward per word.\n",
    "                            # If word i in query j was edited idx[j,i]=1 --> rewards[i,j] = 1*reward\n",
    "                            # If word i in query j was not edited idx[j,i]=0 --> rewards[i,j] = 0*reward\n",
    "                            rewards = idx*np.expand_dims(\n",
    "                                edit_reward*BCE/queries_lens, axis=1)\n",
    "                            \n",
    "                            # Scale new losses\n",
    "                            Bce_min = min(B_ce1)\n",
    "                            Bce_max = max(B_ce1)\n",
    "                            Bce_scale = (B_ce1-Bce_min)/(Bce_max-Bce_min)\n",
    "                            s = np.std(Bce_scale)\n",
    "                            BCE1 = .3*Bce_scale/s\n",
    "                            BCE1 = 1 + BCE1 - np.mean(BCE1)\n",
    "                            \n",
    "                            feed_dict[self.actions_idx] = np.abs(list(zip(range(\n",
    "                                        self.batch_size*idx.shape[-1]), idx.reshape(-1))))\n",
    "                            feed_dict[self.bell_val] = self.discount_rewards(rewards, BCE1)\n",
    "                            feed_dict[self.set_actions] = idx\n",
    "                            feed_dict[self.isIDX]=True\n",
    "                                                         \n",
    "                            A_loss, _ = sess.run(\n",
    "                                [self.A_loss, self.A_optimizer], feed_dict=feed_dict)\n",
    "                                                        \n",
    "                            if toTrainB:\n",
    "                                feed_dict[self.isIDX]=False\n",
    "                                lr, gs, B_loss, edit_num, _ = sess.run(\n",
    "                                    [self.learning_rate, self.global_step, self.B_loss, self.edit_num, self.B_optimizer], \n",
    "                                    feed_dict=feed_dict)\n",
    "                \n",
    "                    \n",
    "                            acc = self.accuracy(sess=sess, feed_dict=feed_dict, isEdit=isEdit, \n",
    "                                                imScale=imScale, MIXER_delta=MIXER_delta) \n",
    "                        \n",
    "                            iou_acc = self.iou_accuracy(\n",
    "                                trn_data[b], 0, self.batch_size, imScale=imScale,\n",
    "                                sess=sess, feed_dict=feed_dict, isEdit=isEdit, MIXER_delta=MIXER_delta)\n",
    "\n",
    "                            trn_acc += acc/trn_nbatch\n",
    "                            A_trn_loss += A_loss\n",
    "                            B_trn_loss += B_loss/trn_nbatch\n",
    "                            trn_iou += iou_acc/trn_nbatch\n",
    "                            edits_count += edit_num\n",
    "                            \n",
    "                            if b%50==0:\n",
    "                                if toTrainB: \n",
    "                                    print('Edit:%s'%(isEdit), \n",
    "                                          ';batch:%d'%(b), \n",
    "                                          ';gs:%d'%(gs), ';lr:%.3f'%(lr), ';Bloss:%.3f'%(B_loss), \n",
    "                                          ';Aloss:%.3f'%(A_loss), ';edits:%.2f'%(edit_num),  ';editRandomlyProb:%.2f'%(editRandomlyProb),\n",
    "                                          ';acc:%.3f'%(acc), ';iou:%.3f'%(iou_acc), ';time:', datetime.now().replace(microsecond=0)-startTime)    \n",
    "                                else:\n",
    "                                    print('Edit:%s'%(isEdit),\n",
    "                                          ';batch:%d'%(b), \n",
    "                                          ';Bloss:%.3f'%(B_loss), ';Aloss:%.3f'%(A_loss), \n",
    "                                          ';edits:%.2f'%(edit_num), ';editRandomlyProb:%.2f'%(editRandomlyProb), ';acc:%.3f'%(acc),\n",
    "                                          ';iou:%.3f'%(iou_acc), ';time:', datetime.now().replace(microsecond=0)-startTime)  \n",
    "                                \n",
    "\n",
    "                               \n",
    "                        else: # isEdit=False\n",
    "                            if ep==0:\n",
    "                                B_loss, lr, gs, _ = sess.run([self.B_loss, self.learning_rate, \n",
    "                                                                self.global_step, self.B_optimizer], feed_dict=feed_dict)\n",
    "                            else: \n",
    "                                # just show results of B with no edits\n",
    "                                B_loss, lr, gs = sess.run([self.B_loss, self.learning_rate, self.global_step], feed_dict=feed_dict)\n",
    "\n",
    "                            acc = self.accuracy(sess=sess, feed_dict=feed_dict, isEdit=isEdit, imScale=imScale, MIXER_delta=MIXER_delta)  \n",
    "                            iou_acc = self.iou_accuracy(trn_data[b], 0, self.batch_size, imScale=imScale,\n",
    "                                                        sess=sess, feed_dict=feed_dict, isEdit=isEdit, MIXER_delta=MIXER_delta)\n",
    "\n",
    "                            trn_acc += acc/trn_nbatch\n",
    "                            B_trn_loss += B_loss/trn_nbatch\n",
    "                            trn_iou += iou_acc/trn_nbatch\n",
    "\n",
    "                            if b%50==0:\n",
    "                                print('Edit:%s'%(isEdit), \n",
    "                                      ';batch:%d'%(b),  \n",
    "                                      ';gs:%d'%(gs), ';lr:%.3f'%(lr),\n",
    "                                      ';Bloss:%.3f'%(B_loss),  ';acc:%.3f'%(acc), \n",
    "                                      ';iou:%.3f'%(iou_acc),\n",
    "                                      ';time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "\n",
    "                    if editRount_count>0:\n",
    "                        print('\\n*Training B:', ephoc%3==0, ';B Train loss: %.3f'%(B_trn_loss), ';A Train loss: %.3f'%(A_trn_loss/editRount_count),                                                                                             \n",
    "                          ';Edit num: %.3f'%(edits_count/editRount_count), \n",
    "                          ';Train accuracy: %.3f'%(trn_acc),  ';IOU accuracy: %.3f'%(trn_iou), \n",
    "                          ';Time:', datetime.now().replace(microsecond=0)-startTime, '\\n')\n",
    "                    else:\n",
    "                        print('\\n*Training B:', ephoc%3==0, ';B Train loss: %.3f'%(B_trn_loss),';Train accuracy: %.3f'%(trn_acc), \n",
    "                          ';IOU accuracy: %.3f'%(trn_iou),  \n",
    "                          ';Time:', datetime.now().replace(microsecond=0)-startTime, '\\n')\n",
    "                          \n",
    "                if editRount_count>0:\n",
    "                    self.train_res.append([trn_acc, trn_iou, B_trn_loss, A_trn_loss/editRount_count])\n",
    "                else: \n",
    "                    self.train_res.append([trn_acc, trn_iou, B_trn_loss, 0])\n",
    "                self.saver.save(sess, params_dir + \"/model.ckpt\", global_step=ephoc)    \n",
    "                if ephoc<startA or toTrainB:\n",
    "                    print('Testing, ephoc:',ephoc)\n",
    "                    tstTime = datetime.now().replace(microsecond=0)\n",
    "                    tst_loss, tst_acc, tst_iou = 0, 0, 0\n",
    "                    for b in range(tst_nbatch):\n",
    "                        attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(tst_data[b],\n",
    "                                                                                    0, self.batch_size, imScale=imScale)\n",
    "                        rewards_loss = np.array([[0., 0.] for _ in range(self.batch_size)])\n",
    "                        feed_dict = {\n",
    "                            self.queries:padded_queries,\n",
    "                            self.img:padded_im,\n",
    "                            self.bboxes:padded_bbox,\n",
    "                            self.attn_idx:attn_idx,\n",
    "                            self.labels: labels,\n",
    "                            self.unk:np.array([[vocab['<unk>']]]),\n",
    "                            self.reward_loss:reward_loss,\n",
    "                            self.isEdit:False,\n",
    "                            self.Aattn_vecs:[[[]]],\n",
    "                            self.dropout_in:1.,\n",
    "                            self.dropout_out:1.,\n",
    "                            self.dropout_img:1.,\n",
    "                            self.dropout_q:1.,\n",
    "                            self.isTrain:False,\n",
    "                            self.isIDX:False,\n",
    "                            self.set_actions:[[]],# dummy holder \n",
    "                            self.rnn_editProb:0.,\n",
    "                            self.editRandomlyProb:0.\n",
    "                        }\n",
    "                        B_loss = sess.run(self.B_loss, feed_dict=feed_dict)\n",
    "\n",
    "                        acc = self.accuracy(sess=sess, feed_dict=feed_dict, isEdit=False, imScale=imScale)\n",
    "                        iou_acc = self.iou_accuracy(\n",
    "                            tst_data[b], 0, self.batch_size, sess=sess, \n",
    "                            feed_dict=feed_dict, isEdit=False, imScale=imScale)\n",
    "                        \n",
    "                        tst_acc += acc/tst_nbatch\n",
    "                        tst_loss += B_loss/tst_nbatch\n",
    "                        tst_iou += iou_acc/tst_nbatch\n",
    "                        if b%50==0:\n",
    "                            print('batch:', b, ';B loss: %.3f'%(B_loss), ';acc: %.3f'%(acc), \n",
    "                                   ';iou_acc: %.3f'%(iou_acc), ';time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "                    print('\\n*BTrain:', ephoc%3==0, ';Test loss: %.3f'%(tst_loss), ';Test accuracy %.3f'%(tst_acc), \n",
    "                          ';IOU accuracy: %.3f'%(tst_iou), ';Time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "                    self.test_res.append([tst_acc, tst_iou, tst_loss])\n",
    "                print('='*50,'\\n')\n",
    "            return self.test_res, self.train_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edit_reward: -1.0\n",
      "params_dir: ../data/training/models/All/RL/EXP/2hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 297\n",
      "# Training batches: 297\n",
      "# Test set size: 297\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit:False ;batch:0 ;gs:1 ;lr:0.050 ;Bloss:1.911 ;acc:0.315 ;iou:0.430 ;time: 0:00:00\n",
      "Edit:False ;batch:50 ;gs:51 ;lr:0.050 ;Bloss:2.990 ;acc:0.280 ;iou:0.380 ;time: 0:00:09\n",
      "Edit:False ;batch:100 ;gs:101 ;lr:0.050 ;Bloss:2.199 ;acc:0.550 ;iou:0.670 ;time: 0:00:17\n"
     ]
    }
   ],
   "source": [
    "num_hidden=200\n",
    "edit_reward = -1.\n",
    "params_dir = params_dir_tmp+'RL/EXP/2hidden:'+str(num_hidden)\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=embed_vecs.shape[1],\n",
    "    img_dims=trainset[0][0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "    lr=.05,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.9, \n",
    "    coefAlr=1,\n",
    "    bnorm=False,\n",
    "    toQscale=True\n",
    ")\n",
    "\n",
    "\n",
    "print('edit_reward:', edit_reward)\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=100,\n",
    "        start_ephoc=0,\n",
    "        startA=1,\n",
    "        activation_ephoc=3,\n",
    "        muteB=1, \n",
    "        editProb=0.8,\n",
    "        edit_reward=edit_reward,\n",
    "        imScale=50,\n",
    "        rnn_editProb=0.2,\n",
    "        onlyB=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
