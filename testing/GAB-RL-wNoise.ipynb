{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import retriever\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset_file = '../data/training/order_train_data.bin'\n",
    "testset_file = '../data/training/order_test_data.bin'\n",
    "vocab_file =  '../data/metadata/w2v_vocab.json'\n",
    "params_dir_tmp = '../data/training/models/All/'\n",
    "embed_path =  '../data/metadata/w2v.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<h3>Each entry in this list has the following structure:</h3>\n",
    "<ul>\n",
    "<li>entry[0]: query indexes </li>\n",
    "<li>entry[1:n]: n items where each item is [bounding box vector, bounding box spaital features]. Note that different enteries might have different 'n' </li>\n",
    "<li>entry[n+1]: integer, entry[ 1 + entry[n+1]] is the ture bbox </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset barches #: 297\n",
      "test barches #: 297\n",
      "val barches #: 149\n"
     ]
    }
   ],
   "source": [
    "trainset = np.load(open(trainset_file, 'rb'))\n",
    "trainset = [item for item in trainset if len(item)>2 and len(item[0])>0]\n",
    "print('trainset barches #:', len(trainset))\n",
    "\n",
    "test_N_val_set = np.load(open(testset_file, 'rb'))\n",
    "test_N_val_set = [item for item in test_N_val_set if len(item)>2 and len(item[0])>0]\n",
    "np.random.shuffle(test_N_val_set)\n",
    "np.random.shuffle(test_N_val_set)\n",
    "testset = test_N_val_set[:int(0.5*len(test_N_val_set))]\n",
    "valset = test_N_val_set[int(0.5*len(test_N_val_set)):]\n",
    "\n",
    "print('test barches #:', len(test_N_val_set))\n",
    "print('val barches #:', len(valset))\n",
    "\n",
    "with open(vocab_file, 'r') as f:\n",
    "    vocab = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab['<unk>'] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8242, 8241)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab), vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_vecs = np.load(open(embed_path, 'rb')).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> augment_data function </h3>\n",
    "<br>We try sevral regularization methods. One of the things I've tried is to add data points where for each data I pick a query from a random data point and a set of bbox from a different random point. We build the labels (bboxes) distribution by giving an equal probability to each label. <br><br>\n",
    "The augment_data function does just that but the label of each added poind is writen as -1*number of bboxes. When we build the batch it self (function build_data in class Model), if we see a negative label index, we know its an added point and we know the number of bboxes so we can build the correct distribution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_data(data, ratio=0.5, addNoise=False):\n",
    "        '''\n",
    "        The function add data points. \n",
    "        We pick a query from a random data point,\n",
    "        and a set of bbox from a different random point and we join them\n",
    "        to build a new data point. The label distribution of the new data point will \n",
    "        uniform, that is, all labels will have equal probability. \n",
    "        \n",
    "        \n",
    "        Params:\n",
    "            data: a list of data entries\n",
    "                                                \n",
    "        Returns: a list of augmented data\n",
    "            \n",
    "                        \n",
    "        '''\n",
    "                          \n",
    "        q_idx = np.random.choice(range(len(data)), int(len(data)*ratio), replace=False)\n",
    "        im_idx = np.random.choice([i for i in range(len(data)) if i not in q_idx], int(len(data)*ratio))\n",
    "        for i in range(len(q_idx)):\n",
    "            q, im = data[q_idx[i]][0], data[im_idx[i]][1:-1]\n",
    "            item = [q]\n",
    "            for im_tmp in im:\n",
    "                item.append(im_tmp)\n",
    "            item.append(-len(im))\n",
    "            data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stats(test, train, ephocs=100, title=None, params=[50, 100, 150, 200]):\n",
    "    '''\n",
    "    Plot metrics graphs and print some stats.\n",
    "    \n",
    "    Params:\n",
    "        test: list. \n",
    "              Each item is a tuple, [test accuracy, test IOU, test loss]\n",
    "        \n",
    "        train: list. \n",
    "               Each item is a tuple, [train accuracy, train IOU, train loss, 0]\n",
    "               For now we can ignore the last part in the tuple (zero)\n",
    "               \n",
    "        params: The hyper-parameters to iterate over, defult to number of rnn's hidden units.\n",
    "    '''\n",
    "    \n",
    "    ephocs = range(ephocs)\n",
    "    test_res = np.array(test)\n",
    "    train_res = np.array(train)\n",
    "    test_Glabels = ['test accuracy', 'test IOU', 'test loss']\n",
    "    train_Glabels = ['train accuracy', 'train IOU', 'train loss']\n",
    "\n",
    "    for j, param in enumerate(params):\n",
    "        print('num_hidden:', param)\n",
    "        print('='*(len('num_hidden:')+3))\n",
    "        for i in range(len(train_Glabels)):\n",
    "            plt.plot(ephocs, test_res[j][:,i])\n",
    "            plt.plot(ephocs, train_res[j][:,i])\n",
    "            plt.legend([test_Glabels[i], train_Glabels[i]], loc='upper left')\n",
    "            if title is not None:\n",
    "                plt.title('%s: %d'%(title, param))\n",
    "            plt.show()\n",
    "\n",
    "            metric = ''.join(train_Glabels[i][len('train')+1:])\n",
    "            if metric=='loss':\n",
    "                print('Train min %s:%.3f'%(metric, min(train_res[j][:,i])))\n",
    "                print('Test min %s:%.3f'%(metric, min(test_res[j][:,i])))\n",
    "            else:\n",
    "                print('Train max %s:%.3f'%(metric, max(train_res[j][:,i])))\n",
    "                print('Test max %s:%.3f'%(metric, max(test_res[j][:,i])))\n",
    "        print('-'*100,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALSTM\n",
    "\n",
    "This RNN cell has two LSTM cells, Bcell (for player B) and Acell (for Player A) and work as follow:\n",
    "<ol> \n",
    "<li>We run B's cells with the true query input word, getting the un-edited state. If use_worsAttn=True we add attention on the images vectors for each word.</li>\n",
    "<li>We run B's cells with the edited input word - 'unk', getting the edited state. If use_worsAttn=True we add attention on the images vectors for each word.</li>\n",
    "<li>We feed the un-edited state to A's cell.</li>\n",
    "<li>We run A's cells. A's input are:\n",
    "<ul><li>B's un-edited state</li><li>The reward for editing a word</li><li>B's loss having no edited words.</li></ul></li>\n",
    "<li>A's output is then goes throw a transformation which yields two values, one for editing a word and another for not.<br>If the the value for edit the word is higher, we pass B's edited state to the next time step, else we pass B's un_edit state.</li><br>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ALSTM(tf.nn.rnn_cell.LSTMCell):\n",
    "    def __init__(self, \n",
    "                 batch_size, \n",
    "                 num_units, \n",
    "                 \n",
    "                 # Size of A's attention vector.\n",
    "                 words_attn_dim, \n",
    "                 # B's outputs (for each time step).\n",
    "                 words_attn_states, \n",
    "                 # Inicates whether attentionvec is a padding (0) or not (1).\n",
    "                 words_attn_idx, \n",
    "                 \n",
    "                 # Size of B's attention vector ([image vector, spital features] size) .\n",
    "                 img_attn_dim, \n",
    "                 # B's outputs (for each time step).\n",
    "                 img_attn_states, \n",
    "                 \n",
    "                 \n",
    "                 # Inicates whether attentionvec is a padding (0) or not (1).\n",
    "                 img_attn_idx, \n",
    "                 \n",
    "                 unk, #'unk' word vector\n",
    "                 \n",
    "                 # Whehter to edit the query or not.\n",
    "                 isEdit, \n",
    "                 \n",
    "                 # Whether B uses words levlel attention or not.\n",
    "                 use_wordAttn,\n",
    "                 \n",
    "                 # Probabilty for choosing an action (edit or not) randomly, \n",
    "                 editRandomlyProb, \n",
    "                 # If the action is chosen randomly. edit with probability of rnn_editProb\n",
    "                 rnn_editProb,\n",
    "                 \n",
    "                 # Dropin and dropout ratio.\n",
    "                 dropout_in, \n",
    "                 dropout_out,\n",
    "                 # If True add noise instead of using 'unk'\n",
    "                 editByNoise=False,\n",
    "                 \n",
    "                 # If useNoise is true word vec = alpha*word_vector+(1-alpha)*noise\n",
    "                 useNoise=False,\n",
    "                 alpha=.2,\n",
    "                 \n",
    "                 #this holds A's rewards and B's losses to\n",
    "                 # be add to A's feature vectors.\n",
    "                 reward_loss=None,\n",
    "                 state_is_tuple=True\n",
    "                ):\n",
    "        \n",
    "        \n",
    "        # When useing A, the cell state will contain the concatenation \n",
    "        # of both B and A states. Therefore we set the unit number to be\n",
    "        # 2*(A and B unit size).\n",
    "        super().__init__(2*num_units, state_is_tuple=state_is_tuple)\n",
    "    \n",
    "        self.words_attn_states = words_attn_states\n",
    "        self.words_attn_idx = words_attn_idx\n",
    "        self.words_attn_dim = words_attn_dim\n",
    "        \n",
    "        self.img_attn_states = img_attn_states\n",
    "        self.img_attn_idx = img_attn_idx\n",
    "        self.img_attn_dim = img_attn_dim\n",
    "        \n",
    "        self.num_units = num_units\n",
    "        self.batch_size = batch_size\n",
    "        self.unk = unk \n",
    "        self.isEdit = isEdit\n",
    "        self.use_wordAttn=use_wordAttn\n",
    "        \n",
    "        self.Bcell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "                tf.nn.rnn_cell.LSTMCell(self.num_units, state_is_tuple=True), input_keep_prob=dropout_in, output_keep_prob=dropout_out)\n",
    "        \n",
    "        self.Acell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "                tf.nn.rnn_cell.LSTMCell(self.num_units, state_is_tuple=True), output_keep_prob=dropout_out)\n",
    "        \n",
    "        \n",
    "        self.editRandomlyProb = editRandomlyProb\n",
    "        self.rnn_editProb = rnn_editProb\n",
    "        self.reward_loss = reward_loss\n",
    "        self.useNoise=useNoise\n",
    "        self.alpha=alpha\n",
    "        \n",
    "\n",
    "    def call(self, inputs, state):\n",
    "        '''\n",
    "        Params:\n",
    "            inputs: word embadding.\n",
    "            state:  [B's state form privious state, A's state form privious state]\n",
    "        '''\n",
    "        # takse B's state from state[:self.num_units]\n",
    "        Bstate_c = tf.slice(state[0], [0, 0], [-1, self.num_units])\n",
    "        Bstate_h = tf.slice(state[1], [0, 0], [-1, self.num_units])\n",
    "        self.Bstate =  tf.nn.rnn_cell.LSTMStateTuple(c=Bstate_c, h=Bstate_h)\n",
    "         \n",
    "        # If B's cell uses attention\n",
    "        if self.use_wordAttn:\n",
    "            words_attn = self.attention(Bstate_h, self.img_attn_states, self.img_attn_dim, self.img_attn_idx)\n",
    "            new_input = tf.concat([inputs, words_attn], -1)\n",
    "            Boutputs, Bnew_state =  self.Bcell(new_input, self.Bstate, 'Bcell')\n",
    "        else:\n",
    "            Boutputs, Bnew_state =  self.Bcell(inputs, self.Bstate, 'Bcell')\n",
    "\n",
    "        \n",
    "        def f1(): # If isEdit==True\n",
    "            # takse A's state from state[self.num_units: 2*self.num_units]\n",
    "            Astate_c = tf.slice(state[0], [0, self.num_units], [-1, self.num_units])\n",
    "            Astate_h = tf.slice(state[1], [0, self.num_units], [-1, self.num_units])\n",
    "            self.Astate =  tf.nn.rnn_cell.LSTMStateTuple(c=Astate_c, h=Astate_h)\n",
    "            \n",
    "            if self.useNoise: # just add noise to the edited words\n",
    "                new_unk_vecs = self.alpha*inputs + (1-self.alpha)*tf.random_normal(shape=[self.batch_size, 100], stddev=0.1)\n",
    "            else: # change the edited words by 'unk'\n",
    "                unk_vecs = tf.concat([self.unk for _ in range(self.batch_size)], 0) # shape: self.batch_size x 1 x embed_size\n",
    "                new_unk_vecs = tf.squeeze(unk_vecs) # shape: self.batch_size x embed_size\n",
    "            \n",
    "            # run B's cell with unk_batch\n",
    "            if self.use_wordAttn:\n",
    "                new_unk = tf.concat([new_unk_vecs, words_attn], -1)\n",
    "            else:\n",
    "                new_unk = new_unk_vecs\n",
    "            edit_output, edit_new_state = self.Bcell(new_unk, self.Bstate, 'Bcell')  \n",
    "            out1, state1 = self.runCell(Boutputs, Bnew_state, edit_new_state)\n",
    "            return out1, state1\n",
    "        \n",
    "        def f2(): \n",
    "            outs = tf.concat([Boutputs, tf.zeros((self.batch_size, self.num_units))], 1)\n",
    "            new_state_c = tf.concat([Bnew_state[0], tf.zeros_like(Bnew_state[0])], 1)\n",
    "            new_state_h = tf.concat([Bnew_state[1], tf.zeros_like(Bnew_state[1])], 1)\n",
    "            return outs, tf.nn.rnn_cell.LSTMStateTuple(c=new_state_c, h=new_state_h)\n",
    "        \n",
    "        new_output, new_state = tf.cond(self.isEdit, f1, f2)\n",
    "        \n",
    "        return new_output, new_state\n",
    "    \n",
    "    def runCell(self, Boutputs, Bnew_state, edit_new_state):\n",
    "        '''\n",
    "        Run B's cell after editing.\n",
    "        \n",
    "        params:\n",
    "            Boutputs: output vector without editing.\n",
    "            Bnew_state: state vector without editing.\n",
    "            edit_new_state: state vector after editing the input word to 'unk'. \n",
    "        '''\n",
    "        \n",
    "        with tf.variable_scope('runcell'):\n",
    "            # get action values according to B's hidden state\n",
    "            Aout, Anew_state, actions_vals = self.action_vals(Boutputs) \n",
    "            \n",
    "            # We can't use a tf.cond with batch_size  conditions so....\n",
    "            \n",
    "            # A choose to edit a word if actions_vals[0]<actions_vals[1].\n",
    "            # Note: if we edit the word cond=1, else cond=0.\n",
    "            a1, a2 = tf.split(value=actions_vals, num_or_size_splits=2, axis=1)\n",
    "            A_choice = tf.cast(tf.less(a1, a2), tf.float32)\n",
    "            \n",
    "            # If action is chosen randomly, edit word with probability self.rnn_editProb\n",
    "            # Note: if we edit the word cond=1, else cond=0.\n",
    "            rand = tf.multinomial(tf.log([[self.rnn_editProb, 1-self.rnn_editProb]]), self.batch_size)\n",
    "            rand_choice = tf.cast(tf.less(tf.transpose(rand), 1), tf.float32) \n",
    "            \n",
    "            # Choose whether to edit a word randomly with probability of editRandomlyProb\n",
    "            editRandomly = tf.multinomial(tf.log([[self.editRandomlyProb, 1-self.editRandomlyProb]]), self.batch_size)\n",
    "            editRandomly_choice = tf.cast(tf.less(tf.transpose(editRandomly), 1), tf.float32)\n",
    "            \n",
    "            # A list of decisions for each word in the batch. actions_idx[i] = 1->edit word in query i (at this time step), 0->do not edit.\n",
    "            actions_idx = editRandomly_choice*rand_choice + (1-editRandomly_choice)*A_choice\n",
    "\n",
    "            # We'd like to know the action values and decision for each word,\n",
    "            # therefore theses info are placed on the first 3 dimensions of the \n",
    "            # output vector. Note that this vector is not passed to the \n",
    "            # next tiee step so it won't affect the model. \n",
    "            outs = tf.concat([actions_vals,  actions_idx], 1)\n",
    "\n",
    "            # B's i state is replaced by the edited state if actions_idx[i]=1 (i =1, 2, ..., batch_size)\n",
    "            new_edit_state_c = (1-actions_idx)*Bnew_state[0] + actions_idx*edit_new_state[0]\n",
    "            new_edit_state_h = (1-actions_idx)*Bnew_state[1] + actions_idx*edit_new_state[1]\n",
    "\n",
    "\n",
    "            new_outs = tf.concat([outs, tf.zeros((self.batch_size, 2*self.num_units-3))], 1)\n",
    "            new_state_c = tf.concat([new_edit_state_c, Anew_state[0]], 1)\n",
    "            new_state_h = tf.concat([new_edit_state_h, Anew_state[1]], 1)\n",
    "            return new_outs, tf.nn.rnn_cell.LSTMStateTuple(c=new_state_c, h=new_state_h)\n",
    "    \n",
    "    \n",
    "    def action_vals(self, Boutputs):\n",
    "        '''\n",
    "        Get values for editing/not editing the input word.\n",
    "        \n",
    "        Params:\n",
    "            Boutputs: output vector without editing.\n",
    "            \n",
    "        Returns vals where:\n",
    "            Aout: A's cell output\n",
    "            Anew_state: A's cell state\n",
    "            vals: Tensor where vals[0] is the value for not editing the word \n",
    "                    and vals[1] is the value for editing the word.\n",
    "        '''\n",
    "        \n",
    "        with tf.variable_scope('action_vals') as scope:\n",
    "            Aattn = self.attention(self.Astate[1], self.words_attn_states, self.words_attn_dim, self.words_attn_idx)\n",
    "            \n",
    "            # A's input: [input, B's output, attntion state, reward, B's loss with no edits]\n",
    "            Anew_inputs = tf.concat([Boutputs, Aattn, self.reward_loss], 1)\n",
    "            \n",
    "            Aout, Anew_state = self.Acell(Anew_inputs, self.Astate, 'Acell')\n",
    "            vals = self.linear(Aout, 2)\n",
    "\n",
    "            # Save the variables that only A uses. \n",
    "            # These variables will be trained separately from B's model.\n",
    "            self.Avars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
    "            \n",
    "            return Aout, Anew_state, vals\n",
    "            \n",
    "        \n",
    "    def linear(self, inputs, output_dim, scope='linear', bias=True, reuse=False):\n",
    "        with tf.variable_scope(scope, reuse=False):\n",
    "            W = tf.get_variable('W', initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                shape=(inputs.get_shape()[-1], output_dim))\n",
    "            if bias:\n",
    "                b = tf.get_variable('b', initializer=tf.constant_initializer(0.1),\n",
    "                               shape=[1, output_dim])\n",
    "                return tf.matmul(inputs, W) + b\n",
    "\n",
    "        return tf.matmul(inputs, W)\n",
    "    \n",
    "    \n",
    "    def attention(self, state, attn_states, attn_dim, attn_idx, relu=False):\n",
    "        '''\n",
    "        Attention mechanism (see https://arxiv.org/pdf/1409.0473.pdf)\n",
    "        \n",
    "        state: State from previous time step.\n",
    "        attn_states: Attetntion states. \n",
    "                     Tensor of shape (batch_size x max([len(attention_vectors[i]) for i in range(bach_size)]) x attn_dim)\n",
    "        attn_dim: Attention vector size.\n",
    "        attn_idx,: Tensor used for masking of shape (batch_size x max([len(attention_vectors[i]) for i in range(bach_size)]). \n",
    "                   attn_idx[i, j]=1 if the j's attention vcctior of sample i  is not padding, else its equat to 0.\n",
    "        '''\n",
    "        \n",
    "        self.attn_length = tf.shape(attn_states)[1]  \n",
    "        \n",
    "        # Computing... hidden_attn = W*v_att (use tf.nn.conv2d for efficiency)\n",
    "        attn_vecs = tf.reshape(attn_states, [self.batch_size, self.attn_length, 1, attn_dim])\n",
    "        W = tf.get_variable(\"attn_W\", [1, 1, attn_dim, self.num_units])\n",
    "        hidden_attn = tf.nn.conv2d(attn_vecs, W, [1, 1, 1, 1], \"SAME\")\n",
    "\n",
    "        # Computing... hidden_s = U*v_state\n",
    "        hidden_s = tf.reshape(\n",
    "            self.linear(\n",
    "                tf.cast(state, tf.float32), output_dim=self.num_units, scope='hidden_s_linear'), [-1, 1, 1,  self.num_units], name='hidden_s')\n",
    "\n",
    "        # Computing alpha\n",
    "        v = tf.get_variable(\"attn_v\", [self.num_units])\n",
    "        if relu:\n",
    "            logits = tf.reduce_sum(v * tf.nn.relu(hidden_attn + hidden_s), [2, 3])\n",
    "        else:\n",
    "            logits = tf.reduce_sum(v * tf.nn.tanh(hidden_attn + hidden_s), [2, 3])\n",
    "\n",
    "        # Masked softmax\n",
    "        max_logits = tf.reduce_max(logits, axis=-1)\n",
    "        masked_logits = tf.exp(logits-tf.expand_dims(max_logits, axis=1))*attn_idx\n",
    "        alpha = masked_logits/tf.reduce_sum(masked_logits, axis=-1, keep_dims=True)\n",
    "\n",
    "        a = tf.reduce_sum(tf.reshape(alpha, [-1, self.attn_length, 1, 1]) * attn_vecs, [1, 2])\n",
    "        b = self.linear(a, output_dim=self.num_units, scope='b')\n",
    "                                               \n",
    "\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "When A joins the game, each iteration is completed via three steps:\n",
    "<ul>\n",
    "<li>We feed the query as it is to B and run it alone (no optimization nor training is done in this step)</li>\n",
    "<li>We run A and B together (no optimization nor training is done in this step). At this step we get A's decition and B's loss on the edited query. We use B's loss to calculate the Bellman's value for each time step. </li>\n",
    "<li>We again run A and B together, since now we know the real values for each time step and the real action for each time step (these will be the same as in the previous step since we did not train optimize the parameters yet), we finaly train the model</li>\n",
    "</ul>\n",
    "<br>\n",
    "But first we check the model's performance with out A. Class Model has a set of conditioning variables that set a different ragularization methods in the model. We start by checking them with out A's interference. We can also make the model RNN become bidirectional (by setting useBidirectionalRnn to True) and use words level attention (by setting use_wordAttn to True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self,\n",
    "                 batch_size, \n",
    "                 num_hidden, \n",
    "                 \n",
    "                 #Image's vector size.\n",
    "                 img_dims, \n",
    "                 \n",
    "                 #Spaital features length.tra\n",
    "                 bbox_dims, \n",
    "                 vocab, \n",
    "                 \n",
    "                 # For learning rate exponential decay\n",
    "                 decay_steps, \n",
    "                 decay_rate, \n",
    "                 \n",
    "                 # whether to use bach normaliztion for the last attention layer\n",
    "                 bnorm,\n",
    "                 \n",
    "                 embed_size=embed_vecs.shape[1],\n",
    "                 \n",
    "                 # Whether B uses words levlel attention or not.\n",
    "                 use_wordAttn=False,\n",
    "                 \n",
    "                 # Whther to use bidirectional rnn\n",
    "                 useBidirectionalRnn=False,\n",
    "                 \n",
    "                 # Urnn_norm: Whether to use batch normalization for the queries.\n",
    "                 # Uatt_norm: Whether to use batch normalization for the VGG outputs.\n",
    "                 Urnn_norm=True, \n",
    "                 Uatt_norm=True,\n",
    "                 \n",
    "                 # If useNoise, A add Normal noise to a word \n",
    "                 # instead of editing it: word_vec = alpha*word_vec+(1-alpha)*noise\n",
    "                 useNoise=False,\n",
    "                 alpha=.5,\n",
    "                 \n",
    "                 # Whether to scale and normelize queries \n",
    "                 # embedding to have zero mean and QSTD std\n",
    "                 toQscale = False,\n",
    "                 Qstd = 0.1\n",
    "                ):\n",
    "#         with tf.device('/cpu:0'):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.img_dims = img_dims\n",
    "        self.bbox_dims = bbox_dims \n",
    "        self.num_hidden = num_hidden\n",
    "        self.embed_size = embed_size\n",
    "        self.vocab = vocab\n",
    "        self.toQscale=toQscale\n",
    "        self.Qstd=Qstd\n",
    "        self.useNoise=useNoise\n",
    "        self.alpha=alpha\n",
    "        \n",
    "        # length of the logest query (all queries will be padded to this length)\n",
    "        self.qlen = tf.placeholder(tf.int32, name='qlen_holder')\n",
    "        self.queries = tf.placeholder(tf.int32, [None, None], name='queries')\n",
    "        self.img  = tf.placeholder(tf.float32, [None, None, self.img_dims], name='img')# VGG output vectors\n",
    "        self.bboxes = tf.placeholder(tf.float32, [None, None, self.bbox_dims], name='bboxes')# spatial bbox's features.\n",
    "\n",
    "        # attn_idx: inicates whether attention box is a dummy (0) or not (1).\n",
    "        self.attn_idx = tf.placeholder(tf.float32, [None, None], name='attn_idx')\n",
    "\n",
    "        self.labels = tf.placeholder(tf.float32, [None, None], name='labels')\n",
    "        self.isEdit = tf.placeholder(tf.bool, name='isEdit') # whehter to edit the query or not.\n",
    "        \n",
    "        # Probabilty for choosing an action (edit or not) randomly, \n",
    "        self.editRandomlyProb = tf.placeholder(tf.float32, name='editRandomlyProb_holder')\n",
    "        # If the action is chosen randomly. edit with probability of rnn_editProb\n",
    "        self.rnn_editProb = tf.placeholder(tf.float32, name='rnn_editProb_holder')\n",
    "\n",
    "        # After we run B with no edited words \n",
    "        # this holds B cross enthropy loss per query, de\n",
    "        # and  A's rewards to be add to A's feature vectors.\n",
    "        self.BCE_holder = tf.placeholder(tf.float32, [None,1], name='BCE_holder')\n",
    "        self.reward_holder = tf.placeholder(tf.float32, [None,1], name='rewards_holder')\n",
    "\n",
    "        # Dropout ratio for rnn's inputs and outpouts\n",
    "        self.dropout_in = tf.placeholder(tf.float32, name='dropoutIn_holder')\n",
    "        self.dropout_out = tf.placeholder(tf.float32, name='dropoutOut_holder')\n",
    "\n",
    "        # Dropout ratio for attention vector (for the final attention layer before the loss function)\n",
    "        self.dropout_img = tf.placeholder(tf.float32, name='dropoutImg_holder')\n",
    "        # Dropout ratio for query vector (for the final attention layer before the loss function)\n",
    "        self.dropout_q = tf.placeholder(tf.float32, name='dropoutImg_holder')\n",
    "        \n",
    "        # A and B learning rates.\n",
    "        self.Alr = tf.placeholder(tf.float32, name='Alr_holder')\n",
    "        self.Blr = tf.placeholder(tf.float32, name='Blr_holder')\n",
    "\n",
    "        # B outputs vectors (with no words edits), These are A's attention vectors\n",
    "        # which it uses to decide whter to edit a word.\n",
    "        self.Aattn_vecs = tf.placeholder(tf.float32, [None, None, None], name='Aattn_vecs_holder')    \n",
    "        self.unk = tf.constant([[vocab['<unk>']]], tf.int32)\n",
    "\n",
    "        self.isTrain = tf.placeholder(tf.bool, name='isTrain_holder') \n",
    "        self.queries_lens = self.length(self.queries) # list of all the lengths  of the batch's queriey \n",
    "\n",
    "        # Concatinate images vectors and their spaital features. \n",
    "        # These vectors wlll be used for attenionn when \n",
    "        # we calculate the loss function.\n",
    "        attn_vecs = tf.concat([self.img, self.bboxes], 2) \n",
    "        voc_size = len(self.vocab)\n",
    "\n",
    "        # Load pre-trained word imaddings.\n",
    "        # w2v_embed is not trainable.\n",
    "        with tf.variable_scope('w2v'):\n",
    "            w2v_embed = tf.get_variable('w2v_embed', initializer=embed_vecs, trainable=False)\n",
    "            w2v_queries = tf.nn.embedding_lookup(w2v_embed, self.queries, name='w2v_queries')\n",
    "\n",
    "        with tf.variable_scope('embed'):\n",
    "            embed = tf.get_variable('embed', shape=[voc_size, self.embed_size], \n",
    "                                    initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1))\n",
    "            embed_queries_tmp = tf.nn.embedding_lookup(embed, self.queries, name='embed_queries')\n",
    "\n",
    "        embed_queries = embed_queries_tmp+w2v_queries\n",
    "\n",
    "        with tf.variable_scope('rnn'):\n",
    "            Aattn_idx = tf.cast(tf.abs(tf.sign(self.queries)), tf.float32)\n",
    "\n",
    "            reward_loss = tf.concat([self.reward_holder, self.BCE_holder], 1)\n",
    "            cell = ALSTM(num_units=self.num_hidden, \n",
    "                            words_attn_dim=self.num_hidden, \n",
    "                            words_attn_states=self.Aattn_vecs, \n",
    "                            words_attn_idx=Aattn_idx,\n",
    "                            img_attn_dim=self.img_dims+self.bbox_dims,\n",
    "                            img_attn_states=attn_vecs,\n",
    "                            img_attn_idx=self.attn_idx,\n",
    "                            batch_size=self.batch_size, \n",
    "                            unk=tf.nn.embedding_lookup(embed, self.unk),\n",
    "                            isEdit=self.isEdit,\n",
    "                            reward_loss=reward_loss, use_wordAttn=use_wordAttn,\n",
    "                            editRandomlyProb=self.editRandomlyProb, rnn_editProb=self.rnn_editProb,\n",
    "                            dropout_in=self.dropout_in, dropout_out=self.dropout_out,\n",
    "                            useNoise=self.useNoise, alpha=self.alpha)\n",
    "\n",
    "            if useBidirectionalRnn:\n",
    "                self.outputs, self.last_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "                    cell_fw=cell,\n",
    "                    cell_bw=cell,\n",
    "                    dtype=tf.float32,\n",
    "                    sequence_length=self.queries_lens,\n",
    "                    inputs=embed_queries)\n",
    "\n",
    "                # self.last_states contain both forward state\n",
    "                # and backward state.\n",
    "                # We don't use A with bidirectional rnn\n",
    "                # so no need for self.values (action values as calculated by A)\n",
    "                Bstate = tf.concat(\n",
    "                    [tf.slice(self.last_states[0][1], [0,0], [-1, self.num_hidden]), \n",
    "                     tf.slice(self.last_states[1][1], [0,0], [-1, self.num_hidden])], -1)\n",
    "            else:\n",
    "                self.outputs, self.last_states = tf.nn.dynamic_rnn(\n",
    "                    cell=cell,\n",
    "                    dtype=tf.float32,\n",
    "                    sequence_length=self.queries_lens,\n",
    "                    inputs=embed_queries)\n",
    "\n",
    "                # self.values[0]=value for not editing, self.values[1]=value for editing\n",
    "                self.values = tf.slice(self.outputs, [0,0,0], [-1,-1,2])\n",
    "                Bstate = tf.slice(self.last_states[1], [0,0], [-1, self.num_hidden])  \n",
    "\n",
    "\n",
    "        Avars = cell.Avars\n",
    "        self.Avars = {var.name:var for var in Avars}\n",
    "       \n",
    "\n",
    "        if bnorm:\n",
    "            self.scores = self.bnorm_attention(Bstate, Urnn_norm=Urnn_norm, Uatt_norm=Uatt_norm) \n",
    "        else:\n",
    "            self.scores = self.attention(Bstate) \n",
    "\n",
    "\n",
    "        # Cross entophy loss per query in the batch.\n",
    "        self.B_ce = -tf.reduce_sum(\n",
    "                        self.labels*tf.log(self.scores+0.00000001)+\n",
    "                            (1-self.labels)*tf.log((1-self.scores)+0.00000001), \n",
    "                            axis=-1)\n",
    "\n",
    "\n",
    "        # We don't use A with bidirectional rnn\n",
    "        if not useBidirectionalRnn:\n",
    "            # A's decision for each word.\n",
    "            # self.idx[i,j]=1 if word j in query i was edited, else zero.\n",
    "            self.idx = tf.squeeze(tf.slice(self.outputs, [0,0,2], [-1,-1,1]))\n",
    "            \n",
    "            # edit_ratio: Over all ratio of edited words per query\n",
    "            # \n",
    "            self.edit_ratio = tf.reduce_mean(tf.reduce_sum(\n",
    "                tf.cast(self.idx, tf.float32)*tf.expand_dims(\n",
    "                        1/tf.cast(self.queries_lens, tf.float32), axis=1), axis=1))\n",
    "\n",
    "            # After running A for the first time, we get A's decisions and their values.\n",
    "            # we then calulate the following tensors:\n",
    "            # actions_idx[j,i] = 1 if the word i in query j was edited or 0 otherwise.     \n",
    "            # bell_vall holds the values for each decision by the bellman function. \n",
    "            \n",
    "           \n",
    "            '''\n",
    "            Now that we know what actions A took,\n",
    "            we calculate the actual reward per word A gets:\n",
    "            act_rewards[i,j] = idx[i,j]*edit_reward*BCE[i]/queries_lens[i]\n",
    "\n",
    "            If word j in query i was edited then idx[i,j]=1 and:\n",
    "               act_rewards[i,j] = 1*edit_reward*BCE[i]/queries_lens[i]=edit_reward*BCE[i]/queries_lens[i]\n",
    "            else edited idx[i,j]=0 and:\n",
    "               act_rewards[i,j] = 0*edit_reward*BCE[i]/queries_lens[i]=0\n",
    "            \n",
    "            if the word is '<pad>' than act_rewards[i,j]=0 always\n",
    "            '''\n",
    "            q_mask = tf.cast(tf.abs(tf.sign(self.queries)), tf.float32)\n",
    "            act_rewards = q_mask*self.idx*self.reward_holder\n",
    "            self.act_rewards=act_rewards\n",
    "            # Scale B's loss per query, when words were edited. \n",
    "            # We scale all the losses to have mean 1 and std 0.5,\n",
    "            # this gives A a fixed range of (state, action) values\n",
    "            Bce_min = tf.reduce_min(self.B_ce)\n",
    "            Bce_max = tf.reduce_max(self.B_ce)\n",
    "            Bce_scale = (self.B_ce-Bce_min)/(Bce_max-Bce_min)\n",
    "            s = tf.contrib.keras.backend.std(Bce_scale, keepdims=True)\n",
    "            # new_BCE is the scaled B's losses with words edits.\n",
    "            new_BCE = 0.5*Bce_scale/s # 0.5 std\n",
    "            new_BCE = 1 + new_BCE - tf.reduce_mean(new_BCE) # 1 mean\n",
    "            self.new_BCE=new_BCE\n",
    "            # In order to get the values of A's real actions (see self.pyrite_val in __init)\n",
    "            # Tensorflow need us to change idx to a list where each item\n",
    "            # is [number of query x maximum number of words in a query, action (1 or 0 for edit or not respectively)]\n",
    "            self.actions_idx = tf.concat(\n",
    "                                [tf.expand_dims(tf.range(self.batch_size*self.qlen), 1), \n",
    "                                         tf.expand_dims(tf.reshape(tf.cast(self.idx,tf.int32), [-1]), 1)], -1)\n",
    "            \n",
    "            # Now that we have the real actions A took and\n",
    "            # B's loss per query, we can calculate the REAL (word, action) value \n",
    "            # using bellman equation.\n",
    "            self.bell_val = self.discount_rewards(act_rewards, new_BCE)\n",
    "            \n",
    "            # pyrite_val: holds A's predicted values for each of its (word, actions) pair.\n",
    "            # self.pyrite_val[i,j] = \n",
    "            #            self.values[i,j][self.actions_idx[i,j]] = \n",
    "            #                               the value A predicted (i.e. self.values[i,j])\n",
    "            #                               for the action it took (i.e. self.actions_idx[i,j])\n",
    "            #                               at query i word j.\n",
    "            # (see https://en.wikipedia.org/wiki/Pyrite.)\n",
    "            pyrite_val = tf.reshape(tf.gather_nd(tf.reshape(self.values, (-1,2)), \n",
    "                                                      self.actions_idx), (self.batch_size, -1))\n",
    "            \n",
    "            self.pyrite_val=pyrite_val\n",
    "            # RMSE loss between the real bellman value and \n",
    "            # A's predicted values. We mask the loss by zeroing the padded words.\n",
    "            # A smooth factor is added to prevent the gradient from being nan. \n",
    "            self.A_loss = tf.sqrt(tf.reduce_mean(\n",
    "                tf.reduce_sum(tf.square(q_mask*(self.bell_val-pyrite_val)), axis=1)/tf.expand_dims(tf.cast(self.queries_lens, tf.float32), \n",
    "                                                                                              axis=1))+0.00000001)\n",
    "\n",
    "        self.B_loss = tf.reduce_mean(self.B_ce)\n",
    "        self.Agrads = {Avar.name:Gvar for Avar, Gvar in zip(Avars, tf.gradients(self.A_loss, Avars))}\n",
    "        ##############\n",
    "        # Optimizers #\n",
    "        ##############\n",
    "\n",
    "        if not useBidirectionalRnn:\n",
    "            # Train only A variables\n",
    "            A_starter_learning_rate = self.Alr\n",
    "            A_global_step = tf.Variable(0, name='A_global_step', trainable=False)\n",
    "            self.A_learning_rate = tf.train.exponential_decay(A_starter_learning_rate, A_global_step,\n",
    "                                                       decay_steps=decay_steps, decay_rate=decay_rate, staircase=True)\n",
    "        \n",
    "            self.A_optimizer =  tf.train.GradientDescentOptimizer(\n",
    "                    learning_rate=self.A_learning_rate).minimize(self.A_loss, global_step=A_global_step, var_list=Avars)  \n",
    "\n",
    "        # Train only B variables \n",
    "        B_starter_learning_rate = self.Blr\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.learning_rate = tf.train.exponential_decay(B_starter_learning_rate, self.global_step,\n",
    "                                                   decay_steps=decay_steps, decay_rate=decay_rate, staircase=True)\n",
    "\n",
    "        Bvars = [var for var in tf.trainable_variables() if var not in Avars]\n",
    "        self.B_optimizer =  tf.train.GradientDescentOptimizer(\n",
    "                    learning_rate=self.learning_rate).minimize(self.B_loss, global_step=self.global_step, \n",
    "                                                               var_list=Bvars)  \n",
    "\n",
    "        if not os.path.exists(params_dir):\n",
    "                os.makedirs(params_dir)\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "        \n",
    "    def length(self, seq):\n",
    "        '''\n",
    "        Retruns real lengths (before addings) of all queries in seq  .\n",
    "        '''\n",
    "        return tf.cast(tf.reduce_sum(tf.sign(tf.abs(seq)), reduction_indices=1), tf.int32)\n",
    "       \n",
    "\n",
    "    def linear(self, inputs, output_dim, scope='linear', bias=True, reuse=False):\n",
    "\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            W = tf.get_variable('W', initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                shape=(inputs.get_shape()[-1], output_dim))\n",
    "            if bias:\n",
    "                b = tf.get_variable('b', initializer=tf.constant_initializer(0.1),\n",
    "                               shape=[1, output_dim])\n",
    "                return tf.matmul(inputs, W) + b\n",
    "            \n",
    "            return tf.matmul(inputs, W)\n",
    "        \n",
    "    \n",
    "    def Qscale(self, qVecs):\n",
    "        '''\n",
    "        Scale queries embedding vectors to have zero mean and std STD.\n",
    "        \n",
    "        Params:\n",
    "            qVecs: Tensor (shape: batch_size x number_of_hidden_units) \n",
    "                   holding the queries vectors, \n",
    "        '''\n",
    "        qVecs_min = tf.reduce_min(qVecs, axis=-1, keep_dims=True)\n",
    "        qVecs_max = tf.reduce_max(qVecs, axis=-1, keep_dims=True)\n",
    "        qVecs_scale = (qVecs-qVecs_min)/(qVecs_max-qVecs_min) # Scale to 0-1\n",
    "        s = tf.contrib.keras.backend.std(qVecs_scale, axis=-1, keepdims=True)\n",
    "        tmp = self.Qstd * qVecs_scale/s #Scale to have lf.Qstd std\n",
    "        new_qVecs = tmp - tf.reduce_mean(tmp, axis=-1, keep_dims=True) # zero mean\n",
    "        \n",
    "        return new_qVecs\n",
    "        \n",
    "\n",
    "            \n",
    "    def attention(self, q_embed):\n",
    "        '''\n",
    "        Given B's output vector, calculate the attention over \n",
    "        all the query's bounding boxes vectors, That is, calculate:\n",
    "        \n",
    "        probs = softmax(relu(context(Sq+Satt+b)))\n",
    "        \n",
    "        Where:\n",
    "        Sq = <Wq, queries_states>\n",
    "        Sattn = <Wattn, attention_bboxes_vectors>\n",
    "        \n",
    "        The  bounding box with the highest attention score will be chosen as the correct bounding box.\n",
    "        \n",
    "        Params:\n",
    "            q_embed: Tensor of shape (batch size x num_hidden)B's outputs. \n",
    "            \n",
    "        Returns:\n",
    "            probs: Tensor of shape (batch_size x max bbox number for query).\n",
    "                   Attention score for each bbox.\n",
    "        '''\n",
    "        # concatenate img vectors with spaical features\n",
    "        attn_vecs = tf.concat([self.img, self.bboxes], 2)\n",
    "        \n",
    "        # B's outputs, shape: (batch size x num_hidden)\n",
    "        if self.toQscale:\n",
    "            Urnn = self.Qscale(q_embed)\n",
    "        else:\n",
    "            Urnn = q_embed\n",
    "        \n",
    "        # Attention vectors, \n",
    "        # shape: (batch size x max bbox number for query x attention vector size)\n",
    "        Uatt = attn_vecs\n",
    "           \n",
    "        with tf.variable_scope('l1'):\n",
    "            b = tf.get_variable(\n",
    "                    'b', \n",
    "                    initializer=tf.constant_initializer(0.1), \n",
    "                    shape=[1, self.num_hidden])\n",
    "\n",
    "            context = tf.get_variable(\n",
    "                    'context', \n",
    "                    initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1), \n",
    "                    shape=[self.num_hidden, 1])\n",
    "\n",
    "\n",
    "            Sq = tf.nn.dropout(\n",
    "                self.linear(Urnn, self.num_hidden, bias=False, scope='Sq'), \n",
    "                self.dropout_q)\n",
    "            \n",
    "            Sattn = tf.nn.dropout(\n",
    "                tf.reshape(\n",
    "                    self.linear(\n",
    "                        tf.reshape(Uatt, (-1, self.img_dims+self.bbox_dims)), \n",
    "                        self.num_hidden, \n",
    "                        bias=False, scope='Sattn'), \n",
    "                    [self.batch_size, -1, self.num_hidden]),\n",
    "                self.dropout_img)\n",
    "\n",
    "        out = tf.nn.relu(tf.expand_dims(Sq, 1) + Sattn + b)\n",
    "        logits = tf.reshape(tf.matmul(tf.reshape(out, (-1, tf.shape(out)[-1])),  context), (tf.shape(out)[0], -1))\n",
    "\n",
    "        # Calculate logits's masked softmax (we use self.attn_idx to mas\n",
    "        max_logits = tf.reduce_max(logits, axis=-1)\n",
    "        masked_logits = tf.exp(logits-tf.expand_dims(max_logits, axis=1))*self.attn_idx\n",
    "        probs = self.attn_idx*masked_logits/tf.reduce_sum(masked_logits, axis=-1, keep_dims=True)\n",
    "\n",
    "        return probs\n",
    "\n",
    "    \n",
    "    def bnorm_attention(self, q_embed, Urnn_norm=True, Uatt_norm=True):\n",
    "        '''\n",
    "        Given B's output vector, calculate the attention over \n",
    "        all the query's bounding boxes vectors, That is, calculate:\n",
    "        \n",
    "        probs = softmax(relu(context(Sq+Satt+b)))\n",
    "        \n",
    "        Where:\n",
    "        Sq = <Wq, queries_states>\n",
    "        Sattn = <Wattn, attention_bboxes_vectors>\n",
    "        \n",
    "        The  bounding box with the highest attention score will be chosen as the correct bounding box.\n",
    "        This function uses batch normalization. \n",
    "        \n",
    "        Params:\n",
    "            q_embed: Tensor of shape (batch size x num_hidden)B's outputs. \n",
    "            Urnn_norm: Whether to use batch normalization for the queries.\n",
    "            Uatt_norm: Whether to use batch normalization for the VGG outputs.\n",
    "            \n",
    "        Returns:\n",
    "            probs: Tensor of shape (batch_size x max bbox number for query).\n",
    "                   Attention score for each bbox.\n",
    "        '''\n",
    "        # concatenate img vectors with with spaical features\n",
    "        attn_vecs = tf.concat([self.img, self.bboxes], 2)\n",
    "        if self.toQscale:\n",
    "            q_embed = self.Qscale(q_embed)\n",
    "            \n",
    "        Urnn = q_embed\n",
    "        Uatt = attn_vecs\n",
    "        \n",
    "        if Urnn_norm:\n",
    "            # B's outputs with bath normalization. \n",
    "            # shape: (batch size x num_hidden)\n",
    "            Urnn = tf.contrib.layers.batch_norm(\n",
    "                q_embed, center=True, scale=True, is_training=self.isTrain) \n",
    "        \n",
    "        if Uatt_norm:\n",
    "            # Attention vectors with bath normalization. \n",
    "            # shape: (batch size x max bbox number for query x attention vector size)\n",
    "            Uatt = tf.contrib.layers.batch_norm(\n",
    "                attn_vecs, center=True, scale=True, is_training=self.isTrain)\n",
    "           \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            with tf.variable_scope('bnorm_l1'):\n",
    "                b = tf.get_variable(\n",
    "                        'b', \n",
    "                        initializer=tf.constant_initializer(0.1), \n",
    "                        shape=[1, self.num_hidden])\n",
    "\n",
    "                context = tf.get_variable(\n",
    "                        'context', \n",
    "                        initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1), \n",
    "                        shape=[self.num_hidden, 1])\n",
    "\n",
    "\n",
    "                Sq = tf.nn.dropout(\n",
    "                    self.linear(Urnn, self.num_hidden, bias=False, scope='Sq'), \n",
    "                    self.dropout_q)\n",
    "                \n",
    "                Sattn = tf.nn.dropout(\n",
    "                            tf.reshape(\n",
    "                                self.linear(\n",
    "                                    tf.reshape(Uatt, (-1, self.img_dims+self.bbox_dims)), \n",
    "                                    self.num_hidden, \n",
    "                                    bias=False, scope='Sattn'), \n",
    "                                 [self.batch_size, -1, self.num_hidden]),\n",
    "                            self.dropout_img)\n",
    "                    \n",
    "                   \n",
    "            out = tf.nn.relu(tf.expand_dims(Sq, 1) + Sattn + b)\n",
    "            logits = tf.reshape(tf.matmul(tf.reshape(out, (-1, tf.shape(out)[-1])),  context), (tf.shape(out)[0], -1))\n",
    "\n",
    "            # Calculate logits's masked softmax (we use self.attn_idx to mas\n",
    "            max_logits = tf.reduce_max(logits, axis=-1)\n",
    "            masked_logits = tf.exp(logits-tf.expand_dims(max_logits, axis=1))*self.attn_idx\n",
    "            probs = self.attn_idx*masked_logits/tf.reduce_sum(masked_logits, axis=-1, keep_dims=True)\n",
    "\n",
    "            return probs\n",
    "  \n",
    "        \n",
    "    def q_padding(self, seq, max_length):\n",
    "        '''\n",
    "        Pad  seq with vocab['<pad>'] (0) to max_length length.\n",
    "        '''                  \n",
    "        return seq + [self.vocab['<pad>']]*(max_length-len(seq))\n",
    "\n",
    "    \n",
    "    def build_data(self, data, start, end, imScale, addNoiseImg=False):\n",
    "        '''\n",
    "        Build batch.\n",
    "        ------------\n",
    "        \n",
    "        Params:\n",
    "            data: each entry in this list has the following structure:\n",
    "                  [query indexes, [bounding box vector (VGG), bounding box spaital features], ..., \n",
    "                  [bounding box vector (VGG), bounding box spaital features], index of the true label]\n",
    "                  \n",
    "            start/end: batch data is built from data[start:end]\n",
    "            \n",
    "        Returns:\n",
    "            attn_idx: attn_idx[i, j]=1 if the j'th bbox in the i'th query is not padding, else equals to 0. \n",
    "            \n",
    "            padded_queries: list of queries, padded to the length of the longest query in the batch.\n",
    "                            Note: vocab['pad']=0\n",
    "                            \n",
    "            padded_im: list of bounding boxes vectors, padded to the maximum number of bbox per query.\n",
    "                       Note: padded vector is vector of zeros. \n",
    "                            \n",
    "            padded_bbox: list of bounding boxes spatial features, padded to the maximum number of bbox per query.\n",
    "                         Note: padded vector is vector of zeros.  \n",
    "        \n",
    "            onehot_labels: onehot_labels[i][j]=1 if j is the true bbox for query i, else  onehot_labels[i][j]=0\n",
    "            \n",
    "            addNoiseImg: Boolean. Whether to add normal noise to the images.\n",
    "            \n",
    "            imScale: If not None, scale the image vectors (VGG16 outputs) to have 0 mean and imScale std\n",
    "                        \n",
    "        '''\n",
    "                          \n",
    "        qlen = max([len(data[i][0]) for i in range(start, end)]) # Length fo the longest query\n",
    "        imlen = max([len(data[i]) for i in range(start, end)])-2 # Maximum number of bbox per query.\n",
    "        padded_queries, padded_im, padded_bbox, attn_idx = [], [], [], []\n",
    "        \n",
    "        # Build one hot labels from the labels index, given in the data.                  \n",
    "        labels = [item[-1] for item in data[start:end]] #data[i][-1]=index of the true bbox of query i\n",
    "        dist_labels = np.zeros((end-start, imlen)) #label distribution\n",
    "        \n",
    "        # Real data points\n",
    "        dist_labels[[i for i in np.arange(end-start) if labels[i]>0], [l for l in labels if l>0]]=1\n",
    "        \n",
    "        # augmented data points\n",
    "        for i in np.arange(end-start):\n",
    "            if labels[i]<0:\n",
    "                dist_labels[i] = [-1/labels[i] for _ in range(-labels[i])]+[0. for _ in range(imlen+labels[i])]\n",
    "                          \n",
    "        im_dim, bbox_dim = data[0][1][0].shape[1], data[0][1][1].shape[1]\n",
    "        for i in range(start, end):\n",
    "            padded_queries.append(self.q_padding(data[i][0], qlen))\n",
    "            \n",
    "            attn_idx.append([1 for _ in range(len(data[i])-2)]+[0 for _ in range(imlen-(len(data[i])-2))])\n",
    "            \n",
    "            padded_im.append(np.concatenate([data[i][j][0] for j in range(1, len(data[i])-1)] + \n",
    "                                       [np.full((imlen-(len(data[i])-2), im_dim), vocab['<pad>'], dtype=np.float32)], axis=0))\n",
    "            \n",
    "            padded_bbox.append(np.concatenate([data[i][j][1] for j in range(1, len(data[i])-1)] + \n",
    "                                       [np.full((imlen-(len(data[i])-2),bbox_dim), vocab['<pad>'], dtype=np.float32)], axis=0))\n",
    "           \n",
    "        \n",
    "        \n",
    "        if addNoiseImg:\n",
    "            padded_im+=(padded_im+np.random.normal(0, .1, np.array(padded_im).shape))*np.expand_dims(attn_idx, 2)\n",
    "        else:\n",
    "            padded_im=np.array(padded_im)\n",
    "            \n",
    "        if imScale is not None:\n",
    "            # Smoothing factor\n",
    "            halper = (1-np.expand_dims(np.array(attn_idx).astype(np.float32), 2))\n",
    "            img_min = np.min(padded_im, axis=-1, keepdims=True)\n",
    "            img_max = np.max(padded_im, axis=-1, keepdims=True)\n",
    "            img_scale = (padded_im-img_min)/((img_max-img_min)+halper) # Scale to 0-1\n",
    "            s = np.std(img_scale, axis=-1, keepdims=True)\n",
    "            padded_im = imScale*img_scale/(s+halper)  #Scale to have imScale std\n",
    "            padded_im = padded_im - np.mean(padded_im, axis=-1, keepdims=True) # scale to zero mean\n",
    "            \n",
    "        return qlen, np.array(attn_idx), np.array(padded_queries, dtype=np.int32), padded_im, np.array(padded_bbox), np.array(dist_labels)\n",
    "            \n",
    "   \n",
    "    def ground(self, data=None, start=None, end=None, sess=None, feed_dict = None, isEdit=True, imScale=False, addNoiseImg=False):\n",
    "        '''\n",
    "        Given a query and a list of bboxes, the function returns the index of the referred bbox.\n",
    "        '''\n",
    "        isSess = (sess==None)\n",
    "        if isSess:\n",
    "            sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            if isSess:\n",
    "                tf.global_variables_initializer().run()\n",
    "                ckpt = tf.train.get_checkpoint_state(params_dir)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    self.saver.restore(sess, ckpt.model_checkpoint_path) # restore all variables\n",
    "                else:\n",
    "                    print('Initializing variables')\n",
    "            if feed_dict is None:\n",
    "                qlen, attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(data, start, end, \n",
    "                                                                                                 imScale=imScale, addNoiseImg=addNoiseImg)\n",
    "                feed_dict = {\n",
    "                        self.qlen:qlen,\n",
    "                        self.queries:padded_queries,\n",
    "                        self.img:padded_im,\n",
    "                        self.bboxes:padded_bbox,\n",
    "                        self.labels:labels,\n",
    "                        self.attn_idx:attn_idx\n",
    "                    }\n",
    "            feed_dict[self.isTrain]=False\n",
    "            feed_dict[self.isEdit] = isEdit\n",
    "            feed_dict[self.dropout_in]=1.\n",
    "            feed_dict[self.dropout_out]=1.\n",
    "            feed_dict[self.dropout_img]=1.\n",
    "            feed_dict[self.dropout_q]=1.\n",
    "            scores = sess.run(self.scores, feed_dict=feed_dict) # get score for each bbox\n",
    "\n",
    "        return np.argmax(scores, axis=1), np.argmax(feed_dict[self.labels], axis=1)\n",
    "        \n",
    "        \n",
    "    def iou_accuracy(self, data, start, end, imScale, sess=None, feed_dict = None, addNoiseImg=False, \n",
    "                     threshold=0.5, test=False, isEdit=True, scores=[], labels=[]):\n",
    "        '''\n",
    "        Calculate the IOU score between the Model bbox and the true bbox.\n",
    "        ''' \n",
    "        # Get score for each bbox (labels) and the true bbox index (gt_idx)  \n",
    "        if len(scores)!=0  and len(labels)!=0:\n",
    "            labels, gt_idx = np.argmax(scores, axis=1), np.argmax(labels, axis=1)\n",
    "        else:             \n",
    "            if feed_dict is None:\n",
    "                labels, gt_idx = self.ground(data, start, end, sess=sess, feed_dict=feed_dict, \n",
    "                                             isEdit=isEdit, imScale=imScale,addNoiseImg=addNoiseImg)\n",
    "            else: labels, gt_idx = self.ground(sess=sess, feed_dict=feed_dict, \n",
    "                                               isEdit=isEdit, imScale=imScale, addNoiseImg=addNoiseImg)\n",
    "            \n",
    "        acc = 0\n",
    "        for i in range(start, end):\n",
    "            gt = data[i][gt_idx[i-start]+1][1][0] # ground truth bbox\n",
    "            crops = np.expand_dims(data[i][labels[i-start]+1][1][0], axis=0) #Model chosen bbox\n",
    "            acc += (retriever.compute_iou(crops, gt)[0]>threshold) #IOU for the i sample.\n",
    "            \n",
    "        return acc/(end-start)\n",
    "        \n",
    "    def accuracy(self, imScale, data=None, start=None, end=None, sess=None, feed_dict = None, isEdit=True, addNoiseImg=False):\n",
    "        isSess = (sess==None)\n",
    "        if isSess:\n",
    "            print('Building sess')\n",
    "            sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            if isSess:\n",
    "                print('Building sess used')\n",
    "                tf.global_variables_initializer().run()\n",
    "                ckpt = tf.train.get_checkpoint_state(params_dir)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    print('3')\n",
    "                    self.saver.restore(sess, ckpt.model_checkpoint_path) # restore all variables\n",
    "                else:\n",
    "                    print('Initializing variables')\n",
    "            if feed_dict is None:\n",
    "                print('Building feed_dict')\n",
    "                qlen, attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(data, start, end, \n",
    "                                                                                                 imScale=imScale, addNoiseImg=addNoiseImg)\n",
    "                feed_dict = {\n",
    "                        self.qlen:qlen,\n",
    "                        self.queries:padded_queries,\n",
    "                        self.img:padded_im,\n",
    "                        self.bboxes:padded_bbox,\n",
    "                        self.attn_idx:attn_idx,\n",
    "                        self.labels:labels,\n",
    "                    }\n",
    "                \n",
    "            feed_dict[self.isTrain]=False\n",
    "            feed_dict[self.isEdit] = isEdit\n",
    "            feed_dict[self.dropout_in]=1.\n",
    "            feed_dict[self.dropout_out]=1.\n",
    "            feed_dict[self.dropout_img]=1.\n",
    "            feed_dict[self.dropout_q]=1.\n",
    "            scores = sess.run(self.scores, feed_dict=feed_dict)\n",
    "            acc = sum(np.equal(np.argmax(scores, axis=1), np.argmax(feed_dict[self.labels], axis=1))/len(feed_dict[self.labels]))\n",
    "\n",
    "                    \n",
    "        return acc\n",
    "    \n",
    "    def discount_rewards(self, rewards, last_rewards, gamma=1.0):\n",
    "        \"\"\" \n",
    "        take 1D float array of rewards and compute discounted reward \n",
    "        using bellman function, i.e. for some query:\n",
    "                \n",
    "                value_(time step t) = rewards[t] + gamma*values_(time step t+1)\n",
    "    \n",
    "        We need to iterate over the rewards tensor, which is tricky \n",
    "        with Tensorflow, specially when the query maximum length (rewards.shape[1])\n",
    "        can change at each iteration.\n",
    "        \n",
    "        We start with initializer tensor with shape (batch_size+1) x self.qlen.\n",
    "        The first vector in initializer is BCE (B's loss per query) all the other \n",
    "        vectors are zero vectors, that is:\n",
    "        \n",
    "        initializer[0][i] is B's loss for query i.\n",
    "        initializer[1:batch_size] are all zero vectors.\n",
    "        \n",
    "        This is doen since tf.foldl does not allow the shape of the function accumulator (bell_vals) to change.\n",
    "        We then use tf.foldl function to go over all the words in reverse (see tf.range(self.qlen)[::-1] in \n",
    "        tf.foldl below). tf.foldl initialize fn's argument, bell_vals, with initializer and change it at each iteration.\n",
    "        \n",
    "        params:\n",
    "            rewards: rewards[i,j] is the reward for the action A took on word j at query i.\n",
    "            last_rewards: last_rewards[i] is B's loss for query i with no edits. This is the final reward.\n",
    "            gamma: discount factor.\n",
    "        \"\"\"\n",
    "                 \n",
    "        initializer = tf.concat(\n",
    "            [tf.expand_dims(last_rewards,1), tf.zeros(shape=(self.batch_size, self.qlen), dtype=tf.float32)], 1)\n",
    "        \n",
    "        def fn(bell_vals, time_steps):\n",
    "            '''\n",
    "            calculate bellman function.\n",
    "            \n",
    "            returns: \n",
    "                bell_vals: Tensor where bell_vals[i][t] is the value for word t in query i. \n",
    "            \n",
    "            algorithm description:\n",
    "                initialization: bell_vals=intitializer.\n",
    "                for time_step in range(maximum_time_step-1, 0, -1):\n",
    "                    1. val_ts = rewards[:,time_step]+bell_vals[0] (time step t values at each query)\n",
    "                    2. bell_vals = bell_vals[:,:-1] (pop last column (zero vector) from bell_vals)\n",
    "                    3. push (concatenate) rewards_ts to the begining of bell_vals so that\n",
    "                       bell_vals[0] = val_ts (time step t values)\n",
    "                    \n",
    "                \n",
    "            '''\n",
    "            \n",
    "            val_ts = tf.slice(bell_vals, [0, 0], [-1, 1]) + tf.slice(rewards, [0, time_steps], [-1 ,1])\n",
    "            bell_vals = tf.concat([val_ts, bell_vals[:,:-1]], 1)\n",
    "            return bell_vals\n",
    "        \n",
    "        bell_vals = tf.foldl(fn, tf.range(self.qlen)[::-1], initializer=initializer)[:,:-1]\n",
    "        \n",
    "        return bell_vals\n",
    "        \n",
    "    def train(self, trn_data, tst_data, val_data, ephocs_num, edit_reward, startA=10, \n",
    "              activation_ephoc=19, muteBnum=3, start_ephoc=0, dropout_in=1., rnn_editProb=0.2,\n",
    "              dropout_out=1., dropout_img=1., dropout_q=1., queries_editProb=0.95,  \n",
    "              addNoiseImg=False, imScale=None, Alr=0.1, Blr=0.05):\n",
    "                          \n",
    "        '''\n",
    "        Params:\n",
    "            trn_data: list, train set. \n",
    " \n",
    "            tst_data: list, test set.\n",
    "            \n",
    "            val_data: list, validation data.\n",
    "                      At each ephoc>activation_ephoc, if we don't train\n",
    "                      B at this ephoc than we run the model twice on val_data:\n",
    "                      \n",
    "                      * The first time no action will be chosen randomly. \n",
    "                        We calculate Bloss (ABloss) and the average ratio of \n",
    "                        edited words per query (p). \n",
    "                      * Then, at the second run, all the actions are chosen\n",
    "                        randomly with probability of p to edit a word. Again, we\n",
    "                        calculate B's loss (RandBloss)\n",
    "                        \n",
    "                      We then define A's gain at ephoc ep as:\n",
    "                          AGain_ep = ABloss_ep - RandBloss_ep\n",
    "                          \n",
    "                      If AGain_ep<AGain_(ep-1) we reduce A's learning rate\n",
    "                      and aventialy stop A training but keep training B with A's\n",
    "                      edits.\n",
    "             \n",
    "            ephocs_num: number of ephocs\n",
    "             \n",
    "            start_ephoc: number of first ephoc.\n",
    "             \n",
    "            edit_reward: int, coefficient to multiply the reward by when editing a word.\n",
    "             \n",
    "            startA: int, Start competition only at ephoc # startA.\n",
    "             \n",
    "            muteBnum: After A starts, for each ephoc which A & B trains, \n",
    "                      only A will be trained for this amount of ephocs.\n",
    "                   \n",
    "            activation_ephoc: at ephoc numer \"activation_ephoc\", A will be activate.\n",
    "                               That is, for (activation_ephoc-startA) number of ephocs, \n",
    "                               A will choose an action randomly and train only when B \n",
    "                               does not (see muteBnum argument).\n",
    "                   \n",
    "            queries_editProb: probabilty for editing a query.\n",
    "            \n",
    "            rnn_edit_prob: If the action is chosen randomly. edit with probability of rnn_editProb\n",
    "            \n",
    "            dropout_in: dropout ratio of B's rnn inputs.\n",
    "            \n",
    "            dropout_output: dropout ratio of B's rnn output.\n",
    "            \n",
    "            dropout_img: dropout ratio of images vectors before the last attention layer .\n",
    "            \n",
    "            addNoiseImg: Boolean. Whether to add normal noise to the images (see build_data).\n",
    "            \n",
    "            imScale: If not None, scale the image vectors (VGG16 outputs) to have 0 mean and 1/imScale std\n",
    "            \n",
    "            Alr: A's learning rate\n",
    "            \n",
    "            Blr: B's learning rate\n",
    "                               \n",
    "        '''                  \n",
    "        \n",
    "        trn_nbatch = len(trn_data)\n",
    "        tst_nbatch = len(tst_data)\n",
    "        val_nbatch = len(val_data)\n",
    "        print('# Train set size:', sum([len(batch) for batch in trn_data]))\n",
    "        print('# Training batches:', trn_nbatch)\n",
    "        print('# Validation set size:', sum([len(batch) for batch in val_data]))\n",
    "        print('# Validation batches:', val_nbatch)\n",
    "        print('# Test set size:', sum([len(batch) for batch in tst_data]))\n",
    "        print('# Testing batches:', tst_nbatch)\n",
    "        self.test_res, self.train_res, self.val_res = [], [], [] #list to hold reults for train, test and validation sets\n",
    "        \n",
    "        # Holds different between validation B loss with and without random actions selections (see val_data in params)\n",
    "        self.AGain = []\n",
    "        \n",
    "        Nrounds = 1 # number of time editRandomlyProb was decreased (see below for details)\n",
    "        AlrDecreaseNum = 0 # number of time we've decrease A's learing rate\n",
    "        \n",
    "        # When AlrDecreaseNum=maxDecreaseNum stop training A (toTrainA=False)\n",
    "        # but keeping using it for B training.\n",
    "        maxDecreaseNum = 6 \n",
    "        toTrainA = True\n",
    "        rnn_editProb_tmp = rnn_editProb\n",
    "        \n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            tf.global_variables_initializer().run()\n",
    "            ckpt = tf.train.get_checkpoint_state(params_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                print('Loading parameters from', ckpt.model_checkpoint_path)\n",
    "                self.saver.restore(sess, ckpt.model_checkpoint_path) # restore all variables\n",
    "            else:\n",
    "                print('Initializing variables')\n",
    "                \n",
    "            for ephoc in range(start_ephoc, ephocs_num):\n",
    "                startTime = datetime.now().replace(microsecond=0)\n",
    "                          \n",
    "                # Start training A only at ephooc number startA. \n",
    "                # when ephoc>=startA, each time we train B we train \n",
    "                # only A for muteBnum ephocs, so at ephoc startA, only \n",
    "                # A will train for muteBnum ephocs and B will only then be trained again.\n",
    "                toTrainB = toTrainA==False or ephoc<startA or (ephoc-(startA-1))%(muteBnum+1)==0 # Whether to train only B \n",
    "                  \n",
    "                '''\n",
    "                If activation_ephoc> ephoc >=startA, A will always choose an action\n",
    "                randomly (i.e. editRandomlyProb=1) and will not edit words while B\n",
    "                is training. At ephoc 'activation_ephoc', editRandomlyProb will decrease \n",
    "                and an action will be chosen randomly only if only A is training, in \n",
    "                other words, when B is training editRandomlyProb will always be 0.\n",
    "                \n",
    "                If ephoc >=activation_ephoc, after each round (in each round we train only A \n",
    "                for muteBnum ephocs and then B for one ephoc, so each round takes muteBnum+1 epohocs\n",
    "                and the first round start at ephoc startA), the probability for choosing an action \n",
    "                randomly will decrease:\n",
    "                let Nrounds be the number of time editRandomlyProb was decreased so far \n",
    "                (Nrounds initialize to be 1), than for every rounds:\n",
    "                    Nrounds+=1\n",
    "                    editRandomlyProb = 1/Nrounds\n",
    "                    \n",
    "                While training B we never choose an action randomly.\n",
    "                    \n",
    "                Note that we set activation_ephoc so that (activation_ephoc-startA)%(muteBnum+1)=0\n",
    "                thereby insuring that editRandomlyProb will start decreasing at the begining of\n",
    "                a round and won't decrease during the following round.\n",
    "                '''\n",
    "                assert (activation_ephoc-startA)%(muteBnum+1)==0, 'activation_ephoc-(startA-1) mod %d != 0'%(muteBnum+1)\n",
    "                editRandomlyProb=0\n",
    "                # editRandomlyProb: Probabilty for choosing an action (edit or not) randomly, \n",
    "                if ephoc>=activation_ephoc and (toTrainB or not toTrainA):\n",
    "                    # Never choose an action randomly if training B or \n",
    "                    # A stoped its training (toTrainA=False).\n",
    "                    # If ephoc<activation_ephoc we set isEdit to False\n",
    "                    # when training B hence no words will be edited \n",
    "                    # during B's training any way, only A training \n",
    "                    # will be effected so we can ignore this case.\n",
    "                    editRandomlyProb=0\n",
    "#                 else:\n",
    "#                     if (ephoc-startA)%(muteBnum+1)==0: # If this is true toTrainB=False\n",
    "#                         Nrounds+=1 \n",
    "#                     editRandomlyProb=1/Nrounds\n",
    "                    \n",
    "                        \n",
    "                # When we train B, we show B's results on the trainset \n",
    "                # with edits (itrInEphoc=1) and without (itrInEphoc=2)\n",
    "                itrInEphoc=1 \n",
    "                if ephoc>=startA and toTrainB:\n",
    "                    # we show B's results on the trainset without edits\n",
    "                    itrInEphoc=2\n",
    "                    \n",
    "                print('='*50,'\\nTRAIN, ephoc:%d; Training B:%s; A is a know-it-all:%s; ActivateA:%s'%(ephoc, toTrainB, \n",
    "                                                                                                      toTrainA==False, \n",
    "                                                                                                      ephoc>=activation_ephoc))\n",
    "                np.random.shuffle(trn_data)\n",
    "                for ep in range(itrInEphoc):\n",
    "                    A_trn_loss, B_trn_loss, trn_acc, trn_iou = 0, 0, 0, 0\n",
    "                    ephoc_edits_ratio = 0 # edited words per query average\n",
    "                    tst_loss, tst_acc, tst_iou = 0, 0, 0\n",
    "                    if ep==1:\n",
    "                        # If ep=1, we're in round 2 in which we only show B's \n",
    "                        # results with out editing (on the train set).\n",
    "                        print('No Edit')\n",
    "                        print('ooooooo')\n",
    "                        \n",
    "                    \n",
    "                    # There's a probability of 1-queries_editProb that B will be trained \n",
    "                    # with no edits in a batch. \n",
    "                    # editRount_count counts the number of batches with competition.\n",
    "                    editRount_count = 0 \n",
    "                    for b in range(trn_nbatch):\n",
    "                        if ep==1:\n",
    "                            # If ep=1, we're in round 2 in which we only show B's \n",
    "                            # results with out editing (on the train set).\n",
    "                            isEdit=False\n",
    "                        else:\n",
    "                            # Edit queries in this \n",
    "                            # batch with probability of queries_editProb else don't edit.\n",
    "                            isEdit = toTrainB==False or np.random.rand(1)[0]<queries_editProb\n",
    "                            \n",
    "                            # If ephoc<startA train A with no edits\n",
    "                            if ephoc<startA:\n",
    "                                editRandomlyProb=1.\n",
    "                                rnn_editProb=0.\n",
    "                            else:\n",
    "                                rnn_editProb=rnn_editProb_tmp\n",
    "                        \n",
    "                        np.random.shuffle(trn_data[b])\n",
    "                        qlen, attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(trn_data[b], \n",
    "                                                                                            0, \n",
    "                                                                                            self.batch_size, \n",
    "                                                                                            addNoiseImg=addNoiseImg,\n",
    "                                                                                            imScale=imScale)\n",
    "                \n",
    "                        feed_dict = {\n",
    "                            self.qlen:qlen,\n",
    "                            self.queries:padded_queries,\n",
    "                            self.img:padded_im,\n",
    "                            self.bboxes:padded_bbox,\n",
    "                            self.attn_idx:attn_idx,\n",
    "                            self.labels: labels,\n",
    "                            self.unk:np.array([[vocab['<unk>']]]),\n",
    "                            self.isEdit:isEdit,\n",
    "                            self.reward_holder:np.array([[0.] for _ in range(self.batch_size)]), # dummy holder \n",
    "                            self.BCE_holder:np.array([[0.] for _ in range(self.batch_size)]), # dummy holder \n",
    "                            self.Aattn_vecs:[[[]]],# dummy holder \n",
    "                            self.dropout_in:dropout_in,\n",
    "                            self.dropout_out:dropout_out,\n",
    "                            self.dropout_img:dropout_img,\n",
    "                            self.dropout_q:dropout_q,\n",
    "                            self.editRandomlyProb:editRandomlyProb,\n",
    "                            self.rnn_editProb:rnn_editProb,\n",
    "                            self.Alr:Alr,\n",
    "                            self.Blr:Blr,\n",
    "                            self.isTrain:True\n",
    "                        }\n",
    "                        \n",
    "                        \n",
    "                        if isEdit:\n",
    "                            editRount_count+=1\n",
    "\n",
    "                            # We first run B with no edit in order to get it's loss, which will be given to A,\n",
    "                            # and outputs, which A will use attention mechanism over them.   \n",
    "                            feed_dict[self.isEdit] = False\n",
    "                            queries_lens, B_ce, outputs = sess.run([self.queries_lens, self.B_ce, self.outputs], feed_dict=feed_dict)\n",
    "                            feed_dict[self.isEdit] = True\n",
    "                            \n",
    "                            # B_ce contain the cross entrophy loss for each query.\n",
    "                            # We scale all the losses to have mean 1 and std 0.5,\n",
    "                            # this gives A a fixed range of (state, action) values\n",
    "                            Bce_min = min(B_ce)\n",
    "                            Bce_max = max(B_ce)\n",
    "                            Bce_scale = (B_ce-Bce_min)/(Bce_max-Bce_min)\n",
    "                            s = np.std(Bce_scale)\n",
    "                            # BCE is the scaled B's losses\n",
    "                            BCE = 0.5*Bce_scale/s\n",
    "                            BCE = 1 + BCE - np.mean(BCE)\n",
    "                          \n",
    "                            # Reward for edit a word = edit_reward*BCE/queries_lens.\n",
    "                            # A's get the reward for edit a word and loss per query as 2 of its features.\n",
    "                            feed_dict[self.reward_holder]=np.expand_dims(edit_reward*BCE/queries_lens, 1)\n",
    "                            feed_dict[self.BCE_holder]=np.expand_dims(BCE, 1)\n",
    "                           \n",
    "                            \n",
    "                            # A's attention vectors are B's outputs \n",
    "                            # when not words were edited (for all time steps).\n",
    "                            Aattn_vecs = outputs[:,:,:self.num_hidden]\n",
    "                            feed_dict[self.Aattn_vecs]=Aattn_vecs\n",
    "                           \n",
    "                            # Next we run B with edits. Now we have everything we need to train A.\n",
    "                            # Note that we din't optemize A or B yet, hence \n",
    "                            # B will losses and un-edited outputs is still relevent\n",
    "                            if toTrainA:\n",
    "                                gs, scores, batch_Alr, batch_Blr, B_loss, batch_edit_ratio, A_loss, _ = sess.run(\n",
    "                                    [self.global_step, self.scores, self.A_learning_rate, self.learning_rate,\n",
    "                                         self.B_loss, self.edit_ratio, self.A_loss, self.A_optimizer], feed_dict=feed_dict)\n",
    "                                \n",
    "                               \n",
    "                            else:\n",
    "                                gs, scores, batch_Blr, B_loss, batch_edit_ratio, A_loss, _ = sess.run([self.global_step, self.scores, self.learning_rate, self.B_loss, \n",
    "                                                                                                    self.edit_ratio, self.A_loss, self.B_optimizer], \n",
    "                                                                                               feed_dict=feed_dict)\n",
    "                                \n",
    "                            # After calculating A results we  want to see\n",
    "                            # B results in this context, therefore we calulate B\n",
    "                            # metrics before optimizing it.\n",
    "                            # In ep=1 we'll see B loss for the unedited inputs.\n",
    "                            acc = sum(np.equal(np.argmax(scores, axis=1), np.argmax(labels, axis=1))/len(labels))\n",
    "                            iou_acc = self.iou_accuracy(\n",
    "                                trn_data[b], 0, self.batch_size, imScale=imScale, addNoiseImg=addNoiseImg,\n",
    "                                sess=sess, feed_dict=feed_dict, isEdit=isEdit, scores=scores, labels=labels)\n",
    "\n",
    "                            trn_acc += acc/trn_nbatch\n",
    "                            A_trn_loss += A_loss\n",
    "                            B_trn_loss += B_loss/trn_nbatch\n",
    "                            trn_iou += iou_acc/trn_nbatch\n",
    "                            ephoc_edits_ratio += batch_edit_ratio\n",
    "                            \n",
    "                            # Optimize B separately from A to insure the correct flow\n",
    "                            if toTrainB and toTrainA:\n",
    "                                if ephoc<activation_ephoc:\n",
    "                                    # if ephoc<activation_ephoc all actions\n",
    "                                    # are chosen randomly and we don't edit words \n",
    "                                    # while B is training.\n",
    "                                    isEdit = False\n",
    "                                    feed_dict[self.isEdit]=isEdit\n",
    "                                    \n",
    "                                batch_Blr, gs, _ = sess.run(\n",
    "                                    [self.learning_rate, self.global_step, self.B_optimizer], \n",
    "                                    feed_dict=feed_dict)\n",
    "                            if b%50==0:\n",
    "                                if toTrainA==0:\n",
    "                                    batch_Alr=-1\n",
    "                                print( 'Edit:', isEdit, \n",
    "                                      ';batch:%s'%(b), ';gs:%d'%(gs), ';Blr: %.3f'%(batch_Blr), \n",
    "                                      ';Alr:%.3f'%(batch_Alr), ';ERP:%.2f'%(editRandomlyProb),\n",
    "                                      ';Bloss:%.3f'%(B_loss), ';Aloss:%.3f'%(A_loss), \n",
    "                                      ';edits ratio:%.3f'%(batch_edit_ratio), ';acc:%.3f'%(acc), \n",
    "                                      ';iou:%.3f'%(iou_acc), ';time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "                                        \n",
    "                        else: # isEdit=False\n",
    "                            if ep==0:\n",
    "                                B_loss, lr, gs, _ = sess.run([self.B_loss, self.learning_rate, \n",
    "                                                                self.global_step, self.B_optimizer], feed_dict=feed_dict)\n",
    "                            else: \n",
    "                                # just show results of B with no edits\n",
    "                                B_loss, lr, gs = sess.run([self.B_loss, self.learning_rate, self.global_step], feed_dict=feed_dict)\n",
    "\n",
    "                            acc = self.accuracy(sess=sess, feed_dict=feed_dict, isEdit=isEdit, imScale=imScale, addNoiseImg=addNoiseImg)  \n",
    "                            iou_acc = self.iou_accuracy(trn_data[b], 0, self.batch_size, imScale=imScale,\n",
    "                                                        sess=sess, feed_dict=feed_dict, isEdit=isEdit, addNoiseImg=addNoiseImg)\n",
    "\n",
    "                            trn_acc += acc/trn_nbatch\n",
    "                            B_trn_loss += B_loss/trn_nbatch\n",
    "                            trn_iou += iou_acc/trn_nbatch\n",
    "\n",
    "                            if b%50==0:\n",
    "                                print('Edit:', isEdit, \n",
    "                                      ';batch:', b, ';gs:', gs, ';Blr: %.3f'%(lr), \n",
    "                                      ';B loss: %.3f'%(B_loss),  ';acc: %.3f'%(acc), \n",
    "                                      ';iou: %.3f'%(iou_acc),';time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "\n",
    "                    if editRount_count>0: \n",
    "                        # If we edited any words during this ephoc,\n",
    "                        # if ephoc <startA we don't.\n",
    "                        print('\\n*B Train loss: %.3f'%(B_trn_loss), \n",
    "                              ';A Train loss: %.3f'%(A_trn_loss/editRount_count),\n",
    "                              ';Edit ratio: %.3f'%(ephoc_edits_ratio/editRount_count), \n",
    "                              ';Train accuracy: %.3f'%(trn_acc),  ';IOU accuracy: %.3f'%(trn_iou), \n",
    "                              ';Time:', datetime.now().replace(microsecond=0)-startTime, '\\n')\n",
    "                        self.train_res.append([trn_acc, trn_iou, B_trn_loss, A_trn_loss/editRount_count])\n",
    "                    else:\n",
    "                        print('\\n*B Train loss: %.3f'%(B_trn_loss),\n",
    "                              ';Train accuracy: %.3f'%(trn_acc), \n",
    "                              ';IOU accuracy: %.3f'%(trn_iou),  \n",
    "                              ';Time:', datetime.now().replace(microsecond=0)-startTime, '\\n')\n",
    "                        self.train_res.append([trn_acc, trn_iou, B_trn_loss, 0])\n",
    "                self.saver.save(sess, params_dir + \"/model.ckpt\", global_step=ephoc)    \n",
    "                \n",
    "#                 print('GRADS:')\n",
    "#                 print('#'*100)\n",
    "#                 for item in Agrads.items():\n",
    "#                     print(item[0])\n",
    "#                     print(item[1], '\\n')\n",
    "#                 print('#'*100, '\\n')\n",
    "#                 print('VARS:')\n",
    "#                 print('#'*100)\n",
    "#                 for item in Avars.items():\n",
    "#                     print(item[0])\n",
    "#                     print(item[1], '\\n')\n",
    "#                 print('#'*100, '\\n')\n",
    "\n",
    "\n",
    "                if toTrainB==False:\n",
    "                    print('VALIDATION, ephoc:',ephoc)\n",
    "                    print('-'*len('VALIDATION, ephoc: %d'%(ephoc)))\n",
    "                    '''\n",
    "                    VALIDATION\n",
    "\n",
    "                    If ephoc>activation_ephoc, and B's not training (toTrainB=False)\n",
    "                    we run the model twice on val_data:\n",
    "\n",
    "                    * The first time no action will be chosen randomly. \n",
    "                        We calculate Bloss (ABloss) and the average ratio of \n",
    "                        edited words per query (p). \n",
    "                    * Then, at the second run, all the actions are chosen\n",
    "                        randomly with probability of p to edit a word. Again, we\n",
    "                        calculate B's loss (RandBloss)\n",
    "\n",
    "                    We then define A's gain at ephoc # ep as: AGain_ep = ABloss_ep - RandBloss_ep\n",
    "\n",
    "                    If AGain_ep<AGain_(ep-1) we reduce A's learning rate, after maxDecreaseNum \n",
    "                    reductions we stop A training but keep training B with A's edits.\n",
    "                    '''\n",
    "                    ABloss = 0 # B loss when none of the actions are chosen randomly\n",
    "                    RandBloss = 0 # B loss when all actions are chosen randomly\n",
    "                    for ep in range(2):\n",
    "                        startTime = datetime.now().replace(microsecond=0)\n",
    "                        \n",
    "                        if ep==0:\n",
    "                            # If ep==0, none of the actions will be chosen randomly\n",
    "                            editRandomlyProb=0\n",
    "                            val_rnn_editProb = rnn_editProb\n",
    "                        else:\n",
    "                            # If ep==1, all actions will be chosen randomly\n",
    "                            editRandomlyProb=1\n",
    "                            val_rnn_editProb = ephoc_edits_ratio\n",
    "                            \n",
    "                        Aval_loss, Bval_loss, val_acc, val_iou, ephoc_edits_ratio = 0, 0, 0, 0, 0\n",
    "                        print('\\nRandom choice:', ep==1)\n",
    "                        for b in range(val_nbatch):\n",
    "                            qlen, attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(val_data[b],\n",
    "                                                                                        0, self.batch_size, imScale=imScale, addNoiseImg=False)\n",
    "                            feed_dict = {\n",
    "                                        self.qlen:qlen,\n",
    "                                        self.queries:padded_queries,\n",
    "                                        self.img:padded_im,\n",
    "                                        self.bboxes:padded_bbox,\n",
    "                                        self.attn_idx:attn_idx,\n",
    "                                        self.labels: labels,\n",
    "                                        self.unk:np.array([[vocab['<unk>']]]),\n",
    "                                        self.isEdit:True,\n",
    "                                        self.reward_holder:np.array([[0.] for _ in range(self.batch_size)]), # dummy holder \n",
    "                                        self.BCE_holder:np.array([[0.] for _ in range(self.batch_size)]), # dummy holder \n",
    "                                        self.Aattn_vecs:[[[]]],# dummy holder \n",
    "                                        self.dropout_in:1.,\n",
    "                                        self.dropout_out:1.,\n",
    "                                        self.dropout_img:1.,\n",
    "                                        self.dropout_q:1.,\n",
    "                                        self.editRandomlyProb:editRandomlyProb,\n",
    "                                        self.rnn_editProb:val_rnn_editProb,\n",
    "                                        self.Alr:Alr,\n",
    "                                        self.Blr:Blr,\n",
    "                                        self.isTrain:False\n",
    "                                    }\n",
    "\n",
    "                            feed_dict[self.isEdit] = False\n",
    "                            queries_lens, B_ce, outputs = sess.run([self.queries_lens, self.B_ce, self.outputs], feed_dict=feed_dict)\n",
    "                            feed_dict[self.isEdit] = True\n",
    "\n",
    "                            Bce_min = min(B_ce)\n",
    "                            Bce_max = max(B_ce)\n",
    "                            Bce_scale = (B_ce-Bce_min)/(Bce_max-Bce_min)\n",
    "                            s = np.std(Bce_scale)\n",
    "                            BCE = 0.5*Bce_scale/s\n",
    "                            BCE = 1 + BCE - np.mean(BCE)\n",
    "\n",
    "                            feed_dict[self.reward_holder]=np.expand_dims(edit_reward*BCE/queries_lens, 1)\n",
    "                            feed_dict[self.BCE_holder]=np.expand_dims(BCE, 1)\n",
    "\n",
    "                            Aattn_vecs = outputs[:,:,:self.num_hidden]\n",
    "                            feed_dict[self.Aattn_vecs]=Aattn_vecs\n",
    "\n",
    "                            scores, B_loss, A_loss, batch_edit_ratio = sess.run(\n",
    "                                [self.scores, self.B_loss, self.A_loss, self.edit_ratio], feed_dict=feed_dict)\n",
    "                            acc = sum(np.equal(np.argmax(scores, axis=1), np.argmax(labels, axis=1))/len(labels))\n",
    "                            iou_acc = self.iou_accuracy(\n",
    "                                val_data[b], 0, self.batch_size, sess=sess, \n",
    "                                feed_dict=feed_dict, isEdit=True, imScale=imScale, labels=labels, scores=scores)\n",
    "\n",
    "                            val_acc += acc/val_nbatch\n",
    "                            Bval_loss += B_loss/val_nbatch\n",
    "                            Aval_loss += A_loss/val_nbatch\n",
    "                            val_iou += iou_acc/val_nbatch\n",
    "                            ephoc_edits_ratio += batch_edit_ratio/val_nbatch\n",
    "\n",
    "                            if b%50==0:\n",
    "                                print('batch:', b, ';edits ratio: %.3f'%(batch_edit_ratio), \n",
    "                                      ';B loss: %.3f'%(B_loss), ';A loss: %.3f'%(A_loss), ';acc: %.3f'%(acc), \n",
    "                                      ';iou_acc: %.3f'%(iou_acc), ';time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "\n",
    "                        print('\\n*B loss: %.3f'%(Bval_loss), ';A loss: %.3f'%(Aval_loss), ';Edit ratio: %.3f'%(ephoc_edits_ratio),  \n",
    "                              ';Accuracy %.3f'%(val_acc), ';IOU accuracy: %.3f'%(val_iou), ';Time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "                        \n",
    "                        if ep==0:\n",
    "                            self.val_res.append([[val_acc, val_iou, Bval_loss, Aval_loss]])\n",
    "                            self.AGain.append(Bval_loss)\n",
    "                        else:\n",
    "                            self.val_res[-1].append([val_acc, val_iou, Bval_loss, Aval_loss])\n",
    "                            self.AGain[-1] = self.AGain[-1]-Bval_loss\n",
    "\n",
    "#                     if toTrainA and  len(self.AGain)>3 and self.AGain[-1]<min(self.AGain[-4:-1]):\n",
    "#                         Alr=Alr*0.8\n",
    "#                         AlrDecreaseNum+=1\n",
    "#                         toTrainA = AlrDecreaseNum<=maxDecreaseNum\n",
    "                        \n",
    "                    print('\\n*AlrDecreaseNum: %d'%(AlrDecreaseNum), '; maxDecreaseNum: %d'%(maxDecreaseNum), \n",
    "                          ';AGain: %.3f'%(self.AGain[-1]), ';toTrainA: %s'%(toTrainA))\n",
    "                    print('-'*len('*AlrDecreaseNum: %d ; maxDecreaseNum: %d ;AGain: %.3f ;toTrainA: %s'%(AlrDecreaseNum, maxDecreaseNum, self.AGain[-1], toTrainA)), '\\n')\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                '''\n",
    "                TESTING\n",
    "                '''\n",
    "                if toTrainB:\n",
    "                    print('TESTING, ephoc:',ephoc)\n",
    "                    tstTime = datetime.now().replace(microsecond=0)\n",
    "                    tst_loss, tst_acc, tst_iou = 0, 0, 0\n",
    "                    t_data = tst_data+val_data\n",
    "                    t_nbatch = len(t_data)\n",
    "                    print('# t_data size:', sum([len(batch) for batch in t_data]))\n",
    "                    print('# t_data batches:', t_nbatch)\n",
    "                    \n",
    "                    for b in range(t_nbatch):\n",
    "                        qlen, attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(t_data[b],\n",
    "                                                                                    0, self.batch_size, imScale=imScale, addNoiseImg=False)\n",
    "                        \n",
    "                        feed_dict={\n",
    "                                    self.qlen:qlen,\n",
    "                                    self.queries:padded_queries,\n",
    "                                    self.img:padded_im,\n",
    "                                    self.bboxes:padded_bbox,\n",
    "                                    self.attn_idx:attn_idx,\n",
    "                                    self.labels: labels,\n",
    "                                    self.unk:np.array([[vocab['<unk>']]]),\n",
    "                                    self.isEdit:False,\n",
    "                                    self.reward_holder:np.array([[0.] for _ in range(self.batch_size)]),# dummy holder \n",
    "                                    self.BCE_holder:np.array([[0.] for _ in range(self.batch_size)]),# dummy holder \n",
    "                                    self.Aattn_vecs:[[[]]],# dummy holder \n",
    "                                    self.dropout_in:1.,\n",
    "                                    self.dropout_out:1.,\n",
    "                                    self.dropout_img:1.,\n",
    "                                    self.dropout_q:1.,\n",
    "                                    self.editRandomlyProb:0.,\n",
    "                                    self.rnn_editProb:0.,\n",
    "                                    self.Alr:Alr,\n",
    "                                    self.Blr:Blr,\n",
    "                                    self.isTrain:False\n",
    "                                }\n",
    "                       \n",
    "                        scores, B_loss = sess.run([self.scores, self.B_loss], feed_dict=feed_dict)\n",
    "                        acc = sum(np.equal(np.argmax(scores, axis=1), np.argmax(labels, axis=1))/len(labels))\n",
    "\n",
    "                        iou_acc = self.iou_accuracy(\n",
    "                            t_data[b], 0, self.batch_size, sess=sess, \n",
    "                            feed_dict=feed_dict, isEdit=False, imScale=imScale)\n",
    "                        \n",
    "                        tst_acc += acc/t_nbatch\n",
    "                        tst_loss += B_loss/t_nbatch\n",
    "                        tst_iou += iou_acc/t_nbatch\n",
    "                        if b%50==0:\n",
    "                            print('batch:', b, ';B loss: %.3f'%(B_loss), ';acc: %.3f'%(acc), \n",
    "                                   ';iou_acc: %.3f'%(iou_acc), ';time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "                            \n",
    "                    print('\\n*Test loss: %.3f'%(tst_loss), ';Test accuracy %.3f'%(tst_acc), \n",
    "                          ';IOU accuracy: %.3f'%(tst_iou), ';Time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "                    self.test_res.append([tst_acc, tst_iou, tst_loss])\n",
    "#                     if len(self.test_res)>10 and self.test_res[-1][-1]>max([item[-1] for item in self.test_res[-6:-1]]):\n",
    "#                         Blr=Blr*0.9\n",
    "                    \n",
    "                print('='*50,'\\n')\n",
    "            return self.test_res, self.train_res, self.val_res, self.AGain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We start by runnging the Grounder in its simplest form\n",
    "<p> We test the model with different state sizes: 50, 100, 150 and 200. We run each test for 100 ephocs</p>\n",
    "<p> We get about 60% IOU in all the test, about the same as the baseline.<br> On the other hand, the train set IOU gets bigger as the hidden state gets bigger, starting from about 89%, for 50 hidden units, to about 97% with 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_hidden=200\n",
    "edit_rewards = [-1., -.9, -.8, -0.7, -0.6]\n",
    "edit_rewards_tst, edit_rewards_trn, edit_rewards_val, edit_rewards_AGain = [], [], [], []\n",
    "\n",
    "for edit_reward in edit_rewards:\n",
    "    params_dir = params_dir_tmp+'RL/1noise_edit_rewards_'+str(-1*edit_reward)+'hidden_'+str(num_hidden)\n",
    "    tf.reset_default_graph()\n",
    "    m = Model(\n",
    "        batch_size=200, \n",
    "        num_hidden=num_hidden,\n",
    "        embed_size=embed_vecs.shape[1],\n",
    "        img_dims=trainset[0][0][1][0].shape[1], \n",
    "        bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "        vocab=vocab, \n",
    "        decay_steps=1000000, \n",
    "        decay_rate=0.9, \n",
    "        bnorm=False,\n",
    "        toQscale=True,\n",
    "        useNoise=True,\n",
    "        alpha=0.2\n",
    "    )\n",
    "\n",
    "    print('params_dir:', params_dir)\n",
    "    print('num_hidden:', m.num_hidden)\n",
    "    print('edit_reward:', edit_reward)\n",
    "    tst, trn, val, AGain = m.train(trainset, testset, valset,\n",
    "                                    ephocs_num=200,\n",
    "                                    start_ephoc=0,\n",
    "                                    startA=8,\n",
    "                                    activation_ephoc=12,\n",
    "                                    muteBnum=3, \n",
    "                                    queries_editProb=0.95,\n",
    "                                    edit_reward=edit_reward,\n",
    "                                    rnn_editProb=0.3,\n",
    "                                    Blr=.1,\n",
    "                                    Alr=.1,\n",
    "                                    imScale=1/50)\n",
    "    edit_rewards_tst.append(tst) \n",
    "    edit_rewards_trn.append(trn)\n",
    "    edit_rewards_val.append(val) \n",
    "    edit_rewards_AGain.append(AGain)\n",
    "\n",
    "    print('\\n'+'*'*100)\n",
    "    print('*'*100)\n",
    "    print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8fd9d2d58659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtoQscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0museNoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1b6446be74ef>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, num_hidden, img_dims, bbox_dims, vocab, decay_steps, decay_rate, bnorm, embed_size, use_wordAttn, useBidirectionalRnn, Urnn_norm, Uatt_norm, useNoise, alpha, toQscale, Qstd)\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueries_lens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                     inputs=embed_queries)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;31m# self.values[0]=value for not editing, self.values[1]=value for editing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[1;32m   2768\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2770\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2771\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2597\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2598\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2599\u001b[0;31m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2600\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2601\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2547\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m-> 2549\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    718\u001b[0m           \u001b[0mcall_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_cell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m           \u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m           skip_conditionals=True)\n\u001b[0m\u001b[1;32m    721\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_rnn_step\u001b[0;34m(time, sequence_length, min_sequence_length, max_sequence_length, zero_output, state, call_cell, state_size, skip_conditionals)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# steps.  This is faster when max_seq_len is equal to the number of unrolls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;31m# (which is typical for dynamic_rnn).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mnew_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    178\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[1;32m    179\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;31m# Apply activity regularization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ab4293ed399c>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, state)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMStateTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_state_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_state_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mnew_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEdit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             instructions)\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    291\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1812\u001b[0m     \u001b[0mcontext_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCondContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0mcontext_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0morig_res_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildCondBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morig_res_t\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"true_fn must have a return value.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildCondBranch\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m   1687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mBuildCondBranch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;34m\"\"\"Add the subgraph defined by fn() to the graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m     \u001b[0moriginal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moriginal_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ab4293ed399c>\u001b[0m in \u001b[0;36mf1\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mnew_unk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_unk_vecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0medit_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medit_new_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_unk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Bcell'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBoutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medit_new_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ab4293ed399c>\u001b[0m in \u001b[0;36mrunCell\u001b[0;34m(self, Boutputs, Bnew_state, edit_new_state)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runcell'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;31m# get action values according to B's hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mAout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# We can't use a tf.cond with batch_size  conditions so....\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ab4293ed399c>\u001b[0m in \u001b[0;36maction_vals\u001b[0;34m(self, Boutputs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'action_vals'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mAattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_attn_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_attn_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_attn_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# A's input: [input, B's output, attntion state, reward, B's loss with no edits]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ab4293ed399c>\u001b[0m in \u001b[0;36mattention\u001b[0;34m(self, state, attn_states, attn_dim, attn_idx, relu)\u001b[0m\n\u001b[1;32m    248\u001b[0m         hidden_s = tf.reshape(\n\u001b[1;32m    249\u001b[0m             self.linear(\n\u001b[0;32m--> 250\u001b[0;31m                 tf.cast(state, tf.float32), output_dim=self.num_units, scope='hidden_s_linear'), [-1, 1, 1,  self.num_units], name='hidden_s')\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# Computing alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ab4293ed399c>\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(self, inputs, output_dim, scope, bias, reuse)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             W = tf.get_variable('W', initializer=tf.contrib.layers.xavier_initializer(),\n\u001b[0m\u001b[1;32m    219\u001b[0m                                 shape=(inputs.get_shape()[-1], output_dim))\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfactorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_editor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/factorization/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclustering_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorization_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgmm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgmm_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/factorization/python/ops/gmm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheckpoint_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_fn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlearn_io\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProblemType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDNNClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDNNEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDNNRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated_arg_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# pylint: disable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;31m# pylint: enable=unused-import,wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontrib_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0membedding_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbucketization_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_feature_cross_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m                \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_FORMAT_NHWC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                \u001b[0moutputs_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                scope=None):\n\u001b[0m\u001b[1;32m     95\u001b[0m   \"\"\"Adds a 2D average pooling op.\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36madd_arg_scope\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_key_op'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_with_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \"\"\"\n\u001b[1;32m     85\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdecorator_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mdecorator_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Caller's name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m   decorator = TFDecorator(decorator_name, target, decorator_doc,\n\u001b[1;32m     88\u001b[0m                           decorator_argspec)\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[0;34m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetouterframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetouterframes\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0mframelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mframeinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1412\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m             \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    742\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;31m# Invalidate cache if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__loader__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;31m# or it is in the linecache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/anaconda3/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_filesbymodname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                 \u001b[0;31m# Have already mapped this module, so skip it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_hidden=200\n",
    "edit_rewards = [-.2, -.9, -.8, -0.7, -0.6]\n",
    "edit_rewards_tst, edit_rewards_trn, edit_rewards_val, edit_rewards_AGain = [], [], [], []\n",
    "\n",
    "for edit_reward in edit_rewards:\n",
    "    params_dir = params_dir_tmp+'RL/noise_edit_rewards_'+str(1.)+'hidden_'+str(num_hidden)\n",
    "    tf.reset_default_graph()\n",
    "    m = Model(\n",
    "        batch_size=200, \n",
    "        num_hidden=num_hidden,\n",
    "        embed_size=embed_vecs.shape[1],\n",
    "        img_dims=trainset[0][0][1][0].shape[1], \n",
    "        bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "        vocab=vocab, \n",
    "        decay_steps=1000000, \n",
    "        decay_rate=0.9, \n",
    "        bnorm=False,\n",
    "        toQscale=True,\n",
    "        useNoise=True,\n",
    "        alpha=0.3\n",
    "    )\n",
    "\n",
    "    print('params_dir:', params_dir)\n",
    "    print('num_hidden:', m.num_hidden)\n",
    "    print('edit_reward:', edit_reward)\n",
    "    tst, trn, val, AGain = m.train(trainset, testset, valset,\n",
    "                                    ephocs_num=200,\n",
    "                                    start_ephoc=85,\n",
    "                                    startA=8,\n",
    "                                    activation_ephoc=12,\n",
    "                                    muteBnum=3, \n",
    "                                    queries_editProb=0.95,\n",
    "                                    edit_reward=edit_reward,\n",
    "                                    rnn_editProb=0.3,\n",
    "                                    Blr=.1,\n",
    "                                    Alr=.1,\n",
    "                                    imScale=1/50)\n",
    "    edit_rewards_tst.append(tst) \n",
    "    edit_rewards_trn.append(trn)\n",
    "    edit_rewards_val.append(val) \n",
    "    edit_rewards_AGain.append(AGain)\n",
    "\n",
    "    print('\\n'+'*'*100)\n",
    "    print('*'*100)\n",
    "    print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'item' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-387f30826a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medit_rewards_tst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'item' is not defined"
     ]
    }
   ],
   "source": [
    "max([item[i][1] for i in range(len(item)) for item in edit_rewards_tst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_hidden=200\n",
    "edit_rewards = [-.2, -.9, -.8, -0.7, -0.6]\n",
    "edit_rewards_tst, edit_rewards_trn, edit_rewards_val, edit_rewards_AGain = [], [], [], []\n",
    "\n",
    "for edit_reward in edit_rewards:\n",
    "    params_dir = params_dir_tmp+'RL/noise_edit_rewards_'+str(1.)+'hidden_'+str(num_hidden)\n",
    "    tf.reset_default_graph()\n",
    "    m = Model(\n",
    "        batch_size=200, \n",
    "        num_hidden=num_hidden,\n",
    "        embed_size=embed_vecs.shape[1],\n",
    "        img_dims=trainset[0][0][1][0].shape[1], \n",
    "        bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "        vocab=vocab, \n",
    "        decay_steps=10000, \n",
    "        decay_rate=0.9, \n",
    "        bnorm=False,\n",
    "        toQscale=True,\n",
    "        useNoise=True,\n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "    print('params_dir:', params_dir)\n",
    "    print('num_hidden:', m.num_hidden)\n",
    "    print('edit_reward:', edit_reward)\n",
    "    tst, trn, val, AGain = m.train(trainset, testset, valset,\n",
    "                                    ephocs_num=200,\n",
    "                                    start_ephoc=82,\n",
    "                                    startA=8,\n",
    "                                    activation_ephoc=12,\n",
    "                                    muteBnum=3, \n",
    "                                    queries_editProb=0.95,\n",
    "                                    edit_reward=edit_reward,\n",
    "                                    rnn_editProb=0.3,\n",
    "                                    Blr=.05,\n",
    "                                    Alr=.1,\n",
    "                                    imScale=1/50)\n",
    "    edit_rewards_tst.append(tst) \n",
    "    edit_rewards_trn.append(trn)\n",
    "    edit_rewards_val.append(val) \n",
    "    edit_rewards_AGain.append(AGain)\n",
    "\n",
    "    print('\\n'+'*'*100)\n",
    "    print('*'*100)\n",
    "    print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_hidden=200\n",
    "edit_rewards = [-1., -.9, -.8, -0.7, -0.6]\n",
    "edit_rewards_tst, edit_rewards_trn, edit_rewards_val, edit_rewards_AGain = [], [], [], []\n",
    "\n",
    "for edit_reward in edit_rewards:\n",
    "    params_dir = params_dir_tmp+'RL/noise_edit_rewards_'+str(-1*edit_reward)+'hidden_'+str(num_hidden)\n",
    "    tf.reset_default_graph()\n",
    "    m = Model(\n",
    "        batch_size=200, \n",
    "        num_hidden=num_hidden,\n",
    "        embed_size=embed_vecs.shape[1],\n",
    "        img_dims=trainset[0][0][1][0].shape[1], \n",
    "        bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "        vocab=vocab, \n",
    "        decay_steps=10000, \n",
    "        decay_rate=0.9, \n",
    "        bnorm=False,\n",
    "        toQscale=True,\n",
    "        useNoise=True,\n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "    print('params_dir:', params_dir)\n",
    "    print('num_hidden:', m.num_hidden)\n",
    "    print('edit_reward:', edit_reward)\n",
    "    tst, trn, val, AGain = m.train(trainset, testset, valset,\n",
    "                                    ephocs_num=200,\n",
    "                                    start_ephoc=71,\n",
    "                                    startA=8,\n",
    "                                    activation_ephoc=12,\n",
    "                                    muteBnum=3, \n",
    "                                    queries_editProb=0.95,\n",
    "                                    edit_reward=edit_reward,\n",
    "                                    rnn_editProb=0.3,\n",
    "                                    Blr=.05,\n",
    "                                    Alr=.1,\n",
    "                                    imScale=1/50)\n",
    "    edit_rewards_tst.append(tst) \n",
    "    edit_rewards_trn.append(trn)\n",
    "    edit_rewards_val.append(val) \n",
    "    edit_rewards_AGain.append(AGain)\n",
    "\n",
    "    print('\\n'+'*'*100)\n",
    "    print('*'*100)\n",
    "    print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_hidden=200\n",
    "edit_rewards = [-1., -.9, -.8, -0.7, -0.6]\n",
    "edit_rewards_tst, edit_rewards_trn, edit_rewards_val, edit_rewards_AGain = [], [], [], []\n",
    "\n",
    "for edit_reward in edit_rewards:\n",
    "    params_dir = params_dir_tmp+'RL/noise_edit_rewards_'+str(-1*edit_reward)+'hidden_'+str(num_hidden)\n",
    "    tf.reset_default_graph()\n",
    "    m = Model(\n",
    "        batch_size=200, \n",
    "        num_hidden=num_hidden,\n",
    "        embed_size=embed_vecs.shape[1],\n",
    "        img_dims=trainset[0][0][1][0].shape[1], \n",
    "        bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "        vocab=vocab, \n",
    "        decay_steps=10000, \n",
    "        decay_rate=0.9, \n",
    "        bnorm=False,\n",
    "        toQscale=True,\n",
    "        useNoise=True,\n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "    print('params_dir:', params_dir)\n",
    "    print('num_hidden:', m.num_hidden)\n",
    "    print('edit_reward:', edit_reward)\n",
    "    tst, trn, val, AGain = m.train(trainset, testset, valset,\n",
    "                                    ephocs_num=200,\n",
    "                                    start_ephoc=0,\n",
    "                                    startA=8,\n",
    "                                    activation_ephoc=12,\n",
    "                                    muteBnum=3, \n",
    "                                    queries_editProb=0.95,\n",
    "                                    edit_reward=edit_reward,\n",
    "                                    rnn_editProb=0.3,\n",
    "                                    Blr=.05,\n",
    "                                    Alr=.1,\n",
    "                                    imScale=1/50)\n",
    "    edit_rewards_tst.append(tst) \n",
    "    edit_rewards_trn.append(trn)\n",
    "    edit_rewards_val.append(val) \n",
    "    edit_rewards_AGain.append(AGain)\n",
    "\n",
    "    print('\\n'+'*'*100)\n",
    "    print('*'*100)\n",
    "    print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
