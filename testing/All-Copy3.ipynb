{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import retriever\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset_file = '../data/training/order_train_data.bin'\n",
    "testset_file = '../data/training/order_test_data.bin'\n",
    "vocab_file =  '../data/metadata/w2v_vocab.json'\n",
    "params_dir_tmp = '../data/training/models/All/'\n",
    "embed_path =  '../data/metadata/w2v.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Each entry in this list has the following structure:</h3>\n",
    "<ul>\n",
    "<li>entry[0]: query indexes </li>\n",
    "<li>entry[1:n]: n items where each item is [bounding box vector, bounding box spaital features]. Note that different enteries might have different 'n' </li>\n",
    "<li>entry[n+1]: integer, entry[ 1 + entry[n+1]] is the ture bbox </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset barches #: 297\n",
      "test barches #: 297\n"
     ]
    }
   ],
   "source": [
    "trainset = np.load(open(trainset_file, 'rb'))\n",
    "trainset = [item for item in trainset if len(item)>2 and len(item[0])>0]\n",
    "print('trainset barches #:', len(trainset))\n",
    "\n",
    "testset = np.load(open(testset_file, 'rb'))\n",
    "testset = [item for item in testset if len(item)>2 and len(item[0])>0]\n",
    "print('test barches #:', len(testset))\n",
    "\n",
    "with open(vocab_file, 'r') as f:\n",
    "    vocab = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab['<unk>'] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_vecs = np.load(open(embed_path, 'rb')).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> augment_data function </h3>\n",
    "<br>We try sevral regularization methods. One of the things I've tried is to add data points where for each data I pick a query from a random data point and a set of bbox from a different random point. We build the labels (bboxes) distribution by giving an equal probability to each label. <br><br>\n",
    "The augment_data function does just that but the label of each added poind is writen as -1*number of bboxes. When we build the batch it self (function build_data in class Model), if we see a negative label index, we know its an added point and we know the number of bboxes so we can build the correct distribution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_data(data, ratio=0.5, addNoise=False):\n",
    "        '''\n",
    "        The function add data points. \n",
    "        We pick a query from a random data point,\n",
    "        and a set of bbox from a different random point and we join them\n",
    "        to build a new data point. The label distribution of the new data point will \n",
    "        uniform, that is, all labels will have equal probability. \n",
    "        \n",
    "        \n",
    "        Params:\n",
    "            data: a list of data entries\n",
    "                                                \n",
    "        Returns: a list of augmented data\n",
    "            \n",
    "                        \n",
    "        '''\n",
    "                          \n",
    "        q_idx = np.random.choice(range(len(data)), int(len(data)*ratio), replace=False)\n",
    "        im_idx = np.random.choice([i for i in range(len(data)) if i not in q_idx], int(len(data)*ratio))\n",
    "        for i in range(len(q_idx)):\n",
    "            q, im = data[q_idx[i]][0], data[im_idx[i]][1:-1]\n",
    "            item = [q]\n",
    "            for im_tmp in im:\n",
    "                item.append(im_tmp)\n",
    "            item.append(-len(im))\n",
    "            data.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALSTM\n",
    "\n",
    "This RNN cell has two LSTM cells, Bcell (for player B) and Acell (for Player A) and work as follow:\n",
    "<ol> \n",
    "<li>We run B's cells with the true query input word, getting the un-edited state. If use_worsAttn=True we add attention on the images vectors for each word.</li>\n",
    "<li>We run B's cells with the edited input word - 'unk', getting the edited state. If use_worsAttn=True we add attention on the images vectors for each word.</li>\n",
    "<li>We feed the un-edited state to A's cell.</li>\n",
    "<li>We run A's cells. A's input are:\n",
    "<ul><li>B's un-edited state</li><li>The reward for editing a word</li><li>B's loss having no edited words.</li></ul></li>\n",
    "<li>A's output is then goes throw a transformation which yields two values, one for editing a word and another for not.<br>If the the value for edit the word is higher, we pass B's edited state to the next time step, else we pass B's un_edit state.</li><br>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ALSTM(tf.nn.rnn_cell.LSTMCell):\n",
    "    def __init__(self, \n",
    "                 batch_size, \n",
    "                 num_units, \n",
    "                 \n",
    "                 # Size of A's attention vector.\n",
    "                 words_attn_dim, \n",
    "                 # B's outputs (for each time step).\n",
    "                 words_attn_states, \n",
    "                 # Inicates whether attentionvec is a padding (0) or not (1).\n",
    "                 words_attn_idx, \n",
    "                 \n",
    "                 # Size of B's attention vector ([image vector, spital features] size) .\n",
    "                 img_attn_dim, \n",
    "                 # B's outputs (for each time step).\n",
    "                 img_attn_states, \n",
    "                 \n",
    "                 \n",
    "                 # Inicates whether attentionvec is a padding (0) or not (1).\n",
    "                 img_attn_idx, \n",
    "                 \n",
    "                 unk, #'unk' word vector\n",
    "                 \n",
    "                 # Probabilty for edit a word in rnn, \n",
    "                 # when decision are taken randomly.\n",
    "                 rnn_editProb, \n",
    "                 \n",
    "                 \n",
    "                 # Whehter to edit the query or not.\n",
    "                 isEdit, \n",
    "                 \n",
    "                 # Whether B uses words levlel attention or not.\n",
    "                 use_wordAttn,\n",
    "                 \n",
    "                 # If True add noise instead of using 'unk'\n",
    "                 useNoise=False,\n",
    "                 \n",
    "                 # If useNoise is true word vec = alpha*word_vector+(1-alpha)*noise\n",
    "                 alpha=.3,\n",
    "                 \n",
    "                 # when isEdit=True, whether or not to use A's \n",
    "                 # output inorder to edit or to do it randomly.\n",
    "                 activateA=False,\n",
    "                 \n",
    "                 #this holds A's rewards and B's losses to\n",
    "                 # be add to A's feature vectors.\n",
    "                 reward_loss=None,\n",
    "                 state_is_tuple=True,):\n",
    "        \n",
    "        \n",
    "        # When useing A, the cell state will contain the concatenation \n",
    "        # of both B and A states. Therefore we set the unit number to be\n",
    "        # 2*(A and B unit size).\n",
    "        super().__init__(2*num_units, state_is_tuple=state_is_tuple)\n",
    "    \n",
    "        self.words_attn_states = words_attn_states\n",
    "        self.words_attn_idx = words_attn_idx\n",
    "        self.words_attn_dim = words_attn_dim\n",
    "        \n",
    "        self.img_attn_states = img_attn_states\n",
    "        self.img_attn_idx = img_attn_idx\n",
    "        self.img_attn_dim = img_attn_dim\n",
    "        \n",
    "        self.num_units = num_units\n",
    "        self.batch_size = batch_size\n",
    "        self.unk = unk \n",
    "        self.isEdit = isEdit\n",
    "        self.activateA = activateA\n",
    "        self.use_wordAttn=use_wordAttn\n",
    "        \n",
    "        \n",
    "        self.Acell = tf.nn.rnn_cell.LSTMCell(self.num_units, state_is_tuple=True)\n",
    "        self.Bcell = tf.nn.rnn_cell.LSTMCell(self.num_units, state_is_tuple=True)\n",
    "        \n",
    "        self.rnn_editProb = rnn_editProb\n",
    "        self.reward_loss = reward_loss\n",
    "        self.useNoise=useNoise\n",
    "        self.alpha=alpha\n",
    "        \n",
    "\n",
    "    def call(self, inputs, state):\n",
    "        '''\n",
    "        Params:\n",
    "            inputs: word embadding.\n",
    "            state:  [B's state form privious state, A's state form privious state]\n",
    "        '''\n",
    "        # takse B's state from state[:self.num_units]\n",
    "        Bstate_c = tf.slice(state[0], [0, 0], [-1, self.num_units])\n",
    "        Bstate_h = tf.slice(state[1], [0, 0], [-1, self.num_units])\n",
    "        self.Bstate =  tf.nn.rnn_cell.LSTMStateTuple(c=Bstate_c, h=Bstate_h)\n",
    "         \n",
    "        # If B's cell uses attention\n",
    "        if self.use_wordAttn:\n",
    "            words_attn = self.attention(Bstate_h, self.img_attn_states, self.img_attn_dim, self.img_attn_idx)\n",
    "            new_input = tf.concat([inputs, words_attn], -1)\n",
    "            Boutputs, Bnew_state =  self.Bcell(new_input, self.Bstate, 'Bcell')\n",
    "        else:\n",
    "            Boutputs, Bnew_state =  self.Bcell(inputs, self.Bstate, 'Bcell')\n",
    "\n",
    "        \n",
    "        # If isEdit==True \n",
    "        def f1(): \n",
    "            # takse A's state from state[self.num_units: 2*self.num_units]\n",
    "            Astate_c = tf.slice(state[0], [0, self.num_units], [-1, self.num_units])\n",
    "            Astate_h = tf.slice(state[1], [0, self.num_units], [-1, self.num_units])\n",
    "            self.Astate =  tf.nn.rnn_cell.LSTMStateTuple(c=Astate_c, h=Astate_h)\n",
    "            \n",
    "            if self.useNoise: # just add noise to the edited words\n",
    "                new_unk_vecs = self.alpha*inputs + (1-alpha)*tf.random_normal(shape=inputs.get_shape(), stddev=0.1)\n",
    "            else: # change the edited words by 'unk'\n",
    "                unk_vecs = tf.concat([self.unk for _ in range(self.batch_size)], 0) # shape: self.batch_size x 1 x embed_size\n",
    "                new_unk_vecs = tf.squeeze(unk_vecs) # shape: self.batch_size x embed_size\n",
    "            \n",
    "            # run B's cell with unk_batch\n",
    "            if self.use_wordAttn:\n",
    "                new_unk = tf.concat([new_unk_vecs, words_attn], -1)\n",
    "            else:\n",
    "                new_unk = new_unk_vecs\n",
    "            edit_output, edit_new_state = self.Bcell(new_unk, self.Bstate, 'Bcell')  \n",
    "            out1, state1 = self.runCell(Boutputs, Bnew_state, edit_new_state)\n",
    "            return out1, state1\n",
    "        \n",
    "        def f2(): \n",
    "            outs = tf.concat([Boutputs, tf.zeros((self.batch_size, self.num_units))], 1)\n",
    "            new_state_c = tf.concat([Bnew_state[0], tf.zeros_like(Bnew_state[0])], 1)\n",
    "            new_state_h = tf.concat([Bnew_state[1], tf.zeros_like(Bnew_state[1])], 1)\n",
    "            return outs, tf.nn.rnn_cell.LSTMStateTuple(c=new_state_c, h=new_state_h)\n",
    "        \n",
    "        new_output, new_state = tf.cond(self.isEdit, f1, f2)\n",
    "        \n",
    "        return new_output, new_state\n",
    "    \n",
    "    def runCell(self, Boutputs, Bnew_state, edit_new_state):\n",
    "        '''\n",
    "        Run B's cell after editing.\n",
    "        \n",
    "        params:\n",
    "            Boutputs: output vector without editing.\n",
    "            Bnew_state: state vector without editing.\n",
    "            edit_new_state: state vector after editing the input word to 'unk'. \n",
    "        '''\n",
    "        \n",
    "        with tf.variable_scope('runcell'):\n",
    "            # get action values according to B's hidden state\n",
    "            Aout, Anew_state, actions_vals = self.action_vals(Boutputs) \n",
    "            \n",
    "            def f1(): \n",
    "                '''\n",
    "                If self.activateA==True, edit word if actions_vals[0]<actions_vals[1].\n",
    "                Note: if we edit the word cond=1, else cond=0.\n",
    "                '''\n",
    "                a1, a2 = tf.split(value=actions_vals, num_or_size_splits=2, axis=1)\n",
    "                cond = tf.less(a1, a2)\n",
    "                return cond\n",
    "\n",
    "            def f2(): \n",
    "                '''\n",
    "                If self.activateA==False, choose randomly whether to edit a word.\n",
    "                We edit a word with 'rnn_editProb' probability (~U[0,1]).\n",
    "                Note: if we edit the word cond=1, else cond=0.\n",
    "                '''\n",
    "                rand = tf.multinomial(tf.log([[self.rnn_editProb, 1-self.rnn_editProb]]), self.batch_size)\n",
    "                cond = tf.less(tf.transpose(rand), 1) \n",
    "                return cond\n",
    "\n",
    "            # a list of A's decisions for each batch.  1->edit, 0-> do not edit.\n",
    "            cond = tf.cast(tf.cond(self.activateA, f1, f2), tf.float32)\n",
    "\n",
    "            # We'd like to know the action values and decision for each word,\n",
    "            # therefore theses info are placed on the first 3 dimensions of the \n",
    "            # output vector. Note that this vector is not passed to the \n",
    "            # next tiee step so it won't affect the model. \n",
    "            outs = tf.concat([actions_vals, cond], 1)\n",
    "\n",
    "            # B's i state is replaced by the edited state if cond[i]=1 (i =1, 2, ..., batch_size)\n",
    "            new_edit_state_c = (1-cond)*Bnew_state[0] + cond*edit_new_state[0]\n",
    "            new_edit_state_h = (1-cond)*Bnew_state[1] + cond*edit_new_state[1]\n",
    "\n",
    "\n",
    "            new_outs = tf.concat([outs, tf.zeros((self.batch_size, 2*self.num_units-3))], 1)\n",
    "            new_state_c = tf.concat([new_edit_state_c, Anew_state[0]], 1)\n",
    "            new_state_h = tf.concat([new_edit_state_h, Anew_state[1]], 1)\n",
    "            return new_outs, tf.nn.rnn_cell.LSTMStateTuple(c=new_state_c, h=new_state_h)\n",
    "    \n",
    "    \n",
    "    def action_vals(self, Boutputs):\n",
    "        '''\n",
    "        Get values for editing/not editing the input word.\n",
    "        \n",
    "        Params:\n",
    "            Boutputs: output vector without editing.\n",
    "            \n",
    "        Returns vals where:\n",
    "            Aout: A's cell output\n",
    "            Anew_state: A's cell state\n",
    "            vals: Tensor where vals[0] is the value for not editing the word \n",
    "                    and vals[1] is the value for editing the word.\n",
    "        '''\n",
    "        \n",
    "        with tf.variable_scope('action_vals') as scope:\n",
    "            Aattn = self.attention(self.Astate[1], self.words_attn_states, self.words_attn_dim, self.words_attn_idx)\n",
    "            \n",
    "            # A's input: [input, B's output, attntion state, reward, B's loss with no edits]\n",
    "            Anew_inputs = tf.concat([Boutputs, Aattn, self.reward_loss], 1)\n",
    "            \n",
    "            Aout, Anew_state = self.Acell(Anew_inputs, self.Astate, 'Acell')\n",
    "            vals = tf.nn.relu(self.linear(Aout, 2))\n",
    "\n",
    "            # Save the variables that only A uses. \n",
    "            # These variables will be trained separately from B's model.\n",
    "            self.Avars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope.name)\n",
    "            \n",
    "            return Aout, Anew_state, vals\n",
    "            \n",
    "        \n",
    "    def linear(self, inputs, output_dim, scope='linear', bias=True, reuse=False):\n",
    "        with tf.variable_scope(scope, reuse=False):\n",
    "            W = tf.get_variable('W', initializer=tf.random_uniform_initializer(maxval=1., minval=-1.),\n",
    "                                shape=(inputs.get_shape()[-1], output_dim))\n",
    "            if bias:\n",
    "                b = tf.get_variable('b', initializer=tf.constant_initializer(0.1),\n",
    "                               shape=[1, output_dim])\n",
    "                return tf.matmul(inputs, W) + b\n",
    "\n",
    "        return tf.matmul(inputs, W)\n",
    "    \n",
    "    \n",
    "    def attention(self, state, attn_states, attn_dim, attn_idx, relu=False):\n",
    "        '''\n",
    "        Attention mechanism (see https://arxiv.org/pdf/1409.0473.pdf)\n",
    "        \n",
    "        state: State from previous time step.\n",
    "        attn_states: Attetntion states. \n",
    "                     Tensor of shape (batch_size x max([len(attention_vectors[i]) for i in range(bach_size)]) x attn_dim)\n",
    "        attn_dim: Attention vector size.\n",
    "        attn_idx,: Tensor used for masking of shape (batch_size x max([len(attention_vectors[i]) for i in range(bach_size)]). \n",
    "                   attn_idx[i, j]=1 if the j's attention vcctior of sample i  is not padding, else its equat to 0.\n",
    "        '''\n",
    "        \n",
    "        self.attn_length = tf.shape(attn_states)[1]  \n",
    "        \n",
    "        # Computing... hidden_attn = W*v_att (use tf.nn.conv2d for efficiency)\n",
    "        attn_vecs = tf.reshape(attn_states, [self.batch_size, self.attn_length, 1, attn_dim])\n",
    "        W = tf.get_variable(\"attn_W\", [1, 1, attn_dim, self.num_units])\n",
    "        hidden_attn = tf.nn.conv2d(attn_vecs, W, [1, 1, 1, 1], \"SAME\")\n",
    "\n",
    "        # Computing... hidden_s = U*v_state\n",
    "        hidden_s = tf.reshape(\n",
    "            self.linear(\n",
    "                tf.cast(state, tf.float32), output_dim=self.num_units, scope='hidden_s_linear'), [-1, 1, 1,  self.num_units], name='hidden_s')\n",
    "\n",
    "        # Computing alpha\n",
    "        v = tf.get_variable(\"attn_v\", [self.num_units])\n",
    "        if relu:\n",
    "            logits = tf.reduce_sum(v * tf.nn.relu(hidden_attn + hidden_s), [2, 3])\n",
    "        else:\n",
    "            logits = tf.reduce_sum(v * tf.nn.tanh(hidden_attn + hidden_s), [2, 3])\n",
    "\n",
    "        # Masked softmax\n",
    "        max_logits = tf.reduce_max(logits, axis=-1)\n",
    "        masked_logits = tf.exp(logits-tf.expand_dims(max_logits, axis=1))*attn_idx\n",
    "        alpha = masked_logits/tf.reduce_sum(masked_logits, axis=-1, keep_dims=True)\n",
    "\n",
    "        a = tf.reduce_sum(tf.reshape(alpha, [-1, self.attn_length, 1, 1]) * attn_vecs, [1, 2])\n",
    "        b = tf.contrib.layers.fully_connected(a, num_outputs=self.num_units, \n",
    "                                                normalizer_fn=tf.contrib.layers.batch_norm, scope='proj')\n",
    "\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "When A joins the game, each iteration is completed via three steps:\n",
    "<ul>\n",
    "<li>We feed the query as it is to B and run it alone (no optimization nor training is done in this step)</li>\n",
    "<li>We run A and B together (no optimization nor training is done in this step). At this step we get A's decition and B's loss on the edited query. We use B's loss to calculate the Bellman's value for each time step. </li>\n",
    "<li>We again run A and B together, since now we know the real values for each time step and the real action for each time step (these will be the same as in the previous step since we did not train optimize the parameters yet), we finaly train the model</li>\n",
    "</ul>\n",
    "<br>\n",
    "But first we check the model's performance with out A. Class Model has a set of conditioning variables that set a different ragularization methods in the model. We start by checking them with out A's interference. We can also make the model RNN become bidirectional (by setting useBidirectionalRnn to True) and use words level attention (by setting use_wordAttn to True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self,\n",
    "                 batch_size, \n",
    "                 num_hidden, \n",
    "                 \n",
    "                 #Image's vector size.\n",
    "                 img_dims, \n",
    "                 \n",
    "                 #Spaital features length.\n",
    "                 bbox_dims, \n",
    "                 \n",
    "                 #Probabilty for edit a word in rnn, when decision are taken randomly.\n",
    "                 rnn_editProb,  \n",
    "                 vocab, \n",
    "                 lr, #  B's learning rate.\n",
    "                 decay_steps, \n",
    "                 decay_rate, \n",
    "                 \n",
    "                # coefficient to multiply the reward by when editing a word.\n",
    "                 edit_reward,\n",
    "                 \n",
    "                 # A's leanring rate = B's learning rate x coefAlr.\n",
    "                 coefAlr,\n",
    "                 \n",
    "                 # whether to use bach normaliztion for the last attention layer\n",
    "                 bnorm,\n",
    "                 embed_size=embed_vecs.shape[1],\n",
    "                 # Whether B uses words levlel attention or not.\n",
    "                 use_wordAttn=False,\n",
    "                 \n",
    "                 # Whther to use bidirectional rnn\n",
    "                 useBidirectionalRnn=False):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.img_dims = img_dims\n",
    "        self.bbox_dims = bbox_dims \n",
    "        self.num_hidden = num_hidden\n",
    "        self.embed_size = embed_size\n",
    "        self.vocab = vocab\n",
    "        L2Reg = 0.0005 # L2 regulizerr coefficient\n",
    "        self.lr = lr\n",
    "\n",
    "\n",
    "        self.queries = tf.placeholder(tf.int32, [None, None], name='queries')\n",
    "        self.img  = tf.placeholder(tf.float32, [None, None, self.img_dims], name='img')# VGG output vectors\n",
    "        self.bboxes = tf.placeholder(tf.float32, [None, None, self.bbox_dims], name='bboxes')# spatial bbox's features.\n",
    "        \n",
    "        # attn_idx: inicates whether attention box is a dummy (0) or not (1).\n",
    "        self.attn_idx = tf.placeholder(tf.float32, [None, None], name='attn_idx')\n",
    "        \n",
    "        self.labels = tf.placeholder(tf.float32, [None, None], name='labels')\n",
    "        self.isEdit = tf.placeholder(tf.bool, name='isEdit') # whehter to edit the query or not.\n",
    "        \n",
    "        # when isEdit=True, whether to use A's output in order to edit or to do it randomly.\n",
    "        self.activateA = tf.placeholder(tf.bool, name='activateA') \n",
    "        \n",
    "       \n",
    "        # this holds  A's rewards and B losses to be add to A's feature vectors.\n",
    "        self.reward_loss = tf.placeholder(tf.float32, [None,2], name='rewards_loss')\n",
    "        \n",
    "        # Dropout ratio for rnn's inputs and outpouts\n",
    "        self.dropout_in = tf.placeholder(tf.float32, name='dropoutIn_holder')\n",
    "        self.dropout_out = tf.placeholder(tf.float32, name='dropoutOut_holder')\n",
    "        \n",
    "        # Dropout ratio for images vector (for the final attention layer before the loss function)\n",
    "        self.dropout_img = tf.placeholder(tf.float32, name='dropoutImg_holder')\n",
    "        \n",
    "        # B outputs vectors (with no words edits), These are A's attention vectors\n",
    "        # which it uses to decide whter to edit a word.\n",
    "        self.Aattn_vecs = tf.placeholder(tf.float32, [None, None, None], name='Aattn_vecs_holder')    \n",
    "        self.unk = tf.constant([[vocab['<unk>']]], tf.int32)\n",
    "\n",
    "        self.queries_lens = self.length(self.queries) # list of all the lengths  of the batch's queriey \n",
    "        \n",
    "        # Concatinate images vectors and their spaital features. \n",
    "        # These vectors wlll be used for attenionn when \n",
    "        # we calculate the loss function.\n",
    "        attn_vecs = tf.concat([self.img, self.bboxes], 2) \n",
    "        voc_size = len(self.vocab)\n",
    "        \n",
    "        # Load pre-trained word imaddings.\n",
    "        # w2v_embed is not trainable.\n",
    "        with tf.variable_scope('w2v'):\n",
    "            w2v_embed = tf.get_variable('w2v_embed', initializer=embed_vecs, trainable=False)\n",
    "            w2v_queries = tf.nn.embedding_lookup(w2v_embed, self.queries, name='w2v_queries')\n",
    "\n",
    "        with tf.variable_scope('embed'):\n",
    "            embed = tf.get_variable('embed', shape=[voc_size, self.embed_size], \n",
    "                                    initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1))\n",
    "            embed_queries_tmp = tf.nn.embedding_lookup(embed, self.queries, name='embed_queries')\n",
    "            \n",
    "        embed_queries = embed_queries_tmp+w2v_queries\n",
    "\n",
    "        with tf.variable_scope('rnn'):\n",
    "            Aattn_idx = tf.cast(tf.abs(tf.sign(self.queries)), tf.float32)\n",
    "            \n",
    "            \n",
    "            cell_tmp = ALSTM(num_units=self.num_hidden, \n",
    "                            words_attn_dim=self.num_hidden, \n",
    "                            words_attn_states=self.Aattn_vecs, \n",
    "                            words_attn_idx=Aattn_idx,\n",
    "                            img_attn_dim=self.img_dims+self.bbox_dims,\n",
    "                            img_attn_states=attn_vecs,\n",
    "                            img_attn_idx=self.attn_idx,\n",
    "                            batch_size=self.batch_size, \n",
    "                            unk=tf.nn.embedding_lookup(embed, self.unk), rnn_editProb=rnn_editProb,\n",
    "                            activateA=self.activateA, isEdit=self.isEdit,\n",
    "                            reward_loss=self.reward_loss, use_wordAttn=use_wordAttn)\n",
    "            \n",
    "            cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "                cell_tmp, input_keep_prob=self.dropout_in, output_keep_prob=self.dropout_out)\n",
    "            \n",
    "            if useBidirectionalRnn:\n",
    "                self.outputs, self.last_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "                    cell_fw=cell,\n",
    "                    cell_bw=cell,\n",
    "                    dtype=tf.float32,\n",
    "                    sequence_length=self.queries_lens,\n",
    "                    inputs=embed_queries)\n",
    "                \n",
    "                # self.last_states contain both forward state\n",
    "                # and backward state.\n",
    "                # We don't use A with bidirectional rnn\n",
    "                # so no need for self.values (action values as calculated by A)\n",
    "                Bstate = tf.concat(\n",
    "                    [tf.slice(self.last_states[0][1], [0,0], [-1, self.num_hidden]), \n",
    "                     tf.slice(self.last_states[1][1], [0,0], [-1, self.num_hidden])], -1)\n",
    "            else:\n",
    "                self.outputs, self.last_states = tf.nn.dynamic_rnn(\n",
    "                    cell=cell,\n",
    "                    dtype=tf.float32,\n",
    "                    sequence_length=self.queries_lens,\n",
    "                    inputs=embed_queries)\n",
    "                \n",
    "                # self.values[0]=value for not editing, self.values[1]=value for editing\n",
    "                self.values = tf.slice(self.outputs, [0,0,0], [-1,-1,2])\n",
    "                Bstate = tf.slice(self.last_states[1], [0,0], [-1, self.num_hidden])  \n",
    "                \n",
    "\n",
    "        Avars = cell_tmp.Avars\n",
    "        self.Avars = {var.name:var for var in Avars}\n",
    "\n",
    "        self.scores = self.attention(Bstate, bnorm) \n",
    "        \n",
    "                          \n",
    "        # Cross entophy loss for each of the queries in the batch.\n",
    "        self.B_ce = -tf.reduce_sum(\n",
    "                        self.labels*tf.log(self.scores+0.00000001)+\n",
    "                            (1-self.labels)*tf.log((1-self.scores)+0.00000001), \n",
    "                            axis=-1)\n",
    "\n",
    "        \n",
    "        # We don't use A with bidirectional rnn\n",
    "        if not useBidirectionalRnn:\n",
    "            # A's decision for each word.\n",
    "            self.idx = tf.squeeze(tf.slice(self.outputs, [0,0,2], [-1,-1,1]))\n",
    "\n",
    "            self.edit_num = tf.reduce_mean(tf.reduce_sum(\n",
    "                tf.cast(self.idx, tf.float32)*tf.expand_dims(\n",
    "                        1/tf.cast(self.queries_lens, tf.float32), axis=1), axis=1))\n",
    "\n",
    "            # After running A for the first time, we get A's decisions and their values.\n",
    "            # we then calulate the following tensors:\n",
    "            # actions_idx[j,i] = 1 if the word i in query j was edited or 0 otherwise.     \n",
    "            # bell_vall holds the values for each decision by the bellman function. \n",
    "\n",
    "            #  self.actions_idx will be used to get the values of the action that were taken by A.                 \n",
    "            self.actions_idx = tf.placeholder(shape=[None, None], dtype=tf.int32, name=\"actions_idx\")\n",
    "            self.bell_val = tf.placeholder(shape=[None, None], dtype=tf.float32, name=\"bell_val\")\n",
    "\n",
    "            # pyrite_val: holds the values for each of A's decisions, claculated by A. \n",
    "            # see https://en.wikipedia.org/wiki/Pyrite.\n",
    "            self.pyrite_val = tf.reshape(tf.gather_nd(tf.reshape(self.values, (-1,2)), self.actions_idx), (self.batch_size, -1))\n",
    "\n",
    "            # RMSE loss\n",
    "            self.A_loss = tf.reduce_mean(tf.reduce_sum(\n",
    "                tf.sqrt(tf.square((self.bell_val-self.pyrite_val+0.000001)*tf.cast(\n",
    "                    tf.sign(tf.abs(self.queries)), tf.float32)))/tf.expand_dims(\n",
    "                                                    tf.cast(self.queries_lens, tf.float32), axis=1), axis=-1))\n",
    "\n",
    "        self.B_loss = tf.reduce_mean(self.B_ce)\n",
    "\n",
    "        ##############\n",
    "        # Optimizers #\n",
    "        ##############\n",
    "\n",
    "        starter_learning_rate = self.lr\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        self.learning_rate = tf.train.exponential_decay(starter_learning_rate, self.global_step,\n",
    "                                                       decay_steps=decay_steps, decay_rate=decay_rate, staircase=True)\n",
    "    \n",
    "        if not useBidirectionalRnn:\n",
    "            # Train only A variables \n",
    "            self.A_optimizer =  tf.train.GradientDescentOptimizer(\n",
    "                    learning_rate=coefAlr*self.learning_rate).minimize(self.A_loss, var_list=Avars)  \n",
    "\n",
    "        # Train only B variables \n",
    "        Bvars = [var for var in tf.trainable_variables() if var not in Avars]\n",
    "        self.B_optimizer =  tf.train.GradientDescentOptimizer(\n",
    "                    learning_rate=self.learning_rate).minimize(self.B_loss, global_step=self.global_step, var_list=Bvars)  \n",
    "\n",
    "        if not os.path.exists(params_dir):\n",
    "                os.makedirs(params_dir)\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "        \n",
    "    def length(self, seq):\n",
    "        '''\n",
    "        Retruns real lengths (before addings) of all queries in seq  .\n",
    "        '''\n",
    "        return tf.cast(tf.reduce_sum(tf.sign(tf.abs(seq)), reduction_indices=1), tf.int32)\n",
    "       \n",
    "\n",
    "    def linear(self, inputs, output_dim, scope='linear', bias=True, reuse=False):\n",
    "\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            W = tf.get_variable('W', initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                shape=(inputs.get_shape()[-1], output_dim))\n",
    "            if bias:\n",
    "                b = tf.get_variable('b', initializer=tf.constant_initializer(0.1),\n",
    "                               shape=[1, output_dim])\n",
    "                return tf.matmul(inputs, W) + b\n",
    "            \n",
    "            return tf.matmul(inputs, W)\n",
    "\n",
    "            \n",
    "    def attention(self, q_embed, bnorm):\n",
    "        '''\n",
    "        Given B's output vector, calculate the attention over all the query's bounding boxes vectors.\n",
    "        The  bounding boxe with the highest attention score will be chosen as the correct bounding box.\n",
    "        \n",
    "        Params:\n",
    "            q_embed: Tensor of shape (batch size x num_hidden)B's outputs. \n",
    "            bnorm: Boolean tensor. Whether to use batch normalization.\n",
    "            \n",
    "        Returns:\n",
    "            probs: Tensor of shape (batch_size x max bbox number for query).\n",
    "                   Attention score for each bbox.\n",
    "        '''\n",
    "        # concatenate img vectors with with spaical features\n",
    "        attn_vecs = tf.concat([self.img, self.bboxes], 2)\n",
    "        Urnn = q_embed # B's outputs. shape: (batch size x num_hidden)\n",
    "        Uatt = tf.nn.dropout(attn_vecs, keep_prob=self.dropout_img) # Attention vectors. shape: (batch size x max bbox number for query x attention vector size)\n",
    "        \n",
    "        # If bnorm is true use batch normalization\n",
    "        if bnorm:    \n",
    "            normalizer_fn=tf.contrib.layers.batch_norm\n",
    "        else:\n",
    "            normalizer_fn=None\n",
    "                          \n",
    "        with tf.variable_scope('l1'):\n",
    "            b = tf.get_variable(\n",
    "                'b1', initializer=tf.constant_initializer(0.1), shape=[1, self.num_hidden])\n",
    "            \n",
    "            context = tf.get_variable(\n",
    "                'context', initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1), shape=[self.num_hidden, 1])\n",
    "            \n",
    "            \n",
    "            rnn_out = tf.contrib.layers.fully_connected(\n",
    "                inputs=Urnn, \n",
    "                num_outputs=self.num_hidden, \n",
    "                activation_fn=None, \n",
    "                normalizer_fn=normalizer_fn\n",
    "            ) \n",
    "            \n",
    "            attn_out = tf.contrib.layers.fully_connected(\n",
    "                inputs=Uatt, \n",
    "                num_outputs=self.num_hidden, \n",
    "                activation_fn=None, \n",
    "                normalizer_fn=normalizer_fn\n",
    "            )\n",
    "            \n",
    "        out = tf.nn.relu(tf.expand_dims(rnn_out, 1) + attn_out + b)\n",
    "        logits = tf.reshape(tf.matmul(tf.reshape(out, (-1, tf.shape(out)[-1])),  context), (tf.shape(out)[0], -1))\n",
    "                          \n",
    "        # Calculate logits's masked softmax (we use self.attn_idx to mas\n",
    "        max_logits = tf.reduce_max(logits, axis=-1)\n",
    "        masked_logits = tf.exp(logits-tf.expand_dims(max_logits, axis=1))*self.attn_idx\n",
    "        probs = self.attn_idx*masked_logits/tf.reduce_sum(masked_logits, axis=-1, keep_dims=True)\n",
    "\n",
    "        return probs\n",
    "  \n",
    "        \n",
    "    def q_padding(self, seq, max_length):\n",
    "        '''\n",
    "        Pad  seq with vocab['<pad>'] (0) to max_length length.\n",
    "        '''                  \n",
    "        return seq + [self.vocab['<pad>']]*(max_length-len(seq))\n",
    "\n",
    "    \n",
    "    def build_data(self, data, start, end, addNoise=False):\n",
    "        '''\n",
    "        Build batch.\n",
    "        ------------\n",
    "        \n",
    "        Params:\n",
    "            data: each entry in this list has the following structure:\n",
    "                  [query indexes, [bounding box vector (VGG), bounding box spaital features], ..., \n",
    "                  [bounding box vector (VGG), bounding box spaital features], index of the true label]\n",
    "                  \n",
    "            start/end: batch data is built from data[start:end]\n",
    "            \n",
    "        Returns:\n",
    "            attn_idx: attn_idx[i, j]=1 if the j'th bbox in the i'th query is not padding, else equals to 0. \n",
    "            \n",
    "            padded_queries: list of queries, padded to the length of the longest query in the batch.\n",
    "                            Note: vocab['pad']=0\n",
    "                            \n",
    "            padded_im: list of bounding boxes vectors, padded to the maximum number of bbox per query.\n",
    "                       Note: padded vector is vector of zeros. \n",
    "                            \n",
    "            padded_bbox: list of bounding boxes spatial features, padded to the maximum number of bbox per query.\n",
    "                         Note: padded vector is vector of zeros.  \n",
    "        \n",
    "            onehot_labels: onehot_labels[i][j]=1 if j is the true bbox for query i, else  onehot_labels[i][j]=0\n",
    "            \n",
    "            addNoise: Boolean. Whether to add normal noise to the images.\n",
    "                        \n",
    "        '''\n",
    "                          \n",
    "        qlen = max([len(data[i][0]) for i in range(start, end)]) # Length fo the longest query\n",
    "        imlen = max([len(data[i]) for i in range(start, end)])-2 # Maximum number of bbox per query.\n",
    "        padded_queries, padded_im, padded_bbox, attn_idx = [], [], [], []\n",
    "        \n",
    "        # Build one hot labels from the labels index, given in the data.                  \n",
    "        labels = [item[-1] for item in data[start:end]] #data[i][-1]=index of the true bbox of query i\n",
    "        dist_labels = np.zeros((end-start, imlen)) #label distribution\n",
    "        \n",
    "        # Real data points\n",
    "        dist_labels[[i for i in np.arange(end-start) if labels[i]>0], [l for l in labels if l>0]]=1\n",
    "        \n",
    "        # augmented data points\n",
    "        for i in np.arange(end-start):\n",
    "            if labels[i]<0:\n",
    "                dist_labels[i] = [-1/labels[i] for _ in range(-labels[i])]+[0. for _ in range(imlen+labels[i])]\n",
    "                          \n",
    "        im_dim, bbox_dim = data[0][1][0].shape[1], data[0][1][1].shape[1]\n",
    "        for i in range(start, end):\n",
    "            padded_queries.append(self.q_padding(data[i][0], qlen))\n",
    "            \n",
    "            attn_idx.append([1 for _ in range(len(data[i])-2)]+[0 for _ in range(imlen-(len(data[i])-2))])\n",
    "            \n",
    "            padded_im.append(np.concatenate([data[i][j][0] for j in range(1, len(data[i])-1)] + \n",
    "                                       [np.full((imlen-(len(data[i])-2), im_dim), vocab['<pad>'], dtype=np.float32)], axis=0))\n",
    "            \n",
    "            padded_bbox.append(np.concatenate([data[i][j][1] for j in range(1, len(data[i])-1)] + \n",
    "                                       [np.full((imlen-(len(data[i])-2),bbox_dim), vocab['<pad>'], dtype=np.float32)], axis=0))\n",
    "           \n",
    "        if addNoise:\n",
    "            padded_im+=(padded_im+np.random.normal(0, .1, np.array(padded_im).shape))*np.expand_dims(attn_idx, 2)\n",
    "        else:\n",
    "            padded_im=np.array(padded_im)\n",
    "            \n",
    "        return np.array(attn_idx), np.array(padded_queries, dtype=np.int32), padded_im, np.array(padded_bbox), np.array(dist_labels)\n",
    "            \n",
    "   \n",
    "    def ground(self, data=None, start=None, end=None, sess=None, feed_dict = None, isEdit=True):\n",
    "        '''\n",
    "        Given a query and a list of bboxes, the function returns the index of the referred bbox.\n",
    "        '''\n",
    "        isSess = (sess==None)\n",
    "        if isSess:\n",
    "            sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            if isSess:\n",
    "                tf.global_variables_initializer().run()\n",
    "                ckpt = tf.train.get_checkpoint_state(params_dir)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    self.saver.restore(sess, ckpt.model_checkpoint_path) # restore all variables\n",
    "                else:\n",
    "                    print('Initializing variables')\n",
    "            if feed_dict is None:\n",
    "                attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(data, start, end)\n",
    "                feed_dict = {\n",
    "                        self.queries:padded_queries,\n",
    "                        self.img:padded_im,\n",
    "                        self.bboxes:padded_bbox,\n",
    "                        self.labels:labels,\n",
    "                        self.attn_idx:attn_idx\n",
    "                    }\n",
    "            feed_dict[self.isEdit] = isEdit\n",
    "            feed_dict[self.dropout_in]=1.\n",
    "            feed_dict[self.dropout_out]=1.\n",
    "            feed_dict[self.dropout_img]=1.\n",
    "            scores = sess.run(self.scores, feed_dict=feed_dict) # get score for each bbox\n",
    "\n",
    "        return np.argmax(scores, axis=1), np.argmax(feed_dict[self.labels], axis=1)\n",
    "        \n",
    "        \n",
    "    def iou_accuracy(self, data, start, end, sess=None, feed_dict = None, threshold=0.5, test=False, isEdit=True):\n",
    "        '''\n",
    "        Calculate the IOU score between the Model bbox and the true bbox.\n",
    "        ''' \n",
    "                          \n",
    "        # Get score for each bbox (labels) and th true bbox index (gt_idx)                  \n",
    "        if feed_dict is None:\n",
    "            labels, gt_idx = self.ground(data, start, end, sess=sess, feed_dict=feed_dict, isEdit=isEdit)\n",
    "        else: labels, gt_idx = self.ground(sess=sess, feed_dict=feed_dict, isEdit=isEdit)\n",
    "        acc = 0\n",
    "        \n",
    "        for i in range(start, end):\n",
    "            gt = data[i][gt_idx[i-start]+1][1][0] # ground truth bbox\n",
    "            crops = np.expand_dims(data[i][labels[i-start]+1][1][0], axis=0) #Model chosen bbox\n",
    "            acc += (retriever.compute_iou(crops, gt)[0]>threshold) #IOU for the i sample.\n",
    "            \n",
    "        return acc/(end-start)\n",
    "        \n",
    "    def accuracy(self, data=None, start=None, end=None, sess=None, feed_dict = None, isEdit=True):\n",
    "        isSess = (sess==None)\n",
    "        if isSess:\n",
    "            print('Building sess')\n",
    "            sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            if isSess:\n",
    "                print('Building sess used')\n",
    "                tf.global_variables_initializer().run()\n",
    "                ckpt = tf.train.get_checkpoint_state(params_dir)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    print('3')\n",
    "                    self.saver.restore(sess, ckpt.model_checkpoint_path) # restore all variables\n",
    "                else:\n",
    "                    print('Initializing variables')\n",
    "            if feed_dict is None:\n",
    "                print('Building feed_dict')\n",
    "                attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(data, start, end)\n",
    "                feed_dict = {\n",
    "                        self.queries:padded_queries,\n",
    "                        self.img:padded_im,\n",
    "                        self.bboxes:padded_bbox,\n",
    "                        self.attn_idx:attn_idx,\n",
    "                        self.labels:labels,\n",
    "                    }\n",
    "                \n",
    "            feed_dict[self.isEdit] = isEdit\n",
    "            feed_dict[self.dropout_in]=1.\n",
    "            feed_dict[self.dropout_out]=1.\n",
    "            feed_dict[self.dropout_img]=1.\n",
    "            scores = sess.run(self.scores, feed_dict=feed_dict)\n",
    "            acc = sum(np.equal(np.argmax(scores, axis=1), np.argmax(feed_dict[self.labels], axis=1))/len(feed_dict[self.labels]))\n",
    "\n",
    "                    \n",
    "        return acc\n",
    "    \n",
    "    def discount_rewards(self, r, last_r, gamma=1.0):\n",
    "        \"\"\" \n",
    "        take 1D float array of rewards and compute discounted reward \n",
    "        using bellman function.\n",
    "        \n",
    "        params:\n",
    "            r: r[i,j]=1 reward of action A did on word j at query i.\n",
    "            last_r: B's loss for query i with no edits. This is the final reward.\n",
    "            gamma: discount factor.\n",
    "        \"\"\"\n",
    "                          \n",
    "        discounted_r = np.zeros(r.shape)\n",
    "        running_add = last_r # B loss\n",
    "        discounted_r = [i for i in range(r.shape[-1])]\n",
    "        for t in reversed(range(0, r.shape[-1])):\n",
    "            running_add = running_add * gamma + r[:,t]\n",
    "            discounted_r[t] = running_add\n",
    "        return np.array(discounted_r).T\n",
    "        \n",
    "    def train(self, trn_data, tst_data, ephocs_num, edit_reward, startA=3, \n",
    "              activation_ephoc=10, muteB=3, start_ephoc=0, dropout_in=1.,\n",
    "              dropout_out=1., dropout_img=1., editProb=0.5, max_activateAProb=0.8, \n",
    "              activateAProb = 0.5, addNoise=False):\n",
    "                          \n",
    "        '''\n",
    "        Params:\n",
    "             trn_data: list, train set. \n",
    "             \n",
    "             tst_data: list, test set. \n",
    "             \n",
    "             ephocs_num: number of ephocs\n",
    "             \n",
    "             start_ephoc: number of first ephoc.\n",
    "             \n",
    "             edit_reward: int, coefficient to multiply the reward by when editing a word.\n",
    "             \n",
    "             startA: int, Start competition only at ephoc # startA.\n",
    "             \n",
    "             activation_ephoc: at ephoc numer \"activation_ephoc\", A will be activate.\n",
    "                               That is, for (activation_ephoc-startA) number of ephocs, \n",
    "                               A will chooce an action randomly.\n",
    "             \n",
    "            muteB: After A starts, for each ephoc which A & B trains, \n",
    "                   only A will be trained for this amount of ephocs.\n",
    "                   \n",
    "            editProb: robabilty for editing a query.\n",
    "            \n",
    "            activateAProb: when running A, we can choos an action randomly or taknig A decision. \n",
    "                            This is the starting probabilty for NOT choocing an action ranomdly.\n",
    "            \n",
    "            max_activateAProb: Final probabilty for NOT choocing an action ranomdly.\n",
    "            \n",
    "            dropout_in: dropout ratio of B's rnn inputs.\n",
    "            \n",
    "            dropout_output: dropout ratio of B's rnn output.\n",
    "            \n",
    "            dropout_img: dropout ratio of images vectors before the last attention layer .\n",
    "            \n",
    "            addNoise: Boolean. Whether to add normal noise to the images (see build_data).\n",
    "                               \n",
    "        '''                  \n",
    "        \n",
    "        trn_nbatch = len(trn_data)\n",
    "        tst_nbatch = len(tst_data)\n",
    "        print('# Train set size:', len([len(batch) for batch in trn_data]))\n",
    "        print('# Training batches:', trn_nbatch)\n",
    "        print('# Test set size:', len([len(batch) for batch in tst_data]))\n",
    "        print('# Testing batches:', tst_nbatch)\n",
    "        self.test_res, self.train_res = [], [] #list to hold accuracy of test set\n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            tf.global_variables_initializer().run()\n",
    "            ckpt = tf.train.get_checkpoint_state(params_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                print('Loading parameters from', ckpt.model_checkpoint_path)\n",
    "                self.saver.restore(sess, ckpt.model_checkpoint_path) # restore all variables\n",
    "            else:\n",
    "                print('Initializing variables')\n",
    "                \n",
    "            for ephoc in range(start_ephoc, ephocs_num):\n",
    "                startTime = datetime.now().replace(microsecond=0)\n",
    "                          \n",
    "                # Train B only after competition start (ephoc<startA). \n",
    "                # Each time we train B, we train only B for muteB ephocs.\n",
    "                if startA>0:\n",
    "                    toTrainB = ephoc<startA or (ephoc-(startA-1))%(muteB+1)==0 # Whether to train only B \n",
    "                else:\n",
    "                    toTrainB = ephoc==0 or ephoc%(muteB+1)==0 # Whether to train only B \n",
    "                    \n",
    "                # Every 2 times we train B and A (+ only A for muteB ephocs), the\n",
    "                # probability for choosing an action using A and not randomly, increases by 1.1.\n",
    "                if activateAProb>0 and activateAProb<max_activateAProb and muteB>0 and (ephoc-activation_ephoc)%((muteB+1)*6)==0 and ephoc>activation_ephoc:\n",
    "                    activateAProb=activateAProb*1.1\n",
    "                        \n",
    "                itrInEphoc=1 # When we train B, we show B results without editing (on train set)\n",
    "                if activateAProb>0 and ephoc>=startA and toTrainB:\n",
    "                    itrInEphoc=2\n",
    "                    \n",
    "                print('='*50,'\\nTrain, ephoc:',ephoc, '; Training B:', toTrainB)\n",
    "                np.random.shuffle(trn_data)\n",
    "                for ep in range(itrInEphoc):\n",
    "                    trn_ce_loss, A_trn_loss, B_trn_loss = 0, 0, 0\n",
    "                    trn_acc, trn_iou, edits_count = 0, 0, 0\n",
    "                    tst_ce_loss, tst_loss, tst_acc, tst_iou = 0, 0, 0, 0\n",
    "                    if ep==1:\n",
    "                        print('No Edit')\n",
    "                        print('ooooooo')\n",
    "                    edit_num = 0 # number of edited words\n",
    "                    editRount_count = 0 # number of iterations with competition.\n",
    "                    for b in range(trn_nbatch):\n",
    "                        if ep==1:\n",
    "                            '''\n",
    "                            If ep=1, we're in round 2 in which we only show B's \n",
    "                            results with out editing (on the train set).\n",
    "                            '''\n",
    "                            isEdit=False\n",
    "                            isActivateA=False\n",
    "                        else:\n",
    "                            isEdit = ephoc>=startA and (toTrainB==False or np.random.rand(1)[0]<editProb)\n",
    "                            # Whether to choose an action using A or randomly.\n",
    "                            isActivateA = (toTrainB==True and activateAProb>0.) or (isEdit and \n",
    "                                                                                    ephoc>=activation_ephoc and \n",
    "                                                                                    np.random.rand(1)[0]<activateAProb)\n",
    "            \n",
    "                        attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(trn_data[b], \n",
    "                                                                                            0, \n",
    "                                                                                            self.batch_size, \n",
    "                                                                                            addNoise=addNoise)\n",
    "                \n",
    "                        reward_loss = np.array([[0., 0.] for _ in range(self.batch_size)]) # dummy holder \n",
    "                    \n",
    "\n",
    "                        feed_dict = {\n",
    "                            self.queries:padded_queries,\n",
    "                            self.img:padded_im,\n",
    "                            self.bboxes:padded_bbox,\n",
    "                            self.attn_idx:attn_idx,\n",
    "                            self.labels: labels,\n",
    "                            self.unk:np.array([[vocab['<unk>']]]),\n",
    "                            self.isEdit:isEdit,\n",
    "                            self.activateA:isActivateA,\n",
    "                            self.reward_loss:reward_loss,\n",
    "                            self.Aattn_vecs:[[[]]],# dummy holder \n",
    "                            self.dropout_in:dropout_in,\n",
    "                            self.dropout_out:dropout_out,\n",
    "                            self.dropout_img:dropout_img,\n",
    "                        }\n",
    "                        \n",
    "                        \n",
    "                        if isEdit:\n",
    "                            editRount_count+=1\n",
    "                          \n",
    "                            '''We first run B with no edit in order to get it's loss and outputs.'''\n",
    "                          \n",
    "                            feed_dict[self.isEdit] = False\n",
    "                            queries_lens, B_ce, outputs = sess.run([self.queries_lens, self.B_ce, self.outputs], feed_dict=feed_dict)\n",
    "                            feed_dict[self.isEdit] = True\n",
    "                            \n",
    "                            # B_ce contain the loss for each query.\n",
    "                            # We scale all the losses to have mean 1 and std 0.5.\n",
    "                            Bce_min = min(B_ce)\n",
    "                            Bce_max = max(B_ce)\n",
    "                            Bce_scale = (B_ce-Bce_min)/(Bce_max-Bce_min)\n",
    "                            s = np.std(Bce_scale)\n",
    "                            BCE = Bce_scale/(2.*s)\n",
    "                            BCE = 1 + BCE - np.mean(BCE)\n",
    "                          \n",
    "                            # reward for edit a word = edit_reward*BCE/queries_lens.\n",
    "                            # A's get the reward and loss per query  as 2 of its features.\n",
    "                            rewards_loss = np.concatenate(\n",
    "                                [np.expand_dims(edit_reward*BCE/queries_lens, 1), np.expand_dims(BCE, 1)], 1)\n",
    "                            \n",
    "                            feed_dict[self.reward_loss]=rewards_loss\n",
    "                            \n",
    "                            # A's attention vectors are B's outputs with no edited words.\n",
    "                            Aattn_vecs = outputs[:,:,:self.num_hidden]\n",
    "                            feed_dict[self.Aattn_vecs]=Aattn_vecs\n",
    "                           \n",
    "                            '''\n",
    "                            We then run B with A edits. \n",
    "                            We get idx (A's decision [0,1] for each words), edit_num: the ratio\n",
    "                            of edited words and B_ce, B_loss: loss poer query and B_vce mean.\n",
    "                            '''\n",
    "                            feed_dict[self.isEdit] = False\n",
    "                            idx, B_ce, B_loss, edit_num = sess.run(\n",
    "                                [self.idx, self.B_ce, self.B_loss, self.edit_num], \n",
    "                                 feed_dict=feed_dict)\n",
    "                            \n",
    "                            # Get rewurd per word.\n",
    "                            # If word i in query j was edited idx[j,i]=1 --> rewards[i,j] = 1*reward\n",
    "                            # If word i in query j was not edited idx[j,i]=0 --> rewards[i,j] = 0*reward\n",
    "                            rewards = idx*np.expand_dims(\n",
    "                                edit_reward*BCE/queries_lens, axis=1)\n",
    "                            \n",
    "                            # Scale new losses\n",
    "                            Bce_min = min(B_ce)\n",
    "                            Bce_max = max(B_ce)\n",
    "                            Bce_scale = (B_ce-Bce_min)/(Bce_max-Bce_min)\n",
    "                            s = np.std(Bce_scale)\n",
    "                            BCE1 = Bce_scale/(2.*s)\n",
    "                            BCE1 = 1 + BCE1 - np.mean(BCE1)\n",
    "                            \n",
    "                            feed_dict[self.actions_idx] = np.abs(list(zip(range(\n",
    "                                        self.batch_size*idx.shape[-1]), idx.reshape(-1))))\n",
    "                            feed_dict[self.bell_val] = self.discount_rewards(rewards1, BCE1)\n",
    "                                                         \n",
    "                            A_loss, _ = sess.run(\n",
    "                                [self.A_loss, self.A_optimizer], feed_dict=feed_dict)\n",
    "                            \n",
    "                            if toTrainB:\n",
    "                                lr, gs, _ = sess.run(\n",
    "                                    [self.learning_rate, self.global_step, self.B_optimizer], \n",
    "                                    feed_dict=feed_dict)\n",
    "                \n",
    "                    \n",
    "                            acc = self.accuracy(sess=sess, feed_dict=feed_dict, isEdit=isEdit)  \n",
    "                            iou_acc = self.iou_accuracy(\n",
    "                                trn_data[b], 0, self.batch_size, \n",
    "                                sess=sess, feed_dict=feed_dict, isEdit=isEdit)\n",
    "\n",
    "                            trn_acc += acc/trn_nbatch\n",
    "                            A_trn_loss += A_loss\n",
    "                            B_trn_loss += B_loss/trn_nbatch\n",
    "                            trn_iou += iou_acc/trn_nbatch\n",
    "                            edits_count += edit_num\n",
    "                            \n",
    "                            if b%50==0:\n",
    "                                if toTrainB: \n",
    "                                    print('Edit:', feed_dict[self.isEdit], ';A:',isActivateA, \n",
    "                                          ';ephoc:',ephoc, ';batch:', b, \n",
    "                                          ';gs:', gs, ';lr: %.4f'%(lr), ';B loss: %.2f'%(B_loss), \n",
    "                                          ';A loss: %.2f'%(A_loss), ';edits: %.2f'%(edit_num),  ';activateAProb: %.3f'%(activateAProb),\n",
    "                                          ';acc: %.3f'%(acc), ';iou: %.3f'%(iou_acc), ';time:', datetime.now().replace(microsecond=0)-startTime)    \n",
    "                                else:\n",
    "                                    print('Edit:', feed_dict[self.isEdit], ';A:',isActivateA, \n",
    "                                          ';ephoc:',ephoc, ';batch:', b, \n",
    "                                          ';B loss: %.2f'%(B_loss), ';A loss: %.2f'%(A_loss), \n",
    "                                          ';edits: %.2f'%(edit_num), ';activateAProb: %.3f'%(activateAProb), ';acc: %.3f'%(acc),\n",
    "                                          ';iou: %.3f'%(iou_acc), ';time:', datetime.now().replace(microsecond=0)-startTime)  \n",
    "                                \n",
    "\n",
    "                               \n",
    "                        else: # isEdit=False\n",
    "                            if ep==0:\n",
    "                                B_loss, lr, gs, _ = sess.run([self.B_loss, self.learning_rate, \n",
    "                                                                self.global_step, self.B_optimizer], feed_dict=feed_dict)\n",
    "                            else: \n",
    "                                # just show results of B with no edits\n",
    "                                B_loss, lr, gs = sess.run([self.B_loss, self.learning_rate, self.global_step], feed_dict=feed_dict)\n",
    "\n",
    "                            acc = self.accuracy(sess=sess, feed_dict=feed_dict, isEdit=isEdit)  \n",
    "                            iou_acc = self.iou_accuracy(trn_data[b], 0, self.batch_size, \n",
    "                                                        sess=sess, feed_dict=feed_dict, isEdit=isEdit)\n",
    "\n",
    "                            trn_acc += acc/trn_nbatch\n",
    "                            B_trn_loss += B_loss/trn_nbatch\n",
    "                            trn_iou += iou_acc/trn_nbatch\n",
    "\n",
    "                            if b%50==0:\n",
    "                                print('Edit:', feed_dict[self.isEdit],  ';A:',isActivateA, ';batch:', b, ';gs:', gs, ';lr: %.4f'%(lr), \n",
    "                                      ';B loss: %.3f'%(B_loss),  ';acc: %.3f'%(acc), \n",
    "                                      ';iou: %.3f'%(iou_acc),\n",
    "                                      ';time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "\n",
    "                    if editRount_count>0:\n",
    "                        print('\\n*Training B:', ephoc%3==0, ';B Train loss: %.3f'%(B_trn_loss), ';A Train loss: %.3f'%(A_trn_loss/editRount_count),                                                                                             \n",
    "                          ';Edit num: %.3f'%(edits_count/editRount_count), \n",
    "                          ';Train accuracy: %.3f'%(trn_acc),  ';IOU accuracy: %.3f'%(trn_iou), \n",
    "                          ';Time:', datetime.now().replace(microsecond=0)-startTime, '\\n')\n",
    "                    else:\n",
    "                        print('\\n*Training B:', ephoc%3==0, ';B Train loss: %.3f'%(B_trn_loss),                                                                                          ';Train accuracy: %.3f'%(trn_acc), \n",
    "                          ';IOU accuracy: %.3f'%(trn_iou),  \n",
    "                          ';Time:', datetime.now().replace(microsecond=0)-startTime, '\\n')\n",
    "                          \n",
    "                if editRount_count>0:\n",
    "                    self.train_res.append([trn_acc, trn_iou, B_trn_loss, A_trn_loss/editRount_count])\n",
    "                else: \n",
    "                    self.train_res.append([trn_acc, trn_iou, B_trn_loss, 0])\n",
    "                self.saver.save(sess, params_dir + \"/model.ckpt\", global_step=ephoc)    \n",
    "                if ephoc<startA or toTrainB:\n",
    "                    print('Testing, ephoc:',ephoc)\n",
    "                    tstTime = datetime.now().replace(microsecond=0)\n",
    "                    tst_loss, tst_acc, tst_iou = 0, 0, 0\n",
    "                    for b in range(tst_nbatch):\n",
    "                        attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(tst_data[b],\n",
    "                                                                                    0, self.batch_size)\n",
    "                        rewards_loss = np.array([[0., 0.] for _ in range(self.batch_size)])\n",
    "                        feed_dict = {\n",
    "                            self.queries:padded_queries,\n",
    "                            self.img:padded_im,\n",
    "                            self.bboxes:padded_bbox,\n",
    "                            self.attn_idx:attn_idx,\n",
    "                            self.labels: labels,\n",
    "                            self.unk:np.array([[vocab['<unk>']]]),\n",
    "                            self.reward_loss:reward_loss,\n",
    "                            self.isEdit:False,\n",
    "                            self.activateA:False,\n",
    "                            self.Aattn_vecs:[[[]]],\n",
    "                            self.dropout_in:1.,\n",
    "                            self.dropout_out:1.,\n",
    "                            self.dropout_img:1.,\n",
    "                        }\n",
    "                        B_loss = sess.run(self.B_loss, feed_dict=feed_dict)\n",
    "\n",
    "                        acc = self.accuracy(sess=sess, feed_dict=feed_dict, isEdit=False)\n",
    "                        iou_acc = self.iou_accuracy(\n",
    "                            tst_data[b], 0, self.batch_size, sess=sess, feed_dict=feed_dict, isEdit=False)\n",
    "                        tst_acc += acc/tst_nbatch\n",
    "                        tst_loss += B_loss/tst_nbatch\n",
    "                        tst_iou += iou_acc/tst_nbatch\n",
    "                        if b%50==0:\n",
    "                            print('batch:', b, ';B loss: %.3f'%(B_loss), ';acc: %.3f'%(acc), \n",
    "                                   ';iou_acc: %.3f'%(iou_acc), ';time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "                    print('\\n*BTrain:', ephoc%3==0, ';Test loss: %.3f'%(tst_loss), ';Test accuracy %.3f'%(tst_acc), \n",
    "                          ';IOU accuracy: %.3f'%(tst_iou), ';Time:', datetime.now().replace(microsecond=0)-startTime)\n",
    "                    self.test_res.append([tst_acc, tst_iou, tst_loss])\n",
    "                print('='*50,'\\n')\n",
    "            return self.test_res, self.train_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We start by runnging B in its simplest form\n",
    "<p> We test the model with different state sizes: 50, 100, 150 and 200. We run each test for 100 ephocs</p>\n",
    "<p> We get about 60% IOU in all the test, about the same as the baseline.<br> On the other hand, the train set IOU gets bigger as the hidden state gets bigger, starting from about 89%, for 50 hidden units, to about 97% with 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stats(test, train):\n",
    "    '''\n",
    "    Plot metrics graphs asnd print some stats.\n",
    "    \n",
    "    Params:\n",
    "        test: list. \n",
    "              Each item is a tuple, [test accuracy, test IOU, test loss]\n",
    "        train: list. \n",
    "               Each item is a tuple, [train accuracy, train IOU, train loss, 0]\n",
    "               For now we can ignore the last part in the tuple (zero)\n",
    "    '''\n",
    "    \n",
    "    ephocs = range(100)\n",
    "    test_res = np.array(test)\n",
    "    train_res = np.array(train)\n",
    "    test_Glabels = ['test accuracy', 'test IOU', 'test loss']\n",
    "    train_Glabels = ['train accuracy', 'train IOU', 'train loss']\n",
    "\n",
    "    for j, num_hidden in enumerate([50, 100, 150, 200]):\n",
    "        print('num_hidden:', num_hidden)\n",
    "        print('='*(len('num_hidden:')+3))\n",
    "        for i in range(len(train_Glabels)):\n",
    "            plt.plot(ephocs, test_res[j][:,i])\n",
    "            plt.plot(ephocs, train_res[j][:,i])\n",
    "            plt.legend([test_Glabels[i], train_Glabels[i]], loc='upper left')\n",
    "            plt.title('num_hidden:%d'%(num_hidden))\n",
    "            plt.show()\n",
    "\n",
    "            metric = ''.join(train_Glabels[i][len('train')+1:])\n",
    "            if metric=='loss':\n",
    "                print('Train min %s:%.3f'%(metric, min(train_res[j][:,i])))\n",
    "                print('Test min %s:%.3f'%(metric, min(test_res[j][:,i])))\n",
    "            else:\n",
    "                print('Train max %s:%.3f'%(metric, max(train_res[j][:,i])))\n",
    "                print('Test max %s:%.3f'%(metric, max(test_res[j][:,i])))\n",
    "        print('-'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/All/base/hidden:50\n",
      "num_hidden: 50\n",
      "learning rate: 0.05\n",
      "# Train set size: 297\n",
      "# Training batches: 297\n",
      "# Test set size: 297\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.282 ;acc: 0.280 ;iou: 0.360 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 1.581 ;acc: 0.385 ;iou: 0.450 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 1.556 ;acc: 0.420 ;iou: 0.530 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 3.811 ;acc: 0.080 ;iou: 0.200 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.405 ;acc: 0.175 ;iou: 0.265 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 3.014 ;acc: 0.090 ;iou: 0.190 ;time: 0:00:27\n",
      "\n",
      "*Training B: True ;B Train loss: 2.437 ;Train accuracy: 0.215 ;IOU accuracy: 0.314 ;Time: 0:00:32 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 1.387 ;acc: 0.435 ;iou_acc: 0.640 ;time: 0:00:32\n",
      "batch: 50 ;B loss: 1.865 ;acc: 0.225 ;iou_acc: 0.350 ;time: 0:00:36\n",
      "batch: 100 ;B loss: 2.120 ;acc: 0.220 ;iou_acc: 0.325 ;time: 0:00:40\n",
      "batch: 150 ;B loss: 2.432 ;acc: 0.150 ;iou_acc: 0.265 ;time: 0:00:43\n",
      "batch: 200 ;B loss: 2.740 ;acc: 0.160 ;iou_acc: 0.240 ;time: 0:00:48\n",
      "batch: 250 ;B loss: 3.169 ;acc: 0.090 ;iou_acc: 0.170 ;time: 0:00:53\n",
      "\n",
      "*BTrain: True ;Test loss: 2.440 ;Test accuracy 0.194 ;IOU accuracy: 0.296 ;Time: 0:00:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 1.558 ;acc: 0.380 ;iou: 0.485 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 1.388 ;acc: 0.520 ;iou: 0.655 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.315 ;acc: 0.195 ;iou: 0.260 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 1.543 ;acc: 0.400 ;iou: 0.525 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.830 ;acc: 0.125 ;iou: 0.200 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 1.563 ;acc: 0.335 ;iou: 0.440 ;time: 0:00:27\n",
      "\n",
      "*Training B: False ;B Train loss: 2.434 ;Train accuracy: 0.218 ;IOU accuracy: 0.314 ;Time: 0:00:32 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 1.387 ;acc: 0.455 ;iou_acc: 0.650 ;time: 0:00:32\n",
      "batch: 50 ;B loss: 1.860 ;acc: 0.275 ;iou_acc: 0.400 ;time: 0:00:36\n",
      "batch: 100 ;B loss: 2.121 ;acc: 0.220 ;iou_acc: 0.310 ;time: 0:00:40\n",
      "batch: 150 ;B loss: 2.435 ;acc: 0.110 ;iou_acc: 0.205 ;time: 0:00:43\n",
      "batch: 200 ;B loss: 2.739 ;acc: 0.150 ;iou_acc: 0.240 ;time: 0:00:47\n",
      "batch: 250 ;B loss: 3.166 ;acc: 0.110 ;iou_acc: 0.200 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.440 ;Test accuracy 0.195 ;IOU accuracy: 0.295 ;Time: 0:00:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 1.388 ;acc: 0.545 ;iou: 0.720 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 3.070 ;acc: 0.120 ;iou: 0.205 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.401 ;acc: 0.160 ;iou: 0.245 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 3.018 ;acc: 0.185 ;iou: 0.265 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.597 ;acc: 0.180 ;iou: 0.250 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 3.009 ;acc: 0.135 ;iou: 0.205 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.433 ;Train accuracy: 0.220 ;IOU accuracy: 0.317 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 1.389 ;acc: 0.425 ;iou_acc: 0.625 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.857 ;acc: 0.280 ;iou_acc: 0.420 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 2.121 ;acc: 0.230 ;iou_acc: 0.320 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.439 ;acc: 0.115 ;iou_acc: 0.205 ;time: 0:00:40\n",
      "batch: 200 ;B loss: 2.740 ;acc: 0.145 ;iou_acc: 0.255 ;time: 0:00:44\n",
      "batch: 250 ;B loss: 3.163 ;acc: 0.085 ;iou_acc: 0.175 ;time: 0:00:49\n",
      "\n",
      "*BTrain: False ;Test loss: 2.440 ;Test accuracy 0.196 ;IOU accuracy: 0.296 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.612 ;acc: 0.170 ;iou: 0.250 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.174 ;acc: 0.245 ;iou: 0.330 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.939 ;acc: 0.245 ;iou: 0.385 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 2.127 ;acc: 0.250 ;iou: 0.350 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.836 ;acc: 0.290 ;iou: 0.395 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 2.422 ;acc: 0.175 ;iou: 0.320 ;time: 0:00:25\n",
      "\n",
      "*Training B: True ;B Train loss: 2.431 ;Train accuracy: 0.226 ;IOU accuracy: 0.322 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.390 ;acc: 0.460 ;iou_acc: 0.665 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.857 ;acc: 0.260 ;iou_acc: 0.410 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.120 ;acc: 0.185 ;iou_acc: 0.265 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.437 ;acc: 0.105 ;iou_acc: 0.225 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.746 ;acc: 0.125 ;iou_acc: 0.215 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.161 ;acc: 0.135 ;iou_acc: 0.230 ;time: 0:00:50\n",
      "\n",
      "*BTrain: True ;Test loss: 2.440 ;Test accuracy 0.196 ;IOU accuracy: 0.297 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 2.758 ;acc: 0.155 ;iou: 0.265 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 2.749 ;acc: 0.215 ;iou: 0.305 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.927 ;acc: 0.255 ;iou: 0.385 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.594 ;acc: 0.410 ;iou: 0.515 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 2.190 ;acc: 0.250 ;iou: 0.310 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 2.425 ;acc: 0.180 ;iou: 0.310 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.429 ;Train accuracy: 0.235 ;IOU accuracy: 0.331 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.390 ;acc: 0.495 ;iou_acc: 0.685 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.861 ;acc: 0.270 ;iou_acc: 0.420 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 2.120 ;acc: 0.185 ;iou_acc: 0.310 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.441 ;acc: 0.105 ;iou_acc: 0.195 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.746 ;acc: 0.160 ;iou_acc: 0.260 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.162 ;acc: 0.115 ;iou_acc: 0.210 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.440 ;Test accuracy 0.197 ;IOU accuracy: 0.292 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.859 ;acc: 0.300 ;iou: 0.385 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.393 ;acc: 0.545 ;iou: 0.675 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 2.856 ;acc: 0.125 ;iou: 0.230 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 2.594 ;acc: 0.205 ;iou: 0.275 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 2.177 ;acc: 0.275 ;iou: 0.380 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 2.376 ;acc: 0.225 ;iou: 0.325 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.427 ;Train accuracy: 0.245 ;IOU accuracy: 0.339 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.393 ;acc: 0.445 ;iou_acc: 0.650 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.858 ;acc: 0.300 ;iou_acc: 0.440 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 2.119 ;acc: 0.210 ;iou_acc: 0.300 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.446 ;acc: 0.145 ;iou_acc: 0.245 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.746 ;acc: 0.130 ;iou_acc: 0.250 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 3.156 ;acc: 0.110 ;iou_acc: 0.190 ;time: 0:00:49\n",
      "\n",
      "*BTrain: False ;Test loss: 2.442 ;Test accuracy 0.196 ;IOU accuracy: 0.298 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 2.363 ;acc: 0.260 ;iou: 0.380 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 2.096 ;acc: 0.255 ;iou: 0.355 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 2.833 ;acc: 0.225 ;iou: 0.315 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 2.558 ;acc: 0.230 ;iou: 0.315 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.394 ;acc: 0.475 ;iou: 0.620 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 3.311 ;acc: 0.110 ;iou: 0.195 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 2.424 ;Train accuracy: 0.252 ;IOU accuracy: 0.347 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.396 ;acc: 0.495 ;iou_acc: 0.695 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.862 ;acc: 0.285 ;iou_acc: 0.445 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.125 ;acc: 0.155 ;iou_acc: 0.245 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.447 ;acc: 0.125 ;iou_acc: 0.235 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.749 ;acc: 0.145 ;iou_acc: 0.280 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.153 ;acc: 0.115 ;iou_acc: 0.235 ;time: 0:00:51\n",
      "\n",
      "*BTrain: True ;Test loss: 2.444 ;Test accuracy 0.196 ;IOU accuracy: 0.299 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 2.630 ;acc: 0.185 ;iou: 0.285 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 2.159 ;acc: 0.350 ;iou: 0.450 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 2.577 ;acc: 0.240 ;iou: 0.285 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 3.268 ;acc: 0.155 ;iou: 0.215 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.395 ;acc: 0.545 ;iou: 0.670 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 2.185 ;acc: 0.290 ;iou: 0.395 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.421 ;Train accuracy: 0.259 ;IOU accuracy: 0.356 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.398 ;acc: 0.465 ;iou_acc: 0.665 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.858 ;acc: 0.295 ;iou_acc: 0.440 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.133 ;acc: 0.165 ;iou_acc: 0.260 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.454 ;acc: 0.105 ;iou_acc: 0.235 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.745 ;acc: 0.125 ;iou_acc: 0.220 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 3.154 ;acc: 0.125 ;iou_acc: 0.230 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.445 ;Test accuracy 0.195 ;IOU accuracy: 0.299 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 3.298 ;acc: 0.195 ;iou: 0.290 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 2.378 ;acc: 0.255 ;iou: 0.345 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 2.381 ;acc: 0.240 ;iou: 0.350 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.882 ;acc: 0.340 ;iou: 0.445 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 2.717 ;acc: 0.150 ;iou: 0.245 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 2.581 ;acc: 0.195 ;iou: 0.320 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.417 ;Train accuracy: 0.266 ;IOU accuracy: 0.362 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.402 ;acc: 0.485 ;iou_acc: 0.665 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.871 ;acc: 0.285 ;iou_acc: 0.425 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.126 ;acc: 0.215 ;iou_acc: 0.305 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.451 ;acc: 0.120 ;iou_acc: 0.185 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.754 ;acc: 0.160 ;iou_acc: 0.265 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.139 ;acc: 0.120 ;iou_acc: 0.210 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.450 ;Test accuracy 0.197 ;IOU accuracy: 0.297 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 3.732 ;acc: 0.180 ;iou: 0.265 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 2.479 ;acc: 0.225 ;iou: 0.275 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.871 ;acc: 0.345 ;iou: 0.430 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 2.139 ;acc: 0.265 ;iou: 0.350 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.843 ;acc: 0.300 ;iou: 0.405 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.880 ;acc: 0.305 ;iou: 0.390 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.413 ;Train accuracy: 0.276 ;IOU accuracy: 0.369 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.404 ;acc: 0.490 ;iou_acc: 0.680 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.861 ;acc: 0.280 ;iou_acc: 0.455 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 2.122 ;acc: 0.205 ;iou_acc: 0.310 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.469 ;acc: 0.105 ;iou_acc: 0.210 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.760 ;acc: 0.135 ;iou_acc: 0.260 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 3.157 ;acc: 0.100 ;iou_acc: 0.210 ;time: 0:00:50\n",
      "\n",
      "*BTrain: True ;Test loss: 2.450 ;Test accuracy 0.197 ;IOU accuracy: 0.300 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 2.478 ;acc: 0.270 ;iou: 0.305 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.832 ;acc: 0.395 ;iou: 0.470 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 2.162 ;acc: 0.335 ;iou: 0.420 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 2.776 ;acc: 0.220 ;iou: 0.300 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 3.248 ;acc: 0.145 ;iou: 0.215 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 3.555 ;acc: 0.125 ;iou: 0.195 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.409 ;Train accuracy: 0.283 ;IOU accuracy: 0.378 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.409 ;acc: 0.440 ;iou_acc: 0.650 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.863 ;acc: 0.300 ;iou_acc: 0.460 ;time: 0:00:35\n",
      "batch: 100 ;B loss: 2.128 ;acc: 0.195 ;iou_acc: 0.320 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.455 ;acc: 0.135 ;iou_acc: 0.235 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.744 ;acc: 0.155 ;iou_acc: 0.235 ;time: 0:00:47\n",
      "batch: 250 ;B loss: 3.158 ;acc: 0.095 ;iou_acc: 0.170 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.452 ;Test accuracy 0.198 ;IOU accuracy: 0.304 ;Time: 0:00:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.514 ;acc: 0.470 ;iou: 0.540 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 2.781 ;acc: 0.235 ;iou: 0.345 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 2.356 ;acc: 0.305 ;iou: 0.400 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.513 ;acc: 0.445 ;iou: 0.545 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.851 ;acc: 0.295 ;iou: 0.405 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 2.244 ;acc: 0.255 ;iou: 0.330 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.403 ;Train accuracy: 0.292 ;IOU accuracy: 0.385 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.405 ;acc: 0.460 ;iou_acc: 0.635 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.867 ;acc: 0.300 ;iou_acc: 0.445 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.135 ;acc: 0.175 ;iou_acc: 0.320 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.457 ;acc: 0.135 ;iou_acc: 0.235 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.750 ;acc: 0.140 ;iou_acc: 0.235 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.153 ;acc: 0.130 ;iou_acc: 0.245 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.450 ;Test accuracy 0.197 ;IOU accuracy: 0.302 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 3.043 ;acc: 0.210 ;iou: 0.300 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 2.674 ;acc: 0.295 ;iou: 0.385 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 2.143 ;acc: 0.295 ;iou: 0.395 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 2.510 ;acc: 0.265 ;iou: 0.365 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.512 ;acc: 0.420 ;iou: 0.505 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 3.194 ;acc: 0.165 ;iou: 0.240 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 2.399 ;Train accuracy: 0.296 ;IOU accuracy: 0.391 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.412 ;acc: 0.495 ;iou_acc: 0.680 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.866 ;acc: 0.295 ;iou_acc: 0.450 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.133 ;acc: 0.195 ;iou_acc: 0.315 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.466 ;acc: 0.105 ;iou_acc: 0.180 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.748 ;acc: 0.140 ;iou_acc: 0.240 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.144 ;acc: 0.115 ;iou_acc: 0.230 ;time: 0:00:51\n",
      "\n",
      "*BTrain: True ;Test loss: 2.455 ;Test accuracy 0.201 ;IOU accuracy: 0.304 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 2.551 ;acc: 0.315 ;iou: 0.370 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 3.534 ;acc: 0.155 ;iou: 0.280 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 2.120 ;acc: 0.320 ;iou: 0.435 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 2.369 ;acc: 0.275 ;iou: 0.365 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.814 ;acc: 0.340 ;iou: 0.465 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 2.182 ;acc: 0.310 ;iou: 0.405 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.394 ;Train accuracy: 0.302 ;IOU accuracy: 0.396 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.408 ;acc: 0.510 ;iou_acc: 0.670 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.861 ;acc: 0.320 ;iou_acc: 0.455 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.139 ;acc: 0.170 ;iou_acc: 0.285 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.443 ;acc: 0.165 ;iou_acc: 0.240 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.731 ;acc: 0.165 ;iou_acc: 0.300 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 3.177 ;acc: 0.115 ;iou_acc: 0.220 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.460 ;Test accuracy 0.200 ;IOU accuracy: 0.307 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 1.482 ;acc: 0.395 ;iou: 0.475 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.499 ;acc: 0.455 ;iou: 0.545 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 2.154 ;acc: 0.355 ;iou: 0.440 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 2.345 ;acc: 0.265 ;iou: 0.325 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.854 ;acc: 0.365 ;iou: 0.440 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 2.320 ;acc: 0.295 ;iou: 0.380 ;time: 0:00:27\n",
      "\n",
      "*Training B: False ;B Train loss: 2.388 ;Train accuracy: 0.312 ;IOU accuracy: 0.406 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.415 ;acc: 0.525 ;iou_acc: 0.690 ;time: 0:00:32\n",
      "batch: 50 ;B loss: 1.871 ;acc: 0.265 ;iou_acc: 0.410 ;time: 0:00:35\n",
      "batch: 100 ;B loss: 2.146 ;acc: 0.185 ;iou_acc: 0.285 ;time: 0:00:39\n",
      "batch: 150 ;B loss: 2.445 ;acc: 0.120 ;iou_acc: 0.190 ;time: 0:00:43\n",
      "batch: 200 ;B loss: 2.724 ;acc: 0.165 ;iou_acc: 0.295 ;time: 0:00:47\n",
      "batch: 250 ;B loss: 3.156 ;acc: 0.100 ;iou_acc: 0.185 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.451 ;Test accuracy 0.207 ;IOU accuracy: 0.315 ;Time: 0:00:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 2.118 ;acc: 0.405 ;iou: 0.495 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 3.183 ;acc: 0.210 ;iou: 0.270 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 3.210 ;acc: 0.200 ;iou: 0.270 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 2.755 ;acc: 0.245 ;iou: 0.340 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 2.118 ;acc: 0.330 ;iou: 0.470 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 1.521 ;acc: 0.495 ;iou: 0.580 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 2.381 ;Train accuracy: 0.318 ;IOU accuracy: 0.411 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.417 ;acc: 0.470 ;iou_acc: 0.630 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.871 ;acc: 0.290 ;iou_acc: 0.435 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.115 ;acc: 0.195 ;iou_acc: 0.335 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.437 ;acc: 0.130 ;iou_acc: 0.250 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.723 ;acc: 0.175 ;iou_acc: 0.305 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.151 ;acc: 0.105 ;iou_acc: 0.250 ;time: 0:00:50\n",
      "\n",
      "*BTrain: True ;Test loss: 2.459 ;Test accuracy 0.205 ;IOU accuracy: 0.317 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 1.544 ;acc: 0.450 ;iou: 0.560 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 2.628 ;acc: 0.255 ;iou: 0.340 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 1.408 ;acc: 0.525 ;iou: 0.665 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 1.413 ;acc: 0.510 ;iou: 0.690 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 3.170 ;acc: 0.245 ;iou: 0.285 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 2.299 ;acc: 0.305 ;iou: 0.400 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.372 ;Train accuracy: 0.327 ;IOU accuracy: 0.421 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.430 ;acc: 0.490 ;iou_acc: 0.650 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.862 ;acc: 0.270 ;iou_acc: 0.395 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.129 ;acc: 0.230 ;iou_acc: 0.365 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.443 ;acc: 0.175 ;iou_acc: 0.275 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.727 ;acc: 0.195 ;iou_acc: 0.305 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 3.124 ;acc: 0.135 ;iou_acc: 0.275 ;time: 0:00:48\n",
      "\n",
      "*BTrain: False ;Test loss: 2.446 ;Test accuracy 0.216 ;IOU accuracy: 0.329 ;Time: 0:00:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 2.277 ;acc: 0.380 ;iou: 0.465 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 2.067 ;acc: 0.395 ;iou: 0.510 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 2.412 ;acc: 0.315 ;iou: 0.400 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 1.493 ;acc: 0.515 ;iou: 0.585 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 2.793 ;acc: 0.235 ;iou: 0.350 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 1.562 ;acc: 0.455 ;iou: 0.575 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.363 ;Train accuracy: 0.333 ;IOU accuracy: 0.427 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.421 ;acc: 0.490 ;iou_acc: 0.650 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.843 ;acc: 0.330 ;iou_acc: 0.455 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 2.132 ;acc: 0.225 ;iou_acc: 0.360 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.423 ;acc: 0.175 ;iou_acc: 0.280 ;time: 0:00:40\n",
      "batch: 200 ;B loss: 2.709 ;acc: 0.220 ;iou_acc: 0.310 ;time: 0:00:44\n",
      "batch: 250 ;B loss: 3.109 ;acc: 0.170 ;iou_acc: 0.270 ;time: 0:00:49\n",
      "\n",
      "*BTrain: False ;Test loss: 2.435 ;Test accuracy 0.223 ;IOU accuracy: 0.338 ;Time: 0:00:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 1.853 ;acc: 0.450 ;iou: 0.560 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 2.059 ;acc: 0.405 ;iou: 0.490 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 1.474 ;acc: 0.480 ;iou: 0.590 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 1.514 ;acc: 0.430 ;iou: 0.515 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 1.808 ;acc: 0.380 ;iou: 0.485 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 3.611 ;acc: 0.175 ;iou: 0.270 ;time: 0:00:25\n",
      "\n",
      "*Training B: True ;B Train loss: 2.351 ;Train accuracy: 0.343 ;IOU accuracy: 0.436 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.424 ;acc: 0.505 ;iou_acc: 0.645 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.841 ;acc: 0.335 ;iou_acc: 0.460 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.121 ;acc: 0.250 ;iou_acc: 0.365 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.386 ;acc: 0.165 ;iou_acc: 0.275 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.680 ;acc: 0.205 ;iou_acc: 0.290 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.086 ;acc: 0.165 ;iou_acc: 0.240 ;time: 0:00:50\n",
      "\n",
      "*BTrain: True ;Test loss: 2.431 ;Test accuracy 0.226 ;IOU accuracy: 0.339 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 2.417 ;acc: 0.370 ;iou: 0.480 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 2.056 ;acc: 0.425 ;iou: 0.525 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 2.058 ;acc: 0.405 ;iou: 0.540 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 1.997 ;acc: 0.390 ;iou: 0.490 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 2.694 ;acc: 0.285 ;iou: 0.420 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 2.778 ;acc: 0.235 ;iou: 0.340 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.341 ;Train accuracy: 0.349 ;IOU accuracy: 0.444 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.431 ;acc: 0.500 ;iou_acc: 0.640 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.838 ;acc: 0.350 ;iou_acc: 0.450 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.099 ;acc: 0.260 ;iou_acc: 0.380 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.395 ;acc: 0.150 ;iou_acc: 0.250 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.704 ;acc: 0.185 ;iou_acc: 0.310 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.072 ;acc: 0.135 ;iou_acc: 0.265 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.425 ;Test accuracy 0.233 ;IOU accuracy: 0.344 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 2.255 ;acc: 0.410 ;iou: 0.490 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 2.035 ;acc: 0.375 ;iou: 0.490 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 2.085 ;acc: 0.395 ;iou: 0.455 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 2.255 ;acc: 0.335 ;iou: 0.425 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 2.430 ;acc: 0.340 ;iou: 0.415 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 3.652 ;acc: 0.180 ;iou: 0.270 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.330 ;Train accuracy: 0.357 ;IOU accuracy: 0.450 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.439 ;acc: 0.525 ;iou_acc: 0.695 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.825 ;acc: 0.350 ;iou_acc: 0.470 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.089 ;acc: 0.285 ;iou_acc: 0.385 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.398 ;acc: 0.215 ;iou_acc: 0.305 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.695 ;acc: 0.195 ;iou_acc: 0.280 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.076 ;acc: 0.155 ;iou_acc: 0.275 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.431 ;Test accuracy 0.236 ;IOU accuracy: 0.347 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 2.601 ;acc: 0.330 ;iou: 0.410 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 2.510 ;acc: 0.320 ;iou: 0.390 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 2.594 ;acc: 0.360 ;iou: 0.435 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 2.956 ;acc: 0.260 ;iou: 0.330 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 1.515 ;acc: 0.570 ;iou: 0.650 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 2.813 ;acc: 0.265 ;iou: 0.350 ;time: 0:00:25\n",
      "\n",
      "*Training B: True ;B Train loss: 2.320 ;Train accuracy: 0.363 ;IOU accuracy: 0.454 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.445 ;acc: 0.550 ;iou_acc: 0.690 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.860 ;acc: 0.335 ;iou_acc: 0.480 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 2.122 ;acc: 0.255 ;iou_acc: 0.405 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.367 ;acc: 0.200 ;iou_acc: 0.300 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.704 ;acc: 0.180 ;iou_acc: 0.240 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 3.132 ;acc: 0.125 ;iou_acc: 0.240 ;time: 0:00:49\n",
      "\n",
      "*BTrain: True ;Test loss: 2.456 ;Test accuracy 0.235 ;IOU accuracy: 0.345 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 1.800 ;acc: 0.500 ;iou: 0.535 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 1.956 ;acc: 0.400 ;iou: 0.485 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 2.789 ;acc: 0.325 ;iou: 0.405 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 2.007 ;acc: 0.400 ;iou: 0.510 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 1.447 ;acc: 0.495 ;iou: 0.590 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 1.466 ;acc: 0.535 ;iou: 0.615 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.310 ;Train accuracy: 0.371 ;IOU accuracy: 0.464 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.441 ;acc: 0.510 ;iou_acc: 0.700 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.822 ;acc: 0.380 ;iou_acc: 0.455 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 2.101 ;acc: 0.245 ;iou_acc: 0.370 ;time: 0:00:36\n",
      "batch: 150 ;B loss: 2.398 ;acc: 0.185 ;iou_acc: 0.270 ;time: 0:00:40\n",
      "batch: 200 ;B loss: 2.697 ;acc: 0.210 ;iou_acc: 0.305 ;time: 0:00:44\n",
      "batch: 250 ;B loss: 3.072 ;acc: 0.160 ;iou_acc: 0.295 ;time: 0:00:49\n",
      "\n",
      "*BTrain: False ;Test loss: 2.419 ;Test accuracy 0.243 ;IOU accuracy: 0.355 ;Time: 0:00:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 1.456 ;acc: 0.490 ;iou: 0.595 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 2.590 ;acc: 0.305 ;iou: 0.400 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 1.957 ;acc: 0.420 ;iou: 0.520 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 1.520 ;acc: 0.510 ;iou: 0.600 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 2.524 ;acc: 0.355 ;iou: 0.455 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 3.115 ;acc: 0.230 ;iou: 0.345 ;time: 0:00:27\n",
      "\n",
      "*Training B: False ;B Train loss: 2.300 ;Train accuracy: 0.379 ;IOU accuracy: 0.471 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.456 ;acc: 0.535 ;iou_acc: 0.715 ;time: 0:00:32\n",
      "batch: 50 ;B loss: 1.824 ;acc: 0.375 ;iou_acc: 0.495 ;time: 0:00:35\n",
      "batch: 100 ;B loss: 2.070 ;acc: 0.310 ;iou_acc: 0.435 ;time: 0:00:39\n",
      "batch: 150 ;B loss: 2.354 ;acc: 0.235 ;iou_acc: 0.325 ;time: 0:00:43\n",
      "batch: 200 ;B loss: 2.689 ;acc: 0.195 ;iou_acc: 0.275 ;time: 0:00:47\n",
      "batch: 250 ;B loss: 3.059 ;acc: 0.185 ;iou_acc: 0.290 ;time: 0:00:52\n",
      "\n",
      "*BTrain: False ;Test loss: 2.413 ;Test accuracy 0.249 ;IOU accuracy: 0.359 ;Time: 0:00:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 2.329 ;acc: 0.315 ;iou: 0.375 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 1.446 ;acc: 0.575 ;iou: 0.650 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 2.170 ;acc: 0.415 ;iou: 0.510 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 3.009 ;acc: 0.280 ;iou: 0.385 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 2.694 ;acc: 0.375 ;iou: 0.430 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 2.522 ;acc: 0.380 ;iou: 0.465 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 2.289 ;Train accuracy: 0.387 ;IOU accuracy: 0.478 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.478 ;acc: 0.550 ;iou_acc: 0.700 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.792 ;acc: 0.410 ;iou_acc: 0.500 ;time: 0:00:35\n",
      "batch: 100 ;B loss: 2.085 ;acc: 0.295 ;iou_acc: 0.440 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.342 ;acc: 0.235 ;iou_acc: 0.345 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.662 ;acc: 0.190 ;iou_acc: 0.270 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.047 ;acc: 0.185 ;iou_acc: 0.295 ;time: 0:00:50\n",
      "\n",
      "*BTrain: True ;Test loss: 2.410 ;Test accuracy 0.256 ;IOU accuracy: 0.368 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 2.447 ;acc: 0.345 ;iou: 0.415 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 2.789 ;acc: 0.335 ;iou: 0.430 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 1.679 ;acc: 0.505 ;iou: 0.585 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 3.746 ;acc: 0.160 ;iou: 0.290 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 3.341 ;acc: 0.185 ;iou: 0.235 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 2.474 ;acc: 0.330 ;iou: 0.415 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.276 ;Train accuracy: 0.395 ;IOU accuracy: 0.485 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.497 ;acc: 0.560 ;iou_acc: 0.715 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.796 ;acc: 0.380 ;iou_acc: 0.510 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.047 ;acc: 0.315 ;iou_acc: 0.415 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.357 ;acc: 0.250 ;iou_acc: 0.335 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.662 ;acc: 0.210 ;iou_acc: 0.305 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.058 ;acc: 0.150 ;iou_acc: 0.270 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.405 ;Test accuracy 0.265 ;IOU accuracy: 0.374 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 4.072 ;acc: 0.140 ;iou: 0.250 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 2.499 ;acc: 0.330 ;iou: 0.425 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 2.396 ;acc: 0.425 ;iou: 0.485 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 2.379 ;acc: 0.340 ;iou: 0.420 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 1.971 ;acc: 0.455 ;iou: 0.525 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 1.471 ;acc: 0.505 ;iou: 0.610 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.264 ;Train accuracy: 0.404 ;IOU accuracy: 0.493 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.492 ;acc: 0.600 ;iou_acc: 0.735 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.799 ;acc: 0.415 ;iou_acc: 0.550 ;time: 0:00:35\n",
      "batch: 100 ;B loss: 2.045 ;acc: 0.335 ;iou_acc: 0.440 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.324 ;acc: 0.260 ;iou_acc: 0.355 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.630 ;acc: 0.225 ;iou_acc: 0.310 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.025 ;acc: 0.195 ;iou_acc: 0.300 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.397 ;Test accuracy 0.270 ;IOU accuracy: 0.379 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 2.082 ;acc: 0.420 ;iou: 0.490 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 1.450 ;acc: 0.600 ;iou: 0.670 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 2.193 ;acc: 0.425 ;iou: 0.490 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 2.694 ;acc: 0.345 ;iou: 0.425 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 2.816 ;acc: 0.280 ;iou: 0.405 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 2.762 ;acc: 0.365 ;iou: 0.455 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 2.245 ;Train accuracy: 0.416 ;IOU accuracy: 0.503 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.542 ;acc: 0.570 ;iou_acc: 0.725 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.759 ;acc: 0.390 ;iou_acc: 0.545 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 2.034 ;acc: 0.305 ;iou_acc: 0.425 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.288 ;acc: 0.295 ;iou_acc: 0.400 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.668 ;acc: 0.215 ;iou_acc: 0.305 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 3.000 ;acc: 0.175 ;iou_acc: 0.290 ;time: 0:00:51\n",
      "\n",
      "*BTrain: True ;Test loss: 2.390 ;Test accuracy 0.280 ;IOU accuracy: 0.390 ;Time: 0:00:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 1.662 ;acc: 0.545 ;iou: 0.610 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 1.405 ;acc: 0.625 ;iou: 0.690 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 1.871 ;acc: 0.495 ;iou: 0.550 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 1.637 ;acc: 0.510 ;iou: 0.575 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 2.107 ;acc: 0.410 ;iou: 0.485 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 1.932 ;acc: 0.460 ;iou: 0.540 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.229 ;Train accuracy: 0.426 ;IOU accuracy: 0.514 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.547 ;acc: 0.610 ;iou_acc: 0.760 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.800 ;acc: 0.425 ;iou_acc: 0.545 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.991 ;acc: 0.325 ;iou_acc: 0.445 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.247 ;acc: 0.260 ;iou_acc: 0.335 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.656 ;acc: 0.205 ;iou_acc: 0.320 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.980 ;acc: 0.190 ;iou_acc: 0.310 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.374 ;Test accuracy 0.288 ;IOU accuracy: 0.399 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 2.780 ;acc: 0.390 ;iou: 0.485 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 1.984 ;acc: 0.460 ;iou: 0.525 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 2.819 ;acc: 0.335 ;iou: 0.445 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 2.724 ;acc: 0.355 ;iou: 0.405 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 3.105 ;acc: 0.265 ;iou: 0.355 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 2.787 ;acc: 0.295 ;iou: 0.370 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.211 ;Train accuracy: 0.434 ;IOU accuracy: 0.519 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.556 ;acc: 0.595 ;iou_acc: 0.750 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.741 ;acc: 0.480 ;iou_acc: 0.575 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.968 ;acc: 0.355 ;iou_acc: 0.485 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.236 ;acc: 0.295 ;iou_acc: 0.395 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.683 ;acc: 0.245 ;iou_acc: 0.345 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.976 ;acc: 0.175 ;iou_acc: 0.285 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.365 ;Test accuracy 0.293 ;IOU accuracy: 0.401 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 2.759 ;acc: 0.315 ;iou: 0.390 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 2.066 ;acc: 0.495 ;iou: 0.580 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 1.604 ;acc: 0.550 ;iou: 0.615 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 3.212 ;acc: 0.255 ;iou: 0.295 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 1.619 ;acc: 0.585 ;iou: 0.685 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 1.311 ;acc: 0.595 ;iou: 0.675 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 2.194 ;Train accuracy: 0.443 ;IOU accuracy: 0.530 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.625 ;acc: 0.605 ;iou_acc: 0.750 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.795 ;acc: 0.415 ;iou_acc: 0.535 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.971 ;acc: 0.330 ;iou_acc: 0.470 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.228 ;acc: 0.275 ;iou_acc: 0.375 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.613 ;acc: 0.220 ;iou_acc: 0.325 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.968 ;acc: 0.220 ;iou_acc: 0.325 ;time: 0:00:51\n",
      "\n",
      "*BTrain: True ;Test loss: 2.350 ;Test accuracy 0.295 ;IOU accuracy: 0.405 ;Time: 0:00:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 2.441 ;acc: 0.425 ;iou: 0.515 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 3.307 ;acc: 0.270 ;iou: 0.355 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 2.350 ;acc: 0.420 ;iou: 0.535 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 1.345 ;acc: 0.610 ;iou: 0.690 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 1.635 ;acc: 0.560 ;iou: 0.630 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 1.523 ;acc: 0.565 ;iou: 0.620 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.179 ;Train accuracy: 0.453 ;IOU accuracy: 0.538 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.617 ;acc: 0.655 ;iou_acc: 0.780 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.768 ;acc: 0.440 ;iou_acc: 0.510 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.953 ;acc: 0.345 ;iou_acc: 0.475 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.176 ;acc: 0.310 ;iou_acc: 0.390 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.596 ;acc: 0.265 ;iou_acc: 0.345 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.943 ;acc: 0.205 ;iou_acc: 0.305 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.342 ;Test accuracy 0.307 ;IOU accuracy: 0.413 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 2.545 ;acc: 0.395 ;iou: 0.490 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 2.797 ;acc: 0.335 ;iou: 0.435 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 3.429 ;acc: 0.270 ;iou: 0.370 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 2.685 ;acc: 0.385 ;iou: 0.440 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 2.893 ;acc: 0.295 ;iou: 0.380 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 1.447 ;acc: 0.600 ;iou: 0.685 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.161 ;Train accuracy: 0.457 ;IOU accuracy: 0.542 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.694 ;acc: 0.630 ;iou_acc: 0.770 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.792 ;acc: 0.420 ;iou_acc: 0.540 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 1.942 ;acc: 0.365 ;iou_acc: 0.500 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.174 ;acc: 0.315 ;iou_acc: 0.420 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.585 ;acc: 0.280 ;iou_acc: 0.350 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.977 ;acc: 0.195 ;iou_acc: 0.275 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.353 ;Test accuracy 0.312 ;IOU accuracy: 0.419 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 1.970 ;acc: 0.470 ;iou: 0.540 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 2.452 ;acc: 0.375 ;iou: 0.470 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 2.016 ;acc: 0.465 ;iou: 0.545 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 1.625 ;acc: 0.635 ;iou: 0.755 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0450 ;B loss: 1.795 ;acc: 0.560 ;iou: 0.610 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0450 ;B loss: 3.185 ;acc: 0.250 ;iou: 0.360 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 2.147 ;Train accuracy: 0.464 ;IOU accuracy: 0.550 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.691 ;acc: 0.680 ;iou_acc: 0.805 ;time: 0:00:32\n",
      "batch: 50 ;B loss: 1.801 ;acc: 0.445 ;iou_acc: 0.555 ;time: 0:00:35\n",
      "batch: 100 ;B loss: 1.933 ;acc: 0.330 ;iou_acc: 0.465 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.192 ;acc: 0.275 ;iou_acc: 0.410 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.601 ;acc: 0.250 ;iou_acc: 0.350 ;time: 0:00:47\n",
      "batch: 250 ;B loss: 2.968 ;acc: 0.180 ;iou_acc: 0.280 ;time: 0:00:51\n",
      "\n",
      "*BTrain: True ;Test loss: 2.350 ;Test accuracy 0.311 ;IOU accuracy: 0.419 ;Time: 0:00:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0450 ;B loss: 1.687 ;acc: 0.565 ;iou: 0.625 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0450 ;B loss: 2.565 ;acc: 0.420 ;iou: 0.505 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0450 ;B loss: 2.206 ;acc: 0.435 ;iou: 0.520 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0450 ;B loss: 1.605 ;acc: 0.575 ;iou: 0.655 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0450 ;B loss: 2.942 ;acc: 0.310 ;iou: 0.370 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0450 ;B loss: 2.706 ;acc: 0.360 ;iou: 0.425 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.128 ;Train accuracy: 0.470 ;IOU accuracy: 0.555 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.709 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.780 ;acc: 0.465 ;iou_acc: 0.580 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.960 ;acc: 0.370 ;iou_acc: 0.510 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.188 ;acc: 0.305 ;iou_acc: 0.405 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.534 ;acc: 0.280 ;iou_acc: 0.355 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.960 ;acc: 0.200 ;iou_acc: 0.310 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.327 ;Test accuracy 0.322 ;IOU accuracy: 0.430 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0450 ;B loss: 1.596 ;acc: 0.580 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0450 ;B loss: 1.783 ;acc: 0.555 ;iou: 0.630 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0450 ;B loss: 1.541 ;acc: 0.615 ;iou: 0.675 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0450 ;B loss: 1.517 ;acc: 0.595 ;iou: 0.690 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0450 ;B loss: 1.361 ;acc: 0.575 ;iou: 0.650 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0450 ;B loss: 1.597 ;acc: 0.595 ;iou: 0.750 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.117 ;Train accuracy: 0.475 ;IOU accuracy: 0.560 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.685 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.736 ;acc: 0.435 ;iou_acc: 0.565 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.962 ;acc: 0.340 ;iou_acc: 0.510 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.164 ;acc: 0.305 ;iou_acc: 0.420 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.536 ;acc: 0.275 ;iou_acc: 0.355 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.961 ;acc: 0.195 ;iou_acc: 0.320 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.326 ;Test accuracy 0.322 ;IOU accuracy: 0.431 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0450 ;B loss: 2.203 ;acc: 0.425 ;iou: 0.530 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0450 ;B loss: 1.765 ;acc: 0.575 ;iou: 0.640 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0450 ;B loss: 1.544 ;acc: 0.585 ;iou: 0.670 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0450 ;B loss: 1.361 ;acc: 0.580 ;iou: 0.685 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0450 ;B loss: 3.331 ;acc: 0.275 ;iou: 0.330 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0450 ;B loss: 3.473 ;acc: 0.220 ;iou: 0.350 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 2.107 ;Train accuracy: 0.480 ;IOU accuracy: 0.564 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.750 ;acc: 0.665 ;iou_acc: 0.805 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.756 ;acc: 0.435 ;iou_acc: 0.535 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.921 ;acc: 0.400 ;iou_acc: 0.520 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.197 ;acc: 0.310 ;iou_acc: 0.415 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.541 ;acc: 0.260 ;iou_acc: 0.335 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.952 ;acc: 0.200 ;iou_acc: 0.315 ;time: 0:00:51\n",
      "\n",
      "*BTrain: True ;Test loss: 2.330 ;Test accuracy 0.325 ;IOU accuracy: 0.431 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0450 ;B loss: 1.734 ;acc: 0.570 ;iou: 0.630 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0450 ;B loss: 2.000 ;acc: 0.480 ;iou: 0.585 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0450 ;B loss: 1.499 ;acc: 0.620 ;iou: 0.710 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0450 ;B loss: 2.115 ;acc: 0.480 ;iou: 0.530 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0450 ;B loss: 2.673 ;acc: 0.335 ;iou: 0.435 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0450 ;B loss: 1.352 ;acc: 0.560 ;iou: 0.660 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.095 ;Train accuracy: 0.487 ;IOU accuracy: 0.571 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.762 ;acc: 0.670 ;iou_acc: 0.810 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.738 ;acc: 0.435 ;iou_acc: 0.560 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.908 ;acc: 0.385 ;iou_acc: 0.510 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.193 ;acc: 0.295 ;iou_acc: 0.390 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.544 ;acc: 0.270 ;iou_acc: 0.350 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.939 ;acc: 0.200 ;iou_acc: 0.315 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.317 ;Test accuracy 0.329 ;IOU accuracy: 0.436 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0450 ;B loss: 1.610 ;acc: 0.650 ;iou: 0.775 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0450 ;B loss: 2.325 ;acc: 0.470 ;iou: 0.520 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0450 ;B loss: 1.762 ;acc: 0.540 ;iou: 0.600 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0450 ;B loss: 1.490 ;acc: 0.590 ;iou: 0.660 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0450 ;B loss: 1.736 ;acc: 0.560 ;iou: 0.640 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0450 ;B loss: 1.505 ;acc: 0.570 ;iou: 0.650 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.088 ;Train accuracy: 0.490 ;IOU accuracy: 0.573 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.579 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.730 ;acc: 0.410 ;iou_acc: 0.545 ;time: 0:00:35\n",
      "batch: 100 ;B loss: 1.933 ;acc: 0.380 ;iou_acc: 0.495 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.234 ;acc: 0.260 ;iou_acc: 0.360 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.525 ;acc: 0.290 ;iou_acc: 0.405 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.940 ;acc: 0.200 ;iou_acc: 0.320 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.326 ;Test accuracy 0.313 ;IOU accuracy: 0.425 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0450 ;B loss: 2.440 ;acc: 0.415 ;iou: 0.475 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0450 ;B loss: 1.736 ;acc: 0.585 ;iou: 0.660 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0450 ;B loss: 3.454 ;acc: 0.240 ;iou: 0.320 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0450 ;B loss: 2.036 ;acc: 0.465 ;iou: 0.555 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0450 ;B loss: 2.881 ;acc: 0.320 ;iou: 0.425 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0450 ;B loss: 1.693 ;acc: 0.575 ;iou: 0.660 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 2.075 ;Train accuracy: 0.498 ;IOU accuracy: 0.581 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.805 ;acc: 0.640 ;iou_acc: 0.780 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.781 ;acc: 0.440 ;iou_acc: 0.575 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.909 ;acc: 0.430 ;iou_acc: 0.550 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.203 ;acc: 0.360 ;iou_acc: 0.475 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.514 ;acc: 0.305 ;iou_acc: 0.375 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.922 ;acc: 0.225 ;iou_acc: 0.345 ;time: 0:00:51\n",
      "\n",
      "*BTrain: True ;Test loss: 2.330 ;Test accuracy 0.335 ;IOU accuracy: 0.445 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0450 ;B loss: 2.840 ;acc: 0.320 ;iou: 0.440 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0450 ;B loss: 2.689 ;acc: 0.395 ;iou: 0.450 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0450 ;B loss: 1.340 ;acc: 0.610 ;iou: 0.715 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0450 ;B loss: 3.263 ;acc: 0.275 ;iou: 0.375 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0450 ;B loss: 3.010 ;acc: 0.295 ;iou: 0.380 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0450 ;B loss: 2.046 ;acc: 0.485 ;iou: 0.570 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.066 ;Train accuracy: 0.501 ;IOU accuracy: 0.584 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.685 ;acc: 0.665 ;iou_acc: 0.805 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.726 ;acc: 0.465 ;iou_acc: 0.565 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 1.936 ;acc: 0.370 ;iou_acc: 0.500 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.211 ;acc: 0.315 ;iou_acc: 0.435 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.497 ;acc: 0.310 ;iou_acc: 0.385 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.952 ;acc: 0.250 ;iou_acc: 0.365 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.321 ;Test accuracy 0.328 ;IOU accuracy: 0.440 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0450 ;B loss: 1.288 ;acc: 0.615 ;iou: 0.690 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0450 ;B loss: 2.030 ;acc: 0.515 ;iou: 0.600 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0450 ;B loss: 1.910 ;acc: 0.525 ;iou: 0.615 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0450 ;B loss: 1.453 ;acc: 0.615 ;iou: 0.685 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0450 ;B loss: 2.531 ;acc: 0.465 ;iou: 0.530 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0450 ;B loss: 1.507 ;acc: 0.520 ;iou: 0.640 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.056 ;Train accuracy: 0.507 ;IOU accuracy: 0.589 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.805 ;acc: 0.680 ;iou_acc: 0.810 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.728 ;acc: 0.475 ;iou_acc: 0.580 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.903 ;acc: 0.405 ;iou_acc: 0.545 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.181 ;acc: 0.345 ;iou_acc: 0.450 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.516 ;acc: 0.325 ;iou_acc: 0.435 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.935 ;acc: 0.200 ;iou_acc: 0.290 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.325 ;Test accuracy 0.337 ;IOU accuracy: 0.446 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0450 ;B loss: 2.498 ;acc: 0.400 ;iou: 0.485 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0450 ;B loss: 1.590 ;acc: 0.635 ;iou: 0.780 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0450 ;B loss: 1.627 ;acc: 0.665 ;iou: 0.725 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0450 ;B loss: 3.273 ;acc: 0.290 ;iou: 0.395 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0450 ;B loss: 1.865 ;acc: 0.550 ;iou: 0.600 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0450 ;B loss: 1.374 ;acc: 0.605 ;iou: 0.660 ;time: 0:00:25\n",
      "\n",
      "*Training B: True ;B Train loss: 2.044 ;Train accuracy: 0.511 ;IOU accuracy: 0.592 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.911 ;acc: 0.700 ;iou_acc: 0.825 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.768 ;acc: 0.495 ;iou_acc: 0.590 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.878 ;acc: 0.445 ;iou_acc: 0.540 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.180 ;acc: 0.310 ;iou_acc: 0.430 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.490 ;acc: 0.325 ;iou_acc: 0.405 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.941 ;acc: 0.195 ;iou_acc: 0.285 ;time: 0:00:50\n",
      "\n",
      "*BTrain: True ;Test loss: 2.339 ;Test accuracy 0.343 ;IOU accuracy: 0.452 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0450 ;B loss: 2.348 ;acc: 0.480 ;iou: 0.575 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0450 ;B loss: 3.094 ;acc: 0.350 ;iou: 0.415 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0450 ;B loss: 2.318 ;acc: 0.475 ;iou: 0.535 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0450 ;B loss: 2.076 ;acc: 0.565 ;iou: 0.620 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0450 ;B loss: 1.602 ;acc: 0.650 ;iou: 0.740 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0450 ;B loss: 3.256 ;acc: 0.295 ;iou: 0.340 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.037 ;Train accuracy: 0.513 ;IOU accuracy: 0.595 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.802 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.726 ;acc: 0.475 ;iou_acc: 0.595 ;time: 0:00:35\n",
      "batch: 100 ;B loss: 1.903 ;acc: 0.405 ;iou_acc: 0.545 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.169 ;acc: 0.325 ;iou_acc: 0.455 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.481 ;acc: 0.295 ;iou_acc: 0.390 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.933 ;acc: 0.205 ;iou_acc: 0.310 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.313 ;Test accuracy 0.343 ;IOU accuracy: 0.454 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0450 ;B loss: 2.548 ;acc: 0.430 ;iou: 0.520 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0450 ;B loss: 2.317 ;acc: 0.445 ;iou: 0.515 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0450 ;B loss: 1.313 ;acc: 0.630 ;iou: 0.710 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0450 ;B loss: 1.247 ;acc: 0.675 ;iou: 0.760 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0450 ;B loss: 1.608 ;acc: 0.580 ;iou: 0.715 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0450 ;B loss: 2.421 ;acc: 0.470 ;iou: 0.555 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.028 ;Train accuracy: 0.517 ;IOU accuracy: 0.599 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.853 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.791 ;acc: 0.475 ;iou_acc: 0.590 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.943 ;acc: 0.355 ;iou_acc: 0.500 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.202 ;acc: 0.305 ;iou_acc: 0.425 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.470 ;acc: 0.310 ;iou_acc: 0.415 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.921 ;acc: 0.195 ;iou_acc: 0.295 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.324 ;Test accuracy 0.344 ;IOU accuracy: 0.455 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0450 ;B loss: 2.299 ;acc: 0.460 ;iou: 0.525 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0450 ;B loss: 1.490 ;acc: 0.630 ;iou: 0.680 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0450 ;B loss: 1.519 ;acc: 0.575 ;iou: 0.710 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0450 ;B loss: 2.515 ;acc: 0.400 ;iou: 0.490 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0450 ;B loss: 2.496 ;acc: 0.470 ;iou: 0.565 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0450 ;B loss: 1.989 ;acc: 0.555 ;iou: 0.610 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.019 ;Train accuracy: 0.521 ;IOU accuracy: 0.602 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.760 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.733 ;acc: 0.490 ;iou_acc: 0.610 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 1.905 ;acc: 0.405 ;iou_acc: 0.505 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.208 ;acc: 0.310 ;iou_acc: 0.415 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.469 ;acc: 0.305 ;iou_acc: 0.405 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 2.905 ;acc: 0.235 ;iou_acc: 0.330 ;time: 0:00:47\n",
      "\n",
      "*BTrain: True ;Test loss: 2.317 ;Test accuracy 0.340 ;IOU accuracy: 0.451 ;Time: 0:00:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0450 ;B loss: 2.187 ;acc: 0.540 ;iou: 0.595 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0450 ;B loss: 3.357 ;acc: 0.255 ;iou: 0.370 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0450 ;B loss: 2.173 ;acc: 0.515 ;iou: 0.615 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0450 ;B loss: 1.638 ;acc: 0.590 ;iou: 0.650 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0450 ;B loss: 2.183 ;acc: 0.445 ;iou: 0.525 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0450 ;B loss: 2.883 ;acc: 0.360 ;iou: 0.430 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.010 ;Train accuracy: 0.526 ;IOU accuracy: 0.607 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.941 ;acc: 0.700 ;iou_acc: 0.830 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.783 ;acc: 0.490 ;iou_acc: 0.600 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 1.905 ;acc: 0.395 ;iou_acc: 0.505 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.191 ;acc: 0.335 ;iou_acc: 0.455 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.533 ;acc: 0.295 ;iou_acc: 0.390 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.911 ;acc: 0.230 ;iou_acc: 0.340 ;time: 0:00:49\n",
      "\n",
      "*BTrain: False ;Test loss: 2.350 ;Test accuracy 0.342 ;IOU accuracy: 0.454 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0450 ;B loss: 2.311 ;acc: 0.500 ;iou: 0.570 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0450 ;B loss: 2.513 ;acc: 0.450 ;iou: 0.530 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0450 ;B loss: 2.499 ;acc: 0.425 ;iou: 0.510 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0450 ;B loss: 1.825 ;acc: 0.570 ;iou: 0.635 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0450 ;B loss: 1.461 ;acc: 0.640 ;iou: 0.675 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0450 ;B loss: 1.693 ;acc: 0.560 ;iou: 0.640 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.002 ;Train accuracy: 0.530 ;IOU accuracy: 0.613 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.822 ;acc: 0.730 ;iou_acc: 0.840 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.769 ;acc: 0.455 ;iou_acc: 0.575 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.915 ;acc: 0.385 ;iou_acc: 0.515 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.177 ;acc: 0.310 ;iou_acc: 0.410 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.505 ;acc: 0.280 ;iou_acc: 0.390 ;time: 0:00:46\n",
      "batch: 250 ;B loss: 2.896 ;acc: 0.225 ;iou_acc: 0.315 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.332 ;Test accuracy 0.342 ;IOU accuracy: 0.456 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0450 ;B loss: 2.171 ;acc: 0.465 ;iou: 0.545 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0450 ;B loss: 2.934 ;acc: 0.305 ;iou: 0.385 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0450 ;B loss: 1.226 ;acc: 0.660 ;iou: 0.735 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0450 ;B loss: 2.019 ;acc: 0.565 ;iou: 0.615 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0450 ;B loss: 2.842 ;acc: 0.385 ;iou: 0.475 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0450 ;B loss: 3.417 ;acc: 0.255 ;iou: 0.330 ;time: 0:00:25\n",
      "\n",
      "*Training B: True ;B Train loss: 1.993 ;Train accuracy: 0.535 ;IOU accuracy: 0.615 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.776 ;acc: 0.690 ;iou_acc: 0.815 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.711 ;acc: 0.465 ;iou_acc: 0.595 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 1.881 ;acc: 0.430 ;iou_acc: 0.550 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.189 ;acc: 0.300 ;iou_acc: 0.415 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.484 ;acc: 0.320 ;iou_acc: 0.395 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.903 ;acc: 0.185 ;iou_acc: 0.275 ;time: 0:00:50\n",
      "\n",
      "*BTrain: True ;Test loss: 2.306 ;Test accuracy 0.346 ;IOU accuracy: 0.458 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0450 ;B loss: 2.648 ;acc: 0.445 ;iou: 0.505 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0450 ;B loss: 2.635 ;acc: 0.435 ;iou: 0.525 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0450 ;B loss: 3.077 ;acc: 0.315 ;iou: 0.425 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0450 ;B loss: 1.691 ;acc: 0.570 ;iou: 0.670 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0450 ;B loss: 2.047 ;acc: 0.430 ;iou: 0.560 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0450 ;B loss: 2.131 ;acc: 0.545 ;iou: 0.600 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 1.985 ;Train accuracy: 0.535 ;IOU accuracy: 0.617 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.931 ;acc: 0.705 ;iou_acc: 0.840 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.806 ;acc: 0.490 ;iou_acc: 0.600 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.904 ;acc: 0.405 ;iou_acc: 0.525 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.245 ;acc: 0.335 ;iou_acc: 0.455 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.491 ;acc: 0.315 ;iou_acc: 0.395 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.909 ;acc: 0.195 ;iou_acc: 0.290 ;time: 0:00:50\n",
      "\n",
      "*BTrain: False ;Test loss: 2.342 ;Test accuracy 0.352 ;IOU accuracy: 0.463 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 50 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14851 ;lr: 0.0450 ;B loss: 2.400 ;acc: 0.445 ;iou: 0.535 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14901 ;lr: 0.0450 ;B loss: 1.412 ;acc: 0.650 ;iou: 0.715 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14951 ;lr: 0.0450 ;B loss: 1.267 ;acc: 0.665 ;iou: 0.760 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15001 ;lr: 0.0450 ;B loss: 2.519 ;acc: 0.450 ;iou: 0.535 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15051 ;lr: 0.0450 ;B loss: 1.918 ;acc: 0.555 ;iou: 0.630 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15101 ;lr: 0.0450 ;B loss: 1.420 ;acc: 0.660 ;iou: 0.725 ;time: 0:00:27\n",
      "\n",
      "*Training B: False ;B Train loss: 1.972 ;Train accuracy: 0.543 ;IOU accuracy: 0.624 ;Time: 0:00:31 \n",
      "\n",
      "Testing, ephoc: 50\n",
      "batch: 0 ;B loss: 1.866 ;acc: 0.720 ;iou_acc: 0.845 ;time: 0:00:32\n",
      "batch: 50 ;B loss: 1.747 ;acc: 0.485 ;iou_acc: 0.585 ;time: 0:00:35\n",
      "batch: 100 ;B loss: 1.901 ;acc: 0.400 ;iou_acc: 0.520 ;time: 0:00:39\n",
      "batch: 150 ;B loss: 2.196 ;acc: 0.330 ;iou_acc: 0.460 ;time: 0:00:42\n",
      "batch: 200 ;B loss: 2.470 ;acc: 0.310 ;iou_acc: 0.400 ;time: 0:00:47\n",
      "batch: 250 ;B loss: 2.900 ;acc: 0.245 ;iou_acc: 0.330 ;time: 0:00:51\n",
      "\n",
      "*BTrain: False ;Test loss: 2.308 ;Test accuracy 0.354 ;IOU accuracy: 0.468 ;Time: 0:00:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 51 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15148 ;lr: 0.0450 ;B loss: 1.433 ;acc: 0.715 ;iou: 0.755 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15198 ;lr: 0.0450 ;B loss: 2.500 ;acc: 0.510 ;iou: 0.580 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15248 ;lr: 0.0450 ;B loss: 1.761 ;acc: 0.565 ;iou: 0.690 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15298 ;lr: 0.0450 ;B loss: 1.652 ;acc: 0.570 ;iou: 0.670 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15348 ;lr: 0.0450 ;B loss: 2.795 ;acc: 0.400 ;iou: 0.460 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15398 ;lr: 0.0450 ;B loss: 1.628 ;acc: 0.610 ;iou: 0.690 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 1.963 ;Train accuracy: 0.549 ;IOU accuracy: 0.627 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 51\n",
      "batch: 0 ;B loss: 1.892 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.732 ;acc: 0.505 ;iou_acc: 0.625 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.899 ;acc: 0.435 ;iou_acc: 0.555 ;time: 0:00:38\n",
      "batch: 150 ;B loss: 2.188 ;acc: 0.350 ;iou_acc: 0.475 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.520 ;acc: 0.285 ;iou_acc: 0.370 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.874 ;acc: 0.260 ;iou_acc: 0.335 ;time: 0:00:50\n",
      "\n",
      "*BTrain: True ;Test loss: 2.312 ;Test accuracy 0.357 ;IOU accuracy: 0.471 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 52 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15445 ;lr: 0.0450 ;B loss: 2.083 ;acc: 0.560 ;iou: 0.615 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15495 ;lr: 0.0450 ;B loss: 2.319 ;acc: 0.430 ;iou: 0.520 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15545 ;lr: 0.0450 ;B loss: 1.345 ;acc: 0.610 ;iou: 0.700 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15595 ;lr: 0.0450 ;B loss: 2.575 ;acc: 0.415 ;iou: 0.465 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15645 ;lr: 0.0450 ;B loss: 1.739 ;acc: 0.580 ;iou: 0.715 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15695 ;lr: 0.0450 ;B loss: 1.300 ;acc: 0.620 ;iou: 0.670 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 1.953 ;Train accuracy: 0.553 ;IOU accuracy: 0.633 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 52\n",
      "batch: 0 ;B loss: 1.872 ;acc: 0.745 ;iou_acc: 0.850 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.744 ;acc: 0.470 ;iou_acc: 0.580 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.925 ;acc: 0.425 ;iou_acc: 0.535 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.199 ;acc: 0.330 ;iou_acc: 0.430 ;time: 0:00:41\n",
      "batch: 200 ;B loss: 2.519 ;acc: 0.310 ;iou_acc: 0.400 ;time: 0:00:45\n",
      "batch: 250 ;B loss: 2.927 ;acc: 0.195 ;iou_acc: 0.310 ;time: 0:00:49\n",
      "\n",
      "*BTrain: False ;Test loss: 2.324 ;Test accuracy 0.356 ;IOU accuracy: 0.468 ;Time: 0:00:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 53 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15742 ;lr: 0.0450 ;B loss: 2.450 ;acc: 0.450 ;iou: 0.535 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15792 ;lr: 0.0450 ;B loss: 1.562 ;acc: 0.625 ;iou: 0.700 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15842 ;lr: 0.0450 ;B loss: 1.575 ;acc: 0.675 ;iou: 0.745 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15892 ;lr: 0.0450 ;B loss: 2.104 ;acc: 0.545 ;iou: 0.650 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15942 ;lr: 0.0450 ;B loss: 1.835 ;acc: 0.555 ;iou: 0.615 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15992 ;lr: 0.0450 ;B loss: 2.840 ;acc: 0.365 ;iou: 0.430 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 1.944 ;Train accuracy: 0.558 ;IOU accuracy: 0.637 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 53\n",
      "batch: 0 ;B loss: 1.891 ;acc: 0.760 ;iou_acc: 0.860 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.739 ;acc: 0.480 ;iou_acc: 0.615 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 1.898 ;acc: 0.425 ;iou_acc: 0.535 ;time: 0:00:36\n",
      "batch: 150 ;B loss: 2.230 ;acc: 0.305 ;iou_acc: 0.410 ;time: 0:00:40\n",
      "batch: 200 ;B loss: 2.499 ;acc: 0.335 ;iou_acc: 0.430 ;time: 0:00:44\n",
      "batch: 250 ;B loss: 2.917 ;acc: 0.270 ;iou_acc: 0.350 ;time: 0:00:49\n",
      "\n",
      "*BTrain: False ;Test loss: 2.331 ;Test accuracy 0.359 ;IOU accuracy: 0.474 ;Time: 0:00:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 54 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16039 ;lr: 0.0450 ;B loss: 2.317 ;acc: 0.420 ;iou: 0.530 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16089 ;lr: 0.0450 ;B loss: 2.125 ;acc: 0.585 ;iou: 0.675 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16139 ;lr: 0.0450 ;B loss: 2.449 ;acc: 0.520 ;iou: 0.590 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16189 ;lr: 0.0450 ;B loss: 2.231 ;acc: 0.545 ;iou: 0.590 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16239 ;lr: 0.0450 ;B loss: 1.453 ;acc: 0.625 ;iou: 0.670 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16289 ;lr: 0.0450 ;B loss: 1.283 ;acc: 0.650 ;iou: 0.730 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.930 ;Train accuracy: 0.564 ;IOU accuracy: 0.643 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 54\n",
      "batch: 0 ;B loss: 1.985 ;acc: 0.730 ;iou_acc: 0.845 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.738 ;acc: 0.495 ;iou_acc: 0.625 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 1.947 ;acc: 0.430 ;iou_acc: 0.545 ;time: 0:00:36\n",
      "batch: 150 ;B loss: 2.230 ;acc: 0.330 ;iou_acc: 0.460 ;time: 0:00:40\n",
      "batch: 200 ;B loss: 2.430 ;acc: 0.375 ;iou_acc: 0.470 ;time: 0:00:44\n",
      "batch: 250 ;B loss: 2.828 ;acc: 0.280 ;iou_acc: 0.375 ;time: 0:00:48\n",
      "\n",
      "*BTrain: True ;Test loss: 2.328 ;Test accuracy 0.365 ;IOU accuracy: 0.478 ;Time: 0:00:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 55 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16336 ;lr: 0.0450 ;B loss: 2.267 ;acc: 0.545 ;iou: 0.600 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16386 ;lr: 0.0450 ;B loss: 1.250 ;acc: 0.650 ;iou: 0.745 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16436 ;lr: 0.0450 ;B loss: 1.325 ;acc: 0.665 ;iou: 0.740 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16486 ;lr: 0.0450 ;B loss: 1.218 ;acc: 0.635 ;iou: 0.735 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16536 ;lr: 0.0450 ;B loss: 2.711 ;acc: 0.390 ;iou: 0.465 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16586 ;lr: 0.0450 ;B loss: 1.194 ;acc: 0.720 ;iou: 0.750 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 1.925 ;Train accuracy: 0.568 ;IOU accuracy: 0.647 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 55\n",
      "batch: 0 ;B loss: 2.008 ;acc: 0.740 ;iou_acc: 0.855 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.730 ;acc: 0.520 ;iou_acc: 0.625 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 1.948 ;acc: 0.390 ;iou_acc: 0.530 ;time: 0:00:36\n",
      "batch: 150 ;B loss: 2.242 ;acc: 0.345 ;iou_acc: 0.445 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.524 ;acc: 0.325 ;iou_acc: 0.405 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 2.873 ;acc: 0.230 ;iou_acc: 0.365 ;time: 0:00:48\n",
      "\n",
      "*BTrain: False ;Test loss: 2.346 ;Test accuracy 0.366 ;IOU accuracy: 0.480 ;Time: 0:00:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 56 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16633 ;lr: 0.0450 ;B loss: 1.338 ;acc: 0.720 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16683 ;lr: 0.0450 ;B loss: 1.977 ;acc: 0.600 ;iou: 0.650 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16733 ;lr: 0.0450 ;B loss: 2.597 ;acc: 0.405 ;iou: 0.505 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16783 ;lr: 0.0450 ;B loss: 2.061 ;acc: 0.565 ;iou: 0.650 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16833 ;lr: 0.0450 ;B loss: 1.682 ;acc: 0.615 ;iou: 0.690 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16883 ;lr: 0.0450 ;B loss: 2.109 ;acc: 0.530 ;iou: 0.605 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.909 ;Train accuracy: 0.574 ;IOU accuracy: 0.653 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 56\n",
      "batch: 0 ;B loss: 1.950 ;acc: 0.685 ;iou_acc: 0.815 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.783 ;acc: 0.480 ;iou_acc: 0.610 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 1.985 ;acc: 0.410 ;iou_acc: 0.520 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.234 ;acc: 0.355 ;iou_acc: 0.490 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.493 ;acc: 0.315 ;iou_acc: 0.430 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.885 ;acc: 0.230 ;iou_acc: 0.360 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.335 ;Test accuracy 0.364 ;IOU accuracy: 0.479 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 57 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16930 ;lr: 0.0450 ;B loss: 2.765 ;acc: 0.370 ;iou: 0.445 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16980 ;lr: 0.0450 ;B loss: 1.521 ;acc: 0.665 ;iou: 0.750 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17030 ;lr: 0.0450 ;B loss: 1.496 ;acc: 0.725 ;iou: 0.770 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17080 ;lr: 0.0450 ;B loss: 2.164 ;acc: 0.530 ;iou: 0.590 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17130 ;lr: 0.0450 ;B loss: 1.676 ;acc: 0.630 ;iou: 0.685 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17180 ;lr: 0.0450 ;B loss: 2.436 ;acc: 0.505 ;iou: 0.605 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 1.896 ;Train accuracy: 0.581 ;IOU accuracy: 0.659 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 57\n",
      "batch: 0 ;B loss: 1.970 ;acc: 0.735 ;iou_acc: 0.855 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.760 ;acc: 0.455 ;iou_acc: 0.560 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 1.974 ;acc: 0.435 ;iou_acc: 0.545 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.203 ;acc: 0.320 ;iou_acc: 0.450 ;time: 0:00:35\n",
      "batch: 200 ;B loss: 2.464 ;acc: 0.310 ;iou_acc: 0.430 ;time: 0:00:38\n",
      "batch: 250 ;B loss: 2.842 ;acc: 0.255 ;iou_acc: 0.345 ;time: 0:00:42\n",
      "\n",
      "*BTrain: True ;Test loss: 2.333 ;Test accuracy 0.362 ;IOU accuracy: 0.477 ;Time: 0:00:47\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 58 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17227 ;lr: 0.0450 ;B loss: 2.332 ;acc: 0.480 ;iou: 0.535 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17277 ;lr: 0.0450 ;B loss: 1.535 ;acc: 0.695 ;iou: 0.765 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17327 ;lr: 0.0450 ;B loss: 1.585 ;acc: 0.635 ;iou: 0.710 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17377 ;lr: 0.0450 ;B loss: 2.104 ;acc: 0.570 ;iou: 0.655 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17427 ;lr: 0.0450 ;B loss: 1.273 ;acc: 0.730 ;iou: 0.790 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17477 ;lr: 0.0450 ;B loss: 1.313 ;acc: 0.675 ;iou: 0.755 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 1.886 ;Train accuracy: 0.587 ;IOU accuracy: 0.667 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 58\n",
      "batch: 0 ;B loss: 1.999 ;acc: 0.750 ;iou_acc: 0.860 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.731 ;acc: 0.520 ;iou_acc: 0.605 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 1.959 ;acc: 0.410 ;iou_acc: 0.515 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.196 ;acc: 0.335 ;iou_acc: 0.445 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.522 ;acc: 0.345 ;iou_acc: 0.440 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 2.857 ;acc: 0.250 ;iou_acc: 0.355 ;time: 0:00:41\n",
      "\n",
      "*BTrain: False ;Test loss: 2.337 ;Test accuracy 0.374 ;IOU accuracy: 0.491 ;Time: 0:00:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 59 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17524 ;lr: 0.0450 ;B loss: 2.097 ;acc: 0.570 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17574 ;lr: 0.0450 ;B loss: 1.557 ;acc: 0.610 ;iou: 0.695 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17624 ;lr: 0.0450 ;B loss: 2.859 ;acc: 0.365 ;iou: 0.450 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17674 ;lr: 0.0450 ;B loss: 1.685 ;acc: 0.600 ;iou: 0.680 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17724 ;lr: 0.0450 ;B loss: 2.185 ;acc: 0.575 ;iou: 0.610 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17774 ;lr: 0.0450 ;B loss: 1.970 ;acc: 0.570 ;iou: 0.635 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 1.870 ;Train accuracy: 0.594 ;IOU accuracy: 0.672 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 59\n",
      "batch: 0 ;B loss: 2.027 ;acc: 0.725 ;iou_acc: 0.850 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.777 ;acc: 0.535 ;iou_acc: 0.625 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 1.949 ;acc: 0.460 ;iou_acc: 0.565 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.153 ;acc: 0.395 ;iou_acc: 0.505 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.533 ;acc: 0.325 ;iou_acc: 0.450 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 2.784 ;acc: 0.290 ;iou_acc: 0.375 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.331 ;Test accuracy 0.384 ;IOU accuracy: 0.500 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 60 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17821 ;lr: 0.0450 ;B loss: 1.921 ;acc: 0.665 ;iou: 0.730 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17871 ;lr: 0.0450 ;B loss: 2.254 ;acc: 0.540 ;iou: 0.615 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17921 ;lr: 0.0450 ;B loss: 1.452 ;acc: 0.710 ;iou: 0.750 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17971 ;lr: 0.0450 ;B loss: 1.491 ;acc: 0.735 ;iou: 0.805 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18021 ;lr: 0.0450 ;B loss: 1.381 ;acc: 0.705 ;iou: 0.765 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18071 ;lr: 0.0450 ;B loss: 1.281 ;acc: 0.695 ;iou: 0.790 ;time: 0:00:21\n",
      "\n",
      "*Training B: True ;B Train loss: 1.856 ;Train accuracy: 0.598 ;IOU accuracy: 0.676 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 60\n",
      "batch: 0 ;B loss: 1.935 ;acc: 0.725 ;iou_acc: 0.850 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.681 ;acc: 0.565 ;iou_acc: 0.685 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 1.880 ;acc: 0.465 ;iou_acc: 0.565 ;time: 0:00:32\n",
      "batch: 150 ;B loss: 2.172 ;acc: 0.325 ;iou_acc: 0.470 ;time: 0:00:35\n",
      "batch: 200 ;B loss: 2.451 ;acc: 0.335 ;iou_acc: 0.430 ;time: 0:00:39\n",
      "batch: 250 ;B loss: 2.826 ;acc: 0.265 ;iou_acc: 0.340 ;time: 0:00:43\n",
      "\n",
      "*BTrain: True ;Test loss: 2.298 ;Test accuracy 0.380 ;IOU accuracy: 0.493 ;Time: 0:00:48\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 61 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18118 ;lr: 0.0450 ;B loss: 1.166 ;acc: 0.670 ;iou: 0.735 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18168 ;lr: 0.0450 ;B loss: 1.979 ;acc: 0.550 ;iou: 0.625 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18218 ;lr: 0.0450 ;B loss: 1.533 ;acc: 0.640 ;iou: 0.715 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18268 ;lr: 0.0450 ;B loss: 2.163 ;acc: 0.580 ;iou: 0.645 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18318 ;lr: 0.0450 ;B loss: 1.677 ;acc: 0.705 ;iou: 0.755 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18368 ;lr: 0.0450 ;B loss: 1.222 ;acc: 0.725 ;iou: 0.785 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.840 ;Train accuracy: 0.603 ;IOU accuracy: 0.681 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 61\n",
      "batch: 0 ;B loss: 1.994 ;acc: 0.695 ;iou_acc: 0.820 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.728 ;acc: 0.550 ;iou_acc: 0.650 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 1.970 ;acc: 0.420 ;iou_acc: 0.555 ;time: 0:00:32\n",
      "batch: 150 ;B loss: 2.153 ;acc: 0.370 ;iou_acc: 0.500 ;time: 0:00:35\n",
      "batch: 200 ;B loss: 2.428 ;acc: 0.385 ;iou_acc: 0.495 ;time: 0:00:39\n",
      "batch: 250 ;B loss: 2.845 ;acc: 0.275 ;iou_acc: 0.360 ;time: 0:00:43\n",
      "\n",
      "*BTrain: False ;Test loss: 2.324 ;Test accuracy 0.385 ;IOU accuracy: 0.502 ;Time: 0:00:48\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 62 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18415 ;lr: 0.0450 ;B loss: 2.014 ;acc: 0.595 ;iou: 0.645 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18465 ;lr: 0.0450 ;B loss: 1.422 ;acc: 0.720 ;iou: 0.800 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18515 ;lr: 0.0450 ;B loss: 1.762 ;acc: 0.555 ;iou: 0.655 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18565 ;lr: 0.0450 ;B loss: 2.114 ;acc: 0.585 ;iou: 0.630 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18615 ;lr: 0.0450 ;B loss: 2.134 ;acc: 0.560 ;iou: 0.640 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18665 ;lr: 0.0450 ;B loss: 1.280 ;acc: 0.695 ;iou: 0.780 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.830 ;Train accuracy: 0.609 ;IOU accuracy: 0.685 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 62\n",
      "batch: 0 ;B loss: 1.995 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.743 ;acc: 0.520 ;iou_acc: 0.640 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 1.921 ;acc: 0.430 ;iou_acc: 0.535 ;time: 0:00:32\n",
      "batch: 150 ;B loss: 2.140 ;acc: 0.370 ;iou_acc: 0.490 ;time: 0:00:35\n",
      "batch: 200 ;B loss: 2.450 ;acc: 0.335 ;iou_acc: 0.445 ;time: 0:00:39\n",
      "batch: 250 ;B loss: 2.812 ;acc: 0.280 ;iou_acc: 0.370 ;time: 0:00:43\n",
      "\n",
      "*BTrain: False ;Test loss: 2.304 ;Test accuracy 0.385 ;IOU accuracy: 0.501 ;Time: 0:00:48\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 63 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18712 ;lr: 0.0450 ;B loss: 1.605 ;acc: 0.680 ;iou: 0.725 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18762 ;lr: 0.0450 ;B loss: 2.997 ;acc: 0.350 ;iou: 0.430 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18812 ;lr: 0.0450 ;B loss: 1.569 ;acc: 0.690 ;iou: 0.750 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18862 ;lr: 0.0450 ;B loss: 1.768 ;acc: 0.610 ;iou: 0.660 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18912 ;lr: 0.0450 ;B loss: 2.408 ;acc: 0.485 ;iou: 0.590 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18962 ;lr: 0.0450 ;B loss: 2.397 ;acc: 0.425 ;iou: 0.505 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 1.813 ;Train accuracy: 0.619 ;IOU accuracy: 0.694 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 63\n",
      "batch: 0 ;B loss: 2.143 ;acc: 0.735 ;iou_acc: 0.850 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.755 ;acc: 0.570 ;iou_acc: 0.675 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.943 ;acc: 0.455 ;iou_acc: 0.580 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.198 ;acc: 0.350 ;iou_acc: 0.490 ;time: 0:00:36\n",
      "batch: 200 ;B loss: 2.427 ;acc: 0.355 ;iou_acc: 0.475 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 2.830 ;acc: 0.260 ;iou_acc: 0.360 ;time: 0:00:44\n",
      "\n",
      "*BTrain: True ;Test loss: 2.311 ;Test accuracy 0.398 ;IOU accuracy: 0.512 ;Time: 0:00:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 64 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19009 ;lr: 0.0450 ;B loss: 1.253 ;acc: 0.735 ;iou: 0.790 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19059 ;lr: 0.0450 ;B loss: 1.245 ;acc: 0.735 ;iou: 0.805 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19109 ;lr: 0.0450 ;B loss: 1.453 ;acc: 0.695 ;iou: 0.755 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19159 ;lr: 0.0450 ;B loss: 2.081 ;acc: 0.645 ;iou: 0.700 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19209 ;lr: 0.0450 ;B loss: 1.257 ;acc: 0.725 ;iou: 0.780 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19259 ;lr: 0.0450 ;B loss: 2.826 ;acc: 0.450 ;iou: 0.540 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.800 ;Train accuracy: 0.622 ;IOU accuracy: 0.696 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 64\n",
      "batch: 0 ;B loss: 1.923 ;acc: 0.625 ;iou_acc: 0.765 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.742 ;acc: 0.505 ;iou_acc: 0.610 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 2.026 ;acc: 0.415 ;iou_acc: 0.535 ;time: 0:00:32\n",
      "batch: 150 ;B loss: 2.193 ;acc: 0.330 ;iou_acc: 0.440 ;time: 0:00:36\n",
      "batch: 200 ;B loss: 2.448 ;acc: 0.350 ;iou_acc: 0.480 ;time: 0:00:39\n",
      "batch: 250 ;B loss: 2.845 ;acc: 0.280 ;iou_acc: 0.385 ;time: 0:00:43\n",
      "\n",
      "*BTrain: False ;Test loss: 2.327 ;Test accuracy 0.372 ;IOU accuracy: 0.490 ;Time: 0:00:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 65 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19306 ;lr: 0.0450 ;B loss: 1.552 ;acc: 0.700 ;iou: 0.755 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19356 ;lr: 0.0450 ;B loss: 1.512 ;acc: 0.710 ;iou: 0.775 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19406 ;lr: 0.0450 ;B loss: 2.546 ;acc: 0.500 ;iou: 0.550 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19456 ;lr: 0.0450 ;B loss: 1.387 ;acc: 0.660 ;iou: 0.720 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19506 ;lr: 0.0450 ;B loss: 2.061 ;acc: 0.550 ;iou: 0.605 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19556 ;lr: 0.0450 ;B loss: 1.741 ;acc: 0.635 ;iou: 0.725 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 1.789 ;Train accuracy: 0.626 ;IOU accuracy: 0.701 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 65\n",
      "batch: 0 ;B loss: 2.164 ;acc: 0.740 ;iou_acc: 0.840 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.808 ;acc: 0.545 ;iou_acc: 0.670 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 1.918 ;acc: 0.450 ;iou_acc: 0.595 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.260 ;acc: 0.390 ;iou_acc: 0.505 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.509 ;acc: 0.390 ;iou_acc: 0.480 ;time: 0:00:38\n",
      "batch: 250 ;B loss: 2.809 ;acc: 0.285 ;iou_acc: 0.380 ;time: 0:00:42\n",
      "\n",
      "*BTrain: False ;Test loss: 2.335 ;Test accuracy 0.400 ;IOU accuracy: 0.516 ;Time: 0:00:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 66 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19603 ;lr: 0.0450 ;B loss: 1.238 ;acc: 0.735 ;iou: 0.805 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19653 ;lr: 0.0450 ;B loss: 1.615 ;acc: 0.665 ;iou: 0.730 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19703 ;lr: 0.0450 ;B loss: 1.965 ;acc: 0.625 ;iou: 0.680 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19753 ;lr: 0.0450 ;B loss: 2.217 ;acc: 0.580 ;iou: 0.660 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19803 ;lr: 0.0450 ;B loss: 1.674 ;acc: 0.680 ;iou: 0.715 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19853 ;lr: 0.0450 ;B loss: 2.224 ;acc: 0.565 ;iou: 0.655 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 1.778 ;Train accuracy: 0.632 ;IOU accuracy: 0.706 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 66\n",
      "batch: 0 ;B loss: 2.355 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.878 ;acc: 0.560 ;iou_acc: 0.670 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 1.969 ;acc: 0.470 ;iou_acc: 0.590 ;time: 0:00:32\n",
      "batch: 150 ;B loss: 2.248 ;acc: 0.375 ;iou_acc: 0.495 ;time: 0:00:35\n",
      "batch: 200 ;B loss: 2.490 ;acc: 0.375 ;iou_acc: 0.475 ;time: 0:00:38\n",
      "batch: 250 ;B loss: 2.826 ;acc: 0.295 ;iou_acc: 0.390 ;time: 0:00:42\n",
      "\n",
      "*BTrain: True ;Test loss: 2.401 ;Test accuracy 0.400 ;IOU accuracy: 0.515 ;Time: 0:00:47\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 67 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19900 ;lr: 0.0450 ;B loss: 2.042 ;acc: 0.585 ;iou: 0.660 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19950 ;lr: 0.0450 ;B loss: 3.503 ;acc: 0.195 ;iou: 0.330 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20000 ;lr: 0.0450 ;B loss: 1.167 ;acc: 0.740 ;iou: 0.785 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20050 ;lr: 0.0405 ;B loss: 2.189 ;acc: 0.575 ;iou: 0.635 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20100 ;lr: 0.0405 ;B loss: 2.247 ;acc: 0.525 ;iou: 0.620 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20150 ;lr: 0.0405 ;B loss: 2.827 ;acc: 0.385 ;iou: 0.445 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 1.753 ;Train accuracy: 0.636 ;IOU accuracy: 0.709 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 67\n",
      "batch: 0 ;B loss: 2.401 ;acc: 0.745 ;iou_acc: 0.835 ;time: 0:00:24\n",
      "batch: 50 ;B loss: 1.824 ;acc: 0.540 ;iou_acc: 0.645 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 1.953 ;acc: 0.470 ;iou_acc: 0.595 ;time: 0:00:29\n",
      "batch: 150 ;B loss: 2.165 ;acc: 0.415 ;iou_acc: 0.530 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.451 ;acc: 0.405 ;iou_acc: 0.495 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 2.782 ;acc: 0.320 ;iou_acc: 0.410 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.392 ;Test accuracy 0.404 ;IOU accuracy: 0.519 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 68 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20197 ;lr: 0.0405 ;B loss: 1.508 ;acc: 0.720 ;iou: 0.780 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20247 ;lr: 0.0405 ;B loss: 1.195 ;acc: 0.735 ;iou: 0.815 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20297 ;lr: 0.0405 ;B loss: 1.220 ;acc: 0.710 ;iou: 0.765 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20347 ;lr: 0.0405 ;B loss: 2.613 ;acc: 0.445 ;iou: 0.530 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20397 ;lr: 0.0405 ;B loss: 1.477 ;acc: 0.720 ;iou: 0.755 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20447 ;lr: 0.0405 ;B loss: 2.173 ;acc: 0.575 ;iou: 0.665 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.730 ;Train accuracy: 0.644 ;IOU accuracy: 0.717 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 68\n",
      "batch: 0 ;B loss: 2.188 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.721 ;acc: 0.575 ;iou_acc: 0.685 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.947 ;acc: 0.480 ;iou_acc: 0.575 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.189 ;acc: 0.360 ;iou_acc: 0.485 ;time: 0:00:36\n",
      "batch: 200 ;B loss: 2.446 ;acc: 0.365 ;iou_acc: 0.500 ;time: 0:00:39\n",
      "batch: 250 ;B loss: 2.831 ;acc: 0.270 ;iou_acc: 0.365 ;time: 0:00:43\n",
      "\n",
      "*BTrain: False ;Test loss: 2.322 ;Test accuracy 0.408 ;IOU accuracy: 0.523 ;Time: 0:00:48\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 69 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20494 ;lr: 0.0405 ;B loss: 1.656 ;acc: 0.655 ;iou: 0.770 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20544 ;lr: 0.0405 ;B loss: 1.286 ;acc: 0.730 ;iou: 0.755 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20594 ;lr: 0.0405 ;B loss: 1.809 ;acc: 0.680 ;iou: 0.745 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20644 ;lr: 0.0405 ;B loss: 1.532 ;acc: 0.695 ;iou: 0.750 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20694 ;lr: 0.0405 ;B loss: 2.136 ;acc: 0.625 ;iou: 0.695 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20744 ;lr: 0.0405 ;B loss: 1.737 ;acc: 0.585 ;iou: 0.680 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.717 ;Train accuracy: 0.649 ;IOU accuracy: 0.721 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 69\n",
      "batch: 0 ;B loss: 2.332 ;acc: 0.750 ;iou_acc: 0.870 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.855 ;acc: 0.580 ;iou_acc: 0.690 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.939 ;acc: 0.480 ;iou_acc: 0.610 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.188 ;acc: 0.390 ;iou_acc: 0.500 ;time: 0:00:36\n",
      "batch: 200 ;B loss: 2.511 ;acc: 0.360 ;iou_acc: 0.475 ;time: 0:00:39\n",
      "batch: 250 ;B loss: 2.802 ;acc: 0.315 ;iou_acc: 0.435 ;time: 0:00:43\n",
      "\n",
      "*BTrain: True ;Test loss: 2.367 ;Test accuracy 0.417 ;IOU accuracy: 0.530 ;Time: 0:00:48\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 70 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20791 ;lr: 0.0405 ;B loss: 1.264 ;acc: 0.730 ;iou: 0.780 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20841 ;lr: 0.0405 ;B loss: 2.974 ;acc: 0.355 ;iou: 0.440 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20891 ;lr: 0.0405 ;B loss: 2.169 ;acc: 0.555 ;iou: 0.615 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20941 ;lr: 0.0405 ;B loss: 1.401 ;acc: 0.730 ;iou: 0.795 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20991 ;lr: 0.0405 ;B loss: 1.692 ;acc: 0.650 ;iou: 0.695 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21041 ;lr: 0.0405 ;B loss: 1.481 ;acc: 0.695 ;iou: 0.760 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 1.709 ;Train accuracy: 0.654 ;IOU accuracy: 0.725 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 70\n",
      "batch: 0 ;B loss: 2.273 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.834 ;acc: 0.565 ;iou_acc: 0.665 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 1.978 ;acc: 0.500 ;iou_acc: 0.615 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.238 ;acc: 0.380 ;iou_acc: 0.490 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.547 ;acc: 0.350 ;iou_acc: 0.455 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 2.883 ;acc: 0.275 ;iou_acc: 0.375 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.382 ;Test accuracy 0.407 ;IOU accuracy: 0.521 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 71 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21088 ;lr: 0.0405 ;B loss: 1.865 ;acc: 0.645 ;iou: 0.705 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21138 ;lr: 0.0405 ;B loss: 1.631 ;acc: 0.595 ;iou: 0.730 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21188 ;lr: 0.0405 ;B loss: 2.075 ;acc: 0.595 ;iou: 0.665 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21238 ;lr: 0.0405 ;B loss: 2.421 ;acc: 0.525 ;iou: 0.600 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21288 ;lr: 0.0405 ;B loss: 1.257 ;acc: 0.670 ;iou: 0.740 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21338 ;lr: 0.0405 ;B loss: 2.324 ;acc: 0.550 ;iou: 0.645 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 1.695 ;Train accuracy: 0.658 ;IOU accuracy: 0.728 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 71\n",
      "batch: 0 ;B loss: 2.265 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.818 ;acc: 0.570 ;iou_acc: 0.675 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 1.953 ;acc: 0.485 ;iou_acc: 0.620 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.167 ;acc: 0.390 ;iou_acc: 0.520 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.467 ;acc: 0.385 ;iou_acc: 0.480 ;time: 0:00:38\n",
      "batch: 250 ;B loss: 2.806 ;acc: 0.265 ;iou_acc: 0.355 ;time: 0:00:42\n",
      "\n",
      "*BTrain: False ;Test loss: 2.364 ;Test accuracy 0.411 ;IOU accuracy: 0.528 ;Time: 0:00:47\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 72 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21385 ;lr: 0.0405 ;B loss: 1.072 ;acc: 0.755 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21435 ;lr: 0.0405 ;B loss: 1.754 ;acc: 0.535 ;iou: 0.640 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21485 ;lr: 0.0405 ;B loss: 1.129 ;acc: 0.730 ;iou: 0.790 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21535 ;lr: 0.0405 ;B loss: 1.349 ;acc: 0.730 ;iou: 0.785 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21585 ;lr: 0.0405 ;B loss: 1.211 ;acc: 0.730 ;iou: 0.800 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21635 ;lr: 0.0405 ;B loss: 1.798 ;acc: 0.705 ;iou: 0.740 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 1.689 ;Train accuracy: 0.661 ;IOU accuracy: 0.732 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 72\n",
      "batch: 0 ;B loss: 2.336 ;acc: 0.730 ;iou_acc: 0.855 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.816 ;acc: 0.600 ;iou_acc: 0.690 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.990 ;acc: 0.480 ;iou_acc: 0.585 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.214 ;acc: 0.405 ;iou_acc: 0.520 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.482 ;acc: 0.400 ;iou_acc: 0.505 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 2.817 ;acc: 0.285 ;iou_acc: 0.390 ;time: 0:00:44\n",
      "\n",
      "*BTrain: True ;Test loss: 2.376 ;Test accuracy 0.416 ;IOU accuracy: 0.530 ;Time: 0:00:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 73 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21682 ;lr: 0.0405 ;B loss: 1.103 ;acc: 0.745 ;iou: 0.805 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21732 ;lr: 0.0405 ;B loss: 2.448 ;acc: 0.495 ;iou: 0.575 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21782 ;lr: 0.0405 ;B loss: 1.562 ;acc: 0.745 ;iou: 0.795 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21832 ;lr: 0.0405 ;B loss: 1.347 ;acc: 0.725 ;iou: 0.800 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21882 ;lr: 0.0405 ;B loss: 1.776 ;acc: 0.635 ;iou: 0.765 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21932 ;lr: 0.0405 ;B loss: 1.896 ;acc: 0.685 ;iou: 0.725 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.671 ;Train accuracy: 0.668 ;IOU accuracy: 0.737 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 73\n",
      "batch: 0 ;B loss: 2.389 ;acc: 0.725 ;iou_acc: 0.840 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.823 ;acc: 0.605 ;iou_acc: 0.700 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.057 ;acc: 0.435 ;iou_acc: 0.585 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.214 ;acc: 0.435 ;iou_acc: 0.540 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.512 ;acc: 0.370 ;iou_acc: 0.490 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.860 ;acc: 0.285 ;iou_acc: 0.380 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.404 ;Test accuracy 0.415 ;IOU accuracy: 0.531 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 74 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21979 ;lr: 0.0405 ;B loss: 1.693 ;acc: 0.630 ;iou: 0.740 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22029 ;lr: 0.0405 ;B loss: 1.743 ;acc: 0.550 ;iou: 0.665 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22079 ;lr: 0.0405 ;B loss: 1.188 ;acc: 0.730 ;iou: 0.800 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22129 ;lr: 0.0405 ;B loss: 1.768 ;acc: 0.660 ;iou: 0.730 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22179 ;lr: 0.0405 ;B loss: 2.185 ;acc: 0.595 ;iou: 0.685 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22229 ;lr: 0.0405 ;B loss: 2.021 ;acc: 0.670 ;iou: 0.720 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.664 ;Train accuracy: 0.668 ;IOU accuracy: 0.737 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 74\n",
      "batch: 0 ;B loss: 2.384 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.811 ;acc: 0.550 ;iou_acc: 0.645 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.995 ;acc: 0.465 ;iou_acc: 0.585 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.133 ;acc: 0.450 ;iou_acc: 0.560 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.538 ;acc: 0.360 ;iou_acc: 0.500 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.857 ;acc: 0.265 ;iou_acc: 0.360 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.393 ;Test accuracy 0.415 ;IOU accuracy: 0.531 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 75 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22276 ;lr: 0.0405 ;B loss: 1.171 ;acc: 0.770 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22326 ;lr: 0.0405 ;B loss: 1.763 ;acc: 0.470 ;iou: 0.610 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22376 ;lr: 0.0405 ;B loss: 1.387 ;acc: 0.810 ;iou: 0.860 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22426 ;lr: 0.0405 ;B loss: 1.319 ;acc: 0.700 ;iou: 0.765 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22476 ;lr: 0.0405 ;B loss: 1.075 ;acc: 0.770 ;iou: 0.820 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22526 ;lr: 0.0405 ;B loss: 1.538 ;acc: 0.690 ;iou: 0.745 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 1.645 ;Train accuracy: 0.678 ;IOU accuracy: 0.747 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 75\n",
      "batch: 0 ;B loss: 2.376 ;acc: 0.730 ;iou_acc: 0.845 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.819 ;acc: 0.565 ;iou_acc: 0.685 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.966 ;acc: 0.465 ;iou_acc: 0.590 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.196 ;acc: 0.410 ;iou_acc: 0.520 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.443 ;acc: 0.375 ;iou_acc: 0.495 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.830 ;acc: 0.290 ;iou_acc: 0.410 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.382 ;Test accuracy 0.416 ;IOU accuracy: 0.532 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 76 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22573 ;lr: 0.0405 ;B loss: 1.128 ;acc: 0.795 ;iou: 0.850 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22623 ;lr: 0.0405 ;B loss: 1.298 ;acc: 0.780 ;iou: 0.840 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22673 ;lr: 0.0405 ;B loss: 1.894 ;acc: 0.645 ;iou: 0.690 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22723 ;lr: 0.0405 ;B loss: 1.112 ;acc: 0.745 ;iou: 0.785 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22773 ;lr: 0.0405 ;B loss: 1.496 ;acc: 0.770 ;iou: 0.830 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22823 ;lr: 0.0405 ;B loss: 1.859 ;acc: 0.665 ;iou: 0.740 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.636 ;Train accuracy: 0.679 ;IOU accuracy: 0.747 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 76\n",
      "batch: 0 ;B loss: 2.419 ;acc: 0.705 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.883 ;acc: 0.555 ;iou_acc: 0.665 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.032 ;acc: 0.500 ;iou_acc: 0.615 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.179 ;acc: 0.425 ;iou_acc: 0.535 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.512 ;acc: 0.425 ;iou_acc: 0.545 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.862 ;acc: 0.285 ;iou_acc: 0.420 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.425 ;Test accuracy 0.419 ;IOU accuracy: 0.536 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 77 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22870 ;lr: 0.0405 ;B loss: 1.033 ;acc: 0.800 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22920 ;lr: 0.0405 ;B loss: 1.731 ;acc: 0.690 ;iou: 0.775 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22970 ;lr: 0.0405 ;B loss: 1.222 ;acc: 0.740 ;iou: 0.810 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23020 ;lr: 0.0405 ;B loss: 1.226 ;acc: 0.785 ;iou: 0.835 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23070 ;lr: 0.0405 ;B loss: 1.322 ;acc: 0.750 ;iou: 0.805 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23120 ;lr: 0.0405 ;B loss: 1.827 ;acc: 0.710 ;iou: 0.745 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.624 ;Train accuracy: 0.684 ;IOU accuracy: 0.752 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 77\n",
      "batch: 0 ;B loss: 2.586 ;acc: 0.730 ;iou_acc: 0.855 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.888 ;acc: 0.585 ;iou_acc: 0.700 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.009 ;acc: 0.495 ;iou_acc: 0.640 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.162 ;acc: 0.445 ;iou_acc: 0.560 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.472 ;acc: 0.435 ;iou_acc: 0.555 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.943 ;acc: 0.260 ;iou_acc: 0.365 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.445 ;Test accuracy 0.428 ;IOU accuracy: 0.545 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 78 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23167 ;lr: 0.0405 ;B loss: 1.706 ;acc: 0.680 ;iou: 0.740 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23217 ;lr: 0.0405 ;B loss: 1.080 ;acc: 0.770 ;iou: 0.830 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23267 ;lr: 0.0405 ;B loss: 1.703 ;acc: 0.670 ;iou: 0.725 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23317 ;lr: 0.0405 ;B loss: 1.191 ;acc: 0.770 ;iou: 0.840 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23367 ;lr: 0.0405 ;B loss: 2.131 ;acc: 0.655 ;iou: 0.730 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23417 ;lr: 0.0405 ;B loss: 1.036 ;acc: 0.805 ;iou: 0.870 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.611 ;Train accuracy: 0.686 ;IOU accuracy: 0.755 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 78\n",
      "batch: 0 ;B loss: 2.539 ;acc: 0.715 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.900 ;acc: 0.580 ;iou_acc: 0.690 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.908 ;acc: 0.505 ;iou_acc: 0.615 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.153 ;acc: 0.445 ;iou_acc: 0.560 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.537 ;acc: 0.425 ;iou_acc: 0.515 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.993 ;acc: 0.260 ;iou_acc: 0.370 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.436 ;Test accuracy 0.429 ;IOU accuracy: 0.545 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 79 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23464 ;lr: 0.0405 ;B loss: 1.125 ;acc: 0.725 ;iou: 0.790 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23514 ;lr: 0.0405 ;B loss: 1.698 ;acc: 0.735 ;iou: 0.795 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23564 ;lr: 0.0405 ;B loss: 1.696 ;acc: 0.725 ;iou: 0.780 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23614 ;lr: 0.0405 ;B loss: 1.230 ;acc: 0.770 ;iou: 0.840 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23664 ;lr: 0.0405 ;B loss: 1.169 ;acc: 0.810 ;iou: 0.835 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23714 ;lr: 0.0405 ;B loss: 1.303 ;acc: 0.765 ;iou: 0.825 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.598 ;Train accuracy: 0.691 ;IOU accuracy: 0.758 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 79\n",
      "batch: 0 ;B loss: 2.548 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.909 ;acc: 0.585 ;iou_acc: 0.690 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.020 ;acc: 0.520 ;iou_acc: 0.635 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.188 ;acc: 0.445 ;iou_acc: 0.560 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.510 ;acc: 0.415 ;iou_acc: 0.535 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.855 ;acc: 0.290 ;iou_acc: 0.400 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.450 ;Test accuracy 0.433 ;IOU accuracy: 0.550 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 80 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23761 ;lr: 0.0405 ;B loss: 1.059 ;acc: 0.680 ;iou: 0.745 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23811 ;lr: 0.0405 ;B loss: 1.183 ;acc: 0.810 ;iou: 0.850 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23861 ;lr: 0.0405 ;B loss: 1.103 ;acc: 0.785 ;iou: 0.845 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23911 ;lr: 0.0405 ;B loss: 2.513 ;acc: 0.480 ;iou: 0.590 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23961 ;lr: 0.0405 ;B loss: 2.118 ;acc: 0.635 ;iou: 0.735 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24011 ;lr: 0.0405 ;B loss: 2.088 ;acc: 0.640 ;iou: 0.725 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.586 ;Train accuracy: 0.694 ;IOU accuracy: 0.762 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 80\n",
      "batch: 0 ;B loss: 2.406 ;acc: 0.710 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.813 ;acc: 0.590 ;iou_acc: 0.705 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.007 ;acc: 0.530 ;iou_acc: 0.640 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.101 ;acc: 0.460 ;iou_acc: 0.555 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.545 ;acc: 0.385 ;iou_acc: 0.500 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.919 ;acc: 0.270 ;iou_acc: 0.380 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.417 ;Test accuracy 0.429 ;IOU accuracy: 0.549 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 81 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24058 ;lr: 0.0405 ;B loss: 1.053 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24108 ;lr: 0.0405 ;B loss: 1.197 ;acc: 0.800 ;iou: 0.855 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24158 ;lr: 0.0405 ;B loss: 1.103 ;acc: 0.805 ;iou: 0.845 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24208 ;lr: 0.0405 ;B loss: 2.169 ;acc: 0.630 ;iou: 0.725 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24258 ;lr: 0.0405 ;B loss: 2.452 ;acc: 0.535 ;iou: 0.615 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24308 ;lr: 0.0405 ;B loss: 1.198 ;acc: 0.760 ;iou: 0.795 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.571 ;Train accuracy: 0.700 ;IOU accuracy: 0.767 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 81\n",
      "batch: 0 ;B loss: 2.584 ;acc: 0.740 ;iou_acc: 0.840 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.019 ;acc: 0.570 ;iou_acc: 0.690 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.101 ;acc: 0.495 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.133 ;acc: 0.485 ;iou_acc: 0.595 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.573 ;acc: 0.430 ;iou_acc: 0.530 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.935 ;acc: 0.260 ;iou_acc: 0.375 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.459 ;Test accuracy 0.435 ;IOU accuracy: 0.554 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 82 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24355 ;lr: 0.0405 ;B loss: 1.771 ;acc: 0.580 ;iou: 0.680 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24405 ;lr: 0.0405 ;B loss: 1.462 ;acc: 0.705 ;iou: 0.755 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24455 ;lr: 0.0405 ;B loss: 1.637 ;acc: 0.740 ;iou: 0.795 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24505 ;lr: 0.0405 ;B loss: 1.589 ;acc: 0.760 ;iou: 0.815 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24555 ;lr: 0.0405 ;B loss: 2.153 ;acc: 0.585 ;iou: 0.655 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24605 ;lr: 0.0405 ;B loss: 1.126 ;acc: 0.745 ;iou: 0.835 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.551 ;Train accuracy: 0.708 ;IOU accuracy: 0.774 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 82\n",
      "batch: 0 ;B loss: 2.582 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.936 ;acc: 0.570 ;iou_acc: 0.675 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.991 ;acc: 0.520 ;iou_acc: 0.625 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.199 ;acc: 0.465 ;iou_acc: 0.580 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.492 ;acc: 0.405 ;iou_acc: 0.535 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.849 ;acc: 0.310 ;iou_acc: 0.415 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.418 ;Test accuracy 0.439 ;IOU accuracy: 0.559 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 83 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24652 ;lr: 0.0405 ;B loss: 1.103 ;acc: 0.770 ;iou: 0.855 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24702 ;lr: 0.0405 ;B loss: 1.982 ;acc: 0.630 ;iou: 0.725 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24752 ;lr: 0.0405 ;B loss: 1.190 ;acc: 0.810 ;iou: 0.870 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24802 ;lr: 0.0405 ;B loss: 1.554 ;acc: 0.755 ;iou: 0.830 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24852 ;lr: 0.0405 ;B loss: 1.846 ;acc: 0.670 ;iou: 0.725 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24902 ;lr: 0.0405 ;B loss: 1.515 ;acc: 0.720 ;iou: 0.755 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.538 ;Train accuracy: 0.709 ;IOU accuracy: 0.776 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 83\n",
      "batch: 0 ;B loss: 2.611 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.893 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.057 ;acc: 0.505 ;iou_acc: 0.635 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.143 ;acc: 0.490 ;iou_acc: 0.600 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.507 ;acc: 0.380 ;iou_acc: 0.515 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.873 ;acc: 0.320 ;iou_acc: 0.410 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.448 ;Test accuracy 0.448 ;IOU accuracy: 0.568 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 84 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24949 ;lr: 0.0405 ;B loss: 1.060 ;acc: 0.805 ;iou: 0.855 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24999 ;lr: 0.0405 ;B loss: 1.643 ;acc: 0.705 ;iou: 0.755 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25049 ;lr: 0.0405 ;B loss: 1.464 ;acc: 0.740 ;iou: 0.815 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25099 ;lr: 0.0405 ;B loss: 1.831 ;acc: 0.540 ;iou: 0.695 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25149 ;lr: 0.0405 ;B loss: 2.151 ;acc: 0.590 ;iou: 0.645 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25199 ;lr: 0.0405 ;B loss: 1.922 ;acc: 0.685 ;iou: 0.755 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.521 ;Train accuracy: 0.716 ;IOU accuracy: 0.781 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 84\n",
      "batch: 0 ;B loss: 2.734 ;acc: 0.710 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.957 ;acc: 0.645 ;iou_acc: 0.740 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.018 ;acc: 0.545 ;iou_acc: 0.670 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.068 ;acc: 0.500 ;iou_acc: 0.600 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.528 ;acc: 0.400 ;iou_acc: 0.535 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.892 ;acc: 0.320 ;iou_acc: 0.450 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.460 ;Test accuracy 0.451 ;IOU accuracy: 0.574 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 85 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25246 ;lr: 0.0405 ;B loss: 1.980 ;acc: 0.615 ;iou: 0.695 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25296 ;lr: 0.0405 ;B loss: 1.062 ;acc: 0.760 ;iou: 0.830 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25346 ;lr: 0.0405 ;B loss: 1.089 ;acc: 0.780 ;iou: 0.820 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25396 ;lr: 0.0405 ;B loss: 1.340 ;acc: 0.770 ;iou: 0.845 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25446 ;lr: 0.0405 ;B loss: 1.637 ;acc: 0.705 ;iou: 0.750 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25496 ;lr: 0.0405 ;B loss: 1.803 ;acc: 0.675 ;iou: 0.755 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.501 ;Train accuracy: 0.719 ;IOU accuracy: 0.784 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 85\n",
      "batch: 0 ;B loss: 2.767 ;acc: 0.730 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.974 ;acc: 0.620 ;iou_acc: 0.725 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.049 ;acc: 0.525 ;iou_acc: 0.610 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.144 ;acc: 0.495 ;iou_acc: 0.600 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.543 ;acc: 0.410 ;iou_acc: 0.550 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.836 ;acc: 0.325 ;iou_acc: 0.425 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.453 ;Test accuracy 0.456 ;IOU accuracy: 0.575 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 86 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25543 ;lr: 0.0405 ;B loss: 1.828 ;acc: 0.615 ;iou: 0.690 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25593 ;lr: 0.0405 ;B loss: 1.764 ;acc: 0.700 ;iou: 0.765 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25643 ;lr: 0.0405 ;B loss: 1.903 ;acc: 0.670 ;iou: 0.735 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25693 ;lr: 0.0405 ;B loss: 1.526 ;acc: 0.760 ;iou: 0.805 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25743 ;lr: 0.0405 ;B loss: 2.655 ;acc: 0.500 ;iou: 0.605 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25793 ;lr: 0.0405 ;B loss: 1.322 ;acc: 0.735 ;iou: 0.805 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.492 ;Train accuracy: 0.725 ;IOU accuracy: 0.789 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 86\n",
      "batch: 0 ;B loss: 2.582 ;acc: 0.740 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.914 ;acc: 0.585 ;iou_acc: 0.695 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.056 ;acc: 0.515 ;iou_acc: 0.660 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.067 ;acc: 0.470 ;iou_acc: 0.570 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.425 ;acc: 0.420 ;iou_acc: 0.550 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 2.866 ;acc: 0.340 ;iou_acc: 0.425 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.414 ;Test accuracy 0.452 ;IOU accuracy: 0.573 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 87 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25840 ;lr: 0.0405 ;B loss: 1.166 ;acc: 0.830 ;iou: 0.870 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25890 ;lr: 0.0405 ;B loss: 1.224 ;acc: 0.765 ;iou: 0.805 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25940 ;lr: 0.0405 ;B loss: 2.653 ;acc: 0.340 ;iou: 0.485 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25990 ;lr: 0.0405 ;B loss: 1.456 ;acc: 0.790 ;iou: 0.810 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26040 ;lr: 0.0405 ;B loss: 1.469 ;acc: 0.780 ;iou: 0.800 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26090 ;lr: 0.0405 ;B loss: 1.913 ;acc: 0.525 ;iou: 0.660 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.474 ;Train accuracy: 0.728 ;IOU accuracy: 0.791 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 87\n",
      "batch: 0 ;B loss: 2.508 ;acc: 0.720 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.966 ;acc: 0.565 ;iou_acc: 0.680 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.055 ;acc: 0.495 ;iou_acc: 0.630 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.098 ;acc: 0.465 ;iou_acc: 0.570 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.689 ;acc: 0.365 ;iou_acc: 0.520 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.894 ;acc: 0.300 ;iou_acc: 0.430 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.468 ;Test accuracy 0.443 ;IOU accuracy: 0.565 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 88 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26137 ;lr: 0.0405 ;B loss: 1.284 ;acc: 0.815 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26187 ;lr: 0.0405 ;B loss: 1.088 ;acc: 0.775 ;iou: 0.820 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26237 ;lr: 0.0405 ;B loss: 1.205 ;acc: 0.795 ;iou: 0.875 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26287 ;lr: 0.0405 ;B loss: 1.177 ;acc: 0.745 ;iou: 0.815 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26337 ;lr: 0.0405 ;B loss: 2.494 ;acc: 0.490 ;iou: 0.575 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26387 ;lr: 0.0405 ;B loss: 1.868 ;acc: 0.705 ;iou: 0.760 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.460 ;Train accuracy: 0.730 ;IOU accuracy: 0.795 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 88\n",
      "batch: 0 ;B loss: 2.651 ;acc: 0.750 ;iou_acc: 0.855 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.961 ;acc: 0.620 ;iou_acc: 0.765 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.017 ;acc: 0.535 ;iou_acc: 0.660 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.146 ;acc: 0.465 ;iou_acc: 0.575 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.463 ;acc: 0.390 ;iou_acc: 0.530 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.800 ;acc: 0.345 ;iou_acc: 0.490 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.418 ;Test accuracy 0.460 ;IOU accuracy: 0.583 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 89 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26434 ;lr: 0.0405 ;B loss: 1.062 ;acc: 0.810 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26484 ;lr: 0.0405 ;B loss: 1.791 ;acc: 0.720 ;iou: 0.775 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26534 ;lr: 0.0405 ;B loss: 1.759 ;acc: 0.710 ;iou: 0.770 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26584 ;lr: 0.0405 ;B loss: 1.503 ;acc: 0.735 ;iou: 0.810 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26634 ;lr: 0.0405 ;B loss: 1.417 ;acc: 0.765 ;iou: 0.805 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26684 ;lr: 0.0405 ;B loss: 1.639 ;acc: 0.800 ;iou: 0.835 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.446 ;Train accuracy: 0.735 ;IOU accuracy: 0.798 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 89\n",
      "batch: 0 ;B loss: 2.588 ;acc: 0.745 ;iou_acc: 0.860 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.960 ;acc: 0.615 ;iou_acc: 0.735 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 1.988 ;acc: 0.540 ;iou_acc: 0.665 ;time: 0:00:32\n",
      "batch: 150 ;B loss: 2.070 ;acc: 0.525 ;iou_acc: 0.625 ;time: 0:00:36\n",
      "batch: 200 ;B loss: 2.463 ;acc: 0.405 ;iou_acc: 0.540 ;time: 0:00:39\n",
      "batch: 250 ;B loss: 2.803 ;acc: 0.330 ;iou_acc: 0.450 ;time: 0:00:43\n",
      "\n",
      "*BTrain: False ;Test loss: 2.426 ;Test accuracy 0.462 ;IOU accuracy: 0.585 ;Time: 0:00:48\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 90 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26731 ;lr: 0.0405 ;B loss: 1.268 ;acc: 0.780 ;iou: 0.840 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26781 ;lr: 0.0405 ;B loss: 1.474 ;acc: 0.775 ;iou: 0.830 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26831 ;lr: 0.0405 ;B loss: 1.150 ;acc: 0.825 ;iou: 0.845 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26881 ;lr: 0.0405 ;B loss: 0.994 ;acc: 0.830 ;iou: 0.860 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26931 ;lr: 0.0405 ;B loss: 1.345 ;acc: 0.775 ;iou: 0.835 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26981 ;lr: 0.0405 ;B loss: 1.397 ;acc: 0.715 ;iou: 0.780 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 1.423 ;Train accuracy: 0.740 ;IOU accuracy: 0.803 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 90\n",
      "batch: 0 ;B loss: 2.686 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.989 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 2.114 ;acc: 0.510 ;iou_acc: 0.640 ;time: 0:00:32\n",
      "batch: 150 ;B loss: 2.101 ;acc: 0.520 ;iou_acc: 0.610 ;time: 0:00:35\n",
      "batch: 200 ;B loss: 2.653 ;acc: 0.390 ;iou_acc: 0.550 ;time: 0:00:39\n",
      "batch: 250 ;B loss: 2.792 ;acc: 0.335 ;iou_acc: 0.485 ;time: 0:00:43\n",
      "\n",
      "*BTrain: True ;Test loss: 2.490 ;Test accuracy 0.457 ;IOU accuracy: 0.581 ;Time: 0:00:47\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 91 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27028 ;lr: 0.0405 ;B loss: 1.228 ;acc: 0.830 ;iou: 0.870 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27078 ;lr: 0.0405 ;B loss: 1.564 ;acc: 0.760 ;iou: 0.815 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27128 ;lr: 0.0405 ;B loss: 0.944 ;acc: 0.865 ;iou: 0.925 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27178 ;lr: 0.0405 ;B loss: 0.989 ;acc: 0.785 ;iou: 0.805 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27228 ;lr: 0.0405 ;B loss: 1.347 ;acc: 0.785 ;iou: 0.840 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27278 ;lr: 0.0405 ;B loss: 1.662 ;acc: 0.780 ;iou: 0.815 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.405 ;Train accuracy: 0.746 ;IOU accuracy: 0.808 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 91\n",
      "batch: 0 ;B loss: 2.537 ;acc: 0.705 ;iou_acc: 0.830 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.938 ;acc: 0.595 ;iou_acc: 0.715 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 1.989 ;acc: 0.540 ;iou_acc: 0.655 ;time: 0:00:32\n",
      "batch: 150 ;B loss: 2.156 ;acc: 0.490 ;iou_acc: 0.585 ;time: 0:00:35\n",
      "batch: 200 ;B loss: 2.591 ;acc: 0.385 ;iou_acc: 0.525 ;time: 0:00:39\n",
      "batch: 250 ;B loss: 2.886 ;acc: 0.330 ;iou_acc: 0.460 ;time: 0:00:43\n",
      "\n",
      "*BTrain: False ;Test loss: 2.406 ;Test accuracy 0.451 ;IOU accuracy: 0.576 ;Time: 0:00:48\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 92 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27325 ;lr: 0.0405 ;B loss: 1.278 ;acc: 0.775 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27375 ;lr: 0.0405 ;B loss: 1.639 ;acc: 0.770 ;iou: 0.815 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27425 ;lr: 0.0405 ;B loss: 1.310 ;acc: 0.795 ;iou: 0.850 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27475 ;lr: 0.0405 ;B loss: 1.001 ;acc: 0.765 ;iou: 0.815 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27525 ;lr: 0.0405 ;B loss: 1.334 ;acc: 0.800 ;iou: 0.860 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27575 ;lr: 0.0405 ;B loss: 1.551 ;acc: 0.790 ;iou: 0.845 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 1.387 ;Train accuracy: 0.751 ;IOU accuracy: 0.813 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 92\n",
      "batch: 0 ;B loss: 2.718 ;acc: 0.685 ;iou_acc: 0.815 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.896 ;acc: 0.605 ;iou_acc: 0.710 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.102 ;acc: 0.505 ;iou_acc: 0.665 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.094 ;acc: 0.490 ;iou_acc: 0.585 ;time: 0:00:35\n",
      "batch: 200 ;B loss: 2.483 ;acc: 0.410 ;iou_acc: 0.570 ;time: 0:00:38\n",
      "batch: 250 ;B loss: 2.850 ;acc: 0.365 ;iou_acc: 0.485 ;time: 0:00:42\n",
      "\n",
      "*BTrain: False ;Test loss: 2.450 ;Test accuracy 0.454 ;IOU accuracy: 0.577 ;Time: 0:00:47\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 93 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27622 ;lr: 0.0405 ;B loss: 1.217 ;acc: 0.715 ;iou: 0.795 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27672 ;lr: 0.0405 ;B loss: 0.990 ;acc: 0.840 ;iou: 0.905 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27722 ;lr: 0.0405 ;B loss: 1.057 ;acc: 0.780 ;iou: 0.845 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27772 ;lr: 0.0405 ;B loss: 1.037 ;acc: 0.820 ;iou: 0.845 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27822 ;lr: 0.0405 ;B loss: 1.752 ;acc: 0.670 ;iou: 0.795 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27872 ;lr: 0.0405 ;B loss: 1.235 ;acc: 0.845 ;iou: 0.885 ;time: 0:00:21\n",
      "\n",
      "*Training B: True ;B Train loss: 1.378 ;Train accuracy: 0.751 ;IOU accuracy: 0.813 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 93\n",
      "batch: 0 ;B loss: 2.783 ;acc: 0.725 ;iou_acc: 0.820 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.946 ;acc: 0.615 ;iou_acc: 0.750 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.002 ;acc: 0.555 ;iou_acc: 0.720 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.113 ;acc: 0.480 ;iou_acc: 0.605 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.532 ;acc: 0.420 ;iou_acc: 0.575 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 2.787 ;acc: 0.345 ;iou_acc: 0.485 ;time: 0:00:40\n",
      "\n",
      "*BTrain: True ;Test loss: 2.426 ;Test accuracy 0.477 ;IOU accuracy: 0.604 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 94 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27919 ;lr: 0.0405 ;B loss: 2.121 ;acc: 0.695 ;iou: 0.770 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27969 ;lr: 0.0405 ;B loss: 1.027 ;acc: 0.815 ;iou: 0.850 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28019 ;lr: 0.0405 ;B loss: 1.112 ;acc: 0.805 ;iou: 0.830 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28069 ;lr: 0.0405 ;B loss: 0.925 ;acc: 0.825 ;iou: 0.880 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28119 ;lr: 0.0405 ;B loss: 2.205 ;acc: 0.635 ;iou: 0.710 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28169 ;lr: 0.0405 ;B loss: 1.144 ;acc: 0.860 ;iou: 0.890 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 1.363 ;Train accuracy: 0.753 ;IOU accuracy: 0.815 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 94\n",
      "batch: 0 ;B loss: 2.852 ;acc: 0.730 ;iou_acc: 0.840 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 2.038 ;acc: 0.600 ;iou_acc: 0.725 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.019 ;acc: 0.540 ;iou_acc: 0.655 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.111 ;acc: 0.535 ;iou_acc: 0.640 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.628 ;acc: 0.425 ;iou_acc: 0.550 ;time: 0:00:38\n",
      "batch: 250 ;B loss: 2.908 ;acc: 0.325 ;iou_acc: 0.440 ;time: 0:00:41\n",
      "\n",
      "*BTrain: False ;Test loss: 2.492 ;Test accuracy 0.478 ;IOU accuracy: 0.602 ;Time: 0:00:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 95 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28216 ;lr: 0.0405 ;B loss: 1.012 ;acc: 0.845 ;iou: 0.885 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28266 ;lr: 0.0405 ;B loss: 0.989 ;acc: 0.810 ;iou: 0.865 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28316 ;lr: 0.0405 ;B loss: 1.151 ;acc: 0.805 ;iou: 0.840 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28366 ;lr: 0.0405 ;B loss: 1.023 ;acc: 0.760 ;iou: 0.815 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28416 ;lr: 0.0405 ;B loss: 1.155 ;acc: 0.725 ;iou: 0.795 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28466 ;lr: 0.0405 ;B loss: 1.108 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.349 ;Train accuracy: 0.757 ;IOU accuracy: 0.818 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 95\n",
      "batch: 0 ;B loss: 2.925 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 2.020 ;acc: 0.620 ;iou_acc: 0.745 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 1.985 ;acc: 0.560 ;iou_acc: 0.695 ;time: 0:00:32\n",
      "batch: 150 ;B loss: 1.998 ;acc: 0.515 ;iou_acc: 0.625 ;time: 0:00:35\n",
      "batch: 200 ;B loss: 2.550 ;acc: 0.435 ;iou_acc: 0.545 ;time: 0:00:38\n",
      "batch: 250 ;B loss: 2.835 ;acc: 0.375 ;iou_acc: 0.490 ;time: 0:00:42\n",
      "\n",
      "*BTrain: False ;Test loss: 2.462 ;Test accuracy 0.484 ;IOU accuracy: 0.611 ;Time: 0:00:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 96 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28513 ;lr: 0.0405 ;B loss: 1.054 ;acc: 0.815 ;iou: 0.855 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28563 ;lr: 0.0405 ;B loss: 0.886 ;acc: 0.815 ;iou: 0.850 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28613 ;lr: 0.0405 ;B loss: 1.225 ;acc: 0.785 ;iou: 0.890 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28663 ;lr: 0.0405 ;B loss: 1.025 ;acc: 0.815 ;iou: 0.870 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28713 ;lr: 0.0405 ;B loss: 1.026 ;acc: 0.815 ;iou: 0.870 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28763 ;lr: 0.0405 ;B loss: 1.922 ;acc: 0.630 ;iou: 0.710 ;time: 0:00:20\n",
      "\n",
      "*Training B: True ;B Train loss: 1.332 ;Train accuracy: 0.763 ;IOU accuracy: 0.823 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 96\n",
      "batch: 0 ;B loss: 2.961 ;acc: 0.735 ;iou_acc: 0.845 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.998 ;acc: 0.625 ;iou_acc: 0.735 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.108 ;acc: 0.570 ;iou_acc: 0.705 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.064 ;acc: 0.530 ;iou_acc: 0.620 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.558 ;acc: 0.425 ;iou_acc: 0.570 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 2.902 ;acc: 0.340 ;iou_acc: 0.455 ;time: 0:00:40\n",
      "\n",
      "*BTrain: True ;Test loss: 2.484 ;Test accuracy 0.481 ;IOU accuracy: 0.606 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 97 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28810 ;lr: 0.0405 ;B loss: 1.141 ;acc: 0.860 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28860 ;lr: 0.0405 ;B loss: 1.000 ;acc: 0.750 ;iou: 0.800 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28910 ;lr: 0.0405 ;B loss: 0.894 ;acc: 0.840 ;iou: 0.885 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28960 ;lr: 0.0405 ;B loss: 0.955 ;acc: 0.845 ;iou: 0.885 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29010 ;lr: 0.0405 ;B loss: 1.166 ;acc: 0.810 ;iou: 0.875 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29060 ;lr: 0.0405 ;B loss: 0.972 ;acc: 0.760 ;iou: 0.830 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 1.315 ;Train accuracy: 0.764 ;IOU accuracy: 0.824 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 97\n",
      "batch: 0 ;B loss: 2.952 ;acc: 0.715 ;iou_acc: 0.820 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 2.144 ;acc: 0.625 ;iou_acc: 0.720 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.208 ;acc: 0.570 ;iou_acc: 0.705 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.050 ;acc: 0.540 ;iou_acc: 0.640 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.594 ;acc: 0.465 ;iou_acc: 0.600 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 2.878 ;acc: 0.340 ;iou_acc: 0.485 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.589 ;Test accuracy 0.475 ;IOU accuracy: 0.601 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 98 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 29107 ;lr: 0.0405 ;B loss: 2.035 ;acc: 0.580 ;iou: 0.720 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29157 ;lr: 0.0405 ;B loss: 1.197 ;acc: 0.865 ;iou: 0.915 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 29207 ;lr: 0.0405 ;B loss: 1.259 ;acc: 0.795 ;iou: 0.835 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 29257 ;lr: 0.0405 ;B loss: 1.023 ;acc: 0.800 ;iou: 0.840 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29307 ;lr: 0.0405 ;B loss: 1.067 ;acc: 0.890 ;iou: 0.910 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29357 ;lr: 0.0405 ;B loss: 1.228 ;acc: 0.825 ;iou: 0.855 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 1.314 ;Train accuracy: 0.765 ;IOU accuracy: 0.824 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 98\n",
      "batch: 0 ;B loss: 3.144 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:00:24\n",
      "batch: 50 ;B loss: 2.083 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.088 ;acc: 0.570 ;iou_acc: 0.700 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.249 ;acc: 0.490 ;iou_acc: 0.595 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.657 ;acc: 0.420 ;iou_acc: 0.585 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.002 ;acc: 0.375 ;iou_acc: 0.485 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.577 ;Test accuracy 0.483 ;IOU accuracy: 0.608 ;Time: 0:00:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 99 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 29404 ;lr: 0.0405 ;B loss: 1.846 ;acc: 0.525 ;iou: 0.655 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29454 ;lr: 0.0405 ;B loss: 1.606 ;acc: 0.740 ;iou: 0.790 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 29504 ;lr: 0.0405 ;B loss: 1.143 ;acc: 0.755 ;iou: 0.830 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 29554 ;lr: 0.0405 ;B loss: 1.043 ;acc: 0.770 ;iou: 0.830 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29604 ;lr: 0.0405 ;B loss: 1.734 ;acc: 0.720 ;iou: 0.785 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29654 ;lr: 0.0405 ;B loss: 0.977 ;acc: 0.825 ;iou: 0.870 ;time: 0:00:21\n",
      "\n",
      "*Training B: True ;B Train loss: 1.293 ;Train accuracy: 0.769 ;IOU accuracy: 0.828 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 99\n",
      "batch: 0 ;B loss: 3.033 ;acc: 0.700 ;iou_acc: 0.830 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 2.127 ;acc: 0.625 ;iou_acc: 0.730 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.107 ;acc: 0.555 ;iou_acc: 0.705 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.030 ;acc: 0.575 ;iou_acc: 0.650 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.606 ;acc: 0.455 ;iou_acc: 0.565 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 2.846 ;acc: 0.375 ;iou_acc: 0.475 ;time: 0:00:40\n",
      "\n",
      "*BTrain: True ;Test loss: 2.520 ;Test accuracy 0.494 ;IOU accuracy: 0.619 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "params_dir: ../data/training/models/All/base/hidden:100\n",
      "num_hidden: 100\n",
      "learning rate: 0.05\n",
      "# Train set size: 297\n",
      "# Training batches: 297\n",
      "# Test set size: 297\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 3.387 ;acc: 0.115 ;iou: 0.185 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 1.570 ;acc: 0.375 ;iou: 0.500 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 1.621 ;acc: 0.360 ;iou: 0.475 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 3.550 ;acc: 0.100 ;iou: 0.180 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.154 ;acc: 0.255 ;iou: 0.325 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.140 ;acc: 0.230 ;iou: 0.330 ;time: 0:00:21\n",
      "\n",
      "*Training B: True ;B Train loss: 2.440 ;Train accuracy: 0.228 ;IOU accuracy: 0.325 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 1.388 ;acc: 0.505 ;iou_acc: 0.630 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.866 ;acc: 0.200 ;iou_acc: 0.355 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.120 ;acc: 0.185 ;iou_acc: 0.285 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.435 ;acc: 0.130 ;iou_acc: 0.220 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.743 ;acc: 0.120 ;iou_acc: 0.225 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.168 ;acc: 0.105 ;iou_acc: 0.215 ;time: 0:00:40\n",
      "\n",
      "*BTrain: True ;Test loss: 2.440 ;Test accuracy 0.192 ;IOU accuracy: 0.290 ;Time: 0:00:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 1.388 ;acc: 0.525 ;iou: 0.675 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 1.389 ;acc: 0.445 ;iou: 0.585 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.499 ;acc: 0.235 ;iou: 0.280 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 1.390 ;acc: 0.490 ;iou: 0.630 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.595 ;acc: 0.170 ;iou: 0.235 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.561 ;acc: 0.195 ;iou: 0.255 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 2.433 ;Train accuracy: 0.226 ;IOU accuracy: 0.321 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 1.390 ;acc: 0.490 ;iou_acc: 0.645 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.858 ;acc: 0.245 ;iou_acc: 0.385 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.121 ;acc: 0.210 ;iou_acc: 0.300 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.440 ;acc: 0.130 ;iou_acc: 0.210 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.743 ;acc: 0.130 ;iou_acc: 0.220 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.164 ;acc: 0.110 ;iou_acc: 0.205 ;time: 0:00:41\n",
      "\n",
      "*BTrain: False ;Test loss: 2.440 ;Test accuracy 0.196 ;IOU accuracy: 0.294 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 1.537 ;acc: 0.380 ;iou: 0.470 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 1.390 ;acc: 0.555 ;iou: 0.665 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 3.780 ;acc: 0.125 ;iou: 0.180 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 1.390 ;acc: 0.530 ;iou: 0.650 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 3.451 ;acc: 0.110 ;iou: 0.200 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 3.570 ;acc: 0.085 ;iou: 0.145 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 2.431 ;Train accuracy: 0.232 ;IOU accuracy: 0.327 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 1.391 ;acc: 0.470 ;iou_acc: 0.625 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.857 ;acc: 0.270 ;iou_acc: 0.365 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.122 ;acc: 0.165 ;iou_acc: 0.255 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.439 ;acc: 0.115 ;iou_acc: 0.210 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.746 ;acc: 0.155 ;iou_acc: 0.230 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.160 ;acc: 0.135 ;iou_acc: 0.245 ;time: 0:00:41\n",
      "\n",
      "*BTrain: False ;Test loss: 2.441 ;Test accuracy 0.197 ;IOU accuracy: 0.297 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.613 ;acc: 0.350 ;iou: 0.460 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.939 ;acc: 0.335 ;iou: 0.470 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 3.259 ;acc: 0.125 ;iou: 0.240 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 2.995 ;acc: 0.180 ;iou: 0.305 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 2.193 ;acc: 0.260 ;iou: 0.360 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.392 ;acc: 0.515 ;iou: 0.650 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 2.428 ;Train accuracy: 0.242 ;IOU accuracy: 0.337 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.391 ;acc: 0.475 ;iou_acc: 0.615 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.855 ;acc: 0.290 ;iou_acc: 0.425 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.125 ;acc: 0.175 ;iou_acc: 0.305 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.443 ;acc: 0.150 ;iou_acc: 0.215 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.752 ;acc: 0.120 ;iou_acc: 0.235 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.162 ;acc: 0.125 ;iou_acc: 0.250 ;time: 0:00:41\n",
      "\n",
      "*BTrain: True ;Test loss: 2.442 ;Test accuracy 0.196 ;IOU accuracy: 0.297 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.525 ;acc: 0.400 ;iou: 0.490 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 2.432 ;acc: 0.210 ;iou: 0.340 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.912 ;acc: 0.340 ;iou: 0.455 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 3.282 ;acc: 0.160 ;iou: 0.235 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 2.562 ;acc: 0.190 ;iou: 0.270 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 2.170 ;acc: 0.240 ;iou: 0.325 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 2.424 ;Train accuracy: 0.254 ;IOU accuracy: 0.347 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.396 ;acc: 0.490 ;iou_acc: 0.630 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.863 ;acc: 0.275 ;iou_acc: 0.410 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.124 ;acc: 0.190 ;iou_acc: 0.300 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.451 ;acc: 0.140 ;iou_acc: 0.205 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.758 ;acc: 0.140 ;iou_acc: 0.240 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.159 ;acc: 0.140 ;iou_acc: 0.255 ;time: 0:00:41\n",
      "\n",
      "*BTrain: False ;Test loss: 2.445 ;Test accuracy 0.196 ;IOU accuracy: 0.294 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.878 ;acc: 0.305 ;iou: 0.405 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 2.125 ;acc: 0.330 ;iou: 0.375 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 2.928 ;acc: 0.185 ;iou: 0.250 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.397 ;acc: 0.505 ;iou: 0.625 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 3.073 ;acc: 0.175 ;iou: 0.310 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 2.372 ;acc: 0.220 ;iou: 0.325 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 2.420 ;Train accuracy: 0.265 ;IOU accuracy: 0.358 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.396 ;acc: 0.480 ;iou_acc: 0.635 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.863 ;acc: 0.285 ;iou_acc: 0.415 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.125 ;acc: 0.225 ;iou_acc: 0.315 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.447 ;acc: 0.180 ;iou_acc: 0.255 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.751 ;acc: 0.145 ;iou_acc: 0.220 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.164 ;acc: 0.130 ;iou_acc: 0.250 ;time: 0:00:41\n",
      "\n",
      "*BTrain: False ;Test loss: 2.445 ;Test accuracy 0.197 ;IOU accuracy: 0.297 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 2.453 ;acc: 0.235 ;iou: 0.310 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 2.378 ;acc: 0.270 ;iou: 0.355 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 2.720 ;acc: 0.205 ;iou: 0.290 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 2.578 ;acc: 0.235 ;iou: 0.325 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 2.740 ;acc: 0.195 ;iou: 0.305 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 3.452 ;acc: 0.150 ;iou: 0.215 ;time: 0:00:20\n",
      "\n",
      "*Training B: True ;B Train loss: 2.416 ;Train accuracy: 0.272 ;IOU accuracy: 0.363 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.400 ;acc: 0.440 ;iou_acc: 0.610 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.863 ;acc: 0.270 ;iou_acc: 0.395 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.128 ;acc: 0.220 ;iou_acc: 0.305 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.449 ;acc: 0.120 ;iou_acc: 0.210 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.751 ;acc: 0.150 ;iou_acc: 0.225 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.154 ;acc: 0.155 ;iou_acc: 0.290 ;time: 0:00:40\n",
      "\n",
      "*BTrain: True ;Test loss: 2.447 ;Test accuracy 0.197 ;IOU accuracy: 0.300 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 2.160 ;acc: 0.345 ;iou: 0.415 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 3.410 ;acc: 0.195 ;iou: 0.305 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 2.581 ;acc: 0.210 ;iou: 0.280 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 2.181 ;acc: 0.275 ;iou: 0.330 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 2.083 ;acc: 0.295 ;iou: 0.375 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 3.347 ;acc: 0.180 ;iou: 0.270 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 2.411 ;Train accuracy: 0.281 ;IOU accuracy: 0.375 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.400 ;acc: 0.450 ;iou_acc: 0.620 ;time: 0:00:24\n",
      "batch: 50 ;B loss: 1.862 ;acc: 0.250 ;iou_acc: 0.395 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.138 ;acc: 0.165 ;iou_acc: 0.250 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.433 ;acc: 0.185 ;iou_acc: 0.260 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.758 ;acc: 0.135 ;iou_acc: 0.210 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.174 ;acc: 0.155 ;iou_acc: 0.275 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.449 ;Test accuracy 0.197 ;IOU accuracy: 0.297 ;Time: 0:00:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.394 ;acc: 0.505 ;iou: 0.655 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.401 ;acc: 0.475 ;iou: 0.625 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.530 ;acc: 0.460 ;iou: 0.540 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.833 ;acc: 0.370 ;iou: 0.465 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 3.653 ;acc: 0.150 ;iou: 0.235 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 3.399 ;acc: 0.110 ;iou: 0.150 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 2.406 ;Train accuracy: 0.288 ;IOU accuracy: 0.379 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.404 ;acc: 0.435 ;iou_acc: 0.580 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.867 ;acc: 0.240 ;iou_acc: 0.360 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.129 ;acc: 0.205 ;iou_acc: 0.290 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.451 ;acc: 0.170 ;iou_acc: 0.220 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.754 ;acc: 0.145 ;iou_acc: 0.230 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.160 ;acc: 0.150 ;iou_acc: 0.260 ;time: 0:00:41\n",
      "\n",
      "*BTrain: False ;Test loss: 2.452 ;Test accuracy 0.196 ;IOU accuracy: 0.297 ;Time: 0:00:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 2.200 ;acc: 0.270 ;iou: 0.330 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.585 ;acc: 0.425 ;iou: 0.485 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 2.579 ;acc: 0.230 ;iou: 0.345 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 2.339 ;acc: 0.285 ;iou: 0.380 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 2.974 ;acc: 0.295 ;iou: 0.355 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.476 ;acc: 0.440 ;iou: 0.500 ;time: 0:00:21\n",
      "\n",
      "*Training B: True ;B Train loss: 2.401 ;Train accuracy: 0.295 ;IOU accuracy: 0.387 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.405 ;acc: 0.465 ;iou_acc: 0.610 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.863 ;acc: 0.260 ;iou_acc: 0.415 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.129 ;acc: 0.195 ;iou_acc: 0.275 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.450 ;acc: 0.150 ;iou_acc: 0.225 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.749 ;acc: 0.125 ;iou_acc: 0.230 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.162 ;acc: 0.155 ;iou_acc: 0.265 ;time: 0:00:41\n",
      "\n",
      "*BTrain: True ;Test loss: 2.453 ;Test accuracy 0.198 ;IOU accuracy: 0.299 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 2.469 ;acc: 0.345 ;iou: 0.415 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 3.723 ;acc: 0.105 ;iou: 0.205 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.530 ;acc: 0.430 ;iou: 0.530 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 2.292 ;acc: 0.255 ;iou: 0.315 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 2.087 ;acc: 0.310 ;iou: 0.360 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 3.569 ;acc: 0.115 ;iou: 0.205 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 2.397 ;Train accuracy: 0.303 ;IOU accuracy: 0.393 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.414 ;acc: 0.515 ;iou_acc: 0.660 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.872 ;acc: 0.225 ;iou_acc: 0.370 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.148 ;acc: 0.205 ;iou_acc: 0.300 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.449 ;acc: 0.155 ;iou_acc: 0.215 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.763 ;acc: 0.115 ;iou_acc: 0.245 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.160 ;acc: 0.150 ;iou_acc: 0.260 ;time: 0:00:41\n",
      "\n",
      "*BTrain: False ;Test loss: 2.458 ;Test accuracy 0.196 ;IOU accuracy: 0.297 ;Time: 0:00:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 2.344 ;acc: 0.285 ;iou: 0.385 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.835 ;acc: 0.400 ;iou: 0.460 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 2.942 ;acc: 0.305 ;iou: 0.360 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.838 ;acc: 0.340 ;iou: 0.425 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 2.352 ;acc: 0.310 ;iou: 0.400 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 3.723 ;acc: 0.130 ;iou: 0.240 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 2.391 ;Train accuracy: 0.307 ;IOU accuracy: 0.398 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.409 ;acc: 0.485 ;iou_acc: 0.645 ;time: 0:00:24\n",
      "batch: 50 ;B loss: 1.875 ;acc: 0.230 ;iou_acc: 0.355 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.161 ;acc: 0.175 ;iou_acc: 0.275 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.439 ;acc: 0.195 ;iou_acc: 0.275 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.749 ;acc: 0.105 ;iou_acc: 0.230 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.175 ;acc: 0.155 ;iou_acc: 0.260 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.457 ;Test accuracy 0.198 ;IOU accuracy: 0.299 ;Time: 0:00:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 3.011 ;acc: 0.235 ;iou: 0.355 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 2.759 ;acc: 0.250 ;iou: 0.310 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 2.147 ;acc: 0.335 ;iou: 0.415 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 3.480 ;acc: 0.180 ;iou: 0.290 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.889 ;acc: 0.355 ;iou: 0.475 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 2.152 ;acc: 0.350 ;iou: 0.410 ;time: 0:00:21\n",
      "\n",
      "*Training B: True ;B Train loss: 2.387 ;Train accuracy: 0.314 ;IOU accuracy: 0.403 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.415 ;acc: 0.510 ;iou_acc: 0.665 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.877 ;acc: 0.220 ;iou_acc: 0.370 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.140 ;acc: 0.180 ;iou_acc: 0.280 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.435 ;acc: 0.195 ;iou_acc: 0.270 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.735 ;acc: 0.150 ;iou_acc: 0.250 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.168 ;acc: 0.140 ;iou_acc: 0.225 ;time: 0:00:41\n",
      "\n",
      "*BTrain: True ;Test loss: 2.457 ;Test accuracy 0.200 ;IOU accuracy: 0.299 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 2.652 ;acc: 0.330 ;iou: 0.420 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 3.868 ;acc: 0.145 ;iou: 0.270 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 2.269 ;acc: 0.340 ;iou: 0.420 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 2.880 ;acc: 0.275 ;iou: 0.345 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 2.741 ;acc: 0.280 ;iou: 0.345 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 2.417 ;acc: 0.325 ;iou: 0.390 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 2.381 ;Train accuracy: 0.321 ;IOU accuracy: 0.412 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.421 ;acc: 0.485 ;iou_acc: 0.645 ;time: 0:00:24\n",
      "batch: 50 ;B loss: 1.867 ;acc: 0.290 ;iou_acc: 0.430 ;time: 0:00:26\n",
      "batch: 100 ;B loss: 2.140 ;acc: 0.240 ;iou_acc: 0.315 ;time: 0:00:29\n",
      "batch: 150 ;B loss: 2.432 ;acc: 0.195 ;iou_acc: 0.270 ;time: 0:00:32\n",
      "batch: 200 ;B loss: 2.756 ;acc: 0.125 ;iou_acc: 0.215 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.170 ;acc: 0.145 ;iou_acc: 0.205 ;time: 0:00:39\n",
      "\n",
      "*BTrain: False ;Test loss: 2.458 ;Test accuracy 0.201 ;IOU accuracy: 0.303 ;Time: 0:00:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 2.732 ;acc: 0.250 ;iou: 0.375 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 2.990 ;acc: 0.260 ;iou: 0.335 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 2.127 ;acc: 0.375 ;iou: 0.465 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 2.156 ;acc: 0.345 ;iou: 0.430 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 2.403 ;acc: 0.300 ;iou: 0.395 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.775 ;acc: 0.380 ;iou: 0.495 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 2.374 ;Train accuracy: 0.327 ;IOU accuracy: 0.418 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.421 ;acc: 0.470 ;iou_acc: 0.620 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.883 ;acc: 0.325 ;iou_acc: 0.450 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.150 ;acc: 0.220 ;iou_acc: 0.325 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.412 ;acc: 0.195 ;iou_acc: 0.275 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.749 ;acc: 0.145 ;iou_acc: 0.255 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.187 ;acc: 0.120 ;iou_acc: 0.205 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.456 ;Test accuracy 0.204 ;IOU accuracy: 0.307 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 2.219 ;acc: 0.315 ;iou: 0.425 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 1.542 ;acc: 0.475 ;iou: 0.565 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 2.196 ;acc: 0.390 ;iou: 0.450 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 1.826 ;acc: 0.405 ;iou: 0.490 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.543 ;acc: 0.485 ;iou: 0.585 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 2.890 ;acc: 0.295 ;iou: 0.380 ;time: 0:00:21\n",
      "\n",
      "*Training B: True ;B Train loss: 2.366 ;Train accuracy: 0.337 ;IOU accuracy: 0.427 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.424 ;acc: 0.485 ;iou_acc: 0.640 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.869 ;acc: 0.300 ;iou_acc: 0.450 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.123 ;acc: 0.205 ;iou_acc: 0.330 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.427 ;acc: 0.230 ;iou_acc: 0.310 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.726 ;acc: 0.175 ;iou_acc: 0.275 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.153 ;acc: 0.140 ;iou_acc: 0.235 ;time: 0:00:41\n",
      "\n",
      "*BTrain: True ;Test loss: 2.453 ;Test accuracy 0.210 ;IOU accuracy: 0.319 ;Time: 0:00:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 2.734 ;acc: 0.315 ;iou: 0.410 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 1.503 ;acc: 0.480 ;iou: 0.565 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 2.100 ;acc: 0.375 ;iou: 0.475 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 2.255 ;acc: 0.365 ;iou: 0.445 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 2.671 ;acc: 0.295 ;iou: 0.400 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 1.841 ;acc: 0.395 ;iou: 0.490 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 2.356 ;Train accuracy: 0.341 ;IOU accuracy: 0.434 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.429 ;acc: 0.490 ;iou_acc: 0.660 ;time: 0:00:24\n",
      "batch: 50 ;B loss: 1.873 ;acc: 0.335 ;iou_acc: 0.440 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.133 ;acc: 0.245 ;iou_acc: 0.325 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.424 ;acc: 0.195 ;iou_acc: 0.255 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.757 ;acc: 0.165 ;iou_acc: 0.250 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.157 ;acc: 0.140 ;iou_acc: 0.225 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.454 ;Test accuracy 0.215 ;IOU accuracy: 0.315 ;Time: 0:00:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 3.110 ;acc: 0.250 ;iou: 0.370 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 3.489 ;acc: 0.215 ;iou: 0.280 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 3.157 ;acc: 0.250 ;iou: 0.325 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 3.550 ;acc: 0.185 ;iou: 0.265 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 2.698 ;acc: 0.295 ;iou: 0.405 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 1.417 ;acc: 0.545 ;iou: 0.660 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 2.343 ;Train accuracy: 0.353 ;IOU accuracy: 0.445 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.437 ;acc: 0.480 ;iou_acc: 0.645 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.863 ;acc: 0.355 ;iou_acc: 0.470 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.133 ;acc: 0.245 ;iou_acc: 0.335 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.428 ;acc: 0.215 ;iou_acc: 0.285 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.758 ;acc: 0.165 ;iou_acc: 0.285 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.151 ;acc: 0.115 ;iou_acc: 0.180 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.456 ;Test accuracy 0.219 ;IOU accuracy: 0.321 ;Time: 0:00:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 1.498 ;acc: 0.495 ;iou: 0.590 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 2.870 ;acc: 0.235 ;iou: 0.305 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 2.433 ;acc: 0.355 ;iou: 0.430 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 3.114 ;acc: 0.250 ;iou: 0.300 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 2.819 ;acc: 0.235 ;iou: 0.350 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 3.576 ;acc: 0.205 ;iou: 0.320 ;time: 0:00:20\n",
      "\n",
      "*Training B: True ;B Train loss: 2.333 ;Train accuracy: 0.359 ;IOU accuracy: 0.451 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.433 ;acc: 0.505 ;iou_acc: 0.665 ;time: 0:00:24\n",
      "batch: 50 ;B loss: 1.861 ;acc: 0.310 ;iou_acc: 0.450 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.107 ;acc: 0.230 ;iou_acc: 0.350 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.363 ;acc: 0.230 ;iou_acc: 0.315 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.693 ;acc: 0.205 ;iou_acc: 0.325 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.093 ;acc: 0.150 ;iou_acc: 0.225 ;time: 0:00:40\n",
      "\n",
      "*BTrain: True ;Test loss: 2.428 ;Test accuracy 0.232 ;IOU accuracy: 0.341 ;Time: 0:00:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 1.942 ;acc: 0.385 ;iou: 0.470 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 1.451 ;acc: 0.525 ;iou: 0.590 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 3.075 ;acc: 0.255 ;iou: 0.335 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 3.262 ;acc: 0.235 ;iou: 0.335 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 1.784 ;acc: 0.450 ;iou: 0.535 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 1.731 ;acc: 0.400 ;iou: 0.455 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 2.322 ;Train accuracy: 0.367 ;IOU accuracy: 0.459 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.446 ;acc: 0.510 ;iou_acc: 0.665 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.878 ;acc: 0.355 ;iou_acc: 0.510 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.126 ;acc: 0.230 ;iou_acc: 0.350 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.371 ;acc: 0.240 ;iou_acc: 0.315 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.717 ;acc: 0.170 ;iou_acc: 0.280 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.073 ;acc: 0.155 ;iou_acc: 0.235 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.430 ;Test accuracy 0.233 ;IOU accuracy: 0.347 ;Time: 0:00:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 2.269 ;acc: 0.335 ;iou: 0.425 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 1.703 ;acc: 0.465 ;iou: 0.555 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 2.378 ;acc: 0.365 ;iou: 0.470 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 2.370 ;acc: 0.330 ;iou: 0.400 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 2.233 ;acc: 0.395 ;iou: 0.485 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 2.874 ;acc: 0.280 ;iou: 0.370 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 2.312 ;Train accuracy: 0.374 ;IOU accuracy: 0.465 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.440 ;acc: 0.470 ;iou_acc: 0.620 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.856 ;acc: 0.330 ;iou_acc: 0.450 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.102 ;acc: 0.245 ;iou_acc: 0.350 ;time: 0:00:31\n",
      "batch: 150 ;B loss: 2.344 ;acc: 0.235 ;iou_acc: 0.320 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.697 ;acc: 0.205 ;iou_acc: 0.285 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.119 ;acc: 0.185 ;iou_acc: 0.245 ;time: 0:00:41\n",
      "\n",
      "*BTrain: False ;Test loss: 2.423 ;Test accuracy 0.238 ;IOU accuracy: 0.346 ;Time: 0:00:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 2.464 ;acc: 0.395 ;iou: 0.465 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 2.130 ;acc: 0.430 ;iou: 0.485 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 2.285 ;acc: 0.320 ;iou: 0.405 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 2.570 ;acc: 0.320 ;iou: 0.400 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 2.777 ;acc: 0.255 ;iou: 0.345 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 1.499 ;acc: 0.510 ;iou: 0.630 ;time: 0:00:20\n",
      "\n",
      "*Training B: True ;B Train loss: 2.303 ;Train accuracy: 0.379 ;IOU accuracy: 0.469 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.456 ;acc: 0.480 ;iou_acc: 0.635 ;time: 0:00:24\n",
      "batch: 50 ;B loss: 1.860 ;acc: 0.340 ;iou_acc: 0.485 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.117 ;acc: 0.225 ;iou_acc: 0.340 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.321 ;acc: 0.240 ;iou_acc: 0.320 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.688 ;acc: 0.230 ;iou_acc: 0.340 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.076 ;acc: 0.190 ;iou_acc: 0.275 ;time: 0:00:40\n",
      "\n",
      "*BTrain: True ;Test loss: 2.425 ;Test accuracy 0.241 ;IOU accuracy: 0.352 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 2.723 ;acc: 0.275 ;iou: 0.380 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 3.441 ;acc: 0.225 ;iou: 0.310 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 1.745 ;acc: 0.485 ;iou: 0.585 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 3.041 ;acc: 0.285 ;iou: 0.395 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 2.912 ;acc: 0.300 ;iou: 0.390 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 4.114 ;acc: 0.125 ;iou: 0.250 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 2.295 ;Train accuracy: 0.383 ;IOU accuracy: 0.472 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.470 ;acc: 0.495 ;iou_acc: 0.670 ;time: 0:00:24\n",
      "batch: 50 ;B loss: 1.838 ;acc: 0.365 ;iou_acc: 0.490 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.098 ;acc: 0.250 ;iou_acc: 0.360 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.336 ;acc: 0.240 ;iou_acc: 0.310 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.694 ;acc: 0.230 ;iou_acc: 0.295 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.074 ;acc: 0.155 ;iou_acc: 0.225 ;time: 0:00:39\n",
      "\n",
      "*BTrain: False ;Test loss: 2.419 ;Test accuracy 0.244 ;IOU accuracy: 0.356 ;Time: 0:00:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 3.381 ;acc: 0.215 ;iou: 0.315 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 2.876 ;acc: 0.295 ;iou: 0.370 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 1.977 ;acc: 0.435 ;iou: 0.515 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 1.764 ;acc: 0.455 ;iou: 0.505 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 2.494 ;acc: 0.375 ;iou: 0.460 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 1.442 ;acc: 0.565 ;iou: 0.690 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 2.284 ;Train accuracy: 0.391 ;IOU accuracy: 0.480 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.475 ;acc: 0.525 ;iou_acc: 0.680 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.828 ;acc: 0.380 ;iou_acc: 0.485 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.093 ;acc: 0.270 ;iou_acc: 0.370 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.351 ;acc: 0.235 ;iou_acc: 0.325 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.691 ;acc: 0.225 ;iou_acc: 0.320 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.096 ;acc: 0.140 ;iou_acc: 0.230 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.433 ;Test accuracy 0.243 ;IOU accuracy: 0.354 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 1.452 ;acc: 0.575 ;iou: 0.670 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 2.810 ;acc: 0.310 ;iou: 0.385 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 2.493 ;acc: 0.370 ;iou: 0.455 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 3.289 ;acc: 0.280 ;iou: 0.370 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 2.413 ;acc: 0.330 ;iou: 0.440 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 1.956 ;acc: 0.440 ;iou: 0.535 ;time: 0:00:21\n",
      "\n",
      "*Training B: True ;B Train loss: 2.274 ;Train accuracy: 0.398 ;IOU accuracy: 0.486 ;Time: 0:00:24 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.486 ;acc: 0.495 ;iou_acc: 0.660 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.841 ;acc: 0.385 ;iou_acc: 0.520 ;time: 0:00:27\n",
      "batch: 100 ;B loss: 2.094 ;acc: 0.295 ;iou_acc: 0.415 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.297 ;acc: 0.265 ;iou_acc: 0.375 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.690 ;acc: 0.180 ;iou_acc: 0.265 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.076 ;acc: 0.175 ;iou_acc: 0.295 ;time: 0:00:40\n",
      "\n",
      "*BTrain: True ;Test loss: 2.422 ;Test accuracy 0.251 ;IOU accuracy: 0.359 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 2.046 ;acc: 0.490 ;iou: 0.550 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 2.829 ;acc: 0.335 ;iou: 0.390 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 1.782 ;acc: 0.475 ;iou: 0.575 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 2.617 ;acc: 0.335 ;iou: 0.425 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 3.124 ;acc: 0.295 ;iou: 0.380 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 3.223 ;acc: 0.265 ;iou: 0.345 ;time: 0:00:20\n",
      "\n",
      "*Training B: False ;B Train loss: 2.263 ;Train accuracy: 0.407 ;IOU accuracy: 0.496 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.482 ;acc: 0.510 ;iou_acc: 0.665 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.792 ;acc: 0.385 ;iou_acc: 0.540 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.063 ;acc: 0.325 ;iou_acc: 0.425 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.322 ;acc: 0.245 ;iou_acc: 0.340 ;time: 0:00:34\n",
      "batch: 200 ;B loss: 2.672 ;acc: 0.250 ;iou_acc: 0.310 ;time: 0:00:37\n",
      "batch: 250 ;B loss: 3.058 ;acc: 0.210 ;iou_acc: 0.295 ;time: 0:00:41\n",
      "\n",
      "*BTrain: False ;Test loss: 2.412 ;Test accuracy 0.257 ;IOU accuracy: 0.368 ;Time: 0:00:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 2.654 ;acc: 0.335 ;iou: 0.410 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 1.997 ;acc: 0.490 ;iou: 0.575 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 2.652 ;acc: 0.420 ;iou: 0.455 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 1.971 ;acc: 0.480 ;iou: 0.575 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 1.755 ;acc: 0.460 ;iou: 0.590 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 1.983 ;acc: 0.520 ;iou: 0.585 ;time: 0:00:21\n",
      "\n",
      "*Training B: False ;B Train loss: 2.250 ;Train accuracy: 0.414 ;IOU accuracy: 0.500 ;Time: 0:00:25 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.498 ;acc: 0.555 ;iou_acc: 0.700 ;time: 0:00:25\n",
      "batch: 50 ;B loss: 1.809 ;acc: 0.355 ;iou_acc: 0.485 ;time: 0:00:28\n",
      "batch: 100 ;B loss: 2.066 ;acc: 0.295 ;iou_acc: 0.385 ;time: 0:00:30\n",
      "batch: 150 ;B loss: 2.271 ;acc: 0.280 ;iou_acc: 0.365 ;time: 0:00:33\n",
      "batch: 200 ;B loss: 2.656 ;acc: 0.240 ;iou_acc: 0.310 ;time: 0:00:36\n",
      "batch: 250 ;B loss: 3.051 ;acc: 0.175 ;iou_acc: 0.260 ;time: 0:00:40\n",
      "\n",
      "*BTrain: False ;Test loss: 2.402 ;Test accuracy 0.263 ;IOU accuracy: 0.371 ;Time: 0:00:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 2.669 ;acc: 0.310 ;iou: 0.380 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 2.484 ;acc: 0.420 ;iou: 0.530 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 1.860 ;acc: 0.495 ;iou: 0.565 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 1.861 ;acc: 0.465 ;iou: 0.550 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 2.824 ;acc: 0.270 ;iou: 0.375 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 1.653 ;acc: 0.530 ;iou: 0.585 ;time: 0:00:21\n",
      "\n",
      "*Training B: True ;B Train loss: 2.234 ;Train accuracy: 0.425 ;IOU accuracy: 0.509 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.545 ;acc: 0.580 ;iou_acc: 0.715 ;time: 0:00:26\n",
      "batch: 50 ;B loss: 1.822 ;acc: 0.380 ;iou_acc: 0.500 ;time: 0:00:29\n",
      "batch: 100 ;B loss: 2.020 ;acc: 0.350 ;iou_acc: 0.470 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.256 ;acc: 0.255 ;iou_acc: 0.330 ;time: 0:00:36\n",
      "batch: 200 ;B loss: 2.653 ;acc: 0.250 ;iou_acc: 0.330 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 3.066 ;acc: 0.220 ;iou_acc: 0.295 ;time: 0:00:44\n",
      "\n",
      "*BTrain: True ;Test loss: 2.399 ;Test accuracy 0.271 ;IOU accuracy: 0.379 ;Time: 0:00:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 1.484 ;acc: 0.610 ;iou: 0.720 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 3.407 ;acc: 0.285 ;iou: 0.370 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 3.111 ;acc: 0.285 ;iou: 0.370 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 1.642 ;acc: 0.535 ;iou: 0.620 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 1.955 ;acc: 0.525 ;iou: 0.615 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 1.420 ;acc: 0.615 ;iou: 0.670 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.220 ;Train accuracy: 0.433 ;IOU accuracy: 0.519 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.544 ;acc: 0.560 ;iou_acc: 0.705 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.801 ;acc: 0.420 ;iou_acc: 0.550 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.051 ;acc: 0.290 ;iou_acc: 0.410 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.274 ;acc: 0.270 ;iou_acc: 0.370 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.667 ;acc: 0.240 ;iou_acc: 0.325 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.051 ;acc: 0.205 ;iou_acc: 0.300 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.396 ;Test accuracy 0.277 ;IOU accuracy: 0.383 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 2.467 ;acc: 0.440 ;iou: 0.530 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 3.187 ;acc: 0.280 ;iou: 0.350 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 2.634 ;acc: 0.420 ;iou: 0.495 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 1.434 ;acc: 0.615 ;iou: 0.670 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 2.723 ;acc: 0.410 ;iou: 0.480 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 1.641 ;acc: 0.535 ;iou: 0.640 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.201 ;Train accuracy: 0.444 ;IOU accuracy: 0.526 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.642 ;acc: 0.600 ;iou_acc: 0.740 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.812 ;acc: 0.430 ;iou_acc: 0.550 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.986 ;acc: 0.335 ;iou_acc: 0.470 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.206 ;acc: 0.295 ;iou_acc: 0.375 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.680 ;acc: 0.205 ;iou_acc: 0.295 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.015 ;acc: 0.235 ;iou_acc: 0.330 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.392 ;Test accuracy 0.287 ;IOU accuracy: 0.393 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 2.076 ;acc: 0.465 ;iou: 0.595 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 2.619 ;acc: 0.340 ;iou: 0.455 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 1.380 ;acc: 0.585 ;iou: 0.655 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 1.901 ;acc: 0.530 ;iou: 0.605 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 2.079 ;acc: 0.420 ;iou: 0.470 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 1.666 ;acc: 0.530 ;iou: 0.615 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.183 ;Train accuracy: 0.451 ;IOU accuracy: 0.533 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.586 ;acc: 0.625 ;iou_acc: 0.755 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.767 ;acc: 0.450 ;iou_acc: 0.595 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.989 ;acc: 0.350 ;iou_acc: 0.475 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.216 ;acc: 0.300 ;iou_acc: 0.395 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.634 ;acc: 0.235 ;iou_acc: 0.310 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.999 ;acc: 0.240 ;iou_acc: 0.340 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.364 ;Test accuracy 0.299 ;IOU accuracy: 0.405 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 1.554 ;acc: 0.540 ;iou: 0.610 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 2.181 ;acc: 0.480 ;iou: 0.540 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 2.895 ;acc: 0.345 ;iou: 0.420 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 2.688 ;acc: 0.325 ;iou: 0.420 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 3.031 ;acc: 0.305 ;iou: 0.420 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 1.625 ;acc: 0.540 ;iou: 0.640 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.167 ;Train accuracy: 0.461 ;IOU accuracy: 0.544 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.680 ;acc: 0.610 ;iou_acc: 0.760 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.767 ;acc: 0.485 ;iou_acc: 0.595 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.971 ;acc: 0.335 ;iou_acc: 0.475 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.159 ;acc: 0.350 ;iou_acc: 0.430 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.644 ;acc: 0.260 ;iou_acc: 0.350 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.970 ;acc: 0.265 ;iou_acc: 0.330 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.373 ;Test accuracy 0.302 ;IOU accuracy: 0.408 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 2.772 ;acc: 0.365 ;iou: 0.465 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 2.298 ;acc: 0.415 ;iou: 0.490 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 2.689 ;acc: 0.345 ;iou: 0.450 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 2.029 ;acc: 0.465 ;iou: 0.530 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 1.565 ;acc: 0.600 ;iou: 0.690 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 3.061 ;acc: 0.345 ;iou: 0.450 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.152 ;Train accuracy: 0.467 ;IOU accuracy: 0.550 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.678 ;acc: 0.605 ;iou_acc: 0.725 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.769 ;acc: 0.435 ;iou_acc: 0.570 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.965 ;acc: 0.345 ;iou_acc: 0.475 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.155 ;acc: 0.325 ;iou_acc: 0.425 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.636 ;acc: 0.230 ;iou_acc: 0.330 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.008 ;acc: 0.235 ;iou_acc: 0.350 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.359 ;Test accuracy 0.309 ;IOU accuracy: 0.411 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 1.316 ;acc: 0.680 ;iou: 0.740 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 2.108 ;acc: 0.480 ;iou: 0.550 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 1.591 ;acc: 0.635 ;iou: 0.725 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 2.320 ;acc: 0.505 ;iou: 0.560 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0450 ;B loss: 2.088 ;acc: 0.485 ;iou: 0.560 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0450 ;B loss: 3.318 ;acc: 0.275 ;iou: 0.405 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.136 ;Train accuracy: 0.475 ;IOU accuracy: 0.557 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.679 ;acc: 0.615 ;iou_acc: 0.750 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.771 ;acc: 0.485 ;iou_acc: 0.605 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.955 ;acc: 0.355 ;iou_acc: 0.480 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.150 ;acc: 0.305 ;iou_acc: 0.420 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.634 ;acc: 0.225 ;iou_acc: 0.330 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.016 ;acc: 0.235 ;iou_acc: 0.345 ;time: 0:00:47\n",
      "\n",
      "*BTrain: True ;Test loss: 2.348 ;Test accuracy 0.311 ;IOU accuracy: 0.414 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0450 ;B loss: 2.224 ;acc: 0.490 ;iou: 0.540 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0450 ;B loss: 2.904 ;acc: 0.295 ;iou: 0.400 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0450 ;B loss: 1.762 ;acc: 0.600 ;iou: 0.640 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0450 ;B loss: 1.314 ;acc: 0.590 ;iou: 0.655 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0450 ;B loss: 2.571 ;acc: 0.370 ;iou: 0.455 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0450 ;B loss: 2.178 ;acc: 0.505 ;iou: 0.575 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.116 ;Train accuracy: 0.479 ;IOU accuracy: 0.561 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.708 ;acc: 0.605 ;iou_acc: 0.735 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.768 ;acc: 0.450 ;iou_acc: 0.570 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 1.982 ;acc: 0.345 ;iou_acc: 0.510 ;time: 0:00:36\n",
      "batch: 150 ;B loss: 2.139 ;acc: 0.300 ;iou_acc: 0.395 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.636 ;acc: 0.255 ;iou_acc: 0.330 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 3.022 ;acc: 0.225 ;iou_acc: 0.320 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.361 ;Test accuracy 0.314 ;IOU accuracy: 0.422 ;Time: 0:00:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0450 ;B loss: 1.314 ;acc: 0.610 ;iou: 0.665 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0450 ;B loss: 1.375 ;acc: 0.635 ;iou: 0.690 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0450 ;B loss: 1.587 ;acc: 0.600 ;iou: 0.760 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0450 ;B loss: 2.120 ;acc: 0.515 ;iou: 0.570 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0450 ;B loss: 2.410 ;acc: 0.430 ;iou: 0.495 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0450 ;B loss: 2.096 ;acc: 0.460 ;iou: 0.535 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.105 ;Train accuracy: 0.486 ;IOU accuracy: 0.567 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.733 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.745 ;acc: 0.475 ;iou_acc: 0.590 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 1.971 ;acc: 0.330 ;iou_acc: 0.480 ;time: 0:00:36\n",
      "batch: 150 ;B loss: 2.128 ;acc: 0.365 ;iou_acc: 0.455 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.600 ;acc: 0.280 ;iou_acc: 0.360 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 2.970 ;acc: 0.260 ;iou_acc: 0.380 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.345 ;Test accuracy 0.316 ;IOU accuracy: 0.422 ;Time: 0:00:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0450 ;B loss: 1.839 ;acc: 0.505 ;iou: 0.595 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0450 ;B loss: 2.539 ;acc: 0.445 ;iou: 0.520 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0450 ;B loss: 2.349 ;acc: 0.400 ;iou: 0.505 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0450 ;B loss: 3.498 ;acc: 0.195 ;iou: 0.310 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0450 ;B loss: 1.396 ;acc: 0.610 ;iou: 0.700 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0450 ;B loss: 2.435 ;acc: 0.410 ;iou: 0.470 ;time: 0:00:25\n",
      "\n",
      "*Training B: True ;B Train loss: 2.096 ;Train accuracy: 0.491 ;IOU accuracy: 0.572 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.804 ;acc: 0.630 ;iou_acc: 0.770 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.796 ;acc: 0.485 ;iou_acc: 0.590 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 1.960 ;acc: 0.355 ;iou_acc: 0.495 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.100 ;acc: 0.355 ;iou_acc: 0.455 ;time: 0:00:40\n",
      "batch: 200 ;B loss: 2.601 ;acc: 0.300 ;iou_acc: 0.370 ;time: 0:00:44\n",
      "batch: 250 ;B loss: 2.993 ;acc: 0.225 ;iou_acc: 0.320 ;time: 0:00:48\n",
      "\n",
      "*BTrain: True ;Test loss: 2.359 ;Test accuracy 0.318 ;IOU accuracy: 0.423 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0450 ;B loss: 3.102 ;acc: 0.345 ;iou: 0.490 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0450 ;B loss: 1.841 ;acc: 0.520 ;iou: 0.615 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0450 ;B loss: 2.073 ;acc: 0.445 ;iou: 0.555 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0450 ;B loss: 1.963 ;acc: 0.535 ;iou: 0.615 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0450 ;B loss: 1.349 ;acc: 0.635 ;iou: 0.705 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0450 ;B loss: 1.829 ;acc: 0.525 ;iou: 0.585 ;time: 0:00:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.086 ;Train accuracy: 0.497 ;IOU accuracy: 0.577 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.742 ;acc: 0.605 ;iou_acc: 0.740 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.785 ;acc: 0.460 ;iou_acc: 0.565 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 1.947 ;acc: 0.375 ;iou_acc: 0.490 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.105 ;acc: 0.340 ;iou_acc: 0.420 ;time: 0:00:40\n",
      "batch: 200 ;B loss: 2.577 ;acc: 0.280 ;iou_acc: 0.360 ;time: 0:00:44\n",
      "batch: 250 ;B loss: 2.994 ;acc: 0.220 ;iou_acc: 0.360 ;time: 0:00:48\n",
      "\n",
      "*BTrain: False ;Test loss: 2.346 ;Test accuracy 0.324 ;IOU accuracy: 0.428 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0450 ;B loss: 1.157 ;acc: 0.730 ;iou: 0.765 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0450 ;B loss: 1.810 ;acc: 0.560 ;iou: 0.645 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0450 ;B loss: 2.464 ;acc: 0.365 ;iou: 0.480 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0450 ;B loss: 1.347 ;acc: 0.580 ;iou: 0.670 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0450 ;B loss: 1.942 ;acc: 0.540 ;iou: 0.600 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0450 ;B loss: 1.260 ;acc: 0.680 ;iou: 0.765 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 2.075 ;Train accuracy: 0.503 ;IOU accuracy: 0.582 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.709 ;acc: 0.640 ;iou_acc: 0.775 ;time: 0:00:30\n",
      "batch: 50 ;B loss: 1.772 ;acc: 0.470 ;iou_acc: 0.580 ;time: 0:00:33\n",
      "batch: 100 ;B loss: 1.959 ;acc: 0.380 ;iou_acc: 0.505 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.113 ;acc: 0.340 ;iou_acc: 0.435 ;time: 0:00:40\n",
      "batch: 200 ;B loss: 2.600 ;acc: 0.285 ;iou_acc: 0.360 ;time: 0:00:44\n",
      "batch: 250 ;B loss: 2.989 ;acc: 0.250 ;iou_acc: 0.355 ;time: 0:00:49\n",
      "\n",
      "*BTrain: False ;Test loss: 2.355 ;Test accuracy 0.322 ;IOU accuracy: 0.426 ;Time: 0:00:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0450 ;B loss: 2.008 ;acc: 0.520 ;iou: 0.585 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0450 ;B loss: 1.575 ;acc: 0.620 ;iou: 0.740 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0450 ;B loss: 2.314 ;acc: 0.430 ;iou: 0.540 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0450 ;B loss: 1.329 ;acc: 0.620 ;iou: 0.695 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0450 ;B loss: 1.473 ;acc: 0.620 ;iou: 0.685 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0450 ;B loss: 1.584 ;acc: 0.595 ;iou: 0.730 ;time: 0:00:26\n",
      "\n",
      "*Training B: True ;B Train loss: 2.065 ;Train accuracy: 0.507 ;IOU accuracy: 0.587 ;Time: 0:00:30 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.873 ;acc: 0.650 ;iou_acc: 0.790 ;time: 0:00:31\n",
      "batch: 50 ;B loss: 1.817 ;acc: 0.475 ;iou_acc: 0.590 ;time: 0:00:34\n",
      "batch: 100 ;B loss: 1.924 ;acc: 0.405 ;iou_acc: 0.535 ;time: 0:00:37\n",
      "batch: 150 ;B loss: 2.126 ;acc: 0.385 ;iou_acc: 0.450 ;time: 0:00:40\n",
      "batch: 200 ;B loss: 2.590 ;acc: 0.305 ;iou_acc: 0.400 ;time: 0:00:44\n",
      "batch: 250 ;B loss: 3.008 ;acc: 0.215 ;iou_acc: 0.300 ;time: 0:00:49\n",
      "\n",
      "*BTrain: True ;Test loss: 2.366 ;Test accuracy 0.325 ;IOU accuracy: 0.428 ;Time: 0:00:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0450 ;B loss: 1.548 ;acc: 0.590 ;iou: 0.660 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0450 ;B loss: 1.522 ;acc: 0.595 ;iou: 0.735 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0450 ;B loss: 1.693 ;acc: 0.555 ;iou: 0.630 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0450 ;B loss: 1.687 ;acc: 0.620 ;iou: 0.670 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0450 ;B loss: 1.415 ;acc: 0.615 ;iou: 0.680 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0450 ;B loss: 2.409 ;acc: 0.435 ;iou: 0.510 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.053 ;Train accuracy: 0.512 ;IOU accuracy: 0.591 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.685 ;acc: 0.635 ;iou_acc: 0.775 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.749 ;acc: 0.455 ;iou_acc: 0.575 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.934 ;acc: 0.420 ;iou_acc: 0.545 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.145 ;acc: 0.325 ;iou_acc: 0.405 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.620 ;acc: 0.285 ;iou_acc: 0.400 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.985 ;acc: 0.255 ;iou_acc: 0.335 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.346 ;Test accuracy 0.319 ;IOU accuracy: 0.424 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0450 ;B loss: 2.151 ;acc: 0.500 ;iou: 0.560 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0450 ;B loss: 1.270 ;acc: 0.625 ;iou: 0.710 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0450 ;B loss: 2.428 ;acc: 0.480 ;iou: 0.565 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0450 ;B loss: 2.408 ;acc: 0.495 ;iou: 0.575 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0450 ;B loss: 1.674 ;acc: 0.605 ;iou: 0.665 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0450 ;B loss: 2.142 ;acc: 0.465 ;iou: 0.550 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.045 ;Train accuracy: 0.518 ;IOU accuracy: 0.596 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.784 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.768 ;acc: 0.470 ;iou_acc: 0.575 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.974 ;acc: 0.405 ;iou_acc: 0.515 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.082 ;acc: 0.360 ;iou_acc: 0.455 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.594 ;acc: 0.295 ;iou_acc: 0.380 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.983 ;acc: 0.200 ;iou_acc: 0.310 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.355 ;Test accuracy 0.328 ;IOU accuracy: 0.435 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0450 ;B loss: 2.329 ;acc: 0.465 ;iou: 0.570 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0450 ;B loss: 1.503 ;acc: 0.590 ;iou: 0.705 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0450 ;B loss: 1.186 ;acc: 0.730 ;iou: 0.800 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0450 ;B loss: 2.100 ;acc: 0.505 ;iou: 0.580 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0450 ;B loss: 1.616 ;acc: 0.635 ;iou: 0.685 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0450 ;B loss: 1.302 ;acc: 0.630 ;iou: 0.710 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.033 ;Train accuracy: 0.522 ;IOU accuracy: 0.599 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.874 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.813 ;acc: 0.480 ;iou_acc: 0.595 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.962 ;acc: 0.390 ;iou_acc: 0.515 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.090 ;acc: 0.360 ;iou_acc: 0.460 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.575 ;acc: 0.285 ;iou_acc: 0.400 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 2.986 ;acc: 0.245 ;iou_acc: 0.370 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.369 ;Test accuracy 0.332 ;IOU accuracy: 0.438 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0450 ;B loss: 2.322 ;acc: 0.500 ;iou: 0.560 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0450 ;B loss: 2.659 ;acc: 0.435 ;iou: 0.500 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0450 ;B loss: 1.471 ;acc: 0.630 ;iou: 0.695 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0450 ;B loss: 1.839 ;acc: 0.565 ;iou: 0.665 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0450 ;B loss: 2.264 ;acc: 0.475 ;iou: 0.570 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0450 ;B loss: 1.731 ;acc: 0.610 ;iou: 0.665 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.025 ;Train accuracy: 0.529 ;IOU accuracy: 0.606 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.864 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.772 ;acc: 0.460 ;iou_acc: 0.555 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.966 ;acc: 0.395 ;iou_acc: 0.535 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.105 ;acc: 0.350 ;iou_acc: 0.440 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.579 ;acc: 0.315 ;iou_acc: 0.385 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.992 ;acc: 0.280 ;iou_acc: 0.395 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.353 ;Test accuracy 0.334 ;IOU accuracy: 0.440 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0450 ;B loss: 1.761 ;acc: 0.585 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0450 ;B loss: 1.465 ;acc: 0.640 ;iou: 0.720 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0450 ;B loss: 2.979 ;acc: 0.320 ;iou: 0.385 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0450 ;B loss: 2.841 ;acc: 0.395 ;iou: 0.490 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0450 ;B loss: 2.284 ;acc: 0.500 ;iou: 0.585 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0450 ;B loss: 1.601 ;acc: 0.645 ;iou: 0.770 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.015 ;Train accuracy: 0.533 ;IOU accuracy: 0.609 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.835 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.789 ;acc: 0.455 ;iou_acc: 0.585 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.935 ;acc: 0.445 ;iou_acc: 0.570 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.109 ;acc: 0.365 ;iou_acc: 0.460 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.569 ;acc: 0.265 ;iou_acc: 0.380 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.990 ;acc: 0.240 ;iou_acc: 0.340 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.349 ;Test accuracy 0.333 ;IOU accuracy: 0.439 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0450 ;B loss: 2.183 ;acc: 0.515 ;iou: 0.580 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0450 ;B loss: 1.749 ;acc: 0.595 ;iou: 0.685 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0450 ;B loss: 1.860 ;acc: 0.570 ;iou: 0.635 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0450 ;B loss: 1.199 ;acc: 0.695 ;iou: 0.765 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0450 ;B loss: 2.851 ;acc: 0.395 ;iou: 0.450 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0450 ;B loss: 1.605 ;acc: 0.600 ;iou: 0.695 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.005 ;Train accuracy: 0.536 ;IOU accuracy: 0.614 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.704 ;acc: 0.605 ;iou_acc: 0.765 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.781 ;acc: 0.430 ;iou_acc: 0.545 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.983 ;acc: 0.405 ;iou_acc: 0.545 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.142 ;acc: 0.300 ;iou_acc: 0.400 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.589 ;acc: 0.250 ;iou_acc: 0.375 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.999 ;acc: 0.220 ;iou_acc: 0.310 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.358 ;Test accuracy 0.319 ;IOU accuracy: 0.427 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0450 ;B loss: 1.846 ;acc: 0.550 ;iou: 0.635 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0450 ;B loss: 1.846 ;acc: 0.605 ;iou: 0.670 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0450 ;B loss: 3.017 ;acc: 0.330 ;iou: 0.425 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0450 ;B loss: 2.599 ;acc: 0.350 ;iou: 0.465 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0450 ;B loss: 2.295 ;acc: 0.465 ;iou: 0.530 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0450 ;B loss: 1.702 ;acc: 0.595 ;iou: 0.655 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.995 ;Train accuracy: 0.543 ;IOU accuracy: 0.618 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.890 ;acc: 0.640 ;iou_acc: 0.790 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.829 ;acc: 0.475 ;iou_acc: 0.575 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.943 ;acc: 0.420 ;iou_acc: 0.540 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.105 ;acc: 0.400 ;iou_acc: 0.505 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.564 ;acc: 0.305 ;iou_acc: 0.410 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.018 ;acc: 0.245 ;iou_acc: 0.365 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.377 ;Test accuracy 0.333 ;IOU accuracy: 0.440 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0450 ;B loss: 2.229 ;acc: 0.490 ;iou: 0.560 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0450 ;B loss: 1.567 ;acc: 0.620 ;iou: 0.685 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0450 ;B loss: 1.818 ;acc: 0.600 ;iou: 0.665 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0450 ;B loss: 1.986 ;acc: 0.490 ;iou: 0.580 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0450 ;B loss: 2.784 ;acc: 0.375 ;iou: 0.490 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0450 ;B loss: 2.121 ;acc: 0.560 ;iou: 0.630 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.984 ;Train accuracy: 0.547 ;IOU accuracy: 0.622 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.857 ;acc: 0.690 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.804 ;acc: 0.485 ;iou_acc: 0.605 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.911 ;acc: 0.370 ;iou_acc: 0.505 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.106 ;acc: 0.350 ;iou_acc: 0.465 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.581 ;acc: 0.295 ;iou_acc: 0.390 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.960 ;acc: 0.260 ;iou_acc: 0.395 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.355 ;Test accuracy 0.339 ;IOU accuracy: 0.447 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0450 ;B loss: 1.907 ;acc: 0.620 ;iou: 0.670 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0450 ;B loss: 2.740 ;acc: 0.455 ;iou: 0.520 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0450 ;B loss: 2.113 ;acc: 0.550 ;iou: 0.595 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0450 ;B loss: 2.003 ;acc: 0.545 ;iou: 0.595 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0450 ;B loss: 1.647 ;acc: 0.630 ;iou: 0.745 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0450 ;B loss: 1.222 ;acc: 0.685 ;iou: 0.715 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.974 ;Train accuracy: 0.552 ;IOU accuracy: 0.626 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.932 ;acc: 0.695 ;iou_acc: 0.825 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.789 ;acc: 0.440 ;iou_acc: 0.570 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.936 ;acc: 0.440 ;iou_acc: 0.565 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.077 ;acc: 0.370 ;iou_acc: 0.470 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.593 ;acc: 0.320 ;iou_acc: 0.415 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.999 ;acc: 0.220 ;iou_acc: 0.340 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.362 ;Test accuracy 0.342 ;IOU accuracy: 0.451 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0450 ;B loss: 1.931 ;acc: 0.630 ;iou: 0.695 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0450 ;B loss: 3.427 ;acc: 0.270 ;iou: 0.360 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0450 ;B loss: 1.424 ;acc: 0.685 ;iou: 0.770 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0450 ;B loss: 2.393 ;acc: 0.520 ;iou: 0.595 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0450 ;B loss: 2.958 ;acc: 0.310 ;iou: 0.385 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0450 ;B loss: 2.690 ;acc: 0.400 ;iou: 0.500 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.965 ;Train accuracy: 0.558 ;IOU accuracy: 0.632 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.937 ;acc: 0.685 ;iou_acc: 0.820 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.828 ;acc: 0.445 ;iou_acc: 0.550 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.987 ;acc: 0.395 ;iou_acc: 0.540 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.086 ;acc: 0.380 ;iou_acc: 0.490 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.559 ;acc: 0.295 ;iou_acc: 0.405 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.966 ;acc: 0.260 ;iou_acc: 0.375 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.361 ;Test accuracy 0.344 ;IOU accuracy: 0.454 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 50 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14851 ;lr: 0.0450 ;B loss: 1.900 ;acc: 0.555 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14901 ;lr: 0.0450 ;B loss: 2.204 ;acc: 0.550 ;iou: 0.610 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14951 ;lr: 0.0450 ;B loss: 1.363 ;acc: 0.615 ;iou: 0.680 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15001 ;lr: 0.0450 ;B loss: 2.652 ;acc: 0.425 ;iou: 0.515 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15051 ;lr: 0.0450 ;B loss: 1.480 ;acc: 0.660 ;iou: 0.745 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15101 ;lr: 0.0450 ;B loss: 1.245 ;acc: 0.620 ;iou: 0.715 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.953 ;Train accuracy: 0.562 ;IOU accuracy: 0.636 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 50\n",
      "batch: 0 ;B loss: 1.955 ;acc: 0.695 ;iou_acc: 0.840 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.826 ;acc: 0.445 ;iou_acc: 0.565 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.002 ;acc: 0.375 ;iou_acc: 0.530 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.151 ;acc: 0.355 ;iou_acc: 0.460 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.640 ;acc: 0.270 ;iou_acc: 0.375 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.061 ;acc: 0.215 ;iou_acc: 0.350 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.410 ;Test accuracy 0.330 ;IOU accuracy: 0.439 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 51 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15148 ;lr: 0.0450 ;B loss: 1.408 ;acc: 0.740 ;iou: 0.780 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15198 ;lr: 0.0450 ;B loss: 1.997 ;acc: 0.615 ;iou: 0.655 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15248 ;lr: 0.0450 ;B loss: 1.276 ;acc: 0.605 ;iou: 0.660 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15298 ;lr: 0.0450 ;B loss: 1.501 ;acc: 0.695 ;iou: 0.770 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15348 ;lr: 0.0450 ;B loss: 2.354 ;acc: 0.540 ;iou: 0.595 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15398 ;lr: 0.0450 ;B loss: 2.008 ;acc: 0.505 ;iou: 0.580 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.939 ;Train accuracy: 0.571 ;IOU accuracy: 0.643 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 51\n",
      "batch: 0 ;B loss: 1.872 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.789 ;acc: 0.480 ;iou_acc: 0.590 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.911 ;acc: 0.425 ;iou_acc: 0.530 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.128 ;acc: 0.345 ;iou_acc: 0.440 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.555 ;acc: 0.325 ;iou_acc: 0.435 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.980 ;acc: 0.260 ;iou_acc: 0.375 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.348 ;Test accuracy 0.343 ;IOU accuracy: 0.452 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 52 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15445 ;lr: 0.0450 ;B loss: 1.478 ;acc: 0.670 ;iou: 0.720 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15495 ;lr: 0.0450 ;B loss: 2.239 ;acc: 0.565 ;iou: 0.625 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15545 ;lr: 0.0450 ;B loss: 2.015 ;acc: 0.595 ;iou: 0.640 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15595 ;lr: 0.0450 ;B loss: 1.960 ;acc: 0.570 ;iou: 0.655 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15645 ;lr: 0.0450 ;B loss: 1.669 ;acc: 0.660 ;iou: 0.720 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15695 ;lr: 0.0450 ;B loss: 1.602 ;acc: 0.630 ;iou: 0.745 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.930 ;Train accuracy: 0.574 ;IOU accuracy: 0.648 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 52\n",
      "batch: 0 ;B loss: 1.947 ;acc: 0.620 ;iou_acc: 0.775 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.799 ;acc: 0.450 ;iou_acc: 0.555 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.933 ;acc: 0.420 ;iou_acc: 0.530 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.103 ;acc: 0.360 ;iou_acc: 0.460 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.581 ;acc: 0.280 ;iou_acc: 0.370 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.986 ;acc: 0.240 ;iou_acc: 0.370 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.361 ;Test accuracy 0.347 ;IOU accuracy: 0.460 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 53 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15742 ;lr: 0.0450 ;B loss: 1.574 ;acc: 0.645 ;iou: 0.710 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15792 ;lr: 0.0450 ;B loss: 1.960 ;acc: 0.640 ;iou: 0.685 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15842 ;lr: 0.0450 ;B loss: 2.291 ;acc: 0.495 ;iou: 0.555 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15892 ;lr: 0.0450 ;B loss: 1.378 ;acc: 0.705 ;iou: 0.790 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15942 ;lr: 0.0450 ;B loss: 1.753 ;acc: 0.640 ;iou: 0.710 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15992 ;lr: 0.0450 ;B loss: 2.269 ;acc: 0.525 ;iou: 0.595 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.917 ;Train accuracy: 0.579 ;IOU accuracy: 0.652 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 53\n",
      "batch: 0 ;B loss: 2.022 ;acc: 0.675 ;iou_acc: 0.825 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.783 ;acc: 0.510 ;iou_acc: 0.615 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.918 ;acc: 0.450 ;iou_acc: 0.580 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.084 ;acc: 0.355 ;iou_acc: 0.465 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.565 ;acc: 0.315 ;iou_acc: 0.410 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.996 ;acc: 0.225 ;iou_acc: 0.350 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.388 ;Test accuracy 0.350 ;IOU accuracy: 0.460 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 54 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16039 ;lr: 0.0450 ;B loss: 1.284 ;acc: 0.750 ;iou: 0.825 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16089 ;lr: 0.0450 ;B loss: 1.486 ;acc: 0.715 ;iou: 0.750 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16139 ;lr: 0.0450 ;B loss: 2.088 ;acc: 0.555 ;iou: 0.630 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16189 ;lr: 0.0450 ;B loss: 2.490 ;acc: 0.495 ;iou: 0.550 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16239 ;lr: 0.0450 ;B loss: 1.636 ;acc: 0.570 ;iou: 0.680 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16289 ;lr: 0.0450 ;B loss: 2.689 ;acc: 0.445 ;iou: 0.530 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.904 ;Train accuracy: 0.588 ;IOU accuracy: 0.660 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 54\n",
      "batch: 0 ;B loss: 2.135 ;acc: 0.695 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.853 ;acc: 0.475 ;iou_acc: 0.610 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.942 ;acc: 0.420 ;iou_acc: 0.525 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.147 ;acc: 0.370 ;iou_acc: 0.500 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.568 ;acc: 0.355 ;iou_acc: 0.445 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.050 ;acc: 0.255 ;iou_acc: 0.355 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.408 ;Test accuracy 0.358 ;IOU accuracy: 0.469 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 55 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16336 ;lr: 0.0450 ;B loss: 2.077 ;acc: 0.585 ;iou: 0.680 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16386 ;lr: 0.0450 ;B loss: 2.595 ;acc: 0.495 ;iou: 0.560 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16436 ;lr: 0.0450 ;B loss: 1.307 ;acc: 0.730 ;iou: 0.805 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16486 ;lr: 0.0450 ;B loss: 1.574 ;acc: 0.665 ;iou: 0.715 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16536 ;lr: 0.0450 ;B loss: 1.324 ;acc: 0.730 ;iou: 0.775 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16586 ;lr: 0.0450 ;B loss: 2.450 ;acc: 0.505 ;iou: 0.585 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.892 ;Train accuracy: 0.593 ;IOU accuracy: 0.666 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 55\n",
      "batch: 0 ;B loss: 1.999 ;acc: 0.670 ;iou_acc: 0.815 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.812 ;acc: 0.440 ;iou_acc: 0.590 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.926 ;acc: 0.415 ;iou_acc: 0.560 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.085 ;acc: 0.395 ;iou_acc: 0.500 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.627 ;acc: 0.265 ;iou_acc: 0.410 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.963 ;acc: 0.210 ;iou_acc: 0.365 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.386 ;Test accuracy 0.351 ;IOU accuracy: 0.463 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 56 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16633 ;lr: 0.0450 ;B loss: 2.101 ;acc: 0.615 ;iou: 0.670 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16683 ;lr: 0.0450 ;B loss: 1.160 ;acc: 0.660 ;iou: 0.745 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16733 ;lr: 0.0450 ;B loss: 2.263 ;acc: 0.570 ;iou: 0.645 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16783 ;lr: 0.0450 ;B loss: 1.599 ;acc: 0.700 ;iou: 0.740 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16833 ;lr: 0.0450 ;B loss: 2.764 ;acc: 0.415 ;iou: 0.505 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16883 ;lr: 0.0450 ;B loss: 2.907 ;acc: 0.400 ;iou: 0.485 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.880 ;Train accuracy: 0.597 ;IOU accuracy: 0.669 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 56\n",
      "batch: 0 ;B loss: 2.097 ;acc: 0.705 ;iou_acc: 0.845 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.770 ;acc: 0.490 ;iou_acc: 0.605 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.921 ;acc: 0.440 ;iou_acc: 0.570 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.111 ;acc: 0.440 ;iou_acc: 0.530 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.575 ;acc: 0.285 ;iou_acc: 0.400 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.920 ;acc: 0.255 ;iou_acc: 0.395 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.386 ;Test accuracy 0.363 ;IOU accuracy: 0.472 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 57 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16930 ;lr: 0.0450 ;B loss: 2.023 ;acc: 0.575 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16980 ;lr: 0.0450 ;B loss: 1.468 ;acc: 0.730 ;iou: 0.780 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17030 ;lr: 0.0450 ;B loss: 1.346 ;acc: 0.705 ;iou: 0.760 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17080 ;lr: 0.0450 ;B loss: 1.829 ;acc: 0.690 ;iou: 0.735 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17130 ;lr: 0.0450 ;B loss: 1.269 ;acc: 0.715 ;iou: 0.785 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17180 ;lr: 0.0450 ;B loss: 1.317 ;acc: 0.705 ;iou: 0.800 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.863 ;Train accuracy: 0.604 ;IOU accuracy: 0.675 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 57\n",
      "batch: 0 ;B loss: 1.989 ;acc: 0.720 ;iou_acc: 0.845 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.782 ;acc: 0.485 ;iou_acc: 0.605 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.957 ;acc: 0.440 ;iou_acc: 0.570 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.084 ;acc: 0.390 ;iou_acc: 0.500 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.603 ;acc: 0.290 ;iou_acc: 0.390 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.981 ;acc: 0.230 ;iou_acc: 0.340 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.386 ;Test accuracy 0.357 ;IOU accuracy: 0.470 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 58 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17227 ;lr: 0.0450 ;B loss: 1.121 ;acc: 0.735 ;iou: 0.765 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17277 ;lr: 0.0450 ;B loss: 2.385 ;acc: 0.530 ;iou: 0.595 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17327 ;lr: 0.0450 ;B loss: 2.773 ;acc: 0.440 ;iou: 0.515 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17377 ;lr: 0.0450 ;B loss: 2.157 ;acc: 0.500 ;iou: 0.540 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17427 ;lr: 0.0450 ;B loss: 1.531 ;acc: 0.745 ;iou: 0.780 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17477 ;lr: 0.0450 ;B loss: 1.766 ;acc: 0.600 ;iou: 0.670 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.848 ;Train accuracy: 0.611 ;IOU accuracy: 0.681 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 58\n",
      "batch: 0 ;B loss: 2.067 ;acc: 0.660 ;iou_acc: 0.800 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.781 ;acc: 0.510 ;iou_acc: 0.635 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.984 ;acc: 0.415 ;iou_acc: 0.535 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.073 ;acc: 0.400 ;iou_acc: 0.515 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.654 ;acc: 0.295 ;iou_acc: 0.420 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.010 ;acc: 0.215 ;iou_acc: 0.325 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.422 ;Test accuracy 0.361 ;IOU accuracy: 0.475 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 59 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17524 ;lr: 0.0450 ;B loss: 1.222 ;acc: 0.730 ;iou: 0.805 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17574 ;lr: 0.0450 ;B loss: 1.535 ;acc: 0.550 ;iou: 0.660 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17624 ;lr: 0.0450 ;B loss: 1.542 ;acc: 0.715 ;iou: 0.790 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17674 ;lr: 0.0450 ;B loss: 2.642 ;acc: 0.485 ;iou: 0.570 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17724 ;lr: 0.0450 ;B loss: 2.019 ;acc: 0.645 ;iou: 0.695 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17774 ;lr: 0.0450 ;B loss: 1.485 ;acc: 0.715 ;iou: 0.775 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.834 ;Train accuracy: 0.618 ;IOU accuracy: 0.688 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 59\n",
      "batch: 0 ;B loss: 2.062 ;acc: 0.690 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.778 ;acc: 0.495 ;iou_acc: 0.625 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.976 ;acc: 0.460 ;iou_acc: 0.610 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.046 ;acc: 0.375 ;iou_acc: 0.505 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.639 ;acc: 0.290 ;iou_acc: 0.395 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.991 ;acc: 0.250 ;iou_acc: 0.370 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.394 ;Test accuracy 0.363 ;IOU accuracy: 0.478 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 60 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17821 ;lr: 0.0450 ;B loss: 2.522 ;acc: 0.515 ;iou: 0.590 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17871 ;lr: 0.0450 ;B loss: 2.371 ;acc: 0.565 ;iou: 0.665 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17921 ;lr: 0.0450 ;B loss: 1.975 ;acc: 0.645 ;iou: 0.705 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17971 ;lr: 0.0450 ;B loss: 1.150 ;acc: 0.700 ;iou: 0.755 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18021 ;lr: 0.0450 ;B loss: 1.138 ;acc: 0.705 ;iou: 0.765 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18071 ;lr: 0.0450 ;B loss: 1.276 ;acc: 0.695 ;iou: 0.765 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.817 ;Train accuracy: 0.624 ;IOU accuracy: 0.695 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 60\n",
      "batch: 0 ;B loss: 2.213 ;acc: 0.705 ;iou_acc: 0.860 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.821 ;acc: 0.515 ;iou_acc: 0.625 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.952 ;acc: 0.445 ;iou_acc: 0.545 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.112 ;acc: 0.415 ;iou_acc: 0.520 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.675 ;acc: 0.335 ;iou_acc: 0.455 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.958 ;acc: 0.270 ;iou_acc: 0.400 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.418 ;Test accuracy 0.376 ;IOU accuracy: 0.489 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 61 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18118 ;lr: 0.0450 ;B loss: 1.713 ;acc: 0.565 ;iou: 0.705 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18168 ;lr: 0.0450 ;B loss: 2.072 ;acc: 0.645 ;iou: 0.705 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18218 ;lr: 0.0450 ;B loss: 1.727 ;acc: 0.655 ;iou: 0.720 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18268 ;lr: 0.0450 ;B loss: 1.284 ;acc: 0.705 ;iou: 0.750 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18318 ;lr: 0.0450 ;B loss: 2.256 ;acc: 0.575 ;iou: 0.635 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18368 ;lr: 0.0450 ;B loss: 1.499 ;acc: 0.715 ;iou: 0.790 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.802 ;Train accuracy: 0.630 ;IOU accuracy: 0.700 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 61\n",
      "batch: 0 ;B loss: 2.179 ;acc: 0.720 ;iou_acc: 0.870 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.775 ;acc: 0.545 ;iou_acc: 0.665 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.865 ;acc: 0.485 ;iou_acc: 0.605 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.040 ;acc: 0.405 ;iou_acc: 0.495 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.651 ;acc: 0.300 ;iou_acc: 0.405 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.897 ;acc: 0.295 ;iou_acc: 0.425 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.396 ;Test accuracy 0.381 ;IOU accuracy: 0.495 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 62 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18415 ;lr: 0.0450 ;B loss: 1.563 ;acc: 0.695 ;iou: 0.755 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18465 ;lr: 0.0450 ;B loss: 1.225 ;acc: 0.760 ;iou: 0.810 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18515 ;lr: 0.0450 ;B loss: 1.651 ;acc: 0.555 ;iou: 0.710 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18565 ;lr: 0.0450 ;B loss: 1.293 ;acc: 0.735 ;iou: 0.790 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18615 ;lr: 0.0450 ;B loss: 1.328 ;acc: 0.740 ;iou: 0.800 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18665 ;lr: 0.0450 ;B loss: 3.695 ;acc: 0.195 ;iou: 0.275 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.788 ;Train accuracy: 0.636 ;IOU accuracy: 0.706 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 62\n",
      "batch: 0 ;B loss: 2.295 ;acc: 0.715 ;iou_acc: 0.845 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.822 ;acc: 0.560 ;iou_acc: 0.685 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.933 ;acc: 0.460 ;iou_acc: 0.575 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.090 ;acc: 0.405 ;iou_acc: 0.530 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.646 ;acc: 0.350 ;iou_acc: 0.440 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.921 ;acc: 0.260 ;iou_acc: 0.395 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.405 ;Test accuracy 0.385 ;IOU accuracy: 0.499 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 63 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18712 ;lr: 0.0450 ;B loss: 2.068 ;acc: 0.575 ;iou: 0.685 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18762 ;lr: 0.0450 ;B loss: 1.286 ;acc: 0.755 ;iou: 0.835 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18812 ;lr: 0.0450 ;B loss: 2.005 ;acc: 0.610 ;iou: 0.660 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18862 ;lr: 0.0450 ;B loss: 1.208 ;acc: 0.705 ;iou: 0.760 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18912 ;lr: 0.0450 ;B loss: 1.385 ;acc: 0.775 ;iou: 0.835 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18962 ;lr: 0.0450 ;B loss: 2.306 ;acc: 0.545 ;iou: 0.625 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.769 ;Train accuracy: 0.644 ;IOU accuracy: 0.713 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 63\n",
      "batch: 0 ;B loss: 2.353 ;acc: 0.735 ;iou_acc: 0.860 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.863 ;acc: 0.505 ;iou_acc: 0.645 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.855 ;acc: 0.485 ;iou_acc: 0.590 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.126 ;acc: 0.415 ;iou_acc: 0.535 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.662 ;acc: 0.295 ;iou_acc: 0.415 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.950 ;acc: 0.270 ;iou_acc: 0.400 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.406 ;Test accuracy 0.390 ;IOU accuracy: 0.504 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 64 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19009 ;lr: 0.0450 ;B loss: 1.080 ;acc: 0.810 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19059 ;lr: 0.0450 ;B loss: 1.759 ;acc: 0.585 ;iou: 0.705 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19109 ;lr: 0.0450 ;B loss: 1.159 ;acc: 0.710 ;iou: 0.765 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19159 ;lr: 0.0450 ;B loss: 1.935 ;acc: 0.650 ;iou: 0.695 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19209 ;lr: 0.0450 ;B loss: 1.954 ;acc: 0.645 ;iou: 0.730 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19259 ;lr: 0.0450 ;B loss: 1.443 ;acc: 0.700 ;iou: 0.760 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.759 ;Train accuracy: 0.648 ;IOU accuracy: 0.716 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 64\n",
      "batch: 0 ;B loss: 2.309 ;acc: 0.710 ;iou_acc: 0.840 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.835 ;acc: 0.535 ;iou_acc: 0.685 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.903 ;acc: 0.500 ;iou_acc: 0.610 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.117 ;acc: 0.430 ;iou_acc: 0.550 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.622 ;acc: 0.335 ;iou_acc: 0.465 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.944 ;acc: 0.260 ;iou_acc: 0.380 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.407 ;Test accuracy 0.389 ;IOU accuracy: 0.502 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 65 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19306 ;lr: 0.0450 ;B loss: 1.730 ;acc: 0.715 ;iou: 0.765 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19356 ;lr: 0.0450 ;B loss: 1.101 ;acc: 0.770 ;iou: 0.800 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19406 ;lr: 0.0450 ;B loss: 2.476 ;acc: 0.545 ;iou: 0.605 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19456 ;lr: 0.0450 ;B loss: 1.186 ;acc: 0.755 ;iou: 0.815 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19506 ;lr: 0.0450 ;B loss: 1.319 ;acc: 0.740 ;iou: 0.780 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19556 ;lr: 0.0450 ;B loss: 1.304 ;acc: 0.755 ;iou: 0.795 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.743 ;Train accuracy: 0.654 ;IOU accuracy: 0.721 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 65\n",
      "batch: 0 ;B loss: 2.142 ;acc: 0.720 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.805 ;acc: 0.515 ;iou_acc: 0.655 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.936 ;acc: 0.475 ;iou_acc: 0.575 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.053 ;acc: 0.400 ;iou_acc: 0.515 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.572 ;acc: 0.330 ;iou_acc: 0.440 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.972 ;acc: 0.240 ;iou_acc: 0.355 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.381 ;Test accuracy 0.381 ;IOU accuracy: 0.495 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 66 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19603 ;lr: 0.0450 ;B loss: 2.767 ;acc: 0.455 ;iou: 0.565 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19653 ;lr: 0.0450 ;B loss: 1.629 ;acc: 0.695 ;iou: 0.750 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19703 ;lr: 0.0450 ;B loss: 1.962 ;acc: 0.660 ;iou: 0.720 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19753 ;lr: 0.0450 ;B loss: 3.008 ;acc: 0.330 ;iou: 0.450 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19803 ;lr: 0.0450 ;B loss: 2.444 ;acc: 0.595 ;iou: 0.640 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19853 ;lr: 0.0450 ;B loss: 1.817 ;acc: 0.640 ;iou: 0.700 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.724 ;Train accuracy: 0.659 ;IOU accuracy: 0.725 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 66\n",
      "batch: 0 ;B loss: 2.367 ;acc: 0.735 ;iou_acc: 0.855 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.806 ;acc: 0.525 ;iou_acc: 0.655 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.924 ;acc: 0.475 ;iou_acc: 0.585 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.094 ;acc: 0.390 ;iou_acc: 0.515 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.629 ;acc: 0.315 ;iou_acc: 0.415 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.959 ;acc: 0.285 ;iou_acc: 0.400 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.425 ;Test accuracy 0.395 ;IOU accuracy: 0.508 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 67 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19900 ;lr: 0.0450 ;B loss: 2.158 ;acc: 0.640 ;iou: 0.675 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19950 ;lr: 0.0450 ;B loss: 1.625 ;acc: 0.700 ;iou: 0.735 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20000 ;lr: 0.0450 ;B loss: 2.244 ;acc: 0.565 ;iou: 0.620 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20050 ;lr: 0.0405 ;B loss: 1.322 ;acc: 0.755 ;iou: 0.815 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20100 ;lr: 0.0405 ;B loss: 2.276 ;acc: 0.585 ;iou: 0.655 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20150 ;lr: 0.0405 ;B loss: 1.133 ;acc: 0.765 ;iou: 0.795 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.705 ;Train accuracy: 0.662 ;IOU accuracy: 0.729 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 67\n",
      "batch: 0 ;B loss: 2.317 ;acc: 0.720 ;iou_acc: 0.855 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.811 ;acc: 0.540 ;iou_acc: 0.670 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.909 ;acc: 0.515 ;iou_acc: 0.650 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.110 ;acc: 0.400 ;iou_acc: 0.500 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.629 ;acc: 0.345 ;iou_acc: 0.435 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.997 ;acc: 0.255 ;iou_acc: 0.365 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.411 ;Test accuracy 0.394 ;IOU accuracy: 0.508 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 68 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20197 ;lr: 0.0405 ;B loss: 1.710 ;acc: 0.660 ;iou: 0.720 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20247 ;lr: 0.0405 ;B loss: 1.264 ;acc: 0.785 ;iou: 0.850 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20297 ;lr: 0.0405 ;B loss: 1.272 ;acc: 0.805 ;iou: 0.845 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20347 ;lr: 0.0405 ;B loss: 1.519 ;acc: 0.750 ;iou: 0.800 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20397 ;lr: 0.0405 ;B loss: 1.689 ;acc: 0.675 ;iou: 0.745 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20447 ;lr: 0.0405 ;B loss: 1.698 ;acc: 0.715 ;iou: 0.750 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.676 ;Train accuracy: 0.672 ;IOU accuracy: 0.738 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 68\n",
      "batch: 0 ;B loss: 2.372 ;acc: 0.705 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.901 ;acc: 0.490 ;iou_acc: 0.645 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.005 ;acc: 0.460 ;iou_acc: 0.585 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.170 ;acc: 0.425 ;iou_acc: 0.510 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.727 ;acc: 0.335 ;iou_acc: 0.455 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.997 ;acc: 0.275 ;iou_acc: 0.405 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.501 ;Test accuracy 0.384 ;IOU accuracy: 0.501 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 69 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20494 ;lr: 0.0405 ;B loss: 1.147 ;acc: 0.795 ;iou: 0.880 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20544 ;lr: 0.0405 ;B loss: 2.166 ;acc: 0.565 ;iou: 0.620 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20594 ;lr: 0.0405 ;B loss: 1.080 ;acc: 0.700 ;iou: 0.775 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20644 ;lr: 0.0405 ;B loss: 2.458 ;acc: 0.585 ;iou: 0.670 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20694 ;lr: 0.0405 ;B loss: 1.323 ;acc: 0.775 ;iou: 0.850 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20744 ;lr: 0.0405 ;B loss: 1.455 ;acc: 0.700 ;iou: 0.775 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.664 ;Train accuracy: 0.678 ;IOU accuracy: 0.742 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 69\n",
      "batch: 0 ;B loss: 2.447 ;acc: 0.725 ;iou_acc: 0.850 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.824 ;acc: 0.565 ;iou_acc: 0.695 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.953 ;acc: 0.475 ;iou_acc: 0.605 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.210 ;acc: 0.425 ;iou_acc: 0.515 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.705 ;acc: 0.300 ;iou_acc: 0.430 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.119 ;acc: 0.265 ;iou_acc: 0.390 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.459 ;Test accuracy 0.392 ;IOU accuracy: 0.506 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 70 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20791 ;lr: 0.0405 ;B loss: 1.662 ;acc: 0.770 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20841 ;lr: 0.0405 ;B loss: 1.971 ;acc: 0.655 ;iou: 0.745 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20891 ;lr: 0.0405 ;B loss: 1.482 ;acc: 0.750 ;iou: 0.765 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20941 ;lr: 0.0405 ;B loss: 1.409 ;acc: 0.780 ;iou: 0.825 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20991 ;lr: 0.0405 ;B loss: 1.498 ;acc: 0.730 ;iou: 0.790 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21041 ;lr: 0.0405 ;B loss: 1.174 ;acc: 0.715 ;iou: 0.805 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.654 ;Train accuracy: 0.680 ;IOU accuracy: 0.744 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 70\n",
      "batch: 0 ;B loss: 2.358 ;acc: 0.710 ;iou_acc: 0.850 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.869 ;acc: 0.535 ;iou_acc: 0.685 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.863 ;acc: 0.515 ;iou_acc: 0.610 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.051 ;acc: 0.405 ;iou_acc: 0.510 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.648 ;acc: 0.305 ;iou_acc: 0.430 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.023 ;acc: 0.260 ;iou_acc: 0.390 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.450 ;Test accuracy 0.396 ;IOU accuracy: 0.512 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 71 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21088 ;lr: 0.0405 ;B loss: 2.174 ;acc: 0.630 ;iou: 0.680 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21138 ;lr: 0.0405 ;B loss: 1.590 ;acc: 0.675 ;iou: 0.720 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21188 ;lr: 0.0405 ;B loss: 2.832 ;acc: 0.355 ;iou: 0.470 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21238 ;lr: 0.0405 ;B loss: 2.618 ;acc: 0.515 ;iou: 0.585 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21288 ;lr: 0.0405 ;B loss: 2.624 ;acc: 0.485 ;iou: 0.520 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21338 ;lr: 0.0405 ;B loss: 3.029 ;acc: 0.370 ;iou: 0.470 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.640 ;Train accuracy: 0.685 ;IOU accuracy: 0.748 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 71\n",
      "batch: 0 ;B loss: 2.400 ;acc: 0.710 ;iou_acc: 0.840 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.819 ;acc: 0.565 ;iou_acc: 0.705 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.920 ;acc: 0.510 ;iou_acc: 0.630 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.161 ;acc: 0.405 ;iou_acc: 0.535 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.662 ;acc: 0.330 ;iou_acc: 0.440 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.983 ;acc: 0.285 ;iou_acc: 0.405 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.441 ;Test accuracy 0.399 ;IOU accuracy: 0.513 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 72 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21385 ;lr: 0.0405 ;B loss: 1.535 ;acc: 0.690 ;iou: 0.740 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21435 ;lr: 0.0405 ;B loss: 1.652 ;acc: 0.755 ;iou: 0.790 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21485 ;lr: 0.0405 ;B loss: 1.388 ;acc: 0.765 ;iou: 0.815 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21535 ;lr: 0.0405 ;B loss: 2.679 ;acc: 0.455 ;iou: 0.530 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21585 ;lr: 0.0405 ;B loss: 1.310 ;acc: 0.745 ;iou: 0.830 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21635 ;lr: 0.0405 ;B loss: 1.191 ;acc: 0.725 ;iou: 0.815 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.627 ;Train accuracy: 0.687 ;IOU accuracy: 0.750 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 72\n",
      "batch: 0 ;B loss: 2.422 ;acc: 0.750 ;iou_acc: 0.865 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.854 ;acc: 0.540 ;iou_acc: 0.670 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.004 ;acc: 0.500 ;iou_acc: 0.590 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.219 ;acc: 0.385 ;iou_acc: 0.515 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.725 ;acc: 0.375 ;iou_acc: 0.480 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.137 ;acc: 0.280 ;iou_acc: 0.390 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.486 ;Test accuracy 0.395 ;IOU accuracy: 0.506 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 73 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21682 ;lr: 0.0405 ;B loss: 2.282 ;acc: 0.600 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21732 ;lr: 0.0405 ;B loss: 1.066 ;acc: 0.720 ;iou: 0.805 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21782 ;lr: 0.0405 ;B loss: 1.701 ;acc: 0.765 ;iou: 0.850 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21832 ;lr: 0.0405 ;B loss: 1.196 ;acc: 0.755 ;iou: 0.805 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21882 ;lr: 0.0405 ;B loss: 1.192 ;acc: 0.760 ;iou: 0.815 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21932 ;lr: 0.0405 ;B loss: 2.648 ;acc: 0.530 ;iou: 0.620 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.612 ;Train accuracy: 0.694 ;IOU accuracy: 0.757 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 73\n",
      "batch: 0 ;B loss: 2.471 ;acc: 0.710 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.818 ;acc: 0.540 ;iou_acc: 0.685 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.976 ;acc: 0.515 ;iou_acc: 0.620 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.111 ;acc: 0.450 ;iou_acc: 0.555 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.709 ;acc: 0.330 ;iou_acc: 0.460 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.083 ;acc: 0.270 ;iou_acc: 0.380 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.491 ;Test accuracy 0.401 ;IOU accuracy: 0.518 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 74 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21979 ;lr: 0.0405 ;B loss: 1.390 ;acc: 0.785 ;iou: 0.840 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22029 ;lr: 0.0405 ;B loss: 1.199 ;acc: 0.800 ;iou: 0.840 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22079 ;lr: 0.0405 ;B loss: 1.708 ;acc: 0.750 ;iou: 0.790 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22129 ;lr: 0.0405 ;B loss: 1.923 ;acc: 0.690 ;iou: 0.750 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22179 ;lr: 0.0405 ;B loss: 1.823 ;acc: 0.695 ;iou: 0.775 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22229 ;lr: 0.0405 ;B loss: 1.787 ;acc: 0.730 ;iou: 0.795 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.600 ;Train accuracy: 0.695 ;IOU accuracy: 0.758 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 74\n",
      "batch: 0 ;B loss: 2.543 ;acc: 0.730 ;iou_acc: 0.865 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.858 ;acc: 0.550 ;iou_acc: 0.700 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 1.949 ;acc: 0.550 ;iou_acc: 0.645 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.248 ;acc: 0.425 ;iou_acc: 0.530 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.674 ;acc: 0.310 ;iou_acc: 0.430 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.028 ;acc: 0.290 ;iou_acc: 0.405 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.489 ;Test accuracy 0.407 ;IOU accuracy: 0.523 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 75 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22276 ;lr: 0.0405 ;B loss: 1.092 ;acc: 0.790 ;iou: 0.825 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22326 ;lr: 0.0405 ;B loss: 2.353 ;acc: 0.530 ;iou: 0.620 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22376 ;lr: 0.0405 ;B loss: 1.167 ;acc: 0.745 ;iou: 0.780 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22426 ;lr: 0.0405 ;B loss: 1.273 ;acc: 0.775 ;iou: 0.840 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22476 ;lr: 0.0405 ;B loss: 1.184 ;acc: 0.740 ;iou: 0.815 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22526 ;lr: 0.0405 ;B loss: 2.836 ;acc: 0.435 ;iou: 0.510 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.585 ;Train accuracy: 0.701 ;IOU accuracy: 0.761 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 75\n",
      "batch: 0 ;B loss: 2.604 ;acc: 0.745 ;iou_acc: 0.865 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.837 ;acc: 0.540 ;iou_acc: 0.690 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.959 ;acc: 0.525 ;iou_acc: 0.610 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.189 ;acc: 0.425 ;iou_acc: 0.545 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.684 ;acc: 0.340 ;iou_acc: 0.445 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.097 ;acc: 0.265 ;iou_acc: 0.385 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.515 ;Test accuracy 0.402 ;IOU accuracy: 0.514 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 76 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22573 ;lr: 0.0405 ;B loss: 1.052 ;acc: 0.745 ;iou: 0.820 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22623 ;lr: 0.0405 ;B loss: 1.014 ;acc: 0.770 ;iou: 0.830 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22673 ;lr: 0.0405 ;B loss: 1.507 ;acc: 0.740 ;iou: 0.790 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22723 ;lr: 0.0405 ;B loss: 2.446 ;acc: 0.520 ;iou: 0.585 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22773 ;lr: 0.0405 ;B loss: 1.086 ;acc: 0.725 ;iou: 0.785 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22823 ;lr: 0.0405 ;B loss: 1.267 ;acc: 0.740 ;iou: 0.830 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.575 ;Train accuracy: 0.703 ;IOU accuracy: 0.764 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 76\n",
      "batch: 0 ;B loss: 2.355 ;acc: 0.700 ;iou_acc: 0.840 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.848 ;acc: 0.550 ;iou_acc: 0.695 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.888 ;acc: 0.510 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.169 ;acc: 0.415 ;iou_acc: 0.545 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.652 ;acc: 0.345 ;iou_acc: 0.485 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.066 ;acc: 0.260 ;iou_acc: 0.415 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.484 ;Test accuracy 0.399 ;IOU accuracy: 0.515 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 77 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22870 ;lr: 0.0405 ;B loss: 1.406 ;acc: 0.750 ;iou: 0.790 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22920 ;lr: 0.0405 ;B loss: 1.958 ;acc: 0.710 ;iou: 0.760 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22970 ;lr: 0.0405 ;B loss: 1.172 ;acc: 0.795 ;iou: 0.850 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23020 ;lr: 0.0405 ;B loss: 1.029 ;acc: 0.755 ;iou: 0.825 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23070 ;lr: 0.0405 ;B loss: 1.973 ;acc: 0.675 ;iou: 0.715 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23120 ;lr: 0.0405 ;B loss: 1.159 ;acc: 0.755 ;iou: 0.815 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.562 ;Train accuracy: 0.708 ;IOU accuracy: 0.768 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 77\n",
      "batch: 0 ;B loss: 2.618 ;acc: 0.690 ;iou_acc: 0.825 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.914 ;acc: 0.525 ;iou_acc: 0.680 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.041 ;acc: 0.505 ;iou_acc: 0.590 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.296 ;acc: 0.440 ;iou_acc: 0.535 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.747 ;acc: 0.325 ;iou_acc: 0.425 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.174 ;acc: 0.285 ;iou_acc: 0.390 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.573 ;Test accuracy 0.403 ;IOU accuracy: 0.516 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 78 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23167 ;lr: 0.0405 ;B loss: 2.183 ;acc: 0.640 ;iou: 0.695 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23217 ;lr: 0.0405 ;B loss: 1.650 ;acc: 0.480 ;iou: 0.645 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23267 ;lr: 0.0405 ;B loss: 1.606 ;acc: 0.720 ;iou: 0.745 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23317 ;lr: 0.0405 ;B loss: 1.732 ;acc: 0.700 ;iou: 0.785 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23367 ;lr: 0.0405 ;B loss: 1.725 ;acc: 0.785 ;iou: 0.825 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23417 ;lr: 0.0405 ;B loss: 1.422 ;acc: 0.725 ;iou: 0.790 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.549 ;Train accuracy: 0.710 ;IOU accuracy: 0.769 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 78\n",
      "batch: 0 ;B loss: 2.679 ;acc: 0.695 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.905 ;acc: 0.565 ;iou_acc: 0.720 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.957 ;acc: 0.545 ;iou_acc: 0.625 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.237 ;acc: 0.425 ;iou_acc: 0.555 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.678 ;acc: 0.340 ;iou_acc: 0.475 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.142 ;acc: 0.270 ;iou_acc: 0.425 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.570 ;Test accuracy 0.410 ;IOU accuracy: 0.527 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 79 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23464 ;lr: 0.0405 ;B loss: 1.504 ;acc: 0.770 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23514 ;lr: 0.0405 ;B loss: 2.052 ;acc: 0.680 ;iou: 0.755 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23564 ;lr: 0.0405 ;B loss: 1.133 ;acc: 0.735 ;iou: 0.805 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23614 ;lr: 0.0405 ;B loss: 1.675 ;acc: 0.695 ;iou: 0.730 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23664 ;lr: 0.0405 ;B loss: 1.003 ;acc: 0.775 ;iou: 0.840 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23714 ;lr: 0.0405 ;B loss: 1.575 ;acc: 0.775 ;iou: 0.790 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.544 ;Train accuracy: 0.712 ;IOU accuracy: 0.771 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 79\n",
      "batch: 0 ;B loss: 2.746 ;acc: 0.715 ;iou_acc: 0.840 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.820 ;acc: 0.595 ;iou_acc: 0.730 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.067 ;acc: 0.535 ;iou_acc: 0.635 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.380 ;acc: 0.400 ;iou_acc: 0.530 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.759 ;acc: 0.340 ;iou_acc: 0.470 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.088 ;acc: 0.270 ;iou_acc: 0.380 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.587 ;Test accuracy 0.412 ;IOU accuracy: 0.528 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 80 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23761 ;lr: 0.0405 ;B loss: 2.362 ;acc: 0.545 ;iou: 0.620 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23811 ;lr: 0.0405 ;B loss: 2.148 ;acc: 0.620 ;iou: 0.715 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23861 ;lr: 0.0405 ;B loss: 1.301 ;acc: 0.765 ;iou: 0.795 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23911 ;lr: 0.0405 ;B loss: 1.063 ;acc: 0.775 ;iou: 0.820 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23961 ;lr: 0.0405 ;B loss: 1.327 ;acc: 0.780 ;iou: 0.810 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24011 ;lr: 0.0405 ;B loss: 2.289 ;acc: 0.645 ;iou: 0.685 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.535 ;Train accuracy: 0.713 ;IOU accuracy: 0.772 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 80\n",
      "batch: 0 ;B loss: 2.527 ;acc: 0.710 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.886 ;acc: 0.570 ;iou_acc: 0.710 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.940 ;acc: 0.520 ;iou_acc: 0.625 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.192 ;acc: 0.425 ;iou_acc: 0.545 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.717 ;acc: 0.330 ;iou_acc: 0.450 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.116 ;acc: 0.265 ;iou_acc: 0.380 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.553 ;Test accuracy 0.403 ;IOU accuracy: 0.518 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 81 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24058 ;lr: 0.0405 ;B loss: 1.160 ;acc: 0.795 ;iou: 0.875 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24108 ;lr: 0.0405 ;B loss: 1.054 ;acc: 0.740 ;iou: 0.780 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24158 ;lr: 0.0405 ;B loss: 1.442 ;acc: 0.805 ;iou: 0.840 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24208 ;lr: 0.0405 ;B loss: 1.817 ;acc: 0.735 ;iou: 0.790 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24258 ;lr: 0.0405 ;B loss: 1.272 ;acc: 0.745 ;iou: 0.780 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24308 ;lr: 0.0405 ;B loss: 1.150 ;acc: 0.785 ;iou: 0.845 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.513 ;Train accuracy: 0.720 ;IOU accuracy: 0.778 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 81\n",
      "batch: 0 ;B loss: 2.759 ;acc: 0.695 ;iou_acc: 0.825 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.960 ;acc: 0.545 ;iou_acc: 0.685 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.998 ;acc: 0.535 ;iou_acc: 0.610 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.120 ;acc: 0.485 ;iou_acc: 0.590 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.838 ;acc: 0.355 ;iou_acc: 0.485 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.198 ;acc: 0.235 ;iou_acc: 0.360 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.612 ;Test accuracy 0.411 ;IOU accuracy: 0.528 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 82 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24355 ;lr: 0.0405 ;B loss: 1.038 ;acc: 0.745 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24405 ;lr: 0.0405 ;B loss: 1.805 ;acc: 0.770 ;iou: 0.810 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24455 ;lr: 0.0405 ;B loss: 2.238 ;acc: 0.565 ;iou: 0.655 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24505 ;lr: 0.0405 ;B loss: 1.274 ;acc: 0.810 ;iou: 0.850 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24555 ;lr: 0.0405 ;B loss: 1.649 ;acc: 0.770 ;iou: 0.810 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24605 ;lr: 0.0405 ;B loss: 1.667 ;acc: 0.755 ;iou: 0.830 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.505 ;Train accuracy: 0.721 ;IOU accuracy: 0.779 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 82\n",
      "batch: 0 ;B loss: 2.671 ;acc: 0.755 ;iou_acc: 0.865 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.969 ;acc: 0.580 ;iou_acc: 0.710 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.031 ;acc: 0.505 ;iou_acc: 0.595 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.217 ;acc: 0.430 ;iou_acc: 0.540 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.775 ;acc: 0.360 ;iou_acc: 0.475 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.228 ;acc: 0.275 ;iou_acc: 0.395 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.616 ;Test accuracy 0.410 ;IOU accuracy: 0.525 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 83 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24652 ;lr: 0.0405 ;B loss: 1.688 ;acc: 0.750 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24702 ;lr: 0.0405 ;B loss: 1.065 ;acc: 0.695 ;iou: 0.745 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24752 ;lr: 0.0405 ;B loss: 1.154 ;acc: 0.820 ;iou: 0.865 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24802 ;lr: 0.0405 ;B loss: 1.709 ;acc: 0.720 ;iou: 0.775 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24852 ;lr: 0.0405 ;B loss: 1.094 ;acc: 0.715 ;iou: 0.795 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24902 ;lr: 0.0405 ;B loss: 1.073 ;acc: 0.700 ;iou: 0.765 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.490 ;Train accuracy: 0.725 ;IOU accuracy: 0.782 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 83\n",
      "batch: 0 ;B loss: 2.927 ;acc: 0.750 ;iou_acc: 0.870 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.912 ;acc: 0.545 ;iou_acc: 0.690 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.018 ;acc: 0.540 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.243 ;acc: 0.435 ;iou_acc: 0.555 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.903 ;acc: 0.315 ;iou_acc: 0.450 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.198 ;acc: 0.290 ;iou_acc: 0.430 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.674 ;Test accuracy 0.415 ;IOU accuracy: 0.531 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 84 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24949 ;lr: 0.0405 ;B loss: 1.853 ;acc: 0.630 ;iou: 0.685 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24999 ;lr: 0.0405 ;B loss: 1.392 ;acc: 0.780 ;iou: 0.825 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25049 ;lr: 0.0405 ;B loss: 1.727 ;acc: 0.475 ;iou: 0.630 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25099 ;lr: 0.0405 ;B loss: 1.281 ;acc: 0.805 ;iou: 0.825 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25149 ;lr: 0.0405 ;B loss: 1.387 ;acc: 0.755 ;iou: 0.795 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25199 ;lr: 0.0405 ;B loss: 2.374 ;acc: 0.635 ;iou: 0.710 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.481 ;Train accuracy: 0.729 ;IOU accuracy: 0.786 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 84\n",
      "batch: 0 ;B loss: 2.910 ;acc: 0.740 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.961 ;acc: 0.565 ;iou_acc: 0.710 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.025 ;acc: 0.545 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.281 ;acc: 0.455 ;iou_acc: 0.595 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.900 ;acc: 0.340 ;iou_acc: 0.450 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.264 ;acc: 0.275 ;iou_acc: 0.400 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.720 ;Test accuracy 0.417 ;IOU accuracy: 0.533 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 85 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25246 ;lr: 0.0405 ;B loss: 1.054 ;acc: 0.790 ;iou: 0.835 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25296 ;lr: 0.0405 ;B loss: 1.013 ;acc: 0.725 ;iou: 0.805 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25346 ;lr: 0.0405 ;B loss: 1.007 ;acc: 0.825 ;iou: 0.860 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25396 ;lr: 0.0405 ;B loss: 1.804 ;acc: 0.505 ;iou: 0.615 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25446 ;lr: 0.0405 ;B loss: 1.133 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25496 ;lr: 0.0405 ;B loss: 1.357 ;acc: 0.750 ;iou: 0.800 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.468 ;Train accuracy: 0.731 ;IOU accuracy: 0.786 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 85\n",
      "batch: 0 ;B loss: 2.820 ;acc: 0.755 ;iou_acc: 0.880 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.951 ;acc: 0.550 ;iou_acc: 0.705 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.992 ;acc: 0.530 ;iou_acc: 0.620 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.288 ;acc: 0.440 ;iou_acc: 0.525 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.766 ;acc: 0.385 ;iou_acc: 0.500 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.149 ;acc: 0.295 ;iou_acc: 0.395 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.639 ;Test accuracy 0.418 ;IOU accuracy: 0.534 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 86 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25543 ;lr: 0.0405 ;B loss: 0.924 ;acc: 0.790 ;iou: 0.860 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25593 ;lr: 0.0405 ;B loss: 1.066 ;acc: 0.740 ;iou: 0.790 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25643 ;lr: 0.0405 ;B loss: 2.175 ;acc: 0.650 ;iou: 0.685 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25693 ;lr: 0.0405 ;B loss: 1.173 ;acc: 0.710 ;iou: 0.785 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25743 ;lr: 0.0405 ;B loss: 1.027 ;acc: 0.795 ;iou: 0.840 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25793 ;lr: 0.0405 ;B loss: 1.814 ;acc: 0.715 ;iou: 0.760 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.459 ;Train accuracy: 0.733 ;IOU accuracy: 0.789 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 86\n",
      "batch: 0 ;B loss: 2.913 ;acc: 0.780 ;iou_acc: 0.895 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.892 ;acc: 0.555 ;iou_acc: 0.710 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.062 ;acc: 0.495 ;iou_acc: 0.600 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.284 ;acc: 0.425 ;iou_acc: 0.550 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.847 ;acc: 0.355 ;iou_acc: 0.500 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.159 ;acc: 0.280 ;iou_acc: 0.380 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.667 ;Test accuracy 0.420 ;IOU accuracy: 0.536 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 87 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25840 ;lr: 0.0405 ;B loss: 0.966 ;acc: 0.790 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25890 ;lr: 0.0405 ;B loss: 1.084 ;acc: 0.805 ;iou: 0.865 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25940 ;lr: 0.0405 ;B loss: 1.037 ;acc: 0.730 ;iou: 0.770 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25990 ;lr: 0.0405 ;B loss: 2.484 ;acc: 0.425 ;iou: 0.550 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26040 ;lr: 0.0405 ;B loss: 1.276 ;acc: 0.785 ;iou: 0.830 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26090 ;lr: 0.0405 ;B loss: 1.598 ;acc: 0.805 ;iou: 0.815 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.440 ;Train accuracy: 0.737 ;IOU accuracy: 0.791 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 87\n",
      "batch: 0 ;B loss: 2.862 ;acc: 0.765 ;iou_acc: 0.870 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.909 ;acc: 0.560 ;iou_acc: 0.710 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.022 ;acc: 0.540 ;iou_acc: 0.640 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.358 ;acc: 0.410 ;iou_acc: 0.530 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.829 ;acc: 0.365 ;iou_acc: 0.500 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.138 ;acc: 0.280 ;iou_acc: 0.415 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.664 ;Test accuracy 0.420 ;IOU accuracy: 0.536 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 88 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26137 ;lr: 0.0405 ;B loss: 1.502 ;acc: 0.795 ;iou: 0.825 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26187 ;lr: 0.0405 ;B loss: 0.962 ;acc: 0.840 ;iou: 0.875 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26237 ;lr: 0.0405 ;B loss: 1.125 ;acc: 0.665 ;iou: 0.745 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26287 ;lr: 0.0405 ;B loss: 1.069 ;acc: 0.705 ;iou: 0.775 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26337 ;lr: 0.0405 ;B loss: 0.924 ;acc: 0.740 ;iou: 0.770 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26387 ;lr: 0.0405 ;B loss: 1.582 ;acc: 0.780 ;iou: 0.835 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.428 ;Train accuracy: 0.741 ;IOU accuracy: 0.796 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 88\n",
      "batch: 0 ;B loss: 3.145 ;acc: 0.765 ;iou_acc: 0.885 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.007 ;acc: 0.545 ;iou_acc: 0.680 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.210 ;acc: 0.535 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.379 ;acc: 0.460 ;iou_acc: 0.555 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.862 ;acc: 0.370 ;iou_acc: 0.475 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.300 ;acc: 0.260 ;iou_acc: 0.370 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.765 ;Test accuracy 0.423 ;IOU accuracy: 0.540 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 89 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26434 ;lr: 0.0405 ;B loss: 1.875 ;acc: 0.480 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26484 ;lr: 0.0405 ;B loss: 1.759 ;acc: 0.755 ;iou: 0.795 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26534 ;lr: 0.0405 ;B loss: 1.823 ;acc: 0.755 ;iou: 0.790 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26584 ;lr: 0.0405 ;B loss: 1.077 ;acc: 0.710 ;iou: 0.760 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26634 ;lr: 0.0405 ;B loss: 2.544 ;acc: 0.420 ;iou: 0.540 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26684 ;lr: 0.0405 ;B loss: 0.926 ;acc: 0.820 ;iou: 0.875 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.422 ;Train accuracy: 0.743 ;IOU accuracy: 0.797 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 89\n",
      "batch: 0 ;B loss: 2.883 ;acc: 0.750 ;iou_acc: 0.875 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.843 ;acc: 0.565 ;iou_acc: 0.710 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.057 ;acc: 0.540 ;iou_acc: 0.645 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.303 ;acc: 0.485 ;iou_acc: 0.605 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.843 ;acc: 0.330 ;iou_acc: 0.435 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.218 ;acc: 0.245 ;iou_acc: 0.385 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.681 ;Test accuracy 0.419 ;IOU accuracy: 0.533 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 90 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26731 ;lr: 0.0405 ;B loss: 1.789 ;acc: 0.675 ;iou: 0.730 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26781 ;lr: 0.0405 ;B loss: 1.405 ;acc: 0.815 ;iou: 0.840 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26831 ;lr: 0.0405 ;B loss: 1.049 ;acc: 0.785 ;iou: 0.845 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26881 ;lr: 0.0405 ;B loss: 2.180 ;acc: 0.630 ;iou: 0.700 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26931 ;lr: 0.0405 ;B loss: 1.047 ;acc: 0.755 ;iou: 0.810 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26981 ;lr: 0.0405 ;B loss: 1.878 ;acc: 0.685 ;iou: 0.750 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.411 ;Train accuracy: 0.743 ;IOU accuracy: 0.796 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 90\n",
      "batch: 0 ;B loss: 3.136 ;acc: 0.755 ;iou_acc: 0.860 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 2.018 ;acc: 0.575 ;iou_acc: 0.720 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.087 ;acc: 0.580 ;iou_acc: 0.660 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.324 ;acc: 0.475 ;iou_acc: 0.570 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.819 ;acc: 0.360 ;iou_acc: 0.480 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.307 ;acc: 0.280 ;iou_acc: 0.395 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.772 ;Test accuracy 0.424 ;IOU accuracy: 0.540 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 91 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27028 ;lr: 0.0405 ;B loss: 1.486 ;acc: 0.755 ;iou: 0.800 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27078 ;lr: 0.0405 ;B loss: 1.270 ;acc: 0.800 ;iou: 0.845 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27128 ;lr: 0.0405 ;B loss: 1.740 ;acc: 0.725 ;iou: 0.770 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27178 ;lr: 0.0405 ;B loss: 1.583 ;acc: 0.765 ;iou: 0.805 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27228 ;lr: 0.0405 ;B loss: 0.994 ;acc: 0.800 ;iou: 0.855 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27278 ;lr: 0.0405 ;B loss: 1.396 ;acc: 0.805 ;iou: 0.835 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.394 ;Train accuracy: 0.748 ;IOU accuracy: 0.802 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 91\n",
      "batch: 0 ;B loss: 3.063 ;acc: 0.740 ;iou_acc: 0.855 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.045 ;acc: 0.580 ;iou_acc: 0.695 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.089 ;acc: 0.525 ;iou_acc: 0.635 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.264 ;acc: 0.455 ;iou_acc: 0.580 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.957 ;acc: 0.395 ;iou_acc: 0.500 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.259 ;acc: 0.290 ;iou_acc: 0.425 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.771 ;Test accuracy 0.425 ;IOU accuracy: 0.541 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 92 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27325 ;lr: 0.0405 ;B loss: 2.037 ;acc: 0.670 ;iou: 0.720 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27375 ;lr: 0.0405 ;B loss: 2.102 ;acc: 0.645 ;iou: 0.700 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27425 ;lr: 0.0405 ;B loss: 2.314 ;acc: 0.570 ;iou: 0.660 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27475 ;lr: 0.0405 ;B loss: 1.228 ;acc: 0.780 ;iou: 0.820 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27525 ;lr: 0.0405 ;B loss: 1.210 ;acc: 0.825 ;iou: 0.865 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27575 ;lr: 0.0405 ;B loss: 1.035 ;acc: 0.745 ;iou: 0.795 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.378 ;Train accuracy: 0.752 ;IOU accuracy: 0.806 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 92\n",
      "batch: 0 ;B loss: 2.779 ;acc: 0.710 ;iou_acc: 0.830 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.929 ;acc: 0.575 ;iou_acc: 0.730 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.100 ;acc: 0.500 ;iou_acc: 0.600 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.361 ;acc: 0.415 ;iou_acc: 0.525 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.842 ;acc: 0.355 ;iou_acc: 0.480 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.233 ;acc: 0.265 ;iou_acc: 0.380 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.700 ;Test accuracy 0.407 ;IOU accuracy: 0.525 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 93 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27622 ;lr: 0.0405 ;B loss: 1.091 ;acc: 0.790 ;iou: 0.880 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27672 ;lr: 0.0405 ;B loss: 1.109 ;acc: 0.845 ;iou: 0.880 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27722 ;lr: 0.0405 ;B loss: 1.132 ;acc: 0.720 ;iou: 0.785 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27772 ;lr: 0.0405 ;B loss: 1.610 ;acc: 0.765 ;iou: 0.825 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27822 ;lr: 0.0405 ;B loss: 1.074 ;acc: 0.775 ;iou: 0.815 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27872 ;lr: 0.0405 ;B loss: 1.019 ;acc: 0.770 ;iou: 0.820 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.372 ;Train accuracy: 0.752 ;IOU accuracy: 0.806 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 93\n",
      "batch: 0 ;B loss: 3.100 ;acc: 0.765 ;iou_acc: 0.890 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.024 ;acc: 0.585 ;iou_acc: 0.725 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.059 ;acc: 0.555 ;iou_acc: 0.655 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.353 ;acc: 0.475 ;iou_acc: 0.575 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.822 ;acc: 0.420 ;iou_acc: 0.525 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.274 ;acc: 0.275 ;iou_acc: 0.400 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.717 ;Test accuracy 0.431 ;IOU accuracy: 0.548 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 94 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27919 ;lr: 0.0405 ;B loss: 1.159 ;acc: 0.865 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27969 ;lr: 0.0405 ;B loss: 1.664 ;acc: 0.735 ;iou: 0.795 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28019 ;lr: 0.0405 ;B loss: 1.335 ;acc: 0.815 ;iou: 0.850 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28069 ;lr: 0.0405 ;B loss: 2.170 ;acc: 0.600 ;iou: 0.695 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28119 ;lr: 0.0405 ;B loss: 1.476 ;acc: 0.810 ;iou: 0.830 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28169 ;lr: 0.0405 ;B loss: 1.008 ;acc: 0.795 ;iou: 0.865 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.346 ;Train accuracy: 0.756 ;IOU accuracy: 0.809 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 94\n",
      "batch: 0 ;B loss: 2.776 ;acc: 0.685 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.938 ;acc: 0.570 ;iou_acc: 0.705 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.007 ;acc: 0.535 ;iou_acc: 0.655 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.302 ;acc: 0.440 ;iou_acc: 0.560 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.901 ;acc: 0.375 ;iou_acc: 0.490 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.158 ;acc: 0.285 ;iou_acc: 0.435 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.713 ;Test accuracy 0.412 ;IOU accuracy: 0.532 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 95 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28216 ;lr: 0.0405 ;B loss: 1.566 ;acc: 0.800 ;iou: 0.840 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28266 ;lr: 0.0405 ;B loss: 1.001 ;acc: 0.790 ;iou: 0.835 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28316 ;lr: 0.0405 ;B loss: 1.422 ;acc: 0.770 ;iou: 0.825 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28366 ;lr: 0.0405 ;B loss: 1.460 ;acc: 0.815 ;iou: 0.855 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28416 ;lr: 0.0405 ;B loss: 1.331 ;acc: 0.830 ;iou: 0.855 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28466 ;lr: 0.0405 ;B loss: 1.051 ;acc: 0.765 ;iou: 0.840 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.339 ;Train accuracy: 0.758 ;IOU accuracy: 0.811 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 95\n",
      "batch: 0 ;B loss: 3.046 ;acc: 0.715 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.115 ;acc: 0.555 ;iou_acc: 0.705 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.123 ;acc: 0.550 ;iou_acc: 0.665 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.250 ;acc: 0.460 ;iou_acc: 0.570 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.893 ;acc: 0.380 ;iou_acc: 0.510 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.221 ;acc: 0.260 ;iou_acc: 0.400 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.754 ;Test accuracy 0.427 ;IOU accuracy: 0.548 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 96 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28513 ;lr: 0.0405 ;B loss: 1.953 ;acc: 0.720 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28563 ;lr: 0.0405 ;B loss: 1.042 ;acc: 0.700 ;iou: 0.765 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28613 ;lr: 0.0405 ;B loss: 1.908 ;acc: 0.430 ;iou: 0.570 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28663 ;lr: 0.0405 ;B loss: 1.087 ;acc: 0.720 ;iou: 0.790 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28713 ;lr: 0.0405 ;B loss: 1.568 ;acc: 0.825 ;iou: 0.865 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28763 ;lr: 0.0405 ;B loss: 0.971 ;acc: 0.765 ;iou: 0.800 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.337 ;Train accuracy: 0.758 ;IOU accuracy: 0.812 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 96\n",
      "batch: 0 ;B loss: 3.313 ;acc: 0.755 ;iou_acc: 0.860 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.042 ;acc: 0.600 ;iou_acc: 0.720 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.229 ;acc: 0.530 ;iou_acc: 0.635 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.336 ;acc: 0.490 ;iou_acc: 0.590 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.898 ;acc: 0.400 ;iou_acc: 0.525 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.259 ;acc: 0.290 ;iou_acc: 0.420 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.800 ;Test accuracy 0.436 ;IOU accuracy: 0.556 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 97 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28810 ;lr: 0.0405 ;B loss: 1.157 ;acc: 0.815 ;iou: 0.855 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28860 ;lr: 0.0405 ;B loss: 1.559 ;acc: 0.790 ;iou: 0.825 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28910 ;lr: 0.0405 ;B loss: 1.220 ;acc: 0.770 ;iou: 0.835 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28960 ;lr: 0.0405 ;B loss: 0.879 ;acc: 0.810 ;iou: 0.850 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29010 ;lr: 0.0405 ;B loss: 0.887 ;acc: 0.830 ;iou: 0.855 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29060 ;lr: 0.0405 ;B loss: 1.006 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.315 ;Train accuracy: 0.763 ;IOU accuracy: 0.816 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 97\n",
      "batch: 0 ;B loss: 3.240 ;acc: 0.730 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.034 ;acc: 0.615 ;iou_acc: 0.745 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.185 ;acc: 0.535 ;iou_acc: 0.650 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.317 ;acc: 0.480 ;iou_acc: 0.595 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 3.014 ;acc: 0.430 ;iou_acc: 0.545 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 3.239 ;acc: 0.290 ;iou_acc: 0.435 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.809 ;Test accuracy 0.435 ;IOU accuracy: 0.555 ;Time: 0:00:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 98 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 29107 ;lr: 0.0405 ;B loss: 0.975 ;acc: 0.860 ;iou: 0.915 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29157 ;lr: 0.0405 ;B loss: 1.992 ;acc: 0.570 ;iou: 0.625 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 29207 ;lr: 0.0405 ;B loss: 0.820 ;acc: 0.795 ;iou: 0.865 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 29257 ;lr: 0.0405 ;B loss: 1.130 ;acc: 0.835 ;iou: 0.865 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29307 ;lr: 0.0405 ;B loss: 1.027 ;acc: 0.780 ;iou: 0.825 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29357 ;lr: 0.0405 ;B loss: 1.360 ;acc: 0.805 ;iou: 0.835 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.290 ;Train accuracy: 0.766 ;IOU accuracy: 0.818 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 98\n",
      "batch: 0 ;B loss: 3.170 ;acc: 0.755 ;iou_acc: 0.865 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.045 ;acc: 0.630 ;iou_acc: 0.730 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.063 ;acc: 0.570 ;iou_acc: 0.660 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.357 ;acc: 0.505 ;iou_acc: 0.590 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.075 ;acc: 0.360 ;iou_acc: 0.485 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.420 ;acc: 0.290 ;iou_acc: 0.440 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.809 ;Test accuracy 0.432 ;IOU accuracy: 0.552 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 99 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 29404 ;lr: 0.0405 ;B loss: 1.841 ;acc: 0.740 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29454 ;lr: 0.0405 ;B loss: 0.900 ;acc: 0.845 ;iou: 0.880 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 29504 ;lr: 0.0405 ;B loss: 1.415 ;acc: 0.845 ;iou: 0.860 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 29554 ;lr: 0.0405 ;B loss: 1.120 ;acc: 0.690 ;iou: 0.740 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29604 ;lr: 0.0405 ;B loss: 1.135 ;acc: 0.835 ;iou: 0.880 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29654 ;lr: 0.0405 ;B loss: 1.784 ;acc: 0.785 ;iou: 0.825 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.277 ;Train accuracy: 0.771 ;IOU accuracy: 0.823 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 99\n",
      "batch: 0 ;B loss: 3.367 ;acc: 0.750 ;iou_acc: 0.885 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.163 ;acc: 0.580 ;iou_acc: 0.715 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.167 ;acc: 0.560 ;iou_acc: 0.660 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.352 ;acc: 0.505 ;iou_acc: 0.610 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.089 ;acc: 0.390 ;iou_acc: 0.535 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.404 ;acc: 0.275 ;iou_acc: 0.420 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.871 ;Test accuracy 0.442 ;IOU accuracy: 0.565 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "params_dir: ../data/training/models/All/base/hidden:150\n",
      "num_hidden: 150\n",
      "learning rate: 0.05\n",
      "# Train set size: 297\n",
      "# Training batches: 297\n",
      "# Test set size: 297\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 3.103 ;acc: 0.175 ;iou: 0.255 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 1.563 ;acc: 0.350 ;iou: 0.435 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.816 ;acc: 0.180 ;iou: 0.245 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 3.334 ;acc: 0.085 ;iou: 0.195 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 1.860 ;acc: 0.290 ;iou: 0.380 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 1.560 ;acc: 0.375 ;iou: 0.475 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.443 ;Train accuracy: 0.238 ;IOU accuracy: 0.334 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 1.389 ;acc: 0.515 ;iou_acc: 0.670 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.863 ;acc: 0.275 ;iou_acc: 0.405 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.125 ;acc: 0.190 ;iou_acc: 0.285 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.435 ;acc: 0.165 ;iou_acc: 0.225 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.738 ;acc: 0.145 ;iou_acc: 0.235 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 3.168 ;acc: 0.105 ;iou_acc: 0.210 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.441 ;Test accuracy 0.192 ;IOU accuracy: 0.295 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 1.840 ;acc: 0.315 ;iou: 0.440 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 1.569 ;acc: 0.400 ;iou: 0.500 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 3.403 ;acc: 0.125 ;iou: 0.230 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 1.519 ;acc: 0.345 ;iou: 0.490 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.529 ;acc: 0.245 ;iou: 0.305 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.156 ;acc: 0.260 ;iou: 0.370 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.433 ;Train accuracy: 0.241 ;IOU accuracy: 0.335 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 1.392 ;acc: 0.475 ;iou_acc: 0.610 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.855 ;acc: 0.290 ;iou_acc: 0.395 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.128 ;acc: 0.195 ;iou_acc: 0.300 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.438 ;acc: 0.165 ;iou_acc: 0.225 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.738 ;acc: 0.130 ;iou_acc: 0.240 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.167 ;acc: 0.095 ;iou_acc: 0.155 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.442 ;Test accuracy 0.193 ;IOU accuracy: 0.294 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.541 ;acc: 0.225 ;iou: 0.315 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 3.572 ;acc: 0.115 ;iou: 0.210 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 1.915 ;acc: 0.330 ;iou: 0.440 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 1.938 ;acc: 0.325 ;iou: 0.415 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.335 ;acc: 0.265 ;iou: 0.385 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 1.599 ;acc: 0.395 ;iou: 0.490 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.430 ;Train accuracy: 0.247 ;IOU accuracy: 0.342 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 1.393 ;acc: 0.485 ;iou_acc: 0.630 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.860 ;acc: 0.305 ;iou_acc: 0.415 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.119 ;acc: 0.220 ;iou_acc: 0.310 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.437 ;acc: 0.130 ;iou_acc: 0.185 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.742 ;acc: 0.120 ;iou_acc: 0.260 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.165 ;acc: 0.125 ;iou_acc: 0.225 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.442 ;Test accuracy 0.194 ;IOU accuracy: 0.294 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.519 ;acc: 0.210 ;iou: 0.315 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.547 ;acc: 0.365 ;iou: 0.485 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 2.575 ;acc: 0.255 ;iou: 0.320 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.890 ;acc: 0.290 ;iou: 0.395 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 2.090 ;acc: 0.300 ;iou: 0.415 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 2.151 ;acc: 0.295 ;iou: 0.350 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.426 ;Train accuracy: 0.257 ;IOU accuracy: 0.352 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.395 ;acc: 0.515 ;iou_acc: 0.665 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.864 ;acc: 0.285 ;iou_acc: 0.410 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.126 ;acc: 0.205 ;iou_acc: 0.330 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.448 ;acc: 0.135 ;iou_acc: 0.210 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.741 ;acc: 0.165 ;iou_acc: 0.235 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 3.168 ;acc: 0.085 ;iou_acc: 0.175 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.445 ;Test accuracy 0.194 ;IOU accuracy: 0.292 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 2.141 ;acc: 0.270 ;iou: 0.365 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 2.588 ;acc: 0.220 ;iou: 0.295 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 2.768 ;acc: 0.220 ;iou: 0.310 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.397 ;acc: 0.465 ;iou: 0.605 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 2.177 ;acc: 0.270 ;iou: 0.370 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 2.759 ;acc: 0.190 ;iou: 0.315 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.422 ;Train accuracy: 0.270 ;IOU accuracy: 0.364 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.399 ;acc: 0.460 ;iou_acc: 0.620 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.871 ;acc: 0.300 ;iou_acc: 0.405 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.130 ;acc: 0.180 ;iou_acc: 0.315 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.445 ;acc: 0.135 ;iou_acc: 0.195 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.742 ;acc: 0.145 ;iou_acc: 0.215 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.165 ;acc: 0.105 ;iou_acc: 0.190 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.447 ;Test accuracy 0.195 ;IOU accuracy: 0.294 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.394 ;acc: 0.455 ;iou: 0.610 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 2.070 ;acc: 0.315 ;iou: 0.405 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 2.748 ;acc: 0.195 ;iou: 0.285 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.868 ;acc: 0.305 ;iou: 0.395 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 3.399 ;acc: 0.160 ;iou: 0.230 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 3.213 ;acc: 0.175 ;iou: 0.270 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.416 ;Train accuracy: 0.281 ;IOU accuracy: 0.373 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.401 ;acc: 0.435 ;iou_acc: 0.585 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.867 ;acc: 0.280 ;iou_acc: 0.410 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.126 ;acc: 0.210 ;iou_acc: 0.345 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.450 ;acc: 0.130 ;iou_acc: 0.175 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.742 ;acc: 0.155 ;iou_acc: 0.260 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.177 ;acc: 0.080 ;iou_acc: 0.190 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.449 ;Test accuracy 0.196 ;IOU accuracy: 0.299 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 2.934 ;acc: 0.205 ;iou: 0.295 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 3.299 ;acc: 0.175 ;iou: 0.265 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 2.347 ;acc: 0.225 ;iou: 0.320 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.599 ;acc: 0.460 ;iou: 0.555 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 2.171 ;acc: 0.285 ;iou: 0.420 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.513 ;acc: 0.425 ;iou: 0.520 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.411 ;Train accuracy: 0.289 ;IOU accuracy: 0.381 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.405 ;acc: 0.500 ;iou_acc: 0.645 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.867 ;acc: 0.255 ;iou_acc: 0.395 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.132 ;acc: 0.185 ;iou_acc: 0.300 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.455 ;acc: 0.135 ;iou_acc: 0.205 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.740 ;acc: 0.160 ;iou_acc: 0.260 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.171 ;acc: 0.085 ;iou_acc: 0.190 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.451 ;Test accuracy 0.195 ;IOU accuracy: 0.293 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 2.802 ;acc: 0.280 ;iou: 0.350 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.838 ;acc: 0.430 ;iou: 0.505 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 2.177 ;acc: 0.340 ;iou: 0.440 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.552 ;acc: 0.425 ;iou: 0.565 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.938 ;acc: 0.350 ;iou: 0.420 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.540 ;acc: 0.440 ;iou: 0.525 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.406 ;Train accuracy: 0.299 ;IOU accuracy: 0.389 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.406 ;acc: 0.460 ;iou_acc: 0.625 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.870 ;acc: 0.285 ;iou_acc: 0.415 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.137 ;acc: 0.180 ;iou_acc: 0.315 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.444 ;acc: 0.155 ;iou_acc: 0.210 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.735 ;acc: 0.160 ;iou_acc: 0.285 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.174 ;acc: 0.105 ;iou_acc: 0.190 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.452 ;Test accuracy 0.194 ;IOU accuracy: 0.294 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 2.407 ;acc: 0.275 ;iou: 0.370 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 3.274 ;acc: 0.245 ;iou: 0.315 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 2.526 ;acc: 0.250 ;iou: 0.360 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.511 ;acc: 0.485 ;iou: 0.560 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.544 ;acc: 0.410 ;iou: 0.535 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 2.779 ;acc: 0.265 ;iou: 0.340 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.400 ;Train accuracy: 0.305 ;IOU accuracy: 0.395 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.410 ;acc: 0.465 ;iou_acc: 0.620 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.876 ;acc: 0.255 ;iou_acc: 0.410 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.150 ;acc: 0.180 ;iou_acc: 0.310 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.452 ;acc: 0.150 ;iou_acc: 0.225 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.743 ;acc: 0.150 ;iou_acc: 0.270 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.171 ;acc: 0.105 ;iou_acc: 0.215 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.457 ;Test accuracy 0.196 ;IOU accuracy: 0.298 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 2.433 ;acc: 0.320 ;iou: 0.370 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 3.630 ;acc: 0.155 ;iou: 0.240 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 3.095 ;acc: 0.185 ;iou: 0.280 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 2.721 ;acc: 0.250 ;iou: 0.320 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 3.060 ;acc: 0.195 ;iou: 0.260 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.789 ;acc: 0.345 ;iou: 0.435 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.394 ;Train accuracy: 0.314 ;IOU accuracy: 0.405 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.411 ;acc: 0.450 ;iou_acc: 0.615 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.871 ;acc: 0.265 ;iou_acc: 0.395 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.127 ;acc: 0.230 ;iou_acc: 0.355 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.443 ;acc: 0.125 ;iou_acc: 0.190 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.735 ;acc: 0.165 ;iou_acc: 0.280 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.178 ;acc: 0.100 ;iou_acc: 0.235 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.458 ;Test accuracy 0.195 ;IOU accuracy: 0.300 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 3.673 ;acc: 0.200 ;iou: 0.340 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 2.337 ;acc: 0.325 ;iou: 0.415 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.506 ;acc: 0.410 ;iou: 0.515 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.779 ;acc: 0.370 ;iou: 0.445 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 2.304 ;acc: 0.300 ;iou: 0.405 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 2.949 ;acc: 0.270 ;iou: 0.350 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.390 ;Train accuracy: 0.316 ;IOU accuracy: 0.406 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.421 ;acc: 0.435 ;iou_acc: 0.600 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.870 ;acc: 0.295 ;iou_acc: 0.430 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.136 ;acc: 0.225 ;iou_acc: 0.350 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.443 ;acc: 0.185 ;iou_acc: 0.255 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.746 ;acc: 0.155 ;iou_acc: 0.255 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.160 ;acc: 0.115 ;iou_acc: 0.220 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.459 ;Test accuracy 0.199 ;IOU accuracy: 0.304 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.799 ;acc: 0.380 ;iou: 0.460 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 2.120 ;acc: 0.350 ;iou: 0.415 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 2.290 ;acc: 0.335 ;iou: 0.410 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.488 ;acc: 0.465 ;iou: 0.535 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 3.013 ;acc: 0.205 ;iou: 0.285 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 2.441 ;acc: 0.295 ;iou: 0.355 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.384 ;Train accuracy: 0.323 ;IOU accuracy: 0.413 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.418 ;acc: 0.480 ;iou_acc: 0.620 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.857 ;acc: 0.285 ;iou_acc: 0.415 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.156 ;acc: 0.195 ;iou_acc: 0.305 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.451 ;acc: 0.160 ;iou_acc: 0.240 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.731 ;acc: 0.170 ;iou_acc: 0.265 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.167 ;acc: 0.100 ;iou_acc: 0.200 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.458 ;Test accuracy 0.199 ;IOU accuracy: 0.304 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 3.352 ;acc: 0.155 ;iou: 0.215 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 2.062 ;acc: 0.390 ;iou: 0.475 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 2.115 ;acc: 0.380 ;iou: 0.470 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 2.071 ;acc: 0.360 ;iou: 0.465 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 3.290 ;acc: 0.175 ;iou: 0.270 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 2.130 ;acc: 0.300 ;iou: 0.390 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.378 ;Train accuracy: 0.330 ;IOU accuracy: 0.421 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.418 ;acc: 0.420 ;iou_acc: 0.605 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.868 ;acc: 0.325 ;iou_acc: 0.440 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.135 ;acc: 0.225 ;iou_acc: 0.315 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.442 ;acc: 0.165 ;iou_acc: 0.230 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.734 ;acc: 0.170 ;iou_acc: 0.275 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.169 ;acc: 0.120 ;iou_acc: 0.225 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.457 ;Test accuracy 0.202 ;IOU accuracy: 0.306 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 2.708 ;acc: 0.270 ;iou: 0.365 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 3.618 ;acc: 0.215 ;iou: 0.300 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.406 ;acc: 0.555 ;iou: 0.705 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 2.497 ;acc: 0.300 ;iou: 0.405 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 3.031 ;acc: 0.290 ;iou: 0.400 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 2.710 ;acc: 0.240 ;iou: 0.300 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.370 ;Train accuracy: 0.336 ;IOU accuracy: 0.427 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.418 ;acc: 0.475 ;iou_acc: 0.645 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.865 ;acc: 0.315 ;iou_acc: 0.435 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.124 ;acc: 0.275 ;iou_acc: 0.390 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.432 ;acc: 0.175 ;iou_acc: 0.265 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.712 ;acc: 0.210 ;iou_acc: 0.280 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.180 ;acc: 0.105 ;iou_acc: 0.180 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.456 ;Test accuracy 0.207 ;IOU accuracy: 0.310 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 2.976 ;acc: 0.210 ;iou: 0.295 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.853 ;acc: 0.460 ;iou: 0.565 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 2.299 ;acc: 0.360 ;iou: 0.460 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 2.467 ;acc: 0.325 ;iou: 0.430 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 2.418 ;acc: 0.310 ;iou: 0.410 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 2.132 ;acc: 0.355 ;iou: 0.435 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.362 ;Train accuracy: 0.345 ;IOU accuracy: 0.436 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.429 ;acc: 0.465 ;iou_acc: 0.650 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.861 ;acc: 0.320 ;iou_acc: 0.440 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.139 ;acc: 0.210 ;iou_acc: 0.330 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.429 ;acc: 0.170 ;iou_acc: 0.280 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.723 ;acc: 0.150 ;iou_acc: 0.250 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.145 ;acc: 0.100 ;iou_acc: 0.200 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.448 ;Test accuracy 0.212 ;IOU accuracy: 0.317 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 1.997 ;acc: 0.435 ;iou: 0.495 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 2.003 ;acc: 0.475 ;iou: 0.540 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 2.079 ;acc: 0.420 ;iou: 0.480 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 2.472 ;acc: 0.320 ;iou: 0.415 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.537 ;acc: 0.515 ;iou: 0.590 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 3.520 ;acc: 0.185 ;iou: 0.320 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.350 ;Train accuracy: 0.356 ;IOU accuracy: 0.445 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.429 ;acc: 0.435 ;iou_acc: 0.610 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.874 ;acc: 0.290 ;iou_acc: 0.445 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.144 ;acc: 0.230 ;iou_acc: 0.375 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.397 ;acc: 0.145 ;iou_acc: 0.260 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.718 ;acc: 0.160 ;iou_acc: 0.260 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.166 ;acc: 0.110 ;iou_acc: 0.205 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.451 ;Test accuracy 0.215 ;IOU accuracy: 0.327 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 3.030 ;acc: 0.220 ;iou: 0.285 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 1.430 ;acc: 0.490 ;iou: 0.565 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 2.613 ;acc: 0.310 ;iou: 0.400 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 3.504 ;acc: 0.200 ;iou: 0.325 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 2.125 ;acc: 0.405 ;iou: 0.460 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 1.513 ;acc: 0.475 ;iou: 0.560 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.340 ;Train accuracy: 0.360 ;IOU accuracy: 0.452 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.436 ;acc: 0.465 ;iou_acc: 0.635 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.859 ;acc: 0.360 ;iou_acc: 0.480 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.128 ;acc: 0.240 ;iou_acc: 0.390 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.397 ;acc: 0.135 ;iou_acc: 0.230 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.707 ;acc: 0.180 ;iou_acc: 0.310 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.150 ;acc: 0.110 ;iou_acc: 0.220 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.447 ;Test accuracy 0.222 ;IOU accuracy: 0.334 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 1.441 ;acc: 0.520 ;iou: 0.615 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 2.853 ;acc: 0.240 ;iou: 0.340 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 2.764 ;acc: 0.290 ;iou: 0.400 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 2.979 ;acc: 0.265 ;iou: 0.375 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 3.819 ;acc: 0.120 ;iou: 0.250 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 1.419 ;acc: 0.490 ;iou: 0.660 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.327 ;Train accuracy: 0.371 ;IOU accuracy: 0.462 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.442 ;acc: 0.495 ;iou_acc: 0.665 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.843 ;acc: 0.320 ;iou_acc: 0.405 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.120 ;acc: 0.270 ;iou_acc: 0.400 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.375 ;acc: 0.230 ;iou_acc: 0.325 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.707 ;acc: 0.190 ;iou_acc: 0.280 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.122 ;acc: 0.120 ;iou_acc: 0.205 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.434 ;Test accuracy 0.227 ;IOU accuracy: 0.337 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 2.382 ;acc: 0.380 ;iou: 0.480 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 2.084 ;acc: 0.445 ;iou: 0.525 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 2.459 ;acc: 0.350 ;iou: 0.460 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 1.733 ;acc: 0.495 ;iou: 0.590 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 1.840 ;acc: 0.425 ;iou: 0.525 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 2.834 ;acc: 0.285 ;iou: 0.380 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.316 ;Train accuracy: 0.375 ;IOU accuracy: 0.465 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.450 ;acc: 0.480 ;iou_acc: 0.655 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.847 ;acc: 0.420 ;iou_acc: 0.530 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.096 ;acc: 0.315 ;iou_acc: 0.435 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.360 ;acc: 0.205 ;iou_acc: 0.270 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.677 ;acc: 0.210 ;iou_acc: 0.325 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.102 ;acc: 0.150 ;iou_acc: 0.240 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.426 ;Test accuracy 0.235 ;IOU accuracy: 0.347 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 1.749 ;acc: 0.430 ;iou: 0.520 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 1.736 ;acc: 0.435 ;iou: 0.545 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 1.723 ;acc: 0.450 ;iou: 0.540 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 1.424 ;acc: 0.570 ;iou: 0.740 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 2.098 ;acc: 0.465 ;iou: 0.560 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 2.733 ;acc: 0.310 ;iou: 0.370 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.305 ;Train accuracy: 0.383 ;IOU accuracy: 0.473 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.451 ;acc: 0.510 ;iou_acc: 0.665 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.845 ;acc: 0.390 ;iou_acc: 0.500 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.096 ;acc: 0.285 ;iou_acc: 0.400 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.343 ;acc: 0.250 ;iou_acc: 0.335 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.677 ;acc: 0.235 ;iou_acc: 0.290 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.075 ;acc: 0.140 ;iou_acc: 0.235 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.421 ;Test accuracy 0.243 ;IOU accuracy: 0.350 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 1.741 ;acc: 0.435 ;iou: 0.505 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 1.429 ;acc: 0.555 ;iou: 0.645 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 3.306 ;acc: 0.275 ;iou: 0.365 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 1.765 ;acc: 0.455 ;iou: 0.510 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 3.035 ;acc: 0.280 ;iou: 0.385 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 2.289 ;acc: 0.365 ;iou: 0.450 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.295 ;Train accuracy: 0.388 ;IOU accuracy: 0.477 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.469 ;acc: 0.500 ;iou_acc: 0.670 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.871 ;acc: 0.330 ;iou_acc: 0.465 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.115 ;acc: 0.280 ;iou_acc: 0.390 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.336 ;acc: 0.210 ;iou_acc: 0.310 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.681 ;acc: 0.215 ;iou_acc: 0.310 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.091 ;acc: 0.150 ;iou_acc: 0.245 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.435 ;Test accuracy 0.242 ;IOU accuracy: 0.353 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 1.759 ;acc: 0.485 ;iou: 0.550 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 1.673 ;acc: 0.460 ;iou: 0.525 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 2.392 ;acc: 0.350 ;iou: 0.455 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 2.324 ;acc: 0.430 ;iou: 0.525 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 2.885 ;acc: 0.320 ;iou: 0.400 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 1.546 ;acc: 0.515 ;iou: 0.585 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.285 ;Train accuracy: 0.398 ;IOU accuracy: 0.487 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.468 ;acc: 0.500 ;iou_acc: 0.660 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.837 ;acc: 0.365 ;iou_acc: 0.465 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.098 ;acc: 0.280 ;iou_acc: 0.430 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.338 ;acc: 0.265 ;iou_acc: 0.345 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.671 ;acc: 0.205 ;iou_acc: 0.285 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.064 ;acc: 0.155 ;iou_acc: 0.270 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.422 ;Test accuracy 0.250 ;IOU accuracy: 0.361 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 2.329 ;acc: 0.395 ;iou: 0.475 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 1.970 ;acc: 0.455 ;iou: 0.555 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 2.449 ;acc: 0.355 ;iou: 0.420 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 1.404 ;acc: 0.600 ;iou: 0.665 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 2.137 ;acc: 0.405 ;iou: 0.465 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 3.529 ;acc: 0.205 ;iou: 0.300 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.273 ;Train accuracy: 0.404 ;IOU accuracy: 0.493 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.480 ;acc: 0.550 ;iou_acc: 0.695 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.856 ;acc: 0.315 ;iou_acc: 0.440 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.083 ;acc: 0.290 ;iou_acc: 0.420 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.317 ;acc: 0.260 ;iou_acc: 0.350 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.668 ;acc: 0.205 ;iou_acc: 0.275 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.055 ;acc: 0.150 ;iou_acc: 0.225 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.415 ;Test accuracy 0.255 ;IOU accuracy: 0.367 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 1.907 ;acc: 0.515 ;iou: 0.610 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 1.333 ;acc: 0.530 ;iou: 0.620 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 1.761 ;acc: 0.480 ;iou: 0.565 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 2.714 ;acc: 0.360 ;iou: 0.445 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 2.725 ;acc: 0.345 ;iou: 0.445 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 1.427 ;acc: 0.560 ;iou: 0.600 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.261 ;Train accuracy: 0.413 ;IOU accuracy: 0.500 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.477 ;acc: 0.525 ;iou_acc: 0.680 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.818 ;acc: 0.380 ;iou_acc: 0.495 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.058 ;acc: 0.305 ;iou_acc: 0.420 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.340 ;acc: 0.200 ;iou_acc: 0.310 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.655 ;acc: 0.245 ;iou_acc: 0.360 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.068 ;acc: 0.165 ;iou_acc: 0.260 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.413 ;Test accuracy 0.255 ;IOU accuracy: 0.365 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 2.264 ;acc: 0.430 ;iou: 0.495 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 1.422 ;acc: 0.555 ;iou: 0.695 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 3.035 ;acc: 0.295 ;iou: 0.370 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 3.040 ;acc: 0.270 ;iou: 0.365 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 2.784 ;acc: 0.350 ;iou: 0.435 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 1.672 ;acc: 0.490 ;iou: 0.580 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.247 ;Train accuracy: 0.423 ;IOU accuracy: 0.509 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.499 ;acc: 0.550 ;iou_acc: 0.705 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.806 ;acc: 0.385 ;iou_acc: 0.495 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.070 ;acc: 0.360 ;iou_acc: 0.470 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.317 ;acc: 0.230 ;iou_acc: 0.315 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.663 ;acc: 0.215 ;iou_acc: 0.310 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.062 ;acc: 0.165 ;iou_acc: 0.260 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.407 ;Test accuracy 0.268 ;IOU accuracy: 0.376 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 1.336 ;acc: 0.535 ;iou: 0.590 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 2.851 ;acc: 0.335 ;iou: 0.450 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 2.257 ;acc: 0.405 ;iou: 0.465 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 2.627 ;acc: 0.330 ;iou: 0.410 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 2.518 ;acc: 0.370 ;iou: 0.435 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 1.694 ;acc: 0.510 ;iou: 0.570 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.232 ;Train accuracy: 0.432 ;IOU accuracy: 0.517 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.545 ;acc: 0.550 ;iou_acc: 0.705 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.858 ;acc: 0.335 ;iou_acc: 0.465 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.033 ;acc: 0.365 ;iou_acc: 0.490 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.266 ;acc: 0.260 ;iou_acc: 0.355 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.632 ;acc: 0.210 ;iou_acc: 0.295 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.055 ;acc: 0.150 ;iou_acc: 0.205 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.402 ;Test accuracy 0.268 ;IOU accuracy: 0.377 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 2.573 ;acc: 0.380 ;iou: 0.450 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 1.645 ;acc: 0.545 ;iou: 0.615 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 2.618 ;acc: 0.355 ;iou: 0.470 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 1.479 ;acc: 0.585 ;iou: 0.740 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 2.379 ;acc: 0.420 ;iou: 0.475 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 2.132 ;acc: 0.410 ;iou: 0.515 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.214 ;Train accuracy: 0.441 ;IOU accuracy: 0.525 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.536 ;acc: 0.565 ;iou_acc: 0.715 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.804 ;acc: 0.380 ;iou_acc: 0.490 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.011 ;acc: 0.350 ;iou_acc: 0.465 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.255 ;acc: 0.285 ;iou_acc: 0.360 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.609 ;acc: 0.240 ;iou_acc: 0.310 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.028 ;acc: 0.155 ;iou_acc: 0.250 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.387 ;Test accuracy 0.285 ;IOU accuracy: 0.389 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 2.954 ;acc: 0.285 ;iou: 0.370 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 2.140 ;acc: 0.460 ;iou: 0.535 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 1.576 ;acc: 0.525 ;iou: 0.600 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 1.377 ;acc: 0.585 ;iou: 0.710 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 1.935 ;acc: 0.500 ;iou: 0.570 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 2.141 ;acc: 0.395 ;iou: 0.520 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.196 ;Train accuracy: 0.453 ;IOU accuracy: 0.536 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.560 ;acc: 0.590 ;iou_acc: 0.710 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.810 ;acc: 0.400 ;iou_acc: 0.510 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.016 ;acc: 0.370 ;iou_acc: 0.515 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.247 ;acc: 0.255 ;iou_acc: 0.345 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.623 ;acc: 0.195 ;iou_acc: 0.285 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.027 ;acc: 0.160 ;iou_acc: 0.265 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.383 ;Test accuracy 0.286 ;IOU accuracy: 0.392 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 2.451 ;acc: 0.465 ;iou: 0.550 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 1.613 ;acc: 0.550 ;iou: 0.640 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 2.005 ;acc: 0.450 ;iou: 0.515 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 1.340 ;acc: 0.635 ;iou: 0.695 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 3.161 ;acc: 0.285 ;iou: 0.320 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 1.841 ;acc: 0.575 ;iou: 0.635 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.176 ;Train accuracy: 0.461 ;IOU accuracy: 0.544 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.661 ;acc: 0.620 ;iou_acc: 0.765 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.798 ;acc: 0.390 ;iou_acc: 0.495 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.971 ;acc: 0.410 ;iou_acc: 0.560 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.197 ;acc: 0.290 ;iou_acc: 0.375 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.642 ;acc: 0.265 ;iou_acc: 0.360 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.996 ;acc: 0.180 ;iou_acc: 0.285 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.380 ;Test accuracy 0.298 ;IOU accuracy: 0.403 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 1.578 ;acc: 0.590 ;iou: 0.695 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 1.316 ;acc: 0.620 ;iou: 0.710 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 2.637 ;acc: 0.420 ;iou: 0.510 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 1.341 ;acc: 0.630 ;iou: 0.705 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 2.776 ;acc: 0.340 ;iou: 0.440 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 2.406 ;acc: 0.435 ;iou: 0.515 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.162 ;Train accuracy: 0.470 ;IOU accuracy: 0.551 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.575 ;acc: 0.605 ;iou_acc: 0.760 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.758 ;acc: 0.425 ;iou_acc: 0.535 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.006 ;acc: 0.330 ;iou_acc: 0.515 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.190 ;acc: 0.305 ;iou_acc: 0.385 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.594 ;acc: 0.230 ;iou_acc: 0.330 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.999 ;acc: 0.185 ;iou_acc: 0.280 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.355 ;Test accuracy 0.301 ;IOU accuracy: 0.405 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 2.460 ;acc: 0.450 ;iou: 0.515 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 1.762 ;acc: 0.570 ;iou: 0.665 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 1.305 ;acc: 0.595 ;iou: 0.660 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 2.032 ;acc: 0.480 ;iou: 0.535 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 2.074 ;acc: 0.460 ;iou: 0.525 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 2.553 ;acc: 0.390 ;iou: 0.495 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.144 ;Train accuracy: 0.479 ;IOU accuracy: 0.560 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.604 ;acc: 0.645 ;iou_acc: 0.790 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.788 ;acc: 0.430 ;iou_acc: 0.520 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.987 ;acc: 0.350 ;iou_acc: 0.525 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.146 ;acc: 0.325 ;iou_acc: 0.400 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.577 ;acc: 0.265 ;iou_acc: 0.375 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.995 ;acc: 0.195 ;iou_acc: 0.320 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.353 ;Test accuracy 0.312 ;IOU accuracy: 0.416 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 2.483 ;acc: 0.460 ;iou: 0.520 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 2.419 ;acc: 0.410 ;iou: 0.515 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 2.301 ;acc: 0.425 ;iou: 0.515 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 1.948 ;acc: 0.465 ;iou: 0.540 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 3.306 ;acc: 0.290 ;iou: 0.345 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 1.578 ;acc: 0.615 ;iou: 0.775 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.128 ;Train accuracy: 0.487 ;IOU accuracy: 0.567 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.670 ;acc: 0.580 ;iou_acc: 0.765 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.800 ;acc: 0.420 ;iou_acc: 0.535 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.016 ;acc: 0.350 ;iou_acc: 0.505 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.166 ;acc: 0.325 ;iou_acc: 0.415 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.586 ;acc: 0.280 ;iou_acc: 0.390 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.968 ;acc: 0.190 ;iou_acc: 0.320 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.348 ;Test accuracy 0.308 ;IOU accuracy: 0.415 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 2.382 ;acc: 0.470 ;iou: 0.540 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 2.887 ;acc: 0.350 ;iou: 0.460 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 1.621 ;acc: 0.595 ;iou: 0.675 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 2.011 ;acc: 0.500 ;iou: 0.565 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 1.228 ;acc: 0.680 ;iou: 0.735 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 3.270 ;acc: 0.280 ;iou: 0.355 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.114 ;Train accuracy: 0.493 ;IOU accuracy: 0.573 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.753 ;acc: 0.660 ;iou_acc: 0.820 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.796 ;acc: 0.435 ;iou_acc: 0.545 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 1.967 ;acc: 0.360 ;iou_acc: 0.500 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.152 ;acc: 0.345 ;iou_acc: 0.425 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.583 ;acc: 0.245 ;iou_acc: 0.375 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 2.987 ;acc: 0.175 ;iou_acc: 0.290 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.352 ;Test accuracy 0.319 ;IOU accuracy: 0.425 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 2.126 ;acc: 0.445 ;iou: 0.530 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 1.658 ;acc: 0.605 ;iou: 0.715 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 1.894 ;acc: 0.530 ;iou: 0.600 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 2.127 ;acc: 0.515 ;iou: 0.590 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0450 ;B loss: 1.593 ;acc: 0.535 ;iou: 0.625 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0450 ;B loss: 2.535 ;acc: 0.415 ;iou: 0.490 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.102 ;Train accuracy: 0.497 ;IOU accuracy: 0.576 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.735 ;acc: 0.660 ;iou_acc: 0.800 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.804 ;acc: 0.425 ;iou_acc: 0.555 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.984 ;acc: 0.420 ;iou_acc: 0.560 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.159 ;acc: 0.305 ;iou_acc: 0.405 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.559 ;acc: 0.295 ;iou_acc: 0.370 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.980 ;acc: 0.210 ;iou_acc: 0.315 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.350 ;Test accuracy 0.323 ;IOU accuracy: 0.429 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0450 ;B loss: 1.428 ;acc: 0.710 ;iou: 0.770 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0450 ;B loss: 3.200 ;acc: 0.300 ;iou: 0.410 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0450 ;B loss: 2.230 ;acc: 0.505 ;iou: 0.580 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0450 ;B loss: 2.583 ;acc: 0.415 ;iou: 0.505 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0450 ;B loss: 3.433 ;acc: 0.265 ;iou: 0.360 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0450 ;B loss: 2.380 ;acc: 0.425 ;iou: 0.505 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.082 ;Train accuracy: 0.503 ;IOU accuracy: 0.583 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.689 ;acc: 0.615 ;iou_acc: 0.770 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.790 ;acc: 0.425 ;iou_acc: 0.545 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.975 ;acc: 0.355 ;iou_acc: 0.475 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.200 ;acc: 0.290 ;iou_acc: 0.400 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.563 ;acc: 0.260 ;iou_acc: 0.385 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.976 ;acc: 0.210 ;iou_acc: 0.315 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.345 ;Test accuracy 0.320 ;IOU accuracy: 0.426 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0450 ;B loss: 2.704 ;acc: 0.390 ;iou: 0.465 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0450 ;B loss: 2.261 ;acc: 0.480 ;iou: 0.555 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0450 ;B loss: 1.949 ;acc: 0.485 ;iou: 0.560 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0450 ;B loss: 2.886 ;acc: 0.350 ;iou: 0.410 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0450 ;B loss: 2.599 ;acc: 0.425 ;iou: 0.485 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0450 ;B loss: 1.318 ;acc: 0.555 ;iou: 0.645 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.072 ;Train accuracy: 0.508 ;IOU accuracy: 0.588 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.775 ;acc: 0.690 ;iou_acc: 0.820 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.832 ;acc: 0.425 ;iou_acc: 0.535 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.948 ;acc: 0.360 ;iou_acc: 0.515 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.164 ;acc: 0.335 ;iou_acc: 0.430 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.597 ;acc: 0.285 ;iou_acc: 0.385 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.971 ;acc: 0.220 ;iou_acc: 0.360 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.361 ;Test accuracy 0.325 ;IOU accuracy: 0.431 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0450 ;B loss: 2.017 ;acc: 0.530 ;iou: 0.605 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0450 ;B loss: 1.303 ;acc: 0.665 ;iou: 0.725 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0450 ;B loss: 1.463 ;acc: 0.610 ;iou: 0.690 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0450 ;B loss: 2.645 ;acc: 0.400 ;iou: 0.485 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0450 ;B loss: 2.394 ;acc: 0.470 ;iou: 0.540 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0450 ;B loss: 1.642 ;acc: 0.635 ;iou: 0.750 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.060 ;Train accuracy: 0.514 ;IOU accuracy: 0.593 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.774 ;acc: 0.700 ;iou_acc: 0.820 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.834 ;acc: 0.420 ;iou_acc: 0.545 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.966 ;acc: 0.430 ;iou_acc: 0.560 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.159 ;acc: 0.320 ;iou_acc: 0.435 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.565 ;acc: 0.300 ;iou_acc: 0.405 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.972 ;acc: 0.195 ;iou_acc: 0.285 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.355 ;Test accuracy 0.324 ;IOU accuracy: 0.432 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0450 ;B loss: 1.223 ;acc: 0.655 ;iou: 0.730 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0450 ;B loss: 1.446 ;acc: 0.570 ;iou: 0.640 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0450 ;B loss: 2.201 ;acc: 0.550 ;iou: 0.630 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0450 ;B loss: 1.339 ;acc: 0.580 ;iou: 0.665 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0450 ;B loss: 1.645 ;acc: 0.560 ;iou: 0.635 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0450 ;B loss: 1.581 ;acc: 0.625 ;iou: 0.700 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.050 ;Train accuracy: 0.519 ;IOU accuracy: 0.597 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.749 ;acc: 0.660 ;iou_acc: 0.805 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.825 ;acc: 0.425 ;iou_acc: 0.555 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.999 ;acc: 0.385 ;iou_acc: 0.535 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.179 ;acc: 0.270 ;iou_acc: 0.380 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.560 ;acc: 0.295 ;iou_acc: 0.405 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.979 ;acc: 0.190 ;iou_acc: 0.285 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.358 ;Test accuracy 0.324 ;IOU accuracy: 0.433 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0450 ;B loss: 1.243 ;acc: 0.670 ;iou: 0.740 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0450 ;B loss: 2.783 ;acc: 0.410 ;iou: 0.465 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0450 ;B loss: 1.266 ;acc: 0.615 ;iou: 0.675 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0450 ;B loss: 2.421 ;acc: 0.455 ;iou: 0.535 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0450 ;B loss: 2.795 ;acc: 0.400 ;iou: 0.515 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0450 ;B loss: 2.279 ;acc: 0.505 ;iou: 0.590 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.040 ;Train accuracy: 0.523 ;IOU accuracy: 0.602 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.776 ;acc: 0.665 ;iou_acc: 0.810 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.814 ;acc: 0.440 ;iou_acc: 0.560 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.989 ;acc: 0.390 ;iou_acc: 0.535 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.180 ;acc: 0.305 ;iou_acc: 0.435 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.576 ;acc: 0.275 ;iou_acc: 0.375 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.972 ;acc: 0.200 ;iou_acc: 0.305 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.349 ;Test accuracy 0.324 ;IOU accuracy: 0.429 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0450 ;B loss: 1.806 ;acc: 0.615 ;iou: 0.705 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0450 ;B loss: 2.915 ;acc: 0.385 ;iou: 0.460 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0450 ;B loss: 2.046 ;acc: 0.515 ;iou: 0.580 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0450 ;B loss: 1.374 ;acc: 0.675 ;iou: 0.760 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0450 ;B loss: 1.656 ;acc: 0.605 ;iou: 0.685 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0450 ;B loss: 2.415 ;acc: 0.460 ;iou: 0.540 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.031 ;Train accuracy: 0.531 ;IOU accuracy: 0.608 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.740 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.823 ;acc: 0.430 ;iou_acc: 0.540 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.027 ;acc: 0.375 ;iou_acc: 0.515 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.198 ;acc: 0.280 ;iou_acc: 0.400 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.541 ;acc: 0.330 ;iou_acc: 0.425 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.990 ;acc: 0.180 ;iou_acc: 0.305 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.356 ;Test accuracy 0.323 ;IOU accuracy: 0.429 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0450 ;B loss: 3.411 ;acc: 0.235 ;iou: 0.320 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0450 ;B loss: 1.947 ;acc: 0.525 ;iou: 0.610 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0450 ;B loss: 2.125 ;acc: 0.545 ;iou: 0.590 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0450 ;B loss: 2.112 ;acc: 0.570 ;iou: 0.635 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0450 ;B loss: 2.565 ;acc: 0.425 ;iou: 0.525 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0450 ;B loss: 2.002 ;acc: 0.515 ;iou: 0.595 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.019 ;Train accuracy: 0.536 ;IOU accuracy: 0.612 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.750 ;acc: 0.655 ;iou_acc: 0.795 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.806 ;acc: 0.435 ;iou_acc: 0.525 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.997 ;acc: 0.400 ;iou_acc: 0.555 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.192 ;acc: 0.325 ;iou_acc: 0.415 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.562 ;acc: 0.300 ;iou_acc: 0.400 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.999 ;acc: 0.220 ;iou_acc: 0.320 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.355 ;Test accuracy 0.328 ;IOU accuracy: 0.434 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0450 ;B loss: 3.126 ;acc: 0.320 ;iou: 0.400 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0450 ;B loss: 1.950 ;acc: 0.635 ;iou: 0.700 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0450 ;B loss: 2.555 ;acc: 0.470 ;iou: 0.560 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0450 ;B loss: 2.355 ;acc: 0.485 ;iou: 0.560 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0450 ;B loss: 2.117 ;acc: 0.540 ;iou: 0.570 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0450 ;B loss: 2.404 ;acc: 0.485 ;iou: 0.540 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.008 ;Train accuracy: 0.541 ;IOU accuracy: 0.617 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.947 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.850 ;acc: 0.465 ;iou_acc: 0.565 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.996 ;acc: 0.380 ;iou_acc: 0.540 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.215 ;acc: 0.320 ;iou_acc: 0.445 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.606 ;acc: 0.325 ;iou_acc: 0.425 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.036 ;acc: 0.205 ;iou_acc: 0.340 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.387 ;Test accuracy 0.335 ;IOU accuracy: 0.441 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0450 ;B loss: 2.167 ;acc: 0.545 ;iou: 0.630 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0450 ;B loss: 2.049 ;acc: 0.565 ;iou: 0.620 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0450 ;B loss: 1.701 ;acc: 0.650 ;iou: 0.705 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0450 ;B loss: 2.004 ;acc: 0.540 ;iou: 0.615 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0450 ;B loss: 2.031 ;acc: 0.550 ;iou: 0.620 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0450 ;B loss: 2.547 ;acc: 0.460 ;iou: 0.500 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.999 ;Train accuracy: 0.548 ;IOU accuracy: 0.622 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.794 ;acc: 0.675 ;iou_acc: 0.810 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.813 ;acc: 0.435 ;iou_acc: 0.560 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.997 ;acc: 0.385 ;iou_acc: 0.525 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.213 ;acc: 0.305 ;iou_acc: 0.440 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.545 ;acc: 0.335 ;iou_acc: 0.435 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.950 ;acc: 0.240 ;iou_acc: 0.320 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.357 ;Test accuracy 0.331 ;IOU accuracy: 0.438 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0450 ;B loss: 3.010 ;acc: 0.350 ;iou: 0.440 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0450 ;B loss: 1.642 ;acc: 0.540 ;iou: 0.675 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0450 ;B loss: 2.287 ;acc: 0.475 ;iou: 0.570 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0450 ;B loss: 2.329 ;acc: 0.480 ;iou: 0.545 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0450 ;B loss: 1.582 ;acc: 0.640 ;iou: 0.700 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0450 ;B loss: 1.954 ;acc: 0.505 ;iou: 0.625 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.987 ;Train accuracy: 0.553 ;IOU accuracy: 0.627 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.847 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.812 ;acc: 0.455 ;iou_acc: 0.560 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.028 ;acc: 0.365 ;iou_acc: 0.510 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.218 ;acc: 0.300 ;iou_acc: 0.455 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.561 ;acc: 0.295 ;iou_acc: 0.385 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.988 ;acc: 0.205 ;iou_acc: 0.315 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.363 ;Test accuracy 0.330 ;IOU accuracy: 0.438 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0450 ;B loss: 1.837 ;acc: 0.585 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0450 ;B loss: 3.331 ;acc: 0.275 ;iou: 0.355 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0450 ;B loss: 1.488 ;acc: 0.655 ;iou: 0.745 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0450 ;B loss: 2.651 ;acc: 0.430 ;iou: 0.500 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0450 ;B loss: 1.873 ;acc: 0.560 ;iou: 0.625 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0450 ;B loss: 1.349 ;acc: 0.625 ;iou: 0.690 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.977 ;Train accuracy: 0.556 ;IOU accuracy: 0.630 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.882 ;acc: 0.695 ;iou_acc: 0.830 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.818 ;acc: 0.485 ;iou_acc: 0.570 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.988 ;acc: 0.410 ;iou_acc: 0.570 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.228 ;acc: 0.295 ;iou_acc: 0.410 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.543 ;acc: 0.320 ;iou_acc: 0.405 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.981 ;acc: 0.210 ;iou_acc: 0.330 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.368 ;Test accuracy 0.333 ;IOU accuracy: 0.440 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0450 ;B loss: 1.560 ;acc: 0.565 ;iou: 0.710 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0450 ;B loss: 2.256 ;acc: 0.555 ;iou: 0.620 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0450 ;B loss: 1.887 ;acc: 0.555 ;iou: 0.600 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0450 ;B loss: 1.542 ;acc: 0.650 ;iou: 0.710 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0450 ;B loss: 2.888 ;acc: 0.380 ;iou: 0.450 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0450 ;B loss: 1.614 ;acc: 0.560 ;iou: 0.690 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.964 ;Train accuracy: 0.565 ;IOU accuracy: 0.638 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.923 ;acc: 0.715 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.840 ;acc: 0.460 ;iou_acc: 0.565 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.991 ;acc: 0.390 ;iou_acc: 0.555 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.208 ;acc: 0.345 ;iou_acc: 0.475 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.565 ;acc: 0.325 ;iou_acc: 0.425 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.962 ;acc: 0.175 ;iou_acc: 0.300 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.379 ;Test accuracy 0.341 ;IOU accuracy: 0.449 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0450 ;B loss: 1.309 ;acc: 0.700 ;iou: 0.745 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0450 ;B loss: 1.415 ;acc: 0.640 ;iou: 0.715 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0450 ;B loss: 2.437 ;acc: 0.520 ;iou: 0.565 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0450 ;B loss: 1.110 ;acc: 0.675 ;iou: 0.725 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0450 ;B loss: 1.356 ;acc: 0.730 ;iou: 0.790 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0450 ;B loss: 1.988 ;acc: 0.520 ;iou: 0.605 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.953 ;Train accuracy: 0.570 ;IOU accuracy: 0.641 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.926 ;acc: 0.705 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.835 ;acc: 0.465 ;iou_acc: 0.570 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.963 ;acc: 0.405 ;iou_acc: 0.550 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.180 ;acc: 0.345 ;iou_acc: 0.465 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.506 ;acc: 0.330 ;iou_acc: 0.420 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.982 ;acc: 0.230 ;iou_acc: 0.310 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.371 ;Test accuracy 0.343 ;IOU accuracy: 0.451 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0450 ;B loss: 2.494 ;acc: 0.455 ;iou: 0.545 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0450 ;B loss: 1.500 ;acc: 0.645 ;iou: 0.710 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0450 ;B loss: 2.366 ;acc: 0.520 ;iou: 0.555 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0450 ;B loss: 1.308 ;acc: 0.710 ;iou: 0.770 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0450 ;B loss: 1.193 ;acc: 0.665 ;iou: 0.720 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0450 ;B loss: 2.916 ;acc: 0.375 ;iou: 0.435 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.940 ;Train accuracy: 0.578 ;IOU accuracy: 0.650 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.889 ;acc: 0.700 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.809 ;acc: 0.455 ;iou_acc: 0.560 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.996 ;acc: 0.390 ;iou_acc: 0.530 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.245 ;acc: 0.330 ;iou_acc: 0.460 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.550 ;acc: 0.335 ;iou_acc: 0.430 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.989 ;acc: 0.205 ;iou_acc: 0.310 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.373 ;Test accuracy 0.339 ;IOU accuracy: 0.446 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0450 ;B loss: 1.844 ;acc: 0.575 ;iou: 0.640 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0450 ;B loss: 1.246 ;acc: 0.735 ;iou: 0.780 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0450 ;B loss: 1.555 ;acc: 0.700 ;iou: 0.755 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0450 ;B loss: 2.258 ;acc: 0.585 ;iou: 0.645 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0450 ;B loss: 1.823 ;acc: 0.560 ;iou: 0.625 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0450 ;B loss: 2.488 ;acc: 0.515 ;iou: 0.570 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.929 ;Train accuracy: 0.583 ;IOU accuracy: 0.653 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.961 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.835 ;acc: 0.430 ;iou_acc: 0.540 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.009 ;acc: 0.390 ;iou_acc: 0.550 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.206 ;acc: 0.320 ;iou_acc: 0.455 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.519 ;acc: 0.295 ;iou_acc: 0.395 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.038 ;acc: 0.195 ;iou_acc: 0.295 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.394 ;Test accuracy 0.340 ;IOU accuracy: 0.451 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0450 ;B loss: 1.511 ;acc: 0.675 ;iou: 0.745 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0450 ;B loss: 2.410 ;acc: 0.575 ;iou: 0.625 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0450 ;B loss: 1.935 ;acc: 0.600 ;iou: 0.680 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0450 ;B loss: 1.537 ;acc: 0.625 ;iou: 0.695 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0450 ;B loss: 1.577 ;acc: 0.605 ;iou: 0.735 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0450 ;B loss: 1.641 ;acc: 0.635 ;iou: 0.680 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.915 ;Train accuracy: 0.589 ;IOU accuracy: 0.659 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 2.000 ;acc: 0.695 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.842 ;acc: 0.455 ;iou_acc: 0.565 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.963 ;acc: 0.400 ;iou_acc: 0.555 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.218 ;acc: 0.370 ;iou_acc: 0.475 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.513 ;acc: 0.360 ;iou_acc: 0.450 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.964 ;acc: 0.230 ;iou_acc: 0.355 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.386 ;Test accuracy 0.349 ;IOU accuracy: 0.459 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 50 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14851 ;lr: 0.0450 ;B loss: 1.155 ;acc: 0.680 ;iou: 0.755 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14901 ;lr: 0.0450 ;B loss: 2.449 ;acc: 0.575 ;iou: 0.620 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14951 ;lr: 0.0450 ;B loss: 2.677 ;acc: 0.490 ;iou: 0.555 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15001 ;lr: 0.0450 ;B loss: 1.230 ;acc: 0.700 ;iou: 0.760 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15051 ;lr: 0.0450 ;B loss: 1.619 ;acc: 0.680 ;iou: 0.730 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15101 ;lr: 0.0450 ;B loss: 2.352 ;acc: 0.535 ;iou: 0.630 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.905 ;Train accuracy: 0.595 ;IOU accuracy: 0.665 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 50\n",
      "batch: 0 ;B loss: 2.045 ;acc: 0.710 ;iou_acc: 0.840 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.866 ;acc: 0.470 ;iou_acc: 0.565 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.996 ;acc: 0.420 ;iou_acc: 0.560 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.212 ;acc: 0.355 ;iou_acc: 0.475 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.504 ;acc: 0.335 ;iou_acc: 0.435 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.962 ;acc: 0.160 ;iou_acc: 0.320 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.399 ;Test accuracy 0.349 ;IOU accuracy: 0.456 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 51 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15148 ;lr: 0.0450 ;B loss: 1.189 ;acc: 0.635 ;iou: 0.700 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15198 ;lr: 0.0450 ;B loss: 1.623 ;acc: 0.695 ;iou: 0.750 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15248 ;lr: 0.0450 ;B loss: 1.270 ;acc: 0.740 ;iou: 0.810 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15298 ;lr: 0.0450 ;B loss: 1.655 ;acc: 0.685 ;iou: 0.750 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15348 ;lr: 0.0450 ;B loss: 2.955 ;acc: 0.395 ;iou: 0.455 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15398 ;lr: 0.0450 ;B loss: 1.346 ;acc: 0.670 ;iou: 0.750 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.888 ;Train accuracy: 0.600 ;IOU accuracy: 0.669 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 51\n",
      "batch: 0 ;B loss: 1.973 ;acc: 0.695 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.896 ;acc: 0.435 ;iou_acc: 0.540 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.030 ;acc: 0.425 ;iou_acc: 0.575 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.248 ;acc: 0.335 ;iou_acc: 0.475 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.508 ;acc: 0.305 ;iou_acc: 0.425 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.029 ;acc: 0.210 ;iou_acc: 0.345 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.389 ;Test accuracy 0.350 ;IOU accuracy: 0.460 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 52 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15445 ;lr: 0.0450 ;B loss: 1.282 ;acc: 0.715 ;iou: 0.795 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15495 ;lr: 0.0450 ;B loss: 1.634 ;acc: 0.535 ;iou: 0.660 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15545 ;lr: 0.0450 ;B loss: 1.222 ;acc: 0.625 ;iou: 0.740 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15595 ;lr: 0.0450 ;B loss: 1.853 ;acc: 0.615 ;iou: 0.705 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15645 ;lr: 0.0450 ;B loss: 2.284 ;acc: 0.545 ;iou: 0.595 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15695 ;lr: 0.0450 ;B loss: 1.217 ;acc: 0.670 ;iou: 0.735 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.876 ;Train accuracy: 0.607 ;IOU accuracy: 0.676 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 52\n",
      "batch: 0 ;B loss: 1.888 ;acc: 0.680 ;iou_acc: 0.815 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.854 ;acc: 0.450 ;iou_acc: 0.560 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.028 ;acc: 0.440 ;iou_acc: 0.620 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.223 ;acc: 0.335 ;iou_acc: 0.485 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.448 ;acc: 0.325 ;iou_acc: 0.425 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 3.010 ;acc: 0.205 ;iou_acc: 0.360 ;time: 0:00:44\n",
      "\n",
      "*BTrain: False ;Test loss: 2.380 ;Test accuracy 0.342 ;IOU accuracy: 0.455 ;Time: 0:00:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 53 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15742 ;lr: 0.0450 ;B loss: 2.139 ;acc: 0.580 ;iou: 0.625 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15792 ;lr: 0.0450 ;B loss: 1.257 ;acc: 0.715 ;iou: 0.790 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15842 ;lr: 0.0450 ;B loss: 1.160 ;acc: 0.665 ;iou: 0.735 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15892 ;lr: 0.0450 ;B loss: 1.776 ;acc: 0.675 ;iou: 0.720 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15942 ;lr: 0.0450 ;B loss: 1.432 ;acc: 0.695 ;iou: 0.770 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15992 ;lr: 0.0450 ;B loss: 1.190 ;acc: 0.630 ;iou: 0.725 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.860 ;Train accuracy: 0.615 ;IOU accuracy: 0.684 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 53\n",
      "batch: 0 ;B loss: 2.014 ;acc: 0.685 ;iou_acc: 0.820 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.861 ;acc: 0.485 ;iou_acc: 0.605 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.985 ;acc: 0.420 ;iou_acc: 0.580 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.224 ;acc: 0.360 ;iou_acc: 0.460 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.502 ;acc: 0.325 ;iou_acc: 0.435 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.958 ;acc: 0.235 ;iou_acc: 0.315 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.389 ;Test accuracy 0.358 ;IOU accuracy: 0.470 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 54 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16039 ;lr: 0.0450 ;B loss: 1.983 ;acc: 0.635 ;iou: 0.695 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16089 ;lr: 0.0450 ;B loss: 1.201 ;acc: 0.670 ;iou: 0.735 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16139 ;lr: 0.0450 ;B loss: 1.468 ;acc: 0.720 ;iou: 0.760 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16189 ;lr: 0.0450 ;B loss: 3.123 ;acc: 0.375 ;iou: 0.495 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16239 ;lr: 0.0450 ;B loss: 1.522 ;acc: 0.725 ;iou: 0.770 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16289 ;lr: 0.0450 ;B loss: 1.675 ;acc: 0.525 ;iou: 0.645 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.846 ;Train accuracy: 0.621 ;IOU accuracy: 0.689 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 54\n",
      "batch: 0 ;B loss: 2.029 ;acc: 0.725 ;iou_acc: 0.845 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.849 ;acc: 0.485 ;iou_acc: 0.570 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.040 ;acc: 0.395 ;iou_acc: 0.565 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.220 ;acc: 0.355 ;iou_acc: 0.490 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.498 ;acc: 0.330 ;iou_acc: 0.435 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 3.003 ;acc: 0.215 ;iou_acc: 0.350 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.390 ;Test accuracy 0.359 ;IOU accuracy: 0.472 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 55 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16336 ;lr: 0.0450 ;B loss: 1.414 ;acc: 0.780 ;iou: 0.805 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16386 ;lr: 0.0450 ;B loss: 1.707 ;acc: 0.705 ;iou: 0.745 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16436 ;lr: 0.0450 ;B loss: 2.036 ;acc: 0.605 ;iou: 0.680 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16486 ;lr: 0.0450 ;B loss: 2.484 ;acc: 0.510 ;iou: 0.585 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16536 ;lr: 0.0450 ;B loss: 2.213 ;acc: 0.590 ;iou: 0.635 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16586 ;lr: 0.0450 ;B loss: 1.669 ;acc: 0.640 ;iou: 0.685 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.829 ;Train accuracy: 0.630 ;IOU accuracy: 0.697 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 55\n",
      "batch: 0 ;B loss: 2.105 ;acc: 0.720 ;iou_acc: 0.865 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.858 ;acc: 0.500 ;iou_acc: 0.620 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.029 ;acc: 0.405 ;iou_acc: 0.565 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.214 ;acc: 0.360 ;iou_acc: 0.495 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.514 ;acc: 0.335 ;iou_acc: 0.425 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.016 ;acc: 0.235 ;iou_acc: 0.370 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.401 ;Test accuracy 0.369 ;IOU accuracy: 0.478 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 56 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16633 ;lr: 0.0450 ;B loss: 1.467 ;acc: 0.735 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16683 ;lr: 0.0450 ;B loss: 1.638 ;acc: 0.560 ;iou: 0.680 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16733 ;lr: 0.0450 ;B loss: 2.451 ;acc: 0.550 ;iou: 0.625 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16783 ;lr: 0.0450 ;B loss: 2.153 ;acc: 0.570 ;iou: 0.655 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16833 ;lr: 0.0450 ;B loss: 1.145 ;acc: 0.695 ;iou: 0.750 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16883 ;lr: 0.0450 ;B loss: 1.177 ;acc: 0.705 ;iou: 0.760 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.811 ;Train accuracy: 0.635 ;IOU accuracy: 0.702 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 56\n",
      "batch: 0 ;B loss: 2.245 ;acc: 0.735 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.862 ;acc: 0.480 ;iou_acc: 0.580 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.000 ;acc: 0.455 ;iou_acc: 0.595 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.212 ;acc: 0.380 ;iou_acc: 0.510 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.546 ;acc: 0.360 ;iou_acc: 0.455 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.938 ;acc: 0.260 ;iou_acc: 0.380 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.416 ;Test accuracy 0.374 ;IOU accuracy: 0.487 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 57 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16930 ;lr: 0.0450 ;B loss: 1.655 ;acc: 0.720 ;iou: 0.765 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16980 ;lr: 0.0450 ;B loss: 2.047 ;acc: 0.615 ;iou: 0.680 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17030 ;lr: 0.0450 ;B loss: 1.242 ;acc: 0.720 ;iou: 0.785 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17080 ;lr: 0.0450 ;B loss: 2.639 ;acc: 0.480 ;iou: 0.560 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17130 ;lr: 0.0450 ;B loss: 1.437 ;acc: 0.735 ;iou: 0.800 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17180 ;lr: 0.0450 ;B loss: 1.705 ;acc: 0.560 ;iou: 0.685 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 1.794 ;Train accuracy: 0.642 ;IOU accuracy: 0.709 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 57\n",
      "batch: 0 ;B loss: 2.000 ;acc: 0.695 ;iou_acc: 0.825 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.851 ;acc: 0.440 ;iou_acc: 0.565 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.996 ;acc: 0.430 ;iou_acc: 0.565 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.202 ;acc: 0.340 ;iou_acc: 0.470 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.430 ;acc: 0.345 ;iou_acc: 0.460 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.046 ;acc: 0.195 ;iou_acc: 0.335 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.379 ;Test accuracy 0.364 ;IOU accuracy: 0.475 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 58 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17227 ;lr: 0.0450 ;B loss: 2.010 ;acc: 0.685 ;iou: 0.735 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17277 ;lr: 0.0450 ;B loss: 2.377 ;acc: 0.585 ;iou: 0.685 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17327 ;lr: 0.0450 ;B loss: 1.431 ;acc: 0.650 ;iou: 0.720 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17377 ;lr: 0.0450 ;B loss: 2.283 ;acc: 0.605 ;iou: 0.665 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17427 ;lr: 0.0450 ;B loss: 2.033 ;acc: 0.660 ;iou: 0.695 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17477 ;lr: 0.0450 ;B loss: 1.829 ;acc: 0.640 ;iou: 0.710 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.780 ;Train accuracy: 0.649 ;IOU accuracy: 0.715 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 58\n",
      "batch: 0 ;B loss: 2.289 ;acc: 0.740 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.866 ;acc: 0.540 ;iou_acc: 0.635 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.043 ;acc: 0.450 ;iou_acc: 0.600 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.248 ;acc: 0.380 ;iou_acc: 0.510 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.504 ;acc: 0.375 ;iou_acc: 0.490 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.000 ;acc: 0.220 ;iou_acc: 0.340 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.430 ;Test accuracy 0.382 ;IOU accuracy: 0.494 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 59 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17524 ;lr: 0.0450 ;B loss: 1.329 ;acc: 0.690 ;iou: 0.775 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17574 ;lr: 0.0450 ;B loss: 1.599 ;acc: 0.700 ;iou: 0.730 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17624 ;lr: 0.0450 ;B loss: 1.406 ;acc: 0.720 ;iou: 0.790 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17674 ;lr: 0.0450 ;B loss: 2.216 ;acc: 0.645 ;iou: 0.700 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17724 ;lr: 0.0450 ;B loss: 1.181 ;acc: 0.760 ;iou: 0.845 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17774 ;lr: 0.0450 ;B loss: 1.418 ;acc: 0.705 ;iou: 0.765 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.761 ;Train accuracy: 0.656 ;IOU accuracy: 0.722 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 59\n",
      "batch: 0 ;B loss: 2.178 ;acc: 0.715 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.944 ;acc: 0.480 ;iou_acc: 0.600 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.086 ;acc: 0.425 ;iou_acc: 0.580 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.213 ;acc: 0.350 ;iou_acc: 0.505 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.556 ;acc: 0.280 ;iou_acc: 0.415 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.000 ;acc: 0.260 ;iou_acc: 0.400 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.440 ;Test accuracy 0.370 ;IOU accuracy: 0.481 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 60 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17821 ;lr: 0.0450 ;B loss: 2.339 ;acc: 0.550 ;iou: 0.620 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17871 ;lr: 0.0450 ;B loss: 1.343 ;acc: 0.730 ;iou: 0.805 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17921 ;lr: 0.0450 ;B loss: 1.806 ;acc: 0.505 ;iou: 0.650 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17971 ;lr: 0.0450 ;B loss: 1.488 ;acc: 0.750 ;iou: 0.785 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18021 ;lr: 0.0450 ;B loss: 1.583 ;acc: 0.670 ;iou: 0.715 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18071 ;lr: 0.0450 ;B loss: 1.697 ;acc: 0.555 ;iou: 0.695 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.744 ;Train accuracy: 0.662 ;IOU accuracy: 0.727 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 60\n",
      "batch: 0 ;B loss: 2.283 ;acc: 0.730 ;iou_acc: 0.860 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.973 ;acc: 0.530 ;iou_acc: 0.645 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.106 ;acc: 0.440 ;iou_acc: 0.590 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.250 ;acc: 0.365 ;iou_acc: 0.505 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.549 ;acc: 0.345 ;iou_acc: 0.450 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.928 ;acc: 0.235 ;iou_acc: 0.335 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.447 ;Test accuracy 0.387 ;IOU accuracy: 0.499 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 61 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18118 ;lr: 0.0450 ;B loss: 1.615 ;acc: 0.530 ;iou: 0.710 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18168 ;lr: 0.0450 ;B loss: 1.040 ;acc: 0.795 ;iou: 0.850 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18218 ;lr: 0.0450 ;B loss: 1.321 ;acc: 0.725 ;iou: 0.770 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18268 ;lr: 0.0450 ;B loss: 1.181 ;acc: 0.660 ;iou: 0.740 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18318 ;lr: 0.0450 ;B loss: 2.239 ;acc: 0.600 ;iou: 0.660 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18368 ;lr: 0.0450 ;B loss: 1.372 ;acc: 0.810 ;iou: 0.860 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.728 ;Train accuracy: 0.669 ;IOU accuracy: 0.733 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 61\n",
      "batch: 0 ;B loss: 2.325 ;acc: 0.750 ;iou_acc: 0.855 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.881 ;acc: 0.525 ;iou_acc: 0.655 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.075 ;acc: 0.445 ;iou_acc: 0.625 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.225 ;acc: 0.390 ;iou_acc: 0.510 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.540 ;acc: 0.360 ;iou_acc: 0.470 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.952 ;acc: 0.235 ;iou_acc: 0.350 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.456 ;Test accuracy 0.386 ;IOU accuracy: 0.499 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 62 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18415 ;lr: 0.0450 ;B loss: 1.070 ;acc: 0.750 ;iou: 0.800 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18465 ;lr: 0.0450 ;B loss: 1.530 ;acc: 0.655 ;iou: 0.740 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18515 ;lr: 0.0450 ;B loss: 2.455 ;acc: 0.580 ;iou: 0.635 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18565 ;lr: 0.0450 ;B loss: 1.409 ;acc: 0.735 ;iou: 0.795 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18615 ;lr: 0.0450 ;B loss: 1.594 ;acc: 0.735 ;iou: 0.780 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18665 ;lr: 0.0450 ;B loss: 1.233 ;acc: 0.730 ;iou: 0.780 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.710 ;Train accuracy: 0.674 ;IOU accuracy: 0.738 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 62\n",
      "batch: 0 ;B loss: 2.278 ;acc: 0.770 ;iou_acc: 0.870 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.890 ;acc: 0.550 ;iou_acc: 0.680 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.053 ;acc: 0.460 ;iou_acc: 0.575 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.227 ;acc: 0.345 ;iou_acc: 0.490 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.457 ;acc: 0.375 ;iou_acc: 0.475 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.939 ;acc: 0.300 ;iou_acc: 0.420 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.434 ;Test accuracy 0.391 ;IOU accuracy: 0.502 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 63 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18712 ;lr: 0.0450 ;B loss: 1.115 ;acc: 0.705 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18762 ;lr: 0.0450 ;B loss: 1.907 ;acc: 0.680 ;iou: 0.720 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18812 ;lr: 0.0450 ;B loss: 2.285 ;acc: 0.590 ;iou: 0.645 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18862 ;lr: 0.0450 ;B loss: 2.649 ;acc: 0.500 ;iou: 0.585 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18912 ;lr: 0.0450 ;B loss: 1.851 ;acc: 0.700 ;iou: 0.755 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18962 ;lr: 0.0450 ;B loss: 1.351 ;acc: 0.720 ;iou: 0.780 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.695 ;Train accuracy: 0.679 ;IOU accuracy: 0.743 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 63\n",
      "batch: 0 ;B loss: 2.372 ;acc: 0.745 ;iou_acc: 0.875 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.916 ;acc: 0.540 ;iou_acc: 0.635 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.052 ;acc: 0.475 ;iou_acc: 0.645 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.171 ;acc: 0.420 ;iou_acc: 0.550 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.527 ;acc: 0.375 ;iou_acc: 0.465 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.993 ;acc: 0.275 ;iou_acc: 0.405 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.460 ;Test accuracy 0.393 ;IOU accuracy: 0.504 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 64 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19009 ;lr: 0.0450 ;B loss: 1.293 ;acc: 0.810 ;iou: 0.850 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19059 ;lr: 0.0450 ;B loss: 1.137 ;acc: 0.740 ;iou: 0.810 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19109 ;lr: 0.0450 ;B loss: 1.700 ;acc: 0.720 ;iou: 0.805 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19159 ;lr: 0.0450 ;B loss: 1.365 ;acc: 0.750 ;iou: 0.820 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19209 ;lr: 0.0450 ;B loss: 1.165 ;acc: 0.775 ;iou: 0.825 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19259 ;lr: 0.0450 ;B loss: 1.913 ;acc: 0.675 ;iou: 0.755 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.675 ;Train accuracy: 0.686 ;IOU accuracy: 0.748 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 64\n",
      "batch: 0 ;B loss: 2.417 ;acc: 0.725 ;iou_acc: 0.865 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.988 ;acc: 0.525 ;iou_acc: 0.650 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.049 ;acc: 0.500 ;iou_acc: 0.650 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.288 ;acc: 0.405 ;iou_acc: 0.545 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.483 ;acc: 0.355 ;iou_acc: 0.460 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.011 ;acc: 0.245 ;iou_acc: 0.390 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.484 ;Test accuracy 0.393 ;IOU accuracy: 0.505 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 65 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19306 ;lr: 0.0450 ;B loss: 1.858 ;acc: 0.730 ;iou: 0.775 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19356 ;lr: 0.0450 ;B loss: 1.070 ;acc: 0.760 ;iou: 0.815 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19406 ;lr: 0.0450 ;B loss: 1.136 ;acc: 0.720 ;iou: 0.785 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19456 ;lr: 0.0450 ;B loss: 2.079 ;acc: 0.670 ;iou: 0.725 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19506 ;lr: 0.0450 ;B loss: 2.389 ;acc: 0.555 ;iou: 0.590 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19556 ;lr: 0.0450 ;B loss: 1.672 ;acc: 0.695 ;iou: 0.720 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.661 ;Train accuracy: 0.692 ;IOU accuracy: 0.754 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 65\n",
      "batch: 0 ;B loss: 2.428 ;acc: 0.745 ;iou_acc: 0.870 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.962 ;acc: 0.545 ;iou_acc: 0.690 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 1.986 ;acc: 0.495 ;iou_acc: 0.675 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.278 ;acc: 0.385 ;iou_acc: 0.535 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.494 ;acc: 0.380 ;iou_acc: 0.475 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.079 ;acc: 0.270 ;iou_acc: 0.410 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.472 ;Test accuracy 0.398 ;IOU accuracy: 0.512 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 66 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19603 ;lr: 0.0450 ;B loss: 1.718 ;acc: 0.760 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19653 ;lr: 0.0450 ;B loss: 2.080 ;acc: 0.690 ;iou: 0.735 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19703 ;lr: 0.0450 ;B loss: 1.989 ;acc: 0.690 ;iou: 0.755 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19753 ;lr: 0.0450 ;B loss: 1.225 ;acc: 0.710 ;iou: 0.780 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19803 ;lr: 0.0450 ;B loss: 1.746 ;acc: 0.570 ;iou: 0.715 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19853 ;lr: 0.0450 ;B loss: 1.329 ;acc: 0.750 ;iou: 0.825 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.646 ;Train accuracy: 0.696 ;IOU accuracy: 0.756 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 66\n",
      "batch: 0 ;B loss: 2.257 ;acc: 0.725 ;iou_acc: 0.845 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.997 ;acc: 0.520 ;iou_acc: 0.645 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.104 ;acc: 0.475 ;iou_acc: 0.625 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.275 ;acc: 0.395 ;iou_acc: 0.545 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.420 ;acc: 0.390 ;iou_acc: 0.500 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.011 ;acc: 0.310 ;iou_acc: 0.420 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.469 ;Test accuracy 0.391 ;IOU accuracy: 0.506 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 67 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19900 ;lr: 0.0450 ;B loss: 1.410 ;acc: 0.770 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19950 ;lr: 0.0450 ;B loss: 1.107 ;acc: 0.705 ;iou: 0.770 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20000 ;lr: 0.0450 ;B loss: 1.408 ;acc: 0.790 ;iou: 0.830 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20050 ;lr: 0.0405 ;B loss: 1.159 ;acc: 0.760 ;iou: 0.810 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20100 ;lr: 0.0405 ;B loss: 1.197 ;acc: 0.745 ;iou: 0.800 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20150 ;lr: 0.0405 ;B loss: 1.356 ;acc: 0.775 ;iou: 0.830 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.615 ;Train accuracy: 0.701 ;IOU accuracy: 0.761 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 67\n",
      "batch: 0 ;B loss: 2.197 ;acc: 0.710 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.885 ;acc: 0.530 ;iou_acc: 0.660 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.004 ;acc: 0.450 ;iou_acc: 0.605 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.224 ;acc: 0.430 ;iou_acc: 0.540 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.441 ;acc: 0.400 ;iou_acc: 0.520 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.058 ;acc: 0.320 ;iou_acc: 0.440 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.450 ;Test accuracy 0.388 ;IOU accuracy: 0.502 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 68 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20197 ;lr: 0.0405 ;B loss: 2.208 ;acc: 0.650 ;iou: 0.705 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20247 ;lr: 0.0405 ;B loss: 1.137 ;acc: 0.775 ;iou: 0.800 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20297 ;lr: 0.0405 ;B loss: 1.061 ;acc: 0.720 ;iou: 0.770 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20347 ;lr: 0.0405 ;B loss: 1.091 ;acc: 0.705 ;iou: 0.785 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20397 ;lr: 0.0405 ;B loss: 1.555 ;acc: 0.745 ;iou: 0.780 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20447 ;lr: 0.0405 ;B loss: 1.069 ;acc: 0.730 ;iou: 0.795 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.588 ;Train accuracy: 0.707 ;IOU accuracy: 0.766 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 68\n",
      "batch: 0 ;B loss: 2.412 ;acc: 0.765 ;iou_acc: 0.875 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.981 ;acc: 0.560 ;iou_acc: 0.700 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.121 ;acc: 0.470 ;iou_acc: 0.625 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.271 ;acc: 0.390 ;iou_acc: 0.510 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.481 ;acc: 0.375 ;iou_acc: 0.500 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.028 ;acc: 0.290 ;iou_acc: 0.415 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.512 ;Test accuracy 0.401 ;IOU accuracy: 0.514 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 69 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20494 ;lr: 0.0405 ;B loss: 1.514 ;acc: 0.750 ;iou: 0.800 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20544 ;lr: 0.0405 ;B loss: 1.219 ;acc: 0.765 ;iou: 0.820 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20594 ;lr: 0.0405 ;B loss: 1.548 ;acc: 0.775 ;iou: 0.800 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20644 ;lr: 0.0405 ;B loss: 1.047 ;acc: 0.665 ;iou: 0.795 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20694 ;lr: 0.0405 ;B loss: 2.047 ;acc: 0.720 ;iou: 0.780 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20744 ;lr: 0.0405 ;B loss: 1.965 ;acc: 0.665 ;iou: 0.715 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.582 ;Train accuracy: 0.708 ;IOU accuracy: 0.767 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 69\n",
      "batch: 0 ;B loss: 2.580 ;acc: 0.745 ;iou_acc: 0.865 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.026 ;acc: 0.585 ;iou_acc: 0.695 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.134 ;acc: 0.500 ;iou_acc: 0.645 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.377 ;acc: 0.395 ;iou_acc: 0.530 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.502 ;acc: 0.365 ;iou_acc: 0.460 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.076 ;acc: 0.315 ;iou_acc: 0.440 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.546 ;Test accuracy 0.400 ;IOU accuracy: 0.512 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 70 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20791 ;lr: 0.0405 ;B loss: 1.625 ;acc: 0.715 ;iou: 0.765 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20841 ;lr: 0.0405 ;B loss: 2.352 ;acc: 0.590 ;iou: 0.680 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20891 ;lr: 0.0405 ;B loss: 1.984 ;acc: 0.665 ;iou: 0.740 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20941 ;lr: 0.0405 ;B loss: 1.320 ;acc: 0.790 ;iou: 0.810 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20991 ;lr: 0.0405 ;B loss: 1.146 ;acc: 0.735 ;iou: 0.790 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21041 ;lr: 0.0405 ;B loss: 1.833 ;acc: 0.695 ;iou: 0.780 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.565 ;Train accuracy: 0.714 ;IOU accuracy: 0.773 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 70\n",
      "batch: 0 ;B loss: 2.418 ;acc: 0.730 ;iou_acc: 0.845 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.944 ;acc: 0.535 ;iou_acc: 0.675 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.121 ;acc: 0.465 ;iou_acc: 0.640 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.335 ;acc: 0.410 ;iou_acc: 0.540 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.510 ;acc: 0.355 ;iou_acc: 0.470 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.067 ;acc: 0.310 ;iou_acc: 0.450 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.508 ;Test accuracy 0.393 ;IOU accuracy: 0.509 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 71 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21088 ;lr: 0.0405 ;B loss: 1.873 ;acc: 0.725 ;iou: 0.790 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21138 ;lr: 0.0405 ;B loss: 1.373 ;acc: 0.735 ;iou: 0.775 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21188 ;lr: 0.0405 ;B loss: 1.358 ;acc: 0.815 ;iou: 0.850 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21238 ;lr: 0.0405 ;B loss: 1.397 ;acc: 0.775 ;iou: 0.835 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21288 ;lr: 0.0405 ;B loss: 1.552 ;acc: 0.820 ;iou: 0.840 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21338 ;lr: 0.0405 ;B loss: 2.047 ;acc: 0.695 ;iou: 0.765 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.552 ;Train accuracy: 0.716 ;IOU accuracy: 0.774 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 71\n",
      "batch: 0 ;B loss: 2.526 ;acc: 0.750 ;iou_acc: 0.865 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 2.025 ;acc: 0.580 ;iou_acc: 0.710 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.113 ;acc: 0.505 ;iou_acc: 0.665 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.279 ;acc: 0.415 ;iou_acc: 0.530 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.558 ;acc: 0.370 ;iou_acc: 0.495 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.145 ;acc: 0.270 ;iou_acc: 0.405 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.559 ;Test accuracy 0.406 ;IOU accuracy: 0.522 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 72 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21385 ;lr: 0.0405 ;B loss: 1.551 ;acc: 0.815 ;iou: 0.840 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21435 ;lr: 0.0405 ;B loss: 1.965 ;acc: 0.705 ;iou: 0.760 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21485 ;lr: 0.0405 ;B loss: 1.079 ;acc: 0.775 ;iou: 0.825 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21535 ;lr: 0.0405 ;B loss: 1.782 ;acc: 0.755 ;iou: 0.790 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21585 ;lr: 0.0405 ;B loss: 1.166 ;acc: 0.735 ;iou: 0.800 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21635 ;lr: 0.0405 ;B loss: 2.368 ;acc: 0.580 ;iou: 0.660 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.535 ;Train accuracy: 0.722 ;IOU accuracy: 0.779 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 72\n",
      "batch: 0 ;B loss: 2.651 ;acc: 0.745 ;iou_acc: 0.865 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.997 ;acc: 0.580 ;iou_acc: 0.700 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.115 ;acc: 0.480 ;iou_acc: 0.625 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.326 ;acc: 0.410 ;iou_acc: 0.545 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.537 ;acc: 0.380 ;iou_acc: 0.490 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.259 ;acc: 0.250 ;iou_acc: 0.390 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.596 ;Test accuracy 0.406 ;IOU accuracy: 0.519 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 73 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21682 ;lr: 0.0405 ;B loss: 2.160 ;acc: 0.640 ;iou: 0.715 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21732 ;lr: 0.0405 ;B loss: 2.432 ;acc: 0.540 ;iou: 0.595 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21782 ;lr: 0.0405 ;B loss: 1.063 ;acc: 0.755 ;iou: 0.790 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21832 ;lr: 0.0405 ;B loss: 1.126 ;acc: 0.700 ;iou: 0.775 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21882 ;lr: 0.0405 ;B loss: 1.892 ;acc: 0.740 ;iou: 0.770 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21932 ;lr: 0.0405 ;B loss: 1.486 ;acc: 0.765 ;iou: 0.800 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.522 ;Train accuracy: 0.724 ;IOU accuracy: 0.781 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 73\n",
      "batch: 0 ;B loss: 2.610 ;acc: 0.765 ;iou_acc: 0.880 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.121 ;acc: 0.585 ;iou_acc: 0.735 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.104 ;acc: 0.520 ;iou_acc: 0.650 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.285 ;acc: 0.435 ;iou_acc: 0.550 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.502 ;acc: 0.385 ;iou_acc: 0.485 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.147 ;acc: 0.335 ;iou_acc: 0.475 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.599 ;Test accuracy 0.410 ;IOU accuracy: 0.522 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 74 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21979 ;lr: 0.0405 ;B loss: 1.108 ;acc: 0.780 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22029 ;lr: 0.0405 ;B loss: 1.045 ;acc: 0.845 ;iou: 0.860 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22079 ;lr: 0.0405 ;B loss: 1.052 ;acc: 0.760 ;iou: 0.825 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22129 ;lr: 0.0405 ;B loss: 1.655 ;acc: 0.750 ;iou: 0.775 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22179 ;lr: 0.0405 ;B loss: 2.310 ;acc: 0.685 ;iou: 0.735 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22229 ;lr: 0.0405 ;B loss: 1.411 ;acc: 0.810 ;iou: 0.835 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.507 ;Train accuracy: 0.728 ;IOU accuracy: 0.784 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 74\n",
      "batch: 0 ;B loss: 2.577 ;acc: 0.740 ;iou_acc: 0.865 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.005 ;acc: 0.560 ;iou_acc: 0.710 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.200 ;acc: 0.420 ;iou_acc: 0.580 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.348 ;acc: 0.410 ;iou_acc: 0.555 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.571 ;acc: 0.385 ;iou_acc: 0.495 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.165 ;acc: 0.295 ;iou_acc: 0.420 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.624 ;Test accuracy 0.400 ;IOU accuracy: 0.514 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 75 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22276 ;lr: 0.0405 ;B loss: 2.037 ;acc: 0.660 ;iou: 0.730 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22326 ;lr: 0.0405 ;B loss: 1.244 ;acc: 0.760 ;iou: 0.840 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22376 ;lr: 0.0405 ;B loss: 1.739 ;acc: 0.495 ;iou: 0.645 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22426 ;lr: 0.0405 ;B loss: 1.018 ;acc: 0.715 ;iou: 0.790 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22476 ;lr: 0.0405 ;B loss: 1.205 ;acc: 0.810 ;iou: 0.855 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22526 ;lr: 0.0405 ;B loss: 1.065 ;acc: 0.705 ;iou: 0.770 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.499 ;Train accuracy: 0.727 ;IOU accuracy: 0.784 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 75\n",
      "batch: 0 ;B loss: 2.674 ;acc: 0.725 ;iou_acc: 0.855 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.090 ;acc: 0.580 ;iou_acc: 0.730 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.161 ;acc: 0.485 ;iou_acc: 0.610 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.343 ;acc: 0.465 ;iou_acc: 0.575 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.591 ;acc: 0.380 ;iou_acc: 0.475 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.198 ;acc: 0.270 ;iou_acc: 0.375 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.647 ;Test accuracy 0.407 ;IOU accuracy: 0.520 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 76 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22573 ;lr: 0.0405 ;B loss: 1.145 ;acc: 0.845 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22623 ;lr: 0.0405 ;B loss: 1.828 ;acc: 0.735 ;iou: 0.770 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22673 ;lr: 0.0405 ;B loss: 1.134 ;acc: 0.665 ;iou: 0.735 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22723 ;lr: 0.0405 ;B loss: 1.685 ;acc: 0.430 ;iou: 0.545 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22773 ;lr: 0.0405 ;B loss: 1.668 ;acc: 0.790 ;iou: 0.845 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22823 ;lr: 0.0405 ;B loss: 2.164 ;acc: 0.675 ;iou: 0.710 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.485 ;Train accuracy: 0.734 ;IOU accuracy: 0.788 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 76\n",
      "batch: 0 ;B loss: 2.552 ;acc: 0.755 ;iou_acc: 0.860 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.082 ;acc: 0.595 ;iou_acc: 0.720 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.208 ;acc: 0.450 ;iou_acc: 0.635 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.270 ;acc: 0.390 ;iou_acc: 0.505 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.492 ;acc: 0.435 ;iou_acc: 0.520 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.197 ;acc: 0.275 ;iou_acc: 0.420 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.603 ;Test accuracy 0.410 ;IOU accuracy: 0.524 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 77 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22870 ;lr: 0.0405 ;B loss: 1.360 ;acc: 0.825 ;iou: 0.860 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22920 ;lr: 0.0405 ;B loss: 1.645 ;acc: 0.750 ;iou: 0.770 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22970 ;lr: 0.0405 ;B loss: 1.194 ;acc: 0.800 ;iou: 0.830 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23020 ;lr: 0.0405 ;B loss: 1.758 ;acc: 0.765 ;iou: 0.795 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23070 ;lr: 0.0405 ;B loss: 1.130 ;acc: 0.805 ;iou: 0.855 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23120 ;lr: 0.0405 ;B loss: 0.965 ;acc: 0.705 ;iou: 0.765 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.466 ;Train accuracy: 0.737 ;IOU accuracy: 0.792 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 77\n",
      "batch: 0 ;B loss: 2.705 ;acc: 0.720 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.210 ;acc: 0.570 ;iou_acc: 0.715 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.242 ;acc: 0.470 ;iou_acc: 0.625 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.274 ;acc: 0.445 ;iou_acc: 0.545 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.546 ;acc: 0.420 ;iou_acc: 0.515 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.217 ;acc: 0.300 ;iou_acc: 0.445 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.671 ;Test accuracy 0.411 ;IOU accuracy: 0.525 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 78 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23167 ;lr: 0.0405 ;B loss: 1.060 ;acc: 0.835 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23217 ;lr: 0.0405 ;B loss: 1.058 ;acc: 0.835 ;iou: 0.885 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23267 ;lr: 0.0405 ;B loss: 1.341 ;acc: 0.805 ;iou: 0.840 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23317 ;lr: 0.0405 ;B loss: 1.572 ;acc: 0.765 ;iou: 0.810 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23367 ;lr: 0.0405 ;B loss: 1.965 ;acc: 0.695 ;iou: 0.740 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23417 ;lr: 0.0405 ;B loss: 1.624 ;acc: 0.770 ;iou: 0.815 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.457 ;Train accuracy: 0.739 ;IOU accuracy: 0.793 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 78\n",
      "batch: 0 ;B loss: 2.781 ;acc: 0.770 ;iou_acc: 0.900 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.149 ;acc: 0.545 ;iou_acc: 0.685 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.231 ;acc: 0.485 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.365 ;acc: 0.420 ;iou_acc: 0.540 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.599 ;acc: 0.380 ;iou_acc: 0.475 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.285 ;acc: 0.280 ;iou_acc: 0.390 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.687 ;Test accuracy 0.408 ;IOU accuracy: 0.521 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 79 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23464 ;lr: 0.0405 ;B loss: 1.666 ;acc: 0.780 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23514 ;lr: 0.0405 ;B loss: 0.980 ;acc: 0.675 ;iou: 0.740 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23564 ;lr: 0.0405 ;B loss: 1.330 ;acc: 0.805 ;iou: 0.840 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23614 ;lr: 0.0405 ;B loss: 1.629 ;acc: 0.750 ;iou: 0.785 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23664 ;lr: 0.0405 ;B loss: 2.088 ;acc: 0.710 ;iou: 0.750 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23714 ;lr: 0.0405 ;B loss: 1.847 ;acc: 0.760 ;iou: 0.810 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.449 ;Train accuracy: 0.741 ;IOU accuracy: 0.794 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 79\n",
      "batch: 0 ;B loss: 2.833 ;acc: 0.745 ;iou_acc: 0.875 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.230 ;acc: 0.570 ;iou_acc: 0.715 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.239 ;acc: 0.485 ;iou_acc: 0.615 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.308 ;acc: 0.455 ;iou_acc: 0.540 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.586 ;acc: 0.405 ;iou_acc: 0.500 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.354 ;acc: 0.285 ;iou_acc: 0.395 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.706 ;Test accuracy 0.413 ;IOU accuracy: 0.526 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 80 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23761 ;lr: 0.0405 ;B loss: 1.689 ;acc: 0.780 ;iou: 0.815 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23811 ;lr: 0.0405 ;B loss: 1.296 ;acc: 0.775 ;iou: 0.830 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23861 ;lr: 0.0405 ;B loss: 1.151 ;acc: 0.825 ;iou: 0.870 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23911 ;lr: 0.0405 ;B loss: 1.255 ;acc: 0.815 ;iou: 0.865 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23961 ;lr: 0.0405 ;B loss: 1.726 ;acc: 0.475 ;iou: 0.660 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24011 ;lr: 0.0405 ;B loss: 1.189 ;acc: 0.850 ;iou: 0.880 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.431 ;Train accuracy: 0.744 ;IOU accuracy: 0.797 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 80\n",
      "batch: 0 ;B loss: 2.865 ;acc: 0.755 ;iou_acc: 0.895 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.145 ;acc: 0.590 ;iou_acc: 0.695 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.248 ;acc: 0.465 ;iou_acc: 0.615 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.399 ;acc: 0.450 ;iou_acc: 0.590 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.555 ;acc: 0.405 ;iou_acc: 0.510 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 3.305 ;acc: 0.295 ;iou_acc: 0.435 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.707 ;Test accuracy 0.415 ;IOU accuracy: 0.528 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 81 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24058 ;lr: 0.0405 ;B loss: 1.116 ;acc: 0.815 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24108 ;lr: 0.0405 ;B loss: 0.985 ;acc: 0.810 ;iou: 0.845 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24158 ;lr: 0.0405 ;B loss: 2.278 ;acc: 0.620 ;iou: 0.665 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24208 ;lr: 0.0405 ;B loss: 1.583 ;acc: 0.750 ;iou: 0.775 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24258 ;lr: 0.0405 ;B loss: 0.954 ;acc: 0.760 ;iou: 0.825 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24308 ;lr: 0.0405 ;B loss: 1.659 ;acc: 0.785 ;iou: 0.810 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.416 ;Train accuracy: 0.748 ;IOU accuracy: 0.800 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 81\n",
      "batch: 0 ;B loss: 2.731 ;acc: 0.740 ;iou_acc: 0.880 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.115 ;acc: 0.590 ;iou_acc: 0.720 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.289 ;acc: 0.490 ;iou_acc: 0.620 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.466 ;acc: 0.415 ;iou_acc: 0.530 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.596 ;acc: 0.405 ;iou_acc: 0.520 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.415 ;acc: 0.275 ;iou_acc: 0.375 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.723 ;Test accuracy 0.411 ;IOU accuracy: 0.523 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 82 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24355 ;lr: 0.0405 ;B loss: 2.165 ;acc: 0.620 ;iou: 0.670 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24405 ;lr: 0.0405 ;B loss: 0.979 ;acc: 0.750 ;iou: 0.815 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24455 ;lr: 0.0405 ;B loss: 1.096 ;acc: 0.845 ;iou: 0.880 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24505 ;lr: 0.0405 ;B loss: 1.056 ;acc: 0.795 ;iou: 0.835 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24555 ;lr: 0.0405 ;B loss: 1.077 ;acc: 0.730 ;iou: 0.795 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24605 ;lr: 0.0405 ;B loss: 1.928 ;acc: 0.595 ;iou: 0.660 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.413 ;Train accuracy: 0.746 ;IOU accuracy: 0.799 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 82\n",
      "batch: 0 ;B loss: 2.667 ;acc: 0.690 ;iou_acc: 0.845 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.138 ;acc: 0.580 ;iou_acc: 0.760 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.253 ;acc: 0.475 ;iou_acc: 0.625 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.393 ;acc: 0.445 ;iou_acc: 0.565 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.567 ;acc: 0.325 ;iou_acc: 0.455 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.380 ;acc: 0.245 ;iou_acc: 0.360 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.698 ;Test accuracy 0.413 ;IOU accuracy: 0.527 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 83 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24652 ;lr: 0.0405 ;B loss: 2.512 ;acc: 0.470 ;iou: 0.565 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24702 ;lr: 0.0405 ;B loss: 1.513 ;acc: 0.785 ;iou: 0.830 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24752 ;lr: 0.0405 ;B loss: 0.993 ;acc: 0.845 ;iou: 0.880 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24802 ;lr: 0.0405 ;B loss: 1.360 ;acc: 0.830 ;iou: 0.865 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24852 ;lr: 0.0405 ;B loss: 1.204 ;acc: 0.775 ;iou: 0.810 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24902 ;lr: 0.0405 ;B loss: 1.495 ;acc: 0.835 ;iou: 0.890 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.393 ;Train accuracy: 0.751 ;IOU accuracy: 0.802 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 83\n",
      "batch: 0 ;B loss: 2.877 ;acc: 0.735 ;iou_acc: 0.875 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.250 ;acc: 0.560 ;iou_acc: 0.700 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.258 ;acc: 0.480 ;iou_acc: 0.650 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.425 ;acc: 0.460 ;iou_acc: 0.570 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.514 ;acc: 0.410 ;iou_acc: 0.515 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.341 ;acc: 0.275 ;iou_acc: 0.410 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.731 ;Test accuracy 0.416 ;IOU accuracy: 0.530 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 84 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24949 ;lr: 0.0405 ;B loss: 1.592 ;acc: 0.775 ;iou: 0.845 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24999 ;lr: 0.0405 ;B loss: 1.032 ;acc: 0.745 ;iou: 0.780 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25049 ;lr: 0.0405 ;B loss: 0.971 ;acc: 0.775 ;iou: 0.820 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25099 ;lr: 0.0405 ;B loss: 2.070 ;acc: 0.695 ;iou: 0.750 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25149 ;lr: 0.0405 ;B loss: 1.412 ;acc: 0.805 ;iou: 0.845 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25199 ;lr: 0.0405 ;B loss: 1.039 ;acc: 0.780 ;iou: 0.835 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.378 ;Train accuracy: 0.752 ;IOU accuracy: 0.803 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 84\n",
      "batch: 0 ;B loss: 2.828 ;acc: 0.760 ;iou_acc: 0.875 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.209 ;acc: 0.575 ;iou_acc: 0.690 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.329 ;acc: 0.515 ;iou_acc: 0.655 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.427 ;acc: 0.420 ;iou_acc: 0.525 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.576 ;acc: 0.405 ;iou_acc: 0.505 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.454 ;acc: 0.250 ;iou_acc: 0.360 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.744 ;Test accuracy 0.415 ;IOU accuracy: 0.527 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 85 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25246 ;lr: 0.0405 ;B loss: 0.912 ;acc: 0.750 ;iou: 0.795 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25296 ;lr: 0.0405 ;B loss: 1.500 ;acc: 0.815 ;iou: 0.840 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25346 ;lr: 0.0405 ;B loss: 0.988 ;acc: 0.810 ;iou: 0.840 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25396 ;lr: 0.0405 ;B loss: 0.956 ;acc: 0.785 ;iou: 0.815 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25446 ;lr: 0.0405 ;B loss: 1.701 ;acc: 0.780 ;iou: 0.820 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25496 ;lr: 0.0405 ;B loss: 1.825 ;acc: 0.725 ;iou: 0.780 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.368 ;Train accuracy: 0.754 ;IOU accuracy: 0.806 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 85\n",
      "batch: 0 ;B loss: 2.994 ;acc: 0.755 ;iou_acc: 0.860 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.096 ;acc: 0.615 ;iou_acc: 0.765 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.375 ;acc: 0.500 ;iou_acc: 0.650 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.442 ;acc: 0.470 ;iou_acc: 0.585 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.581 ;acc: 0.395 ;iou_acc: 0.505 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.362 ;acc: 0.310 ;iou_acc: 0.425 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.779 ;Test accuracy 0.420 ;IOU accuracy: 0.535 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 86 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25543 ;lr: 0.0405 ;B loss: 0.991 ;acc: 0.735 ;iou: 0.780 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25593 ;lr: 0.0405 ;B loss: 1.403 ;acc: 0.765 ;iou: 0.795 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25643 ;lr: 0.0405 ;B loss: 1.025 ;acc: 0.815 ;iou: 0.840 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25693 ;lr: 0.0405 ;B loss: 1.964 ;acc: 0.670 ;iou: 0.740 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25743 ;lr: 0.0405 ;B loss: 1.470 ;acc: 0.805 ;iou: 0.870 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25793 ;lr: 0.0405 ;B loss: 2.052 ;acc: 0.720 ;iou: 0.755 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.358 ;Train accuracy: 0.756 ;IOU accuracy: 0.807 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 86\n",
      "batch: 0 ;B loss: 2.950 ;acc: 0.765 ;iou_acc: 0.880 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.157 ;acc: 0.590 ;iou_acc: 0.720 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.301 ;acc: 0.490 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.536 ;acc: 0.435 ;iou_acc: 0.550 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.696 ;acc: 0.390 ;iou_acc: 0.480 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.479 ;acc: 0.270 ;iou_acc: 0.425 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.828 ;Test accuracy 0.412 ;IOU accuracy: 0.527 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 87 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25840 ;lr: 0.0405 ;B loss: 1.789 ;acc: 0.520 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25890 ;lr: 0.0405 ;B loss: 1.037 ;acc: 0.785 ;iou: 0.835 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25940 ;lr: 0.0405 ;B loss: 0.905 ;acc: 0.850 ;iou: 0.870 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25990 ;lr: 0.0405 ;B loss: 1.743 ;acc: 0.450 ;iou: 0.595 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26040 ;lr: 0.0405 ;B loss: 1.620 ;acc: 0.750 ;iou: 0.785 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26090 ;lr: 0.0405 ;B loss: 2.024 ;acc: 0.740 ;iou: 0.790 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.345 ;Train accuracy: 0.760 ;IOU accuracy: 0.810 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 87\n",
      "batch: 0 ;B loss: 2.986 ;acc: 0.740 ;iou_acc: 0.865 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.265 ;acc: 0.540 ;iou_acc: 0.710 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.340 ;acc: 0.510 ;iou_acc: 0.650 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.402 ;acc: 0.435 ;iou_acc: 0.565 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.626 ;acc: 0.420 ;iou_acc: 0.525 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.614 ;acc: 0.280 ;iou_acc: 0.410 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.821 ;Test accuracy 0.419 ;IOU accuracy: 0.533 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 88 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26137 ;lr: 0.0405 ;B loss: 2.044 ;acc: 0.710 ;iou: 0.775 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26187 ;lr: 0.0405 ;B loss: 2.168 ;acc: 0.445 ;iou: 0.555 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26237 ;lr: 0.0405 ;B loss: 1.008 ;acc: 0.755 ;iou: 0.810 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26287 ;lr: 0.0405 ;B loss: 1.221 ;acc: 0.795 ;iou: 0.835 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26337 ;lr: 0.0405 ;B loss: 1.362 ;acc: 0.780 ;iou: 0.835 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26387 ;lr: 0.0405 ;B loss: 2.098 ;acc: 0.635 ;iou: 0.705 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.330 ;Train accuracy: 0.761 ;IOU accuracy: 0.812 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 88\n",
      "batch: 0 ;B loss: 2.984 ;acc: 0.745 ;iou_acc: 0.875 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.214 ;acc: 0.555 ;iou_acc: 0.720 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.366 ;acc: 0.475 ;iou_acc: 0.625 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.540 ;acc: 0.440 ;iou_acc: 0.575 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.591 ;acc: 0.410 ;iou_acc: 0.505 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.581 ;acc: 0.280 ;iou_acc: 0.415 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.847 ;Test accuracy 0.421 ;IOU accuracy: 0.537 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 89 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26434 ;lr: 0.0405 ;B loss: 1.554 ;acc: 0.830 ;iou: 0.855 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26484 ;lr: 0.0405 ;B loss: 1.595 ;acc: 0.765 ;iou: 0.805 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26534 ;lr: 0.0405 ;B loss: 1.316 ;acc: 0.820 ;iou: 0.855 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26584 ;lr: 0.0405 ;B loss: 1.037 ;acc: 0.780 ;iou: 0.820 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26634 ;lr: 0.0405 ;B loss: 1.237 ;acc: 0.770 ;iou: 0.805 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26684 ;lr: 0.0405 ;B loss: 1.668 ;acc: 0.785 ;iou: 0.825 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.325 ;Train accuracy: 0.763 ;IOU accuracy: 0.812 ;Time: 0:00:26 \n",
      "\n",
      "Testing, ephoc: 89\n",
      "batch: 0 ;B loss: 3.104 ;acc: 0.740 ;iou_acc: 0.865 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.276 ;acc: 0.610 ;iou_acc: 0.740 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.414 ;acc: 0.475 ;iou_acc: 0.630 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.524 ;acc: 0.435 ;iou_acc: 0.550 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.833 ;acc: 0.385 ;iou_acc: 0.510 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 3.611 ;acc: 0.275 ;iou_acc: 0.410 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.901 ;Test accuracy 0.420 ;IOU accuracy: 0.534 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 90 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26731 ;lr: 0.0405 ;B loss: 1.237 ;acc: 0.820 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26781 ;lr: 0.0405 ;B loss: 0.857 ;acc: 0.790 ;iou: 0.845 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26831 ;lr: 0.0405 ;B loss: 1.348 ;acc: 0.875 ;iou: 0.885 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26881 ;lr: 0.0405 ;B loss: 1.577 ;acc: 0.825 ;iou: 0.860 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26931 ;lr: 0.0405 ;B loss: 0.936 ;acc: 0.790 ;iou: 0.845 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26981 ;lr: 0.0405 ;B loss: 1.027 ;acc: 0.720 ;iou: 0.785 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.315 ;Train accuracy: 0.766 ;IOU accuracy: 0.815 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 90\n",
      "batch: 0 ;B loss: 2.974 ;acc: 0.740 ;iou_acc: 0.865 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.233 ;acc: 0.570 ;iou_acc: 0.715 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.343 ;acc: 0.510 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.381 ;acc: 0.450 ;iou_acc: 0.560 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.640 ;acc: 0.420 ;iou_acc: 0.515 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.525 ;acc: 0.270 ;iou_acc: 0.385 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.830 ;Test accuracy 0.420 ;IOU accuracy: 0.532 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 91 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27028 ;lr: 0.0405 ;B loss: 1.011 ;acc: 0.850 ;iou: 0.870 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27078 ;lr: 0.0405 ;B loss: 1.086 ;acc: 0.720 ;iou: 0.770 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27128 ;lr: 0.0405 ;B loss: 0.948 ;acc: 0.865 ;iou: 0.890 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27178 ;lr: 0.0405 ;B loss: 2.164 ;acc: 0.625 ;iou: 0.660 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27228 ;lr: 0.0405 ;B loss: 1.018 ;acc: 0.710 ;iou: 0.735 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27278 ;lr: 0.0405 ;B loss: 0.924 ;acc: 0.755 ;iou: 0.800 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.300 ;Train accuracy: 0.767 ;IOU accuracy: 0.815 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 91\n",
      "batch: 0 ;B loss: 3.134 ;acc: 0.760 ;iou_acc: 0.880 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.135 ;acc: 0.590 ;iou_acc: 0.730 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.469 ;acc: 0.515 ;iou_acc: 0.675 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.606 ;acc: 0.435 ;iou_acc: 0.575 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.713 ;acc: 0.400 ;iou_acc: 0.550 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.603 ;acc: 0.255 ;iou_acc: 0.410 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.879 ;Test accuracy 0.417 ;IOU accuracy: 0.533 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 92 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27325 ;lr: 0.0405 ;B loss: 1.026 ;acc: 0.710 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27375 ;lr: 0.0405 ;B loss: 1.320 ;acc: 0.860 ;iou: 0.885 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27425 ;lr: 0.0405 ;B loss: 1.726 ;acc: 0.455 ;iou: 0.605 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27475 ;lr: 0.0405 ;B loss: 0.991 ;acc: 0.725 ;iou: 0.765 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27525 ;lr: 0.0405 ;B loss: 1.096 ;acc: 0.720 ;iou: 0.775 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27575 ;lr: 0.0405 ;B loss: 1.031 ;acc: 0.780 ;iou: 0.855 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.287 ;Train accuracy: 0.768 ;IOU accuracy: 0.816 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 92\n",
      "batch: 0 ;B loss: 3.150 ;acc: 0.730 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.260 ;acc: 0.640 ;iou_acc: 0.755 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.359 ;acc: 0.470 ;iou_acc: 0.610 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.471 ;acc: 0.440 ;iou_acc: 0.570 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.590 ;acc: 0.420 ;iou_acc: 0.530 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.610 ;acc: 0.265 ;iou_acc: 0.420 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.909 ;Test accuracy 0.423 ;IOU accuracy: 0.538 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 93 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27622 ;lr: 0.0405 ;B loss: 1.495 ;acc: 0.830 ;iou: 0.855 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27672 ;lr: 0.0405 ;B loss: 1.285 ;acc: 0.805 ;iou: 0.840 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27722 ;lr: 0.0405 ;B loss: 0.999 ;acc: 0.845 ;iou: 0.875 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27772 ;lr: 0.0405 ;B loss: 1.054 ;acc: 0.850 ;iou: 0.875 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27822 ;lr: 0.0405 ;B loss: 1.300 ;acc: 0.845 ;iou: 0.875 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27872 ;lr: 0.0405 ;B loss: 1.112 ;acc: 0.820 ;iou: 0.865 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.279 ;Train accuracy: 0.768 ;IOU accuracy: 0.817 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 93\n",
      "batch: 0 ;B loss: 3.131 ;acc: 0.730 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.281 ;acc: 0.605 ;iou_acc: 0.745 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.358 ;acc: 0.525 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.520 ;acc: 0.445 ;iou_acc: 0.555 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.633 ;acc: 0.450 ;iou_acc: 0.545 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.732 ;acc: 0.275 ;iou_acc: 0.415 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.916 ;Test accuracy 0.418 ;IOU accuracy: 0.532 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 94 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27919 ;lr: 0.0405 ;B loss: 1.274 ;acc: 0.825 ;iou: 0.860 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27969 ;lr: 0.0405 ;B loss: 1.002 ;acc: 0.865 ;iou: 0.885 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28019 ;lr: 0.0405 ;B loss: 1.388 ;acc: 0.830 ;iou: 0.860 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28069 ;lr: 0.0405 ;B loss: 1.077 ;acc: 0.800 ;iou: 0.835 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28119 ;lr: 0.0405 ;B loss: 0.847 ;acc: 0.835 ;iou: 0.890 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28169 ;lr: 0.0405 ;B loss: 1.213 ;acc: 0.815 ;iou: 0.850 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.262 ;Train accuracy: 0.771 ;IOU accuracy: 0.819 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 94\n",
      "batch: 0 ;B loss: 3.152 ;acc: 0.725 ;iou_acc: 0.865 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.289 ;acc: 0.605 ;iou_acc: 0.755 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.389 ;acc: 0.515 ;iou_acc: 0.635 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.585 ;acc: 0.445 ;iou_acc: 0.565 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.823 ;acc: 0.410 ;iou_acc: 0.555 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.814 ;acc: 0.305 ;iou_acc: 0.420 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 3.024 ;Test accuracy 0.417 ;IOU accuracy: 0.533 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 95 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28216 ;lr: 0.0405 ;B loss: 1.038 ;acc: 0.735 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28266 ;lr: 0.0405 ;B loss: 0.961 ;acc: 0.690 ;iou: 0.750 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28316 ;lr: 0.0405 ;B loss: 1.730 ;acc: 0.795 ;iou: 0.820 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28366 ;lr: 0.0405 ;B loss: 0.939 ;acc: 0.765 ;iou: 0.830 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28416 ;lr: 0.0405 ;B loss: 1.038 ;acc: 0.845 ;iou: 0.875 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28466 ;lr: 0.0405 ;B loss: 1.149 ;acc: 0.805 ;iou: 0.840 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.262 ;Train accuracy: 0.772 ;IOU accuracy: 0.819 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 95\n",
      "batch: 0 ;B loss: 3.150 ;acc: 0.745 ;iou_acc: 0.855 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.320 ;acc: 0.625 ;iou_acc: 0.755 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.446 ;acc: 0.490 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.656 ;acc: 0.455 ;iou_acc: 0.560 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.873 ;acc: 0.420 ;iou_acc: 0.520 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.805 ;acc: 0.280 ;iou_acc: 0.430 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 3.035 ;Test accuracy 0.419 ;IOU accuracy: 0.533 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 96 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28513 ;lr: 0.0405 ;B loss: 0.890 ;acc: 0.745 ;iou: 0.795 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28563 ;lr: 0.0405 ;B loss: 1.510 ;acc: 0.835 ;iou: 0.850 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28613 ;lr: 0.0405 ;B loss: 1.683 ;acc: 0.475 ;iou: 0.625 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28663 ;lr: 0.0405 ;B loss: 1.146 ;acc: 0.840 ;iou: 0.865 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28713 ;lr: 0.0405 ;B loss: 0.828 ;acc: 0.800 ;iou: 0.860 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28763 ;lr: 0.0405 ;B loss: 1.180 ;acc: 0.840 ;iou: 0.880 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 1.239 ;Train accuracy: 0.776 ;IOU accuracy: 0.822 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 96\n",
      "batch: 0 ;B loss: 3.196 ;acc: 0.715 ;iou_acc: 0.845 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.436 ;acc: 0.565 ;iou_acc: 0.715 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.466 ;acc: 0.480 ;iou_acc: 0.635 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.695 ;acc: 0.440 ;iou_acc: 0.555 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.769 ;acc: 0.390 ;iou_acc: 0.545 ;time: 0:00:40\n",
      "batch: 250 ;B loss: 3.865 ;acc: 0.280 ;iou_acc: 0.415 ;time: 0:00:44\n",
      "\n",
      "*BTrain: True ;Test loss: 3.083 ;Test accuracy 0.415 ;IOU accuracy: 0.527 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 97 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28810 ;lr: 0.0405 ;B loss: 1.559 ;acc: 0.730 ;iou: 0.760 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28860 ;lr: 0.0405 ;B loss: 0.956 ;acc: 0.850 ;iou: 0.920 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28910 ;lr: 0.0405 ;B loss: 1.308 ;acc: 0.855 ;iou: 0.895 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28960 ;lr: 0.0405 ;B loss: 0.944 ;acc: 0.815 ;iou: 0.875 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29010 ;lr: 0.0405 ;B loss: 0.961 ;acc: 0.850 ;iou: 0.890 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29060 ;lr: 0.0405 ;B loss: 0.932 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.237 ;Train accuracy: 0.774 ;IOU accuracy: 0.822 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 97\n",
      "batch: 0 ;B loss: 3.342 ;acc: 0.730 ;iou_acc: 0.860 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.364 ;acc: 0.620 ;iou_acc: 0.760 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.605 ;acc: 0.505 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.561 ;acc: 0.475 ;iou_acc: 0.590 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.970 ;acc: 0.410 ;iou_acc: 0.540 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.861 ;acc: 0.265 ;iou_acc: 0.390 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 3.091 ;Test accuracy 0.423 ;IOU accuracy: 0.538 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 98 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 29107 ;lr: 0.0405 ;B loss: 0.928 ;acc: 0.810 ;iou: 0.860 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29157 ;lr: 0.0405 ;B loss: 0.886 ;acc: 0.765 ;iou: 0.810 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 29207 ;lr: 0.0405 ;B loss: 0.797 ;acc: 0.800 ;iou: 0.820 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 29257 ;lr: 0.0405 ;B loss: 1.530 ;acc: 0.805 ;iou: 0.840 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29307 ;lr: 0.0405 ;B loss: 1.633 ;acc: 0.875 ;iou: 0.910 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29357 ;lr: 0.0405 ;B loss: 1.117 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 1.223 ;Train accuracy: 0.775 ;IOU accuracy: 0.823 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 98\n",
      "batch: 0 ;B loss: 3.319 ;acc: 0.715 ;iou_acc: 0.840 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.326 ;acc: 0.605 ;iou_acc: 0.745 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.464 ;acc: 0.500 ;iou_acc: 0.650 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.683 ;acc: 0.445 ;iou_acc: 0.560 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.732 ;acc: 0.425 ;iou_acc: 0.545 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.670 ;acc: 0.275 ;iou_acc: 0.415 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.979 ;Test accuracy 0.421 ;IOU accuracy: 0.535 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 99 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 29404 ;lr: 0.0405 ;B loss: 0.898 ;acc: 0.865 ;iou: 0.885 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29454 ;lr: 0.0405 ;B loss: 1.388 ;acc: 0.820 ;iou: 0.865 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 29504 ;lr: 0.0405 ;B loss: 0.831 ;acc: 0.805 ;iou: 0.840 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 29554 ;lr: 0.0405 ;B loss: 1.039 ;acc: 0.740 ;iou: 0.830 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29604 ;lr: 0.0405 ;B loss: 0.885 ;acc: 0.825 ;iou: 0.870 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29654 ;lr: 0.0405 ;B loss: 0.813 ;acc: 0.805 ;iou: 0.860 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.210 ;Train accuracy: 0.780 ;IOU accuracy: 0.828 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 99\n",
      "batch: 0 ;B loss: 3.476 ;acc: 0.780 ;iou_acc: 0.900 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.336 ;acc: 0.595 ;iou_acc: 0.735 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.499 ;acc: 0.475 ;iou_acc: 0.615 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.627 ;acc: 0.460 ;iou_acc: 0.570 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.809 ;acc: 0.380 ;iou_acc: 0.530 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.707 ;acc: 0.255 ;iou_acc: 0.395 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 3.024 ;Test accuracy 0.428 ;IOU accuracy: 0.541 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "params_dir: ../data/training/models/All/base/hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 297\n",
      "# Training batches: 297\n",
      "# Test set size: 297\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 4.105 ;acc: 0.120 ;iou: 0.210 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 1.932 ;acc: 0.400 ;iou: 0.470 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.520 ;acc: 0.240 ;iou: 0.310 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.548 ;acc: 0.200 ;iou: 0.250 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.825 ;acc: 0.175 ;iou: 0.265 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.390 ;acc: 0.215 ;iou: 0.290 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.447 ;Train accuracy: 0.248 ;IOU accuracy: 0.344 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 1.390 ;acc: 0.470 ;iou_acc: 0.665 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.860 ;acc: 0.285 ;iou_acc: 0.430 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.126 ;acc: 0.185 ;iou_acc: 0.270 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.431 ;acc: 0.165 ;iou_acc: 0.240 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.745 ;acc: 0.120 ;iou_acc: 0.195 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.159 ;acc: 0.130 ;iou_acc: 0.220 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.442 ;Test accuracy 0.190 ;IOU accuracy: 0.291 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 1.530 ;acc: 0.485 ;iou: 0.590 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.095 ;acc: 0.290 ;iou: 0.395 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.171 ;acc: 0.225 ;iou: 0.305 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.191 ;acc: 0.235 ;iou: 0.365 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.365 ;acc: 0.205 ;iou: 0.280 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 3.335 ;acc: 0.105 ;iou: 0.210 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.433 ;Train accuracy: 0.246 ;IOU accuracy: 0.342 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 1.393 ;acc: 0.475 ;iou_acc: 0.665 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.856 ;acc: 0.265 ;iou_acc: 0.365 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.122 ;acc: 0.205 ;iou_acc: 0.280 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.436 ;acc: 0.115 ;iou_acc: 0.185 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.745 ;acc: 0.150 ;iou_acc: 0.235 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.154 ;acc: 0.125 ;iou_acc: 0.240 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.442 ;Test accuracy 0.196 ;IOU accuracy: 0.293 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.128 ;acc: 0.230 ;iou: 0.340 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.759 ;acc: 0.195 ;iou: 0.260 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 1.392 ;acc: 0.455 ;iou: 0.595 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.408 ;acc: 0.170 ;iou: 0.260 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 1.394 ;acc: 0.505 ;iou: 0.625 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 3.123 ;acc: 0.095 ;iou: 0.200 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.429 ;Train accuracy: 0.253 ;IOU accuracy: 0.348 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 1.395 ;acc: 0.475 ;iou_acc: 0.665 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.852 ;acc: 0.265 ;iou_acc: 0.405 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.134 ;acc: 0.210 ;iou_acc: 0.305 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.431 ;acc: 0.155 ;iou_acc: 0.235 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.758 ;acc: 0.125 ;iou_acc: 0.230 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 3.155 ;acc: 0.110 ;iou_acc: 0.210 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.443 ;Test accuracy 0.194 ;IOU accuracy: 0.292 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.588 ;acc: 0.225 ;iou: 0.255 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.573 ;acc: 0.500 ;iou: 0.580 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 2.164 ;acc: 0.225 ;iou: 0.365 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.914 ;acc: 0.370 ;iou: 0.450 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 2.133 ;acc: 0.235 ;iou: 0.315 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 2.787 ;acc: 0.185 ;iou: 0.270 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 2.425 ;Train accuracy: 0.263 ;IOU accuracy: 0.357 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.394 ;acc: 0.455 ;iou_acc: 0.640 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.854 ;acc: 0.310 ;iou_acc: 0.435 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.132 ;acc: 0.150 ;iou_acc: 0.235 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.437 ;acc: 0.185 ;iou_acc: 0.240 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.753 ;acc: 0.120 ;iou_acc: 0.220 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.159 ;acc: 0.115 ;iou_acc: 0.250 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.445 ;Test accuracy 0.193 ;IOU accuracy: 0.294 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 3.737 ;acc: 0.095 ;iou: 0.170 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.898 ;acc: 0.335 ;iou: 0.420 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 2.568 ;acc: 0.260 ;iou: 0.340 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 2.319 ;acc: 0.220 ;iou: 0.305 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 2.521 ;acc: 0.255 ;iou: 0.335 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.577 ;acc: 0.380 ;iou: 0.495 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.420 ;Train accuracy: 0.276 ;IOU accuracy: 0.371 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.397 ;acc: 0.445 ;iou_acc: 0.625 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.848 ;acc: 0.325 ;iou_acc: 0.470 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.141 ;acc: 0.215 ;iou_acc: 0.305 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.445 ;acc: 0.145 ;iou_acc: 0.230 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.756 ;acc: 0.135 ;iou_acc: 0.230 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.154 ;acc: 0.125 ;iou_acc: 0.235 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.448 ;Test accuracy 0.195 ;IOU accuracy: 0.295 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.822 ;acc: 0.340 ;iou: 0.460 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 2.937 ;acc: 0.265 ;iou: 0.365 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 2.757 ;acc: 0.230 ;iou: 0.330 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.530 ;acc: 0.360 ;iou: 0.475 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 2.827 ;acc: 0.245 ;iou: 0.325 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 2.084 ;acc: 0.285 ;iou: 0.330 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.414 ;Train accuracy: 0.284 ;IOU accuracy: 0.376 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.399 ;acc: 0.445 ;iou_acc: 0.635 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.851 ;acc: 0.290 ;iou_acc: 0.435 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.143 ;acc: 0.205 ;iou_acc: 0.305 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.451 ;acc: 0.165 ;iou_acc: 0.270 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.764 ;acc: 0.135 ;iou_acc: 0.230 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.159 ;acc: 0.115 ;iou_acc: 0.230 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.450 ;Test accuracy 0.195 ;IOU accuracy: 0.294 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 2.331 ;acc: 0.285 ;iou: 0.360 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 3.658 ;acc: 0.165 ;iou: 0.230 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.562 ;acc: 0.460 ;iou: 0.575 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 2.700 ;acc: 0.255 ;iou: 0.375 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 3.730 ;acc: 0.165 ;iou: 0.300 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.889 ;acc: 0.380 ;iou: 0.465 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.409 ;Train accuracy: 0.293 ;IOU accuracy: 0.386 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.402 ;acc: 0.405 ;iou_acc: 0.625 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.859 ;acc: 0.305 ;iou_acc: 0.445 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.145 ;acc: 0.180 ;iou_acc: 0.290 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.441 ;acc: 0.160 ;iou_acc: 0.245 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.764 ;acc: 0.120 ;iou_acc: 0.225 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.152 ;acc: 0.140 ;iou_acc: 0.255 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.451 ;Test accuracy 0.196 ;IOU accuracy: 0.298 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 3.888 ;acc: 0.135 ;iou: 0.255 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 2.460 ;acc: 0.250 ;iou: 0.310 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 3.447 ;acc: 0.190 ;iou: 0.285 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.557 ;acc: 0.490 ;iou: 0.575 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.847 ;acc: 0.370 ;iou: 0.460 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.400 ;acc: 0.505 ;iou: 0.620 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.403 ;Train accuracy: 0.302 ;IOU accuracy: 0.392 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.405 ;acc: 0.415 ;iou_acc: 0.615 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.864 ;acc: 0.270 ;iou_acc: 0.415 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.158 ;acc: 0.170 ;iou_acc: 0.255 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.454 ;acc: 0.145 ;iou_acc: 0.230 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.765 ;acc: 0.110 ;iou_acc: 0.180 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.153 ;acc: 0.130 ;iou_acc: 0.260 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.456 ;Test accuracy 0.195 ;IOU accuracy: 0.298 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.775 ;acc: 0.375 ;iou: 0.440 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.787 ;acc: 0.380 ;iou: 0.485 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 2.364 ;acc: 0.325 ;iou: 0.445 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 2.345 ;acc: 0.300 ;iou: 0.390 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 2.932 ;acc: 0.250 ;iou: 0.360 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 2.716 ;acc: 0.270 ;iou: 0.340 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.398 ;Train accuracy: 0.309 ;IOU accuracy: 0.399 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.406 ;acc: 0.405 ;iou_acc: 0.585 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.864 ;acc: 0.245 ;iou_acc: 0.380 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.161 ;acc: 0.200 ;iou_acc: 0.280 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.456 ;acc: 0.170 ;iou_acc: 0.260 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.743 ;acc: 0.140 ;iou_acc: 0.230 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.157 ;acc: 0.145 ;iou_acc: 0.245 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.457 ;Test accuracy 0.196 ;IOU accuracy: 0.298 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 2.724 ;acc: 0.260 ;iou: 0.340 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 2.746 ;acc: 0.270 ;iou: 0.370 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.532 ;acc: 0.445 ;iou: 0.590 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.787 ;acc: 0.380 ;iou: 0.495 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 3.241 ;acc: 0.185 ;iou: 0.255 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.835 ;acc: 0.375 ;iou: 0.465 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.392 ;Train accuracy: 0.314 ;IOU accuracy: 0.404 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.411 ;acc: 0.425 ;iou_acc: 0.605 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.865 ;acc: 0.240 ;iou_acc: 0.375 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.152 ;acc: 0.185 ;iou_acc: 0.270 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.455 ;acc: 0.125 ;iou_acc: 0.195 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.746 ;acc: 0.160 ;iou_acc: 0.225 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.169 ;acc: 0.110 ;iou_acc: 0.225 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.460 ;Test accuracy 0.199 ;IOU accuracy: 0.299 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 2.629 ;acc: 0.255 ;iou: 0.325 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 2.499 ;acc: 0.295 ;iou: 0.365 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.849 ;acc: 0.340 ;iou: 0.440 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.506 ;acc: 0.450 ;iou: 0.515 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 2.508 ;acc: 0.320 ;iou: 0.405 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.538 ;acc: 0.385 ;iou: 0.505 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.387 ;Train accuracy: 0.320 ;IOU accuracy: 0.410 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.416 ;acc: 0.410 ;iou_acc: 0.590 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.864 ;acc: 0.270 ;iou_acc: 0.430 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.155 ;acc: 0.185 ;iou_acc: 0.275 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.440 ;acc: 0.160 ;iou_acc: 0.255 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.766 ;acc: 0.125 ;iou_acc: 0.230 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.181 ;acc: 0.105 ;iou_acc: 0.205 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.464 ;Test accuracy 0.196 ;IOU accuracy: 0.301 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 2.935 ;acc: 0.260 ;iou: 0.320 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 2.451 ;acc: 0.285 ;iou: 0.400 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 2.498 ;acc: 0.315 ;iou: 0.405 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 2.129 ;acc: 0.370 ;iou: 0.435 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 2.064 ;acc: 0.415 ;iou: 0.470 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 2.082 ;acc: 0.365 ;iou: 0.460 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.381 ;Train accuracy: 0.328 ;IOU accuracy: 0.418 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.415 ;acc: 0.440 ;iou_acc: 0.620 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.867 ;acc: 0.290 ;iou_acc: 0.430 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.165 ;acc: 0.190 ;iou_acc: 0.245 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.444 ;acc: 0.175 ;iou_acc: 0.275 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.758 ;acc: 0.150 ;iou_acc: 0.225 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.181 ;acc: 0.085 ;iou_acc: 0.195 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.461 ;Test accuracy 0.200 ;IOU accuracy: 0.299 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.499 ;acc: 0.410 ;iou: 0.520 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 2.511 ;acc: 0.340 ;iou: 0.410 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 2.775 ;acc: 0.265 ;iou: 0.365 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 2.526 ;acc: 0.295 ;iou: 0.410 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.792 ;acc: 0.385 ;iou: 0.465 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 2.919 ;acc: 0.295 ;iou: 0.335 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.374 ;Train accuracy: 0.336 ;IOU accuracy: 0.427 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.415 ;acc: 0.485 ;iou_acc: 0.655 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.862 ;acc: 0.300 ;iou_acc: 0.405 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.162 ;acc: 0.240 ;iou_acc: 0.335 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.476 ;acc: 0.150 ;iou_acc: 0.205 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.777 ;acc: 0.140 ;iou_acc: 0.215 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.170 ;acc: 0.120 ;iou_acc: 0.215 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.467 ;Test accuracy 0.203 ;IOU accuracy: 0.297 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 3.164 ;acc: 0.240 ;iou: 0.315 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 2.434 ;acc: 0.385 ;iou: 0.450 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 2.670 ;acc: 0.275 ;iou: 0.360 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 3.522 ;acc: 0.190 ;iou: 0.285 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 2.785 ;acc: 0.250 ;iou: 0.335 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 2.180 ;acc: 0.335 ;iou: 0.420 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.365 ;Train accuracy: 0.343 ;IOU accuracy: 0.433 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.421 ;acc: 0.445 ;iou_acc: 0.620 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.864 ;acc: 0.290 ;iou_acc: 0.430 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.153 ;acc: 0.180 ;iou_acc: 0.250 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.435 ;acc: 0.185 ;iou_acc: 0.280 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.733 ;acc: 0.155 ;iou_acc: 0.245 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.148 ;acc: 0.115 ;iou_acc: 0.215 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.453 ;Test accuracy 0.209 ;IOU accuracy: 0.312 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 1.510 ;acc: 0.515 ;iou: 0.610 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.500 ;acc: 0.465 ;iou: 0.570 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 2.709 ;acc: 0.280 ;iou: 0.360 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 2.504 ;acc: 0.375 ;iou: 0.440 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 2.710 ;acc: 0.265 ;iou: 0.330 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.517 ;acc: 0.505 ;iou: 0.575 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.353 ;Train accuracy: 0.352 ;IOU accuracy: 0.444 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.426 ;acc: 0.450 ;iou_acc: 0.640 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.859 ;acc: 0.310 ;iou_acc: 0.410 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.159 ;acc: 0.255 ;iou_acc: 0.310 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.460 ;acc: 0.180 ;iou_acc: 0.265 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.762 ;acc: 0.150 ;iou_acc: 0.240 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.166 ;acc: 0.100 ;iou_acc: 0.185 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.466 ;Test accuracy 0.206 ;IOU accuracy: 0.300 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 1.792 ;acc: 0.430 ;iou: 0.500 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 2.696 ;acc: 0.280 ;iou: 0.395 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 2.274 ;acc: 0.350 ;iou: 0.435 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 2.841 ;acc: 0.365 ;iou: 0.410 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 2.006 ;acc: 0.380 ;iou: 0.470 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 1.412 ;acc: 0.515 ;iou: 0.650 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.341 ;Train accuracy: 0.358 ;IOU accuracy: 0.450 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.436 ;acc: 0.445 ;iou_acc: 0.635 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.852 ;acc: 0.320 ;iou_acc: 0.435 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.129 ;acc: 0.210 ;iou_acc: 0.345 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.397 ;acc: 0.195 ;iou_acc: 0.275 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.710 ;acc: 0.195 ;iou_acc: 0.310 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.106 ;acc: 0.125 ;iou_acc: 0.225 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.439 ;Test accuracy 0.223 ;IOU accuracy: 0.331 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 2.540 ;acc: 0.380 ;iou: 0.455 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 3.070 ;acc: 0.285 ;iou: 0.350 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 2.088 ;acc: 0.420 ;iou: 0.495 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 2.345 ;acc: 0.325 ;iou: 0.420 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 1.412 ;acc: 0.475 ;iou: 0.675 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 1.814 ;acc: 0.360 ;iou: 0.450 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.330 ;Train accuracy: 0.366 ;IOU accuracy: 0.456 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.432 ;acc: 0.445 ;iou_acc: 0.635 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.838 ;acc: 0.305 ;iou_acc: 0.420 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.118 ;acc: 0.250 ;iou_acc: 0.370 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.389 ;acc: 0.215 ;iou_acc: 0.320 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.680 ;acc: 0.220 ;iou_acc: 0.315 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.092 ;acc: 0.135 ;iou_acc: 0.200 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.434 ;Test accuracy 0.229 ;IOU accuracy: 0.335 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 2.344 ;acc: 0.350 ;iou: 0.430 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 1.456 ;acc: 0.480 ;iou: 0.575 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 2.465 ;acc: 0.355 ;iou: 0.395 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 1.829 ;acc: 0.470 ;iou: 0.560 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 1.872 ;acc: 0.430 ;iou: 0.510 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 1.802 ;acc: 0.385 ;iou: 0.470 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.319 ;Train accuracy: 0.373 ;IOU accuracy: 0.464 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.443 ;acc: 0.475 ;iou_acc: 0.665 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.851 ;acc: 0.315 ;iou_acc: 0.445 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.118 ;acc: 0.220 ;iou_acc: 0.370 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.358 ;acc: 0.200 ;iou_acc: 0.305 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.689 ;acc: 0.220 ;iou_acc: 0.360 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.098 ;acc: 0.160 ;iou_acc: 0.245 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.430 ;Test accuracy 0.232 ;IOU accuracy: 0.342 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 1.759 ;acc: 0.475 ;iou: 0.550 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 3.422 ;acc: 0.230 ;iou: 0.300 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 3.233 ;acc: 0.260 ;iou: 0.330 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 1.984 ;acc: 0.435 ;iou: 0.535 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 2.012 ;acc: 0.425 ;iou: 0.495 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 2.718 ;acc: 0.350 ;iou: 0.475 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.308 ;Train accuracy: 0.380 ;IOU accuracy: 0.471 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.444 ;acc: 0.515 ;iou_acc: 0.680 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.859 ;acc: 0.280 ;iou_acc: 0.380 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.126 ;acc: 0.255 ;iou_acc: 0.390 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.365 ;acc: 0.225 ;iou_acc: 0.320 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.687 ;acc: 0.185 ;iou_acc: 0.310 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.086 ;acc: 0.165 ;iou_acc: 0.235 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.425 ;Test accuracy 0.238 ;IOU accuracy: 0.347 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 1.746 ;acc: 0.405 ;iou: 0.480 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 1.750 ;acc: 0.440 ;iou: 0.565 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 1.808 ;acc: 0.465 ;iou: 0.605 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 3.057 ;acc: 0.290 ;iou: 0.360 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 1.485 ;acc: 0.510 ;iou: 0.595 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 1.514 ;acc: 0.460 ;iou: 0.560 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.299 ;Train accuracy: 0.386 ;IOU accuracy: 0.477 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.450 ;acc: 0.505 ;iou_acc: 0.665 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.854 ;acc: 0.320 ;iou_acc: 0.430 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.140 ;acc: 0.265 ;iou_acc: 0.385 ;time: 0:00:36\n",
      "batch: 150 ;B loss: 2.378 ;acc: 0.245 ;iou_acc: 0.335 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.691 ;acc: 0.210 ;iou_acc: 0.310 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 3.081 ;acc: 0.130 ;iou_acc: 0.235 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.433 ;Test accuracy 0.239 ;IOU accuracy: 0.348 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 1.762 ;acc: 0.535 ;iou: 0.600 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 1.730 ;acc: 0.480 ;iou: 0.585 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 1.735 ;acc: 0.450 ;iou: 0.565 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 2.518 ;acc: 0.390 ;iou: 0.465 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 1.466 ;acc: 0.515 ;iou: 0.605 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 3.120 ;acc: 0.230 ;iou: 0.345 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.289 ;Train accuracy: 0.396 ;IOU accuracy: 0.485 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.454 ;acc: 0.505 ;iou_acc: 0.675 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.851 ;acc: 0.300 ;iou_acc: 0.415 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.123 ;acc: 0.250 ;iou_acc: 0.350 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.339 ;acc: 0.255 ;iou_acc: 0.340 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.674 ;acc: 0.210 ;iou_acc: 0.315 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.066 ;acc: 0.170 ;iou_acc: 0.250 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.422 ;Test accuracy 0.241 ;IOU accuracy: 0.352 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 2.264 ;acc: 0.400 ;iou: 0.485 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 1.765 ;acc: 0.495 ;iou: 0.620 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 2.708 ;acc: 0.370 ;iou: 0.500 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 2.918 ;acc: 0.295 ;iou: 0.400 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 3.539 ;acc: 0.210 ;iou: 0.340 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 2.338 ;acc: 0.340 ;iou: 0.455 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.279 ;Train accuracy: 0.400 ;IOU accuracy: 0.489 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.463 ;acc: 0.490 ;iou_acc: 0.650 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.842 ;acc: 0.350 ;iou_acc: 0.445 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.104 ;acc: 0.265 ;iou_acc: 0.365 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.371 ;acc: 0.250 ;iou_acc: 0.320 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.717 ;acc: 0.195 ;iou_acc: 0.290 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.139 ;acc: 0.125 ;iou_acc: 0.235 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.437 ;Test accuracy 0.240 ;IOU accuracy: 0.346 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 2.306 ;acc: 0.435 ;iou: 0.510 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 1.451 ;acc: 0.590 ;iou: 0.685 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 2.890 ;acc: 0.290 ;iou: 0.390 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 1.977 ;acc: 0.440 ;iou: 0.535 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 1.449 ;acc: 0.535 ;iou: 0.645 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 1.991 ;acc: 0.425 ;iou: 0.515 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.269 ;Train accuracy: 0.409 ;IOU accuracy: 0.496 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.473 ;acc: 0.535 ;iou_acc: 0.680 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.847 ;acc: 0.295 ;iou_acc: 0.410 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.112 ;acc: 0.240 ;iou_acc: 0.360 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.370 ;acc: 0.220 ;iou_acc: 0.305 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.694 ;acc: 0.220 ;iou_acc: 0.340 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.060 ;acc: 0.160 ;iou_acc: 0.255 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.419 ;Test accuracy 0.249 ;IOU accuracy: 0.358 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 1.683 ;acc: 0.480 ;iou: 0.585 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 1.454 ;acc: 0.535 ;iou: 0.665 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 2.126 ;acc: 0.475 ;iou: 0.535 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 1.434 ;acc: 0.600 ;iou: 0.685 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 1.444 ;acc: 0.595 ;iou: 0.655 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 2.684 ;acc: 0.300 ;iou: 0.395 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.259 ;Train accuracy: 0.416 ;IOU accuracy: 0.502 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.472 ;acc: 0.485 ;iou_acc: 0.650 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.817 ;acc: 0.355 ;iou_acc: 0.440 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.093 ;acc: 0.235 ;iou_acc: 0.345 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.338 ;acc: 0.260 ;iou_acc: 0.325 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.671 ;acc: 0.195 ;iou_acc: 0.305 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.114 ;acc: 0.150 ;iou_acc: 0.250 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.416 ;Test accuracy 0.255 ;IOU accuracy: 0.363 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 2.924 ;acc: 0.310 ;iou: 0.365 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 2.899 ;acc: 0.290 ;iou: 0.400 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 2.515 ;acc: 0.380 ;iou: 0.490 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 1.894 ;acc: 0.445 ;iou: 0.500 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 1.673 ;acc: 0.480 ;iou: 0.530 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 1.983 ;acc: 0.480 ;iou: 0.565 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.245 ;Train accuracy: 0.426 ;IOU accuracy: 0.512 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.511 ;acc: 0.525 ;iou_acc: 0.680 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.832 ;acc: 0.380 ;iou_acc: 0.485 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.098 ;acc: 0.265 ;iou_acc: 0.380 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.302 ;acc: 0.290 ;iou_acc: 0.380 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.701 ;acc: 0.210 ;iou_acc: 0.330 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.045 ;acc: 0.150 ;iou_acc: 0.230 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.417 ;Test accuracy 0.261 ;IOU accuracy: 0.367 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 2.046 ;acc: 0.525 ;iou: 0.555 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 2.961 ;acc: 0.365 ;iou: 0.435 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 1.388 ;acc: 0.570 ;iou: 0.665 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 2.255 ;acc: 0.430 ;iou: 0.510 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 1.699 ;acc: 0.515 ;iou: 0.625 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 3.209 ;acc: 0.270 ;iou: 0.335 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.232 ;Train accuracy: 0.437 ;IOU accuracy: 0.522 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.553 ;acc: 0.555 ;iou_acc: 0.705 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.833 ;acc: 0.345 ;iou_acc: 0.470 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.098 ;acc: 0.300 ;iou_acc: 0.440 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.267 ;acc: 0.280 ;iou_acc: 0.380 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.677 ;acc: 0.210 ;iou_acc: 0.315 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.052 ;acc: 0.190 ;iou_acc: 0.250 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.420 ;Test accuracy 0.265 ;IOU accuracy: 0.372 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 2.346 ;acc: 0.420 ;iou: 0.480 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 2.563 ;acc: 0.425 ;iou: 0.495 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 1.461 ;acc: 0.655 ;iou: 0.785 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 3.082 ;acc: 0.300 ;iou: 0.365 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 1.927 ;acc: 0.515 ;iou: 0.595 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 1.511 ;acc: 0.580 ;iou: 0.690 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.216 ;Train accuracy: 0.446 ;IOU accuracy: 0.529 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.545 ;acc: 0.560 ;iou_acc: 0.695 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.801 ;acc: 0.375 ;iou_acc: 0.490 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.046 ;acc: 0.260 ;iou_acc: 0.380 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.249 ;acc: 0.270 ;iou_acc: 0.355 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.674 ;acc: 0.220 ;iou_acc: 0.340 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.044 ;acc: 0.155 ;iou_acc: 0.255 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.399 ;Test accuracy 0.275 ;IOU accuracy: 0.383 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 2.503 ;acc: 0.455 ;iou: 0.540 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 2.034 ;acc: 0.495 ;iou: 0.555 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 2.162 ;acc: 0.465 ;iou: 0.555 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 2.577 ;acc: 0.385 ;iou: 0.480 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 2.966 ;acc: 0.330 ;iou: 0.405 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 2.476 ;acc: 0.380 ;iou: 0.470 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.196 ;Train accuracy: 0.458 ;IOU accuracy: 0.540 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.559 ;acc: 0.595 ;iou_acc: 0.735 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.794 ;acc: 0.385 ;iou_acc: 0.525 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.068 ;acc: 0.305 ;iou_acc: 0.445 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.249 ;acc: 0.285 ;iou_acc: 0.360 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.632 ;acc: 0.225 ;iou_acc: 0.325 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.033 ;acc: 0.180 ;iou_acc: 0.285 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.382 ;Test accuracy 0.288 ;IOU accuracy: 0.394 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 1.580 ;acc: 0.570 ;iou: 0.665 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 2.917 ;acc: 0.360 ;iou: 0.415 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 1.925 ;acc: 0.535 ;iou: 0.570 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 1.663 ;acc: 0.570 ;iou: 0.625 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 3.626 ;acc: 0.180 ;iou: 0.300 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 2.076 ;acc: 0.470 ;iou: 0.575 ;time: 0:00:22\n",
      "\n",
      "*Training B: False ;B Train loss: 2.179 ;Train accuracy: 0.466 ;IOU accuracy: 0.548 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.610 ;acc: 0.595 ;iou_acc: 0.740 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.781 ;acc: 0.390 ;iou_acc: 0.520 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.048 ;acc: 0.330 ;iou_acc: 0.485 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.221 ;acc: 0.280 ;iou_acc: 0.370 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.642 ;acc: 0.230 ;iou_acc: 0.355 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.980 ;acc: 0.225 ;iou_acc: 0.320 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.385 ;Test accuracy 0.290 ;IOU accuracy: 0.398 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 2.511 ;acc: 0.400 ;iou: 0.500 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 3.355 ;acc: 0.240 ;iou: 0.325 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 1.618 ;acc: 0.560 ;iou: 0.635 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 1.313 ;acc: 0.605 ;iou: 0.680 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 1.819 ;acc: 0.515 ;iou: 0.585 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 2.199 ;acc: 0.440 ;iou: 0.500 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.161 ;Train accuracy: 0.477 ;IOU accuracy: 0.559 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.632 ;acc: 0.640 ;iou_acc: 0.755 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.783 ;acc: 0.405 ;iou_acc: 0.510 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.030 ;acc: 0.355 ;iou_acc: 0.475 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.209 ;acc: 0.300 ;iou_acc: 0.385 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.579 ;acc: 0.245 ;iou_acc: 0.375 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.987 ;acc: 0.210 ;iou_acc: 0.295 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.368 ;Test accuracy 0.305 ;IOU accuracy: 0.410 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 3.203 ;acc: 0.290 ;iou: 0.370 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 2.639 ;acc: 0.410 ;iou: 0.485 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 2.508 ;acc: 0.435 ;iou: 0.500 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 1.284 ;acc: 0.660 ;iou: 0.720 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 2.286 ;acc: 0.445 ;iou: 0.495 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 1.866 ;acc: 0.510 ;iou: 0.585 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.144 ;Train accuracy: 0.485 ;IOU accuracy: 0.565 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.764 ;acc: 0.630 ;iou_acc: 0.770 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.820 ;acc: 0.405 ;iou_acc: 0.545 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.058 ;acc: 0.320 ;iou_acc: 0.465 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.181 ;acc: 0.270 ;iou_acc: 0.380 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.605 ;acc: 0.225 ;iou_acc: 0.355 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.961 ;acc: 0.245 ;iou_acc: 0.340 ;time: 0:00:47\n",
      "\n",
      "*BTrain: True ;Test loss: 2.392 ;Test accuracy 0.300 ;IOU accuracy: 0.406 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 2.360 ;acc: 0.460 ;iou: 0.550 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 2.764 ;acc: 0.435 ;iou: 0.485 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 2.997 ;acc: 0.335 ;iou: 0.405 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 1.315 ;acc: 0.670 ;iou: 0.770 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 2.909 ;acc: 0.330 ;iou: 0.420 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 2.380 ;acc: 0.420 ;iou: 0.510 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.130 ;Train accuracy: 0.491 ;IOU accuracy: 0.571 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.626 ;acc: 0.625 ;iou_acc: 0.760 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.772 ;acc: 0.410 ;iou_acc: 0.520 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.039 ;acc: 0.325 ;iou_acc: 0.445 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.163 ;acc: 0.350 ;iou_acc: 0.440 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.621 ;acc: 0.225 ;iou_acc: 0.360 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.935 ;acc: 0.225 ;iou_acc: 0.335 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.358 ;Test accuracy 0.308 ;IOU accuracy: 0.414 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 2.058 ;acc: 0.480 ;iou: 0.550 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 1.305 ;acc: 0.645 ;iou: 0.720 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 1.346 ;acc: 0.630 ;iou: 0.695 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 1.733 ;acc: 0.555 ;iou: 0.635 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 1.567 ;acc: 0.630 ;iou: 0.765 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 1.333 ;acc: 0.630 ;iou: 0.685 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.113 ;Train accuracy: 0.500 ;IOU accuracy: 0.578 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.632 ;acc: 0.620 ;iou_acc: 0.770 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.799 ;acc: 0.410 ;iou_acc: 0.520 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.050 ;acc: 0.340 ;iou_acc: 0.470 ;time: 0:00:36\n",
      "batch: 150 ;B loss: 2.153 ;acc: 0.325 ;iou_acc: 0.450 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.598 ;acc: 0.205 ;iou_acc: 0.310 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 2.973 ;acc: 0.215 ;iou_acc: 0.310 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.367 ;Test accuracy 0.308 ;IOU accuracy: 0.414 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 2.420 ;acc: 0.480 ;iou: 0.525 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 1.949 ;acc: 0.585 ;iou: 0.625 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 1.708 ;acc: 0.555 ;iou: 0.615 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 1.969 ;acc: 0.540 ;iou: 0.605 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0450 ;B loss: 2.555 ;acc: 0.425 ;iou: 0.490 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0450 ;B loss: 1.410 ;acc: 0.655 ;iou: 0.720 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.099 ;Train accuracy: 0.504 ;IOU accuracy: 0.581 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.618 ;acc: 0.650 ;iou_acc: 0.780 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.794 ;acc: 0.410 ;iou_acc: 0.550 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.011 ;acc: 0.310 ;iou_acc: 0.425 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.204 ;acc: 0.265 ;iou_acc: 0.385 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.601 ;acc: 0.225 ;iou_acc: 0.370 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.964 ;acc: 0.225 ;iou_acc: 0.310 ;time: 0:00:47\n",
      "\n",
      "*BTrain: True ;Test loss: 2.357 ;Test accuracy 0.308 ;IOU accuracy: 0.414 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0450 ;B loss: 1.532 ;acc: 0.615 ;iou: 0.700 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0450 ;B loss: 1.863 ;acc: 0.595 ;iou: 0.680 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0450 ;B loss: 2.176 ;acc: 0.525 ;iou: 0.575 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0450 ;B loss: 3.155 ;acc: 0.310 ;iou: 0.385 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0450 ;B loss: 1.715 ;acc: 0.550 ;iou: 0.610 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0450 ;B loss: 2.441 ;acc: 0.480 ;iou: 0.550 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.079 ;Train accuracy: 0.509 ;IOU accuracy: 0.588 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.783 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.808 ;acc: 0.405 ;iou_acc: 0.525 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.021 ;acc: 0.390 ;iou_acc: 0.515 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.156 ;acc: 0.345 ;iou_acc: 0.440 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.562 ;acc: 0.265 ;iou_acc: 0.365 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.966 ;acc: 0.240 ;iou_acc: 0.325 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.358 ;Test accuracy 0.319 ;IOU accuracy: 0.424 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0450 ;B loss: 3.269 ;acc: 0.325 ;iou: 0.390 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0450 ;B loss: 3.418 ;acc: 0.225 ;iou: 0.325 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0450 ;B loss: 2.920 ;acc: 0.365 ;iou: 0.450 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0450 ;B loss: 1.325 ;acc: 0.635 ;iou: 0.740 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0450 ;B loss: 1.583 ;acc: 0.685 ;iou: 0.730 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0450 ;B loss: 3.474 ;acc: 0.215 ;iou: 0.320 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.068 ;Train accuracy: 0.514 ;IOU accuracy: 0.591 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.832 ;acc: 0.650 ;iou_acc: 0.790 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.836 ;acc: 0.425 ;iou_acc: 0.555 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.046 ;acc: 0.340 ;iou_acc: 0.480 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.150 ;acc: 0.305 ;iou_acc: 0.390 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.590 ;acc: 0.250 ;iou_acc: 0.385 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.972 ;acc: 0.210 ;iou_acc: 0.305 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.374 ;Test accuracy 0.319 ;IOU accuracy: 0.425 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0450 ;B loss: 1.390 ;acc: 0.670 ;iou: 0.750 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0450 ;B loss: 2.548 ;acc: 0.475 ;iou: 0.520 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0450 ;B loss: 2.089 ;acc: 0.520 ;iou: 0.595 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0450 ;B loss: 2.517 ;acc: 0.435 ;iou: 0.520 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0450 ;B loss: 1.265 ;acc: 0.660 ;iou: 0.730 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0450 ;B loss: 1.525 ;acc: 0.620 ;iou: 0.670 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 2.057 ;Train accuracy: 0.520 ;IOU accuracy: 0.596 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.763 ;acc: 0.645 ;iou_acc: 0.785 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.781 ;acc: 0.435 ;iou_acc: 0.540 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.047 ;acc: 0.360 ;iou_acc: 0.485 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.179 ;acc: 0.270 ;iou_acc: 0.375 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.538 ;acc: 0.275 ;iou_acc: 0.395 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 3.012 ;acc: 0.195 ;iou_acc: 0.260 ;time: 0:00:48\n",
      "\n",
      "*BTrain: True ;Test loss: 2.361 ;Test accuracy 0.320 ;IOU accuracy: 0.426 ;Time: 0:00:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0450 ;B loss: 2.814 ;acc: 0.370 ;iou: 0.460 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0450 ;B loss: 1.385 ;acc: 0.645 ;iou: 0.710 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0450 ;B loss: 1.780 ;acc: 0.575 ;iou: 0.615 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0450 ;B loss: 1.639 ;acc: 0.610 ;iou: 0.705 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0450 ;B loss: 2.042 ;acc: 0.520 ;iou: 0.615 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0450 ;B loss: 2.569 ;acc: 0.395 ;iou: 0.470 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.048 ;Train accuracy: 0.527 ;IOU accuracy: 0.602 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.711 ;acc: 0.630 ;iou_acc: 0.785 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.766 ;acc: 0.430 ;iou_acc: 0.545 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.014 ;acc: 0.345 ;iou_acc: 0.465 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.141 ;acc: 0.335 ;iou_acc: 0.420 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.612 ;acc: 0.220 ;iou_acc: 0.345 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 2.997 ;acc: 0.195 ;iou_acc: 0.265 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.367 ;Test accuracy 0.318 ;IOU accuracy: 0.423 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0450 ;B loss: 2.560 ;acc: 0.520 ;iou: 0.610 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0450 ;B loss: 3.174 ;acc: 0.335 ;iou: 0.420 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0450 ;B loss: 1.820 ;acc: 0.615 ;iou: 0.675 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0450 ;B loss: 2.993 ;acc: 0.370 ;iou: 0.430 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0450 ;B loss: 1.586 ;acc: 0.625 ;iou: 0.720 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0450 ;B loss: 1.857 ;acc: 0.570 ;iou: 0.645 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.036 ;Train accuracy: 0.532 ;IOU accuracy: 0.607 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.795 ;acc: 0.635 ;iou_acc: 0.770 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.789 ;acc: 0.405 ;iou_acc: 0.540 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 1.999 ;acc: 0.410 ;iou_acc: 0.535 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.170 ;acc: 0.290 ;iou_acc: 0.395 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.558 ;acc: 0.245 ;iou_acc: 0.350 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.987 ;acc: 0.220 ;iou_acc: 0.295 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.367 ;Test accuracy 0.321 ;IOU accuracy: 0.427 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0450 ;B loss: 2.198 ;acc: 0.565 ;iou: 0.630 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0450 ;B loss: 1.742 ;acc: 0.620 ;iou: 0.680 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0450 ;B loss: 2.137 ;acc: 0.540 ;iou: 0.615 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0450 ;B loss: 2.416 ;acc: 0.510 ;iou: 0.610 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0450 ;B loss: 2.301 ;acc: 0.490 ;iou: 0.585 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0450 ;B loss: 2.178 ;acc: 0.555 ;iou: 0.615 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 2.026 ;Train accuracy: 0.539 ;IOU accuracy: 0.613 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.823 ;acc: 0.630 ;iou_acc: 0.770 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.786 ;acc: 0.430 ;iou_acc: 0.570 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.053 ;acc: 0.365 ;iou_acc: 0.475 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.232 ;acc: 0.325 ;iou_acc: 0.425 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.600 ;acc: 0.270 ;iou_acc: 0.400 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.998 ;acc: 0.180 ;iou_acc: 0.260 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.389 ;Test accuracy 0.324 ;IOU accuracy: 0.429 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0450 ;B loss: 1.404 ;acc: 0.630 ;iou: 0.705 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0450 ;B loss: 1.610 ;acc: 0.685 ;iou: 0.730 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0450 ;B loss: 2.530 ;acc: 0.500 ;iou: 0.590 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0450 ;B loss: 2.084 ;acc: 0.555 ;iou: 0.605 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0450 ;B loss: 2.069 ;acc: 0.510 ;iou: 0.555 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0450 ;B loss: 1.339 ;acc: 0.655 ;iou: 0.730 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.016 ;Train accuracy: 0.544 ;IOU accuracy: 0.618 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.809 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.790 ;acc: 0.420 ;iou_acc: 0.555 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.042 ;acc: 0.365 ;iou_acc: 0.485 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.182 ;acc: 0.340 ;iou_acc: 0.425 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.586 ;acc: 0.235 ;iou_acc: 0.355 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 3.008 ;acc: 0.240 ;iou_acc: 0.315 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.368 ;Test accuracy 0.327 ;IOU accuracy: 0.431 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0450 ;B loss: 1.399 ;acc: 0.635 ;iou: 0.695 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0450 ;B loss: 1.314 ;acc: 0.745 ;iou: 0.795 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0450 ;B loss: 1.611 ;acc: 0.690 ;iou: 0.745 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0450 ;B loss: 1.555 ;acc: 0.585 ;iou: 0.690 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0450 ;B loss: 2.409 ;acc: 0.505 ;iou: 0.560 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0450 ;B loss: 1.691 ;acc: 0.660 ;iou: 0.700 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.006 ;Train accuracy: 0.548 ;IOU accuracy: 0.622 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.886 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.828 ;acc: 0.390 ;iou_acc: 0.535 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.076 ;acc: 0.355 ;iou_acc: 0.470 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.199 ;acc: 0.320 ;iou_acc: 0.425 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.561 ;acc: 0.240 ;iou_acc: 0.360 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 2.997 ;acc: 0.205 ;iou_acc: 0.285 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.397 ;Test accuracy 0.325 ;IOU accuracy: 0.431 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0450 ;B loss: 1.697 ;acc: 0.640 ;iou: 0.695 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0450 ;B loss: 3.157 ;acc: 0.350 ;iou: 0.430 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0450 ;B loss: 2.352 ;acc: 0.515 ;iou: 0.600 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0450 ;B loss: 2.766 ;acc: 0.425 ;iou: 0.515 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0450 ;B loss: 2.023 ;acc: 0.590 ;iou: 0.645 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0450 ;B loss: 1.271 ;acc: 0.665 ;iou: 0.745 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.994 ;Train accuracy: 0.555 ;IOU accuracy: 0.626 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.954 ;acc: 0.640 ;iou_acc: 0.780 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.847 ;acc: 0.410 ;iou_acc: 0.565 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.043 ;acc: 0.355 ;iou_acc: 0.485 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.210 ;acc: 0.335 ;iou_acc: 0.435 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.622 ;acc: 0.250 ;iou_acc: 0.390 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.088 ;acc: 0.200 ;iou_acc: 0.285 ;time: 0:00:47\n",
      "\n",
      "*BTrain: True ;Test loss: 2.410 ;Test accuracy 0.329 ;IOU accuracy: 0.432 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0450 ;B loss: 1.477 ;acc: 0.655 ;iou: 0.710 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0450 ;B loss: 1.212 ;acc: 0.610 ;iou: 0.680 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0450 ;B loss: 2.148 ;acc: 0.525 ;iou: 0.610 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0450 ;B loss: 2.186 ;acc: 0.565 ;iou: 0.625 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0450 ;B loss: 2.522 ;acc: 0.535 ;iou: 0.630 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0450 ;B loss: 1.979 ;acc: 0.590 ;iou: 0.620 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.984 ;Train accuracy: 0.561 ;IOU accuracy: 0.633 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.864 ;acc: 0.655 ;iou_acc: 0.785 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.798 ;acc: 0.455 ;iou_acc: 0.580 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.063 ;acc: 0.375 ;iou_acc: 0.485 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.249 ;acc: 0.310 ;iou_acc: 0.415 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.563 ;acc: 0.285 ;iou_acc: 0.435 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.026 ;acc: 0.210 ;iou_acc: 0.280 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.401 ;Test accuracy 0.328 ;IOU accuracy: 0.435 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0450 ;B loss: 1.576 ;acc: 0.650 ;iou: 0.705 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0450 ;B loss: 2.286 ;acc: 0.550 ;iou: 0.645 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0450 ;B loss: 2.025 ;acc: 0.570 ;iou: 0.610 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0450 ;B loss: 2.380 ;acc: 0.485 ;iou: 0.580 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0450 ;B loss: 2.643 ;acc: 0.460 ;iou: 0.545 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0450 ;B loss: 2.408 ;acc: 0.480 ;iou: 0.555 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.975 ;Train accuracy: 0.564 ;IOU accuracy: 0.635 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 2.033 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.863 ;acc: 0.380 ;iou_acc: 0.525 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.056 ;acc: 0.395 ;iou_acc: 0.510 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.205 ;acc: 0.350 ;iou_acc: 0.445 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.619 ;acc: 0.280 ;iou_acc: 0.365 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.028 ;acc: 0.195 ;iou_acc: 0.300 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.416 ;Test accuracy 0.328 ;IOU accuracy: 0.433 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0450 ;B loss: 1.327 ;acc: 0.675 ;iou: 0.760 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0450 ;B loss: 1.954 ;acc: 0.635 ;iou: 0.705 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0450 ;B loss: 1.727 ;acc: 0.630 ;iou: 0.680 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0450 ;B loss: 2.788 ;acc: 0.410 ;iou: 0.495 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0450 ;B loss: 2.471 ;acc: 0.515 ;iou: 0.560 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0450 ;B loss: 2.326 ;acc: 0.505 ;iou: 0.595 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.964 ;Train accuracy: 0.569 ;IOU accuracy: 0.640 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.936 ;acc: 0.640 ;iou_acc: 0.775 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.813 ;acc: 0.465 ;iou_acc: 0.580 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.077 ;acc: 0.390 ;iou_acc: 0.515 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.241 ;acc: 0.310 ;iou_acc: 0.410 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.627 ;acc: 0.250 ;iou_acc: 0.390 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.030 ;acc: 0.195 ;iou_acc: 0.265 ;time: 0:00:47\n",
      "\n",
      "*BTrain: True ;Test loss: 2.409 ;Test accuracy 0.329 ;IOU accuracy: 0.434 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0450 ;B loss: 2.080 ;acc: 0.525 ;iou: 0.575 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0450 ;B loss: 2.388 ;acc: 0.545 ;iou: 0.600 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0450 ;B loss: 1.369 ;acc: 0.635 ;iou: 0.690 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0450 ;B loss: 1.446 ;acc: 0.665 ;iou: 0.740 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0450 ;B loss: 2.695 ;acc: 0.480 ;iou: 0.540 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0450 ;B loss: 1.773 ;acc: 0.630 ;iou: 0.695 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.954 ;Train accuracy: 0.574 ;IOU accuracy: 0.645 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 2.011 ;acc: 0.630 ;iou_acc: 0.780 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.838 ;acc: 0.430 ;iou_acc: 0.535 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.069 ;acc: 0.405 ;iou_acc: 0.520 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.278 ;acc: 0.340 ;iou_acc: 0.440 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.625 ;acc: 0.280 ;iou_acc: 0.395 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.022 ;acc: 0.215 ;iou_acc: 0.310 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.419 ;Test accuracy 0.333 ;IOU accuracy: 0.437 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0450 ;B loss: 1.746 ;acc: 0.650 ;iou: 0.700 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0450 ;B loss: 1.600 ;acc: 0.500 ;iou: 0.635 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0450 ;B loss: 1.366 ;acc: 0.630 ;iou: 0.695 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0450 ;B loss: 1.701 ;acc: 0.665 ;iou: 0.735 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0450 ;B loss: 1.252 ;acc: 0.650 ;iou: 0.725 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0450 ;B loss: 2.677 ;acc: 0.420 ;iou: 0.470 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.943 ;Train accuracy: 0.581 ;IOU accuracy: 0.651 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.937 ;acc: 0.635 ;iou_acc: 0.760 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.841 ;acc: 0.465 ;iou_acc: 0.575 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.146 ;acc: 0.355 ;iou_acc: 0.485 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.269 ;acc: 0.325 ;iou_acc: 0.420 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.626 ;acc: 0.245 ;iou_acc: 0.380 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.059 ;acc: 0.200 ;iou_acc: 0.305 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.425 ;Test accuracy 0.327 ;IOU accuracy: 0.435 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0450 ;B loss: 2.369 ;acc: 0.555 ;iou: 0.605 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0450 ;B loss: 1.657 ;acc: 0.705 ;iou: 0.760 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0450 ;B loss: 2.658 ;acc: 0.450 ;iou: 0.515 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0450 ;B loss: 2.153 ;acc: 0.535 ;iou: 0.620 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0450 ;B loss: 1.638 ;acc: 0.645 ;iou: 0.720 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0450 ;B loss: 1.981 ;acc: 0.550 ;iou: 0.630 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.931 ;Train accuracy: 0.583 ;IOU accuracy: 0.653 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 2.037 ;acc: 0.640 ;iou_acc: 0.775 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.845 ;acc: 0.425 ;iou_acc: 0.550 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.047 ;acc: 0.355 ;iou_acc: 0.500 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.267 ;acc: 0.340 ;iou_acc: 0.440 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.673 ;acc: 0.195 ;iou_acc: 0.320 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.075 ;acc: 0.200 ;iou_acc: 0.295 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.435 ;Test accuracy 0.325 ;IOU accuracy: 0.431 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0450 ;B loss: 1.187 ;acc: 0.690 ;iou: 0.760 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0450 ;B loss: 2.951 ;acc: 0.345 ;iou: 0.390 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0450 ;B loss: 2.299 ;acc: 0.560 ;iou: 0.655 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0450 ;B loss: 1.661 ;acc: 0.505 ;iou: 0.655 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0450 ;B loss: 1.346 ;acc: 0.650 ;iou: 0.720 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0450 ;B loss: 2.046 ;acc: 0.550 ;iou: 0.585 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.920 ;Train accuracy: 0.591 ;IOU accuracy: 0.659 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.951 ;acc: 0.625 ;iou_acc: 0.765 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.782 ;acc: 0.460 ;iou_acc: 0.575 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.122 ;acc: 0.355 ;iou_acc: 0.460 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.271 ;acc: 0.325 ;iou_acc: 0.440 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.655 ;acc: 0.260 ;iou_acc: 0.375 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.076 ;acc: 0.185 ;iou_acc: 0.275 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.424 ;Test accuracy 0.327 ;IOU accuracy: 0.435 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 50 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14851 ;lr: 0.0450 ;B loss: 2.245 ;acc: 0.555 ;iou: 0.585 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14901 ;lr: 0.0450 ;B loss: 2.824 ;acc: 0.415 ;iou: 0.485 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14951 ;lr: 0.0450 ;B loss: 2.123 ;acc: 0.615 ;iou: 0.680 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15001 ;lr: 0.0450 ;B loss: 1.240 ;acc: 0.670 ;iou: 0.750 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15051 ;lr: 0.0450 ;B loss: 1.955 ;acc: 0.595 ;iou: 0.635 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15101 ;lr: 0.0450 ;B loss: 2.451 ;acc: 0.500 ;iou: 0.580 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.910 ;Train accuracy: 0.596 ;IOU accuracy: 0.664 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 50\n",
      "batch: 0 ;B loss: 2.036 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.840 ;acc: 0.455 ;iou_acc: 0.575 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.149 ;acc: 0.410 ;iou_acc: 0.525 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.322 ;acc: 0.315 ;iou_acc: 0.420 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.668 ;acc: 0.260 ;iou_acc: 0.375 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.142 ;acc: 0.185 ;iou_acc: 0.295 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.457 ;Test accuracy 0.331 ;IOU accuracy: 0.439 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 51 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15148 ;lr: 0.0450 ;B loss: 1.198 ;acc: 0.640 ;iou: 0.715 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15198 ;lr: 0.0450 ;B loss: 2.455 ;acc: 0.525 ;iou: 0.605 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15248 ;lr: 0.0450 ;B loss: 1.621 ;acc: 0.605 ;iou: 0.725 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15298 ;lr: 0.0450 ;B loss: 2.385 ;acc: 0.550 ;iou: 0.630 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15348 ;lr: 0.0450 ;B loss: 2.675 ;acc: 0.470 ;iou: 0.545 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15398 ;lr: 0.0450 ;B loss: 3.139 ;acc: 0.330 ;iou: 0.415 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.900 ;Train accuracy: 0.600 ;IOU accuracy: 0.668 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 51\n",
      "batch: 0 ;B loss: 2.098 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.839 ;acc: 0.435 ;iou_acc: 0.565 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.053 ;acc: 0.425 ;iou_acc: 0.550 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.325 ;acc: 0.315 ;iou_acc: 0.415 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.658 ;acc: 0.260 ;iou_acc: 0.395 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.097 ;acc: 0.190 ;iou_acc: 0.290 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.446 ;Test accuracy 0.338 ;IOU accuracy: 0.445 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 52 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15445 ;lr: 0.0450 ;B loss: 2.105 ;acc: 0.590 ;iou: 0.640 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15495 ;lr: 0.0450 ;B loss: 1.735 ;acc: 0.645 ;iou: 0.750 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15545 ;lr: 0.0450 ;B loss: 1.627 ;acc: 0.660 ;iou: 0.755 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15595 ;lr: 0.0450 ;B loss: 2.900 ;acc: 0.390 ;iou: 0.460 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15645 ;lr: 0.0450 ;B loss: 2.033 ;acc: 0.625 ;iou: 0.670 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15695 ;lr: 0.0450 ;B loss: 1.634 ;acc: 0.650 ;iou: 0.705 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.889 ;Train accuracy: 0.604 ;IOU accuracy: 0.671 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 52\n",
      "batch: 0 ;B loss: 1.944 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.828 ;acc: 0.450 ;iou_acc: 0.550 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.064 ;acc: 0.385 ;iou_acc: 0.510 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.325 ;acc: 0.340 ;iou_acc: 0.440 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.609 ;acc: 0.295 ;iou_acc: 0.385 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.113 ;acc: 0.160 ;iou_acc: 0.285 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.435 ;Test accuracy 0.329 ;IOU accuracy: 0.435 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 53 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15742 ;lr: 0.0450 ;B loss: 1.409 ;acc: 0.730 ;iou: 0.770 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15792 ;lr: 0.0450 ;B loss: 2.935 ;acc: 0.385 ;iou: 0.435 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15842 ;lr: 0.0450 ;B loss: 2.045 ;acc: 0.580 ;iou: 0.635 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15892 ;lr: 0.0450 ;B loss: 1.826 ;acc: 0.645 ;iou: 0.705 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15942 ;lr: 0.0450 ;B loss: 1.736 ;acc: 0.705 ;iou: 0.760 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15992 ;lr: 0.0450 ;B loss: 1.219 ;acc: 0.710 ;iou: 0.790 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.875 ;Train accuracy: 0.609 ;IOU accuracy: 0.675 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 53\n",
      "batch: 0 ;B loss: 2.105 ;acc: 0.680 ;iou_acc: 0.810 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.858 ;acc: 0.425 ;iou_acc: 0.540 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.068 ;acc: 0.405 ;iou_acc: 0.555 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.258 ;acc: 0.330 ;iou_acc: 0.420 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.661 ;acc: 0.285 ;iou_acc: 0.405 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.168 ;acc: 0.190 ;iou_acc: 0.295 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.456 ;Test accuracy 0.341 ;IOU accuracy: 0.448 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 54 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16039 ;lr: 0.0450 ;B loss: 2.323 ;acc: 0.550 ;iou: 0.615 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16089 ;lr: 0.0450 ;B loss: 2.521 ;acc: 0.515 ;iou: 0.595 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16139 ;lr: 0.0450 ;B loss: 1.508 ;acc: 0.680 ;iou: 0.740 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16189 ;lr: 0.0450 ;B loss: 2.563 ;acc: 0.505 ;iou: 0.575 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16239 ;lr: 0.0450 ;B loss: 2.657 ;acc: 0.445 ;iou: 0.515 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16289 ;lr: 0.0450 ;B loss: 1.428 ;acc: 0.680 ;iou: 0.725 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.864 ;Train accuracy: 0.614 ;IOU accuracy: 0.680 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 54\n",
      "batch: 0 ;B loss: 2.100 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.864 ;acc: 0.465 ;iou_acc: 0.570 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.046 ;acc: 0.425 ;iou_acc: 0.570 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.334 ;acc: 0.330 ;iou_acc: 0.425 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.717 ;acc: 0.285 ;iou_acc: 0.380 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 3.109 ;acc: 0.170 ;iou_acc: 0.275 ;time: 0:00:47\n",
      "\n",
      "*BTrain: True ;Test loss: 2.460 ;Test accuracy 0.337 ;IOU accuracy: 0.446 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 55 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16336 ;lr: 0.0450 ;B loss: 3.038 ;acc: 0.360 ;iou: 0.430 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16386 ;lr: 0.0450 ;B loss: 1.216 ;acc: 0.745 ;iou: 0.805 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16436 ;lr: 0.0450 ;B loss: 2.120 ;acc: 0.615 ;iou: 0.665 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16486 ;lr: 0.0450 ;B loss: 1.161 ;acc: 0.640 ;iou: 0.705 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16536 ;lr: 0.0450 ;B loss: 1.262 ;acc: 0.705 ;iou: 0.785 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16586 ;lr: 0.0450 ;B loss: 1.647 ;acc: 0.710 ;iou: 0.780 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.853 ;Train accuracy: 0.621 ;IOU accuracy: 0.686 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 55\n",
      "batch: 0 ;B loss: 2.182 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.872 ;acc: 0.410 ;iou_acc: 0.540 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.141 ;acc: 0.420 ;iou_acc: 0.545 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.341 ;acc: 0.320 ;iou_acc: 0.435 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.640 ;acc: 0.280 ;iou_acc: 0.430 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.101 ;acc: 0.180 ;iou_acc: 0.310 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.471 ;Test accuracy 0.341 ;IOU accuracy: 0.450 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 56 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16633 ;lr: 0.0450 ;B loss: 1.332 ;acc: 0.765 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16683 ;lr: 0.0450 ;B loss: 1.191 ;acc: 0.730 ;iou: 0.780 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16733 ;lr: 0.0450 ;B loss: 2.116 ;acc: 0.655 ;iou: 0.695 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16783 ;lr: 0.0450 ;B loss: 1.601 ;acc: 0.690 ;iou: 0.775 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16833 ;lr: 0.0450 ;B loss: 1.176 ;acc: 0.635 ;iou: 0.700 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16883 ;lr: 0.0450 ;B loss: 2.156 ;acc: 0.600 ;iou: 0.670 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.837 ;Train accuracy: 0.626 ;IOU accuracy: 0.691 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 56\n",
      "batch: 0 ;B loss: 2.158 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.859 ;acc: 0.445 ;iou_acc: 0.585 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.116 ;acc: 0.440 ;iou_acc: 0.555 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.346 ;acc: 0.315 ;iou_acc: 0.410 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.645 ;acc: 0.275 ;iou_acc: 0.385 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.154 ;acc: 0.210 ;iou_acc: 0.285 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.484 ;Test accuracy 0.338 ;IOU accuracy: 0.447 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 57 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16930 ;lr: 0.0450 ;B loss: 1.371 ;acc: 0.730 ;iou: 0.775 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16980 ;lr: 0.0450 ;B loss: 1.653 ;acc: 0.735 ;iou: 0.765 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17030 ;lr: 0.0450 ;B loss: 2.280 ;acc: 0.595 ;iou: 0.640 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17080 ;lr: 0.0450 ;B loss: 1.856 ;acc: 0.630 ;iou: 0.720 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17130 ;lr: 0.0450 ;B loss: 1.969 ;acc: 0.640 ;iou: 0.685 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17180 ;lr: 0.0450 ;B loss: 1.297 ;acc: 0.705 ;iou: 0.770 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.825 ;Train accuracy: 0.631 ;IOU accuracy: 0.694 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 57\n",
      "batch: 0 ;B loss: 2.094 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.918 ;acc: 0.410 ;iou_acc: 0.560 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.159 ;acc: 0.380 ;iou_acc: 0.530 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.404 ;acc: 0.315 ;iou_acc: 0.425 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.669 ;acc: 0.255 ;iou_acc: 0.365 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.171 ;acc: 0.200 ;iou_acc: 0.285 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.496 ;Test accuracy 0.332 ;IOU accuracy: 0.443 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 58 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17227 ;lr: 0.0450 ;B loss: 2.193 ;acc: 0.665 ;iou: 0.725 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17277 ;lr: 0.0450 ;B loss: 1.260 ;acc: 0.745 ;iou: 0.795 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17327 ;lr: 0.0450 ;B loss: 1.517 ;acc: 0.695 ;iou: 0.730 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17377 ;lr: 0.0450 ;B loss: 1.533 ;acc: 0.710 ;iou: 0.750 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17427 ;lr: 0.0450 ;B loss: 1.811 ;acc: 0.680 ;iou: 0.745 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17477 ;lr: 0.0450 ;B loss: 1.241 ;acc: 0.665 ;iou: 0.740 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.813 ;Train accuracy: 0.635 ;IOU accuracy: 0.699 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 58\n",
      "batch: 0 ;B loss: 2.181 ;acc: 0.655 ;iou_acc: 0.785 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.866 ;acc: 0.430 ;iou_acc: 0.560 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.120 ;acc: 0.450 ;iou_acc: 0.595 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.291 ;acc: 0.360 ;iou_acc: 0.465 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.666 ;acc: 0.265 ;iou_acc: 0.365 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.089 ;acc: 0.225 ;iou_acc: 0.330 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.489 ;Test accuracy 0.346 ;IOU accuracy: 0.455 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 59 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17524 ;lr: 0.0450 ;B loss: 1.395 ;acc: 0.750 ;iou: 0.795 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17574 ;lr: 0.0450 ;B loss: 1.189 ;acc: 0.780 ;iou: 0.815 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17624 ;lr: 0.0450 ;B loss: 1.932 ;acc: 0.715 ;iou: 0.745 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17674 ;lr: 0.0450 ;B loss: 1.424 ;acc: 0.725 ;iou: 0.790 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17724 ;lr: 0.0450 ;B loss: 2.389 ;acc: 0.530 ;iou: 0.610 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17774 ;lr: 0.0450 ;B loss: 2.376 ;acc: 0.570 ;iou: 0.650 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.799 ;Train accuracy: 0.639 ;IOU accuracy: 0.703 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 59\n",
      "batch: 0 ;B loss: 2.212 ;acc: 0.645 ;iou_acc: 0.775 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.871 ;acc: 0.425 ;iou_acc: 0.565 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.110 ;acc: 0.425 ;iou_acc: 0.550 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.387 ;acc: 0.340 ;iou_acc: 0.465 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.720 ;acc: 0.250 ;iou_acc: 0.355 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.167 ;acc: 0.195 ;iou_acc: 0.315 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.505 ;Test accuracy 0.348 ;IOU accuracy: 0.457 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 60 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17821 ;lr: 0.0450 ;B loss: 1.098 ;acc: 0.615 ;iou: 0.725 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17871 ;lr: 0.0450 ;B loss: 2.845 ;acc: 0.490 ;iou: 0.550 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17921 ;lr: 0.0450 ;B loss: 2.090 ;acc: 0.635 ;iou: 0.710 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17971 ;lr: 0.0450 ;B loss: 2.017 ;acc: 0.635 ;iou: 0.710 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18021 ;lr: 0.0450 ;B loss: 2.224 ;acc: 0.620 ;iou: 0.675 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18071 ;lr: 0.0450 ;B loss: 1.448 ;acc: 0.710 ;iou: 0.740 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.784 ;Train accuracy: 0.645 ;IOU accuracy: 0.709 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 60\n",
      "batch: 0 ;B loss: 2.248 ;acc: 0.660 ;iou_acc: 0.790 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.884 ;acc: 0.470 ;iou_acc: 0.585 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.068 ;acc: 0.395 ;iou_acc: 0.515 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.314 ;acc: 0.365 ;iou_acc: 0.445 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.686 ;acc: 0.275 ;iou_acc: 0.395 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 3.167 ;acc: 0.190 ;iou_acc: 0.300 ;time: 0:00:47\n",
      "\n",
      "*BTrain: True ;Test loss: 2.487 ;Test accuracy 0.350 ;IOU accuracy: 0.460 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 61 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18118 ;lr: 0.0450 ;B loss: 1.821 ;acc: 0.700 ;iou: 0.760 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18168 ;lr: 0.0450 ;B loss: 1.392 ;acc: 0.720 ;iou: 0.795 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18218 ;lr: 0.0450 ;B loss: 1.259 ;acc: 0.755 ;iou: 0.820 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18268 ;lr: 0.0450 ;B loss: 2.018 ;acc: 0.655 ;iou: 0.715 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18318 ;lr: 0.0450 ;B loss: 2.194 ;acc: 0.630 ;iou: 0.695 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18368 ;lr: 0.0450 ;B loss: 1.108 ;acc: 0.660 ;iou: 0.710 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.772 ;Train accuracy: 0.652 ;IOU accuracy: 0.714 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 61\n",
      "batch: 0 ;B loss: 2.223 ;acc: 0.635 ;iou_acc: 0.765 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.844 ;acc: 0.435 ;iou_acc: 0.565 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.157 ;acc: 0.405 ;iou_acc: 0.520 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.423 ;acc: 0.330 ;iou_acc: 0.445 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.668 ;acc: 0.310 ;iou_acc: 0.420 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.195 ;acc: 0.230 ;iou_acc: 0.335 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.497 ;Test accuracy 0.350 ;IOU accuracy: 0.460 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 62 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18415 ;lr: 0.0450 ;B loss: 1.301 ;acc: 0.770 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18465 ;lr: 0.0450 ;B loss: 1.222 ;acc: 0.710 ;iou: 0.765 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18515 ;lr: 0.0450 ;B loss: 1.398 ;acc: 0.695 ;iou: 0.780 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18565 ;lr: 0.0450 ;B loss: 1.201 ;acc: 0.675 ;iou: 0.755 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18615 ;lr: 0.0450 ;B loss: 1.114 ;acc: 0.640 ;iou: 0.700 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18665 ;lr: 0.0450 ;B loss: 3.259 ;acc: 0.275 ;iou: 0.365 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.759 ;Train accuracy: 0.656 ;IOU accuracy: 0.717 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 62\n",
      "batch: 0 ;B loss: 2.296 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.879 ;acc: 0.470 ;iou_acc: 0.600 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.211 ;acc: 0.405 ;iou_acc: 0.530 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.369 ;acc: 0.370 ;iou_acc: 0.490 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.795 ;acc: 0.280 ;iou_acc: 0.390 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.227 ;acc: 0.195 ;iou_acc: 0.300 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.548 ;Test accuracy 0.351 ;IOU accuracy: 0.462 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 63 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18712 ;lr: 0.0450 ;B loss: 2.226 ;acc: 0.635 ;iou: 0.680 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18762 ;lr: 0.0450 ;B loss: 1.583 ;acc: 0.755 ;iou: 0.800 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18812 ;lr: 0.0450 ;B loss: 2.000 ;acc: 0.705 ;iou: 0.775 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18862 ;lr: 0.0450 ;B loss: 1.068 ;acc: 0.690 ;iou: 0.755 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18912 ;lr: 0.0450 ;B loss: 3.012 ;acc: 0.385 ;iou: 0.445 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18962 ;lr: 0.0450 ;B loss: 1.603 ;acc: 0.615 ;iou: 0.720 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.742 ;Train accuracy: 0.658 ;IOU accuracy: 0.720 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 63\n",
      "batch: 0 ;B loss: 2.360 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.896 ;acc: 0.470 ;iou_acc: 0.605 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.110 ;acc: 0.435 ;iou_acc: 0.565 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.345 ;acc: 0.365 ;iou_acc: 0.485 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.699 ;acc: 0.325 ;iou_acc: 0.450 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.181 ;acc: 0.235 ;iou_acc: 0.350 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.535 ;Test accuracy 0.362 ;IOU accuracy: 0.473 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 64 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19009 ;lr: 0.0450 ;B loss: 1.333 ;acc: 0.770 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19059 ;lr: 0.0450 ;B loss: 1.080 ;acc: 0.700 ;iou: 0.760 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19109 ;lr: 0.0450 ;B loss: 1.619 ;acc: 0.515 ;iou: 0.655 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19159 ;lr: 0.0450 ;B loss: 1.346 ;acc: 0.710 ;iou: 0.765 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19209 ;lr: 0.0450 ;B loss: 2.123 ;acc: 0.615 ;iou: 0.660 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19259 ;lr: 0.0450 ;B loss: 1.379 ;acc: 0.760 ;iou: 0.805 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.726 ;Train accuracy: 0.666 ;IOU accuracy: 0.725 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 64\n",
      "batch: 0 ;B loss: 2.408 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.892 ;acc: 0.465 ;iou_acc: 0.590 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.128 ;acc: 0.420 ;iou_acc: 0.545 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.331 ;acc: 0.350 ;iou_acc: 0.470 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.714 ;acc: 0.320 ;iou_acc: 0.435 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.183 ;acc: 0.220 ;iou_acc: 0.315 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.533 ;Test accuracy 0.361 ;IOU accuracy: 0.472 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 65 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19306 ;lr: 0.0450 ;B loss: 1.978 ;acc: 0.735 ;iou: 0.755 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19356 ;lr: 0.0450 ;B loss: 1.483 ;acc: 0.755 ;iou: 0.805 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19406 ;lr: 0.0450 ;B loss: 1.174 ;acc: 0.725 ;iou: 0.770 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19456 ;lr: 0.0450 ;B loss: 1.221 ;acc: 0.690 ;iou: 0.785 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19506 ;lr: 0.0450 ;B loss: 1.237 ;acc: 0.750 ;iou: 0.785 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19556 ;lr: 0.0450 ;B loss: 2.188 ;acc: 0.665 ;iou: 0.725 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.713 ;Train accuracy: 0.672 ;IOU accuracy: 0.732 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 65\n",
      "batch: 0 ;B loss: 2.406 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.944 ;acc: 0.465 ;iou_acc: 0.600 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.164 ;acc: 0.430 ;iou_acc: 0.555 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.347 ;acc: 0.385 ;iou_acc: 0.510 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.732 ;acc: 0.310 ;iou_acc: 0.425 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.195 ;acc: 0.235 ;iou_acc: 0.345 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.540 ;Test accuracy 0.362 ;IOU accuracy: 0.473 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 66 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19603 ;lr: 0.0450 ;B loss: 1.095 ;acc: 0.730 ;iou: 0.795 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19653 ;lr: 0.0450 ;B loss: 2.179 ;acc: 0.635 ;iou: 0.700 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19703 ;lr: 0.0450 ;B loss: 1.240 ;acc: 0.755 ;iou: 0.810 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19753 ;lr: 0.0450 ;B loss: 1.732 ;acc: 0.695 ;iou: 0.740 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19803 ;lr: 0.0450 ;B loss: 2.219 ;acc: 0.640 ;iou: 0.695 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19853 ;lr: 0.0450 ;B loss: 1.619 ;acc: 0.750 ;iou: 0.805 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.699 ;Train accuracy: 0.675 ;IOU accuracy: 0.735 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 66\n",
      "batch: 0 ;B loss: 2.336 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.940 ;acc: 0.490 ;iou_acc: 0.630 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.157 ;acc: 0.410 ;iou_acc: 0.525 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.459 ;acc: 0.335 ;iou_acc: 0.445 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.742 ;acc: 0.260 ;iou_acc: 0.380 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 3.264 ;acc: 0.215 ;iou_acc: 0.315 ;time: 0:00:47\n",
      "\n",
      "*BTrain: True ;Test loss: 2.562 ;Test accuracy 0.362 ;IOU accuracy: 0.473 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 67 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19900 ;lr: 0.0450 ;B loss: 2.043 ;acc: 0.700 ;iou: 0.745 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19950 ;lr: 0.0450 ;B loss: 1.286 ;acc: 0.760 ;iou: 0.815 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20000 ;lr: 0.0450 ;B loss: 1.233 ;acc: 0.770 ;iou: 0.795 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20050 ;lr: 0.0405 ;B loss: 2.448 ;acc: 0.610 ;iou: 0.660 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20100 ;lr: 0.0405 ;B loss: 1.171 ;acc: 0.680 ;iou: 0.750 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20150 ;lr: 0.0405 ;B loss: 2.107 ;acc: 0.635 ;iou: 0.705 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.671 ;Train accuracy: 0.681 ;IOU accuracy: 0.740 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 67\n",
      "batch: 0 ;B loss: 2.494 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.921 ;acc: 0.505 ;iou_acc: 0.640 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.190 ;acc: 0.460 ;iou_acc: 0.595 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.380 ;acc: 0.340 ;iou_acc: 0.460 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.774 ;acc: 0.275 ;iou_acc: 0.385 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.295 ;acc: 0.205 ;iou_acc: 0.315 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.547 ;Test accuracy 0.370 ;IOU accuracy: 0.481 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 68 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20197 ;lr: 0.0405 ;B loss: 1.064 ;acc: 0.715 ;iou: 0.760 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20247 ;lr: 0.0405 ;B loss: 1.720 ;acc: 0.730 ;iou: 0.760 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20297 ;lr: 0.0405 ;B loss: 1.440 ;acc: 0.755 ;iou: 0.805 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20347 ;lr: 0.0405 ;B loss: 1.871 ;acc: 0.710 ;iou: 0.760 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20397 ;lr: 0.0405 ;B loss: 1.870 ;acc: 0.695 ;iou: 0.750 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20447 ;lr: 0.0405 ;B loss: 1.375 ;acc: 0.770 ;iou: 0.815 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.642 ;Train accuracy: 0.687 ;IOU accuracy: 0.747 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 68\n",
      "batch: 0 ;B loss: 2.465 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.949 ;acc: 0.500 ;iou_acc: 0.635 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.234 ;acc: 0.435 ;iou_acc: 0.575 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.407 ;acc: 0.375 ;iou_acc: 0.510 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.825 ;acc: 0.310 ;iou_acc: 0.420 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.347 ;acc: 0.205 ;iou_acc: 0.325 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.613 ;Test accuracy 0.366 ;IOU accuracy: 0.479 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 69 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20494 ;lr: 0.0405 ;B loss: 1.212 ;acc: 0.780 ;iou: 0.825 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20544 ;lr: 0.0405 ;B loss: 1.642 ;acc: 0.755 ;iou: 0.815 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20594 ;lr: 0.0405 ;B loss: 1.864 ;acc: 0.705 ;iou: 0.755 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20644 ;lr: 0.0405 ;B loss: 2.517 ;acc: 0.540 ;iou: 0.620 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20694 ;lr: 0.0405 ;B loss: 2.438 ;acc: 0.510 ;iou: 0.575 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20744 ;lr: 0.0405 ;B loss: 2.031 ;acc: 0.740 ;iou: 0.805 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.635 ;Train accuracy: 0.689 ;IOU accuracy: 0.747 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 69\n",
      "batch: 0 ;B loss: 2.562 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.041 ;acc: 0.480 ;iou_acc: 0.630 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.210 ;acc: 0.405 ;iou_acc: 0.535 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.357 ;acc: 0.415 ;iou_acc: 0.510 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.829 ;acc: 0.330 ;iou_acc: 0.450 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.307 ;acc: 0.205 ;iou_acc: 0.350 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.628 ;Test accuracy 0.367 ;IOU accuracy: 0.481 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 70 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20791 ;lr: 0.0405 ;B loss: 1.169 ;acc: 0.710 ;iou: 0.750 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20841 ;lr: 0.0405 ;B loss: 1.280 ;acc: 0.805 ;iou: 0.845 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20891 ;lr: 0.0405 ;B loss: 1.176 ;acc: 0.760 ;iou: 0.800 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20941 ;lr: 0.0405 ;B loss: 1.266 ;acc: 0.820 ;iou: 0.855 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20991 ;lr: 0.0405 ;B loss: 2.675 ;acc: 0.445 ;iou: 0.500 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21041 ;lr: 0.0405 ;B loss: 1.623 ;acc: 0.770 ;iou: 0.785 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.622 ;Train accuracy: 0.694 ;IOU accuracy: 0.753 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 70\n",
      "batch: 0 ;B loss: 2.501 ;acc: 0.675 ;iou_acc: 0.805 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 1.923 ;acc: 0.515 ;iou_acc: 0.645 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.234 ;acc: 0.440 ;iou_acc: 0.555 ;time: 0:00:33\n",
      "batch: 150 ;B loss: 2.312 ;acc: 0.390 ;iou_acc: 0.495 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.838 ;acc: 0.305 ;iou_acc: 0.435 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.302 ;acc: 0.215 ;iou_acc: 0.315 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.591 ;Test accuracy 0.368 ;IOU accuracy: 0.483 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 71 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21088 ;lr: 0.0405 ;B loss: 1.607 ;acc: 0.790 ;iou: 0.860 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21138 ;lr: 0.0405 ;B loss: 1.686 ;acc: 0.805 ;iou: 0.820 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21188 ;lr: 0.0405 ;B loss: 1.157 ;acc: 0.740 ;iou: 0.820 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21238 ;lr: 0.0405 ;B loss: 2.239 ;acc: 0.615 ;iou: 0.670 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21288 ;lr: 0.0405 ;B loss: 1.808 ;acc: 0.745 ;iou: 0.780 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21338 ;lr: 0.0405 ;B loss: 1.071 ;acc: 0.730 ;iou: 0.775 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.601 ;Train accuracy: 0.701 ;IOU accuracy: 0.758 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 71\n",
      "batch: 0 ;B loss: 2.481 ;acc: 0.700 ;iou_acc: 0.825 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.949 ;acc: 0.490 ;iou_acc: 0.615 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.290 ;acc: 0.430 ;iou_acc: 0.545 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.402 ;acc: 0.380 ;iou_acc: 0.520 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.888 ;acc: 0.310 ;iou_acc: 0.395 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.391 ;acc: 0.220 ;iou_acc: 0.295 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.635 ;Test accuracy 0.373 ;IOU accuracy: 0.485 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 72 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21385 ;lr: 0.0405 ;B loss: 1.314 ;acc: 0.790 ;iou: 0.850 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21435 ;lr: 0.0405 ;B loss: 1.961 ;acc: 0.680 ;iou: 0.720 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21485 ;lr: 0.0405 ;B loss: 1.873 ;acc: 0.785 ;iou: 0.805 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21535 ;lr: 0.0405 ;B loss: 2.052 ;acc: 0.695 ;iou: 0.735 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21585 ;lr: 0.0405 ;B loss: 2.054 ;acc: 0.675 ;iou: 0.715 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21635 ;lr: 0.0405 ;B loss: 1.393 ;acc: 0.750 ;iou: 0.805 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.597 ;Train accuracy: 0.703 ;IOU accuracy: 0.760 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 72\n",
      "batch: 0 ;B loss: 2.574 ;acc: 0.705 ;iou_acc: 0.815 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.918 ;acc: 0.550 ;iou_acc: 0.675 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.260 ;acc: 0.435 ;iou_acc: 0.550 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.385 ;acc: 0.385 ;iou_acc: 0.490 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.862 ;acc: 0.335 ;iou_acc: 0.430 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.352 ;acc: 0.220 ;iou_acc: 0.345 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.623 ;Test accuracy 0.377 ;IOU accuracy: 0.492 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 73 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21682 ;lr: 0.0405 ;B loss: 1.858 ;acc: 0.730 ;iou: 0.795 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21732 ;lr: 0.0405 ;B loss: 1.164 ;acc: 0.740 ;iou: 0.770 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21782 ;lr: 0.0405 ;B loss: 1.089 ;acc: 0.800 ;iou: 0.860 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21832 ;lr: 0.0405 ;B loss: 1.850 ;acc: 0.705 ;iou: 0.755 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21882 ;lr: 0.0405 ;B loss: 0.977 ;acc: 0.710 ;iou: 0.760 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21932 ;lr: 0.0405 ;B loss: 1.098 ;acc: 0.710 ;iou: 0.785 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.580 ;Train accuracy: 0.708 ;IOU accuracy: 0.763 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 73\n",
      "batch: 0 ;B loss: 2.531 ;acc: 0.660 ;iou_acc: 0.795 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.974 ;acc: 0.485 ;iou_acc: 0.630 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.175 ;acc: 0.450 ;iou_acc: 0.610 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.274 ;acc: 0.385 ;iou_acc: 0.505 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.856 ;acc: 0.305 ;iou_acc: 0.430 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.272 ;acc: 0.240 ;iou_acc: 0.335 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.620 ;Test accuracy 0.376 ;IOU accuracy: 0.489 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 74 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21979 ;lr: 0.0405 ;B loss: 1.154 ;acc: 0.795 ;iou: 0.835 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22029 ;lr: 0.0405 ;B loss: 1.064 ;acc: 0.765 ;iou: 0.805 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22079 ;lr: 0.0405 ;B loss: 1.830 ;acc: 0.780 ;iou: 0.845 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22129 ;lr: 0.0405 ;B loss: 1.153 ;acc: 0.770 ;iou: 0.810 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22179 ;lr: 0.0405 ;B loss: 1.059 ;acc: 0.755 ;iou: 0.820 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22229 ;lr: 0.0405 ;B loss: 1.764 ;acc: 0.730 ;iou: 0.765 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.562 ;Train accuracy: 0.714 ;IOU accuracy: 0.769 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 74\n",
      "batch: 0 ;B loss: 2.685 ;acc: 0.690 ;iou_acc: 0.820 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.998 ;acc: 0.495 ;iou_acc: 0.620 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.279 ;acc: 0.460 ;iou_acc: 0.580 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.413 ;acc: 0.420 ;iou_acc: 0.525 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.878 ;acc: 0.310 ;iou_acc: 0.430 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.461 ;acc: 0.210 ;iou_acc: 0.305 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.677 ;Test accuracy 0.382 ;IOU accuracy: 0.497 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 75 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22276 ;lr: 0.0405 ;B loss: 1.378 ;acc: 0.840 ;iou: 0.855 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22326 ;lr: 0.0405 ;B loss: 1.582 ;acc: 0.720 ;iou: 0.785 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22376 ;lr: 0.0405 ;B loss: 2.278 ;acc: 0.660 ;iou: 0.690 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22426 ;lr: 0.0405 ;B loss: 1.181 ;acc: 0.840 ;iou: 0.870 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22476 ;lr: 0.0405 ;B loss: 1.059 ;acc: 0.730 ;iou: 0.785 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22526 ;lr: 0.0405 ;B loss: 1.223 ;acc: 0.760 ;iou: 0.790 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.553 ;Train accuracy: 0.716 ;IOU accuracy: 0.771 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 75\n",
      "batch: 0 ;B loss: 2.657 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 1.996 ;acc: 0.545 ;iou_acc: 0.675 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.297 ;acc: 0.415 ;iou_acc: 0.555 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.401 ;acc: 0.400 ;iou_acc: 0.505 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.866 ;acc: 0.300 ;iou_acc: 0.420 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.466 ;acc: 0.195 ;iou_acc: 0.335 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.656 ;Test accuracy 0.380 ;IOU accuracy: 0.494 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 76 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22573 ;lr: 0.0405 ;B loss: 1.007 ;acc: 0.695 ;iou: 0.765 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22623 ;lr: 0.0405 ;B loss: 1.709 ;acc: 0.795 ;iou: 0.830 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22673 ;lr: 0.0405 ;B loss: 1.092 ;acc: 0.720 ;iou: 0.760 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22723 ;lr: 0.0405 ;B loss: 1.414 ;acc: 0.785 ;iou: 0.845 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22773 ;lr: 0.0405 ;B loss: 1.071 ;acc: 0.680 ;iou: 0.755 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22823 ;lr: 0.0405 ;B loss: 1.225 ;acc: 0.800 ;iou: 0.815 ;time: 0:00:25\n",
      "\n",
      "*Training B: False ;B Train loss: 1.540 ;Train accuracy: 0.716 ;IOU accuracy: 0.772 ;Time: 0:00:29 \n",
      "\n",
      "Testing, ephoc: 76\n",
      "batch: 0 ;B loss: 2.640 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.968 ;acc: 0.510 ;iou_acc: 0.630 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.330 ;acc: 0.450 ;iou_acc: 0.575 ;time: 0:00:36\n",
      "batch: 150 ;B loss: 2.454 ;acc: 0.380 ;iou_acc: 0.515 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.898 ;acc: 0.325 ;iou_acc: 0.445 ;time: 0:00:43\n",
      "batch: 250 ;B loss: 3.402 ;acc: 0.240 ;iou_acc: 0.335 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.677 ;Test accuracy 0.375 ;IOU accuracy: 0.487 ;Time: 0:00:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 77 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22870 ;lr: 0.0405 ;B loss: 1.120 ;acc: 0.745 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22920 ;lr: 0.0405 ;B loss: 1.279 ;acc: 0.815 ;iou: 0.840 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22970 ;lr: 0.0405 ;B loss: 2.533 ;acc: 0.510 ;iou: 0.560 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23020 ;lr: 0.0405 ;B loss: 2.110 ;acc: 0.660 ;iou: 0.715 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23070 ;lr: 0.0405 ;B loss: 1.678 ;acc: 0.520 ;iou: 0.670 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23120 ;lr: 0.0405 ;B loss: 1.138 ;acc: 0.765 ;iou: 0.830 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.521 ;Train accuracy: 0.725 ;IOU accuracy: 0.780 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 77\n",
      "batch: 0 ;B loss: 2.737 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.036 ;acc: 0.500 ;iou_acc: 0.635 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.251 ;acc: 0.460 ;iou_acc: 0.595 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.322 ;acc: 0.435 ;iou_acc: 0.530 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.878 ;acc: 0.330 ;iou_acc: 0.435 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.431 ;acc: 0.230 ;iou_acc: 0.330 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.683 ;Test accuracy 0.385 ;IOU accuracy: 0.497 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 78 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23167 ;lr: 0.0405 ;B loss: 1.080 ;acc: 0.745 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23217 ;lr: 0.0405 ;B loss: 1.211 ;acc: 0.775 ;iou: 0.835 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23267 ;lr: 0.0405 ;B loss: 2.114 ;acc: 0.695 ;iou: 0.730 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23317 ;lr: 0.0405 ;B loss: 1.603 ;acc: 0.780 ;iou: 0.825 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23367 ;lr: 0.0405 ;B loss: 1.187 ;acc: 0.790 ;iou: 0.825 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23417 ;lr: 0.0405 ;B loss: 1.212 ;acc: 0.750 ;iou: 0.790 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.507 ;Train accuracy: 0.728 ;IOU accuracy: 0.781 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 78\n",
      "batch: 0 ;B loss: 2.696 ;acc: 0.690 ;iou_acc: 0.820 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 1.979 ;acc: 0.515 ;iou_acc: 0.665 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.246 ;acc: 0.445 ;iou_acc: 0.570 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.425 ;acc: 0.365 ;iou_acc: 0.490 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.904 ;acc: 0.325 ;iou_acc: 0.470 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.490 ;acc: 0.210 ;iou_acc: 0.305 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.688 ;Test accuracy 0.384 ;IOU accuracy: 0.499 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 79 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23464 ;lr: 0.0405 ;B loss: 1.420 ;acc: 0.795 ;iou: 0.835 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23514 ;lr: 0.0405 ;B loss: 1.560 ;acc: 0.780 ;iou: 0.805 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23564 ;lr: 0.0405 ;B loss: 1.256 ;acc: 0.815 ;iou: 0.870 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23614 ;lr: 0.0405 ;B loss: 1.477 ;acc: 0.745 ;iou: 0.790 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23664 ;lr: 0.0405 ;B loss: 1.115 ;acc: 0.820 ;iou: 0.860 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23714 ;lr: 0.0405 ;B loss: 1.261 ;acc: 0.780 ;iou: 0.835 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.497 ;Train accuracy: 0.728 ;IOU accuracy: 0.782 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 79\n",
      "batch: 0 ;B loss: 2.771 ;acc: 0.695 ;iou_acc: 0.825 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.064 ;acc: 0.525 ;iou_acc: 0.670 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.265 ;acc: 0.495 ;iou_acc: 0.585 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.507 ;acc: 0.415 ;iou_acc: 0.550 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 2.912 ;acc: 0.290 ;iou_acc: 0.410 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.421 ;acc: 0.220 ;iou_acc: 0.345 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.701 ;Test accuracy 0.389 ;IOU accuracy: 0.503 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 80 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23761 ;lr: 0.0405 ;B loss: 1.690 ;acc: 0.750 ;iou: 0.790 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23811 ;lr: 0.0405 ;B loss: 0.982 ;acc: 0.775 ;iou: 0.810 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23861 ;lr: 0.0405 ;B loss: 1.105 ;acc: 0.715 ;iou: 0.795 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23911 ;lr: 0.0405 ;B loss: 1.465 ;acc: 0.800 ;iou: 0.840 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23961 ;lr: 0.0405 ;B loss: 1.153 ;acc: 0.790 ;iou: 0.835 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24011 ;lr: 0.0405 ;B loss: 1.613 ;acc: 0.765 ;iou: 0.795 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.489 ;Train accuracy: 0.731 ;IOU accuracy: 0.785 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 80\n",
      "batch: 0 ;B loss: 2.731 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.057 ;acc: 0.525 ;iou_acc: 0.660 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.299 ;acc: 0.455 ;iou_acc: 0.605 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.518 ;acc: 0.375 ;iou_acc: 0.500 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.017 ;acc: 0.285 ;iou_acc: 0.405 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.599 ;acc: 0.230 ;iou_acc: 0.300 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.771 ;Test accuracy 0.387 ;IOU accuracy: 0.500 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 81 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24058 ;lr: 0.0405 ;B loss: 1.913 ;acc: 0.680 ;iou: 0.730 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24108 ;lr: 0.0405 ;B loss: 1.015 ;acc: 0.645 ;iou: 0.710 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24158 ;lr: 0.0405 ;B loss: 1.391 ;acc: 0.780 ;iou: 0.840 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24208 ;lr: 0.0405 ;B loss: 1.099 ;acc: 0.790 ;iou: 0.825 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24258 ;lr: 0.0405 ;B loss: 2.252 ;acc: 0.605 ;iou: 0.640 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24308 ;lr: 0.0405 ;B loss: 1.664 ;acc: 0.815 ;iou: 0.845 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.472 ;Train accuracy: 0.734 ;IOU accuracy: 0.786 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 81\n",
      "batch: 0 ;B loss: 2.970 ;acc: 0.685 ;iou_acc: 0.820 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.012 ;acc: 0.585 ;iou_acc: 0.710 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.345 ;acc: 0.455 ;iou_acc: 0.610 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.479 ;acc: 0.415 ;iou_acc: 0.525 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.871 ;acc: 0.325 ;iou_acc: 0.415 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.457 ;acc: 0.240 ;iou_acc: 0.350 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.713 ;Test accuracy 0.396 ;IOU accuracy: 0.511 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 82 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24355 ;lr: 0.0405 ;B loss: 1.186 ;acc: 0.825 ;iou: 0.845 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24405 ;lr: 0.0405 ;B loss: 1.141 ;acc: 0.820 ;iou: 0.870 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24455 ;lr: 0.0405 ;B loss: 1.101 ;acc: 0.805 ;iou: 0.830 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24505 ;lr: 0.0405 ;B loss: 1.070 ;acc: 0.810 ;iou: 0.855 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24555 ;lr: 0.0405 ;B loss: 1.055 ;acc: 0.745 ;iou: 0.800 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24605 ;lr: 0.0405 ;B loss: 1.351 ;acc: 0.805 ;iou: 0.830 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.462 ;Train accuracy: 0.737 ;IOU accuracy: 0.789 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 82\n",
      "batch: 0 ;B loss: 2.826 ;acc: 0.705 ;iou_acc: 0.830 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 2.098 ;acc: 0.505 ;iou_acc: 0.655 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.410 ;acc: 0.480 ;iou_acc: 0.595 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.480 ;acc: 0.420 ;iou_acc: 0.515 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.958 ;acc: 0.345 ;iou_acc: 0.455 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.612 ;acc: 0.220 ;iou_acc: 0.310 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.735 ;Test accuracy 0.392 ;IOU accuracy: 0.506 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 83 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24652 ;lr: 0.0405 ;B loss: 1.587 ;acc: 0.810 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24702 ;lr: 0.0405 ;B loss: 0.951 ;acc: 0.760 ;iou: 0.810 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24752 ;lr: 0.0405 ;B loss: 1.786 ;acc: 0.790 ;iou: 0.825 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24802 ;lr: 0.0405 ;B loss: 0.966 ;acc: 0.780 ;iou: 0.825 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24852 ;lr: 0.0405 ;B loss: 1.699 ;acc: 0.780 ;iou: 0.805 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24902 ;lr: 0.0405 ;B loss: 1.187 ;acc: 0.810 ;iou: 0.860 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.444 ;Train accuracy: 0.741 ;IOU accuracy: 0.794 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 83\n",
      "batch: 0 ;B loss: 2.650 ;acc: 0.665 ;iou_acc: 0.800 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.001 ;acc: 0.480 ;iou_acc: 0.650 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.253 ;acc: 0.475 ;iou_acc: 0.615 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.445 ;acc: 0.420 ;iou_acc: 0.550 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.946 ;acc: 0.290 ;iou_acc: 0.415 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.549 ;acc: 0.255 ;iou_acc: 0.365 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.728 ;Test accuracy 0.384 ;IOU accuracy: 0.501 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 84 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24949 ;lr: 0.0405 ;B loss: 1.141 ;acc: 0.845 ;iou: 0.885 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24999 ;lr: 0.0405 ;B loss: 1.008 ;acc: 0.840 ;iou: 0.870 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25049 ;lr: 0.0405 ;B loss: 1.613 ;acc: 0.795 ;iou: 0.840 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25099 ;lr: 0.0405 ;B loss: 1.818 ;acc: 0.735 ;iou: 0.775 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25149 ;lr: 0.0405 ;B loss: 1.762 ;acc: 0.770 ;iou: 0.800 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25199 ;lr: 0.0405 ;B loss: 1.292 ;acc: 0.775 ;iou: 0.800 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.431 ;Train accuracy: 0.745 ;IOU accuracy: 0.797 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 84\n",
      "batch: 0 ;B loss: 3.114 ;acc: 0.705 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.060 ;acc: 0.575 ;iou_acc: 0.700 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.420 ;acc: 0.500 ;iou_acc: 0.635 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.536 ;acc: 0.420 ;iou_acc: 0.555 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 3.039 ;acc: 0.280 ;iou_acc: 0.390 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.544 ;acc: 0.250 ;iou_acc: 0.345 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.790 ;Test accuracy 0.398 ;IOU accuracy: 0.513 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 85 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25246 ;lr: 0.0405 ;B loss: 1.096 ;acc: 0.685 ;iou: 0.750 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25296 ;lr: 0.0405 ;B loss: 0.920 ;acc: 0.755 ;iou: 0.810 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25346 ;lr: 0.0405 ;B loss: 1.076 ;acc: 0.805 ;iou: 0.850 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25396 ;lr: 0.0405 ;B loss: 1.730 ;acc: 0.450 ;iou: 0.605 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25446 ;lr: 0.0405 ;B loss: 1.184 ;acc: 0.820 ;iou: 0.845 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25496 ;lr: 0.0405 ;B loss: 1.806 ;acc: 0.800 ;iou: 0.845 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.424 ;Train accuracy: 0.746 ;IOU accuracy: 0.798 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 85\n",
      "batch: 0 ;B loss: 3.109 ;acc: 0.710 ;iou_acc: 0.825 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.039 ;acc: 0.590 ;iou_acc: 0.715 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.338 ;acc: 0.470 ;iou_acc: 0.605 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.566 ;acc: 0.395 ;iou_acc: 0.540 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.065 ;acc: 0.285 ;iou_acc: 0.405 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.594 ;acc: 0.255 ;iou_acc: 0.355 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.851 ;Test accuracy 0.396 ;IOU accuracy: 0.513 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 86 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25543 ;lr: 0.0405 ;B loss: 1.402 ;acc: 0.820 ;iou: 0.835 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25593 ;lr: 0.0405 ;B loss: 1.243 ;acc: 0.810 ;iou: 0.835 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25643 ;lr: 0.0405 ;B loss: 1.175 ;acc: 0.815 ;iou: 0.845 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25693 ;lr: 0.0405 ;B loss: 1.127 ;acc: 0.835 ;iou: 0.850 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25743 ;lr: 0.0405 ;B loss: 1.234 ;acc: 0.840 ;iou: 0.875 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25793 ;lr: 0.0405 ;B loss: 1.055 ;acc: 0.690 ;iou: 0.745 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.406 ;Train accuracy: 0.748 ;IOU accuracy: 0.800 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 86\n",
      "batch: 0 ;B loss: 2.947 ;acc: 0.725 ;iou_acc: 0.835 ;time: 0:00:29\n",
      "batch: 50 ;B loss: 2.122 ;acc: 0.555 ;iou_acc: 0.690 ;time: 0:00:32\n",
      "batch: 100 ;B loss: 2.391 ;acc: 0.520 ;iou_acc: 0.655 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.410 ;acc: 0.405 ;iou_acc: 0.540 ;time: 0:00:39\n",
      "batch: 200 ;B loss: 2.969 ;acc: 0.325 ;iou_acc: 0.455 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.552 ;acc: 0.240 ;iou_acc: 0.355 ;time: 0:00:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.787 ;Test accuracy 0.399 ;IOU accuracy: 0.515 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 87 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25840 ;lr: 0.0405 ;B loss: 1.325 ;acc: 0.885 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25890 ;lr: 0.0405 ;B loss: 1.131 ;acc: 0.810 ;iou: 0.830 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25940 ;lr: 0.0405 ;B loss: 1.014 ;acc: 0.785 ;iou: 0.830 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25990 ;lr: 0.0405 ;B loss: 0.989 ;acc: 0.780 ;iou: 0.835 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26040 ;lr: 0.0405 ;B loss: 2.216 ;acc: 0.705 ;iou: 0.740 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26090 ;lr: 0.0405 ;B loss: 1.094 ;acc: 0.750 ;iou: 0.820 ;time: 0:00:22\n",
      "\n",
      "*Training B: True ;B Train loss: 1.389 ;Train accuracy: 0.751 ;IOU accuracy: 0.801 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 87\n",
      "batch: 0 ;B loss: 2.962 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.044 ;acc: 0.565 ;iou_acc: 0.680 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.442 ;acc: 0.495 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.558 ;acc: 0.415 ;iou_acc: 0.530 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 3.188 ;acc: 0.290 ;iou_acc: 0.415 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.676 ;acc: 0.240 ;iou_acc: 0.350 ;time: 0:00:45\n",
      "\n",
      "*BTrain: True ;Test loss: 2.871 ;Test accuracy 0.393 ;IOU accuracy: 0.510 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 88 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26137 ;lr: 0.0405 ;B loss: 2.456 ;acc: 0.450 ;iou: 0.540 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26187 ;lr: 0.0405 ;B loss: 1.713 ;acc: 0.525 ;iou: 0.685 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26237 ;lr: 0.0405 ;B loss: 2.013 ;acc: 0.715 ;iou: 0.755 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26287 ;lr: 0.0405 ;B loss: 1.332 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26337 ;lr: 0.0405 ;B loss: 0.934 ;acc: 0.815 ;iou: 0.840 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26387 ;lr: 0.0405 ;B loss: 1.265 ;acc: 0.820 ;iou: 0.845 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.378 ;Train accuracy: 0.754 ;IOU accuracy: 0.805 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 88\n",
      "batch: 0 ;B loss: 3.091 ;acc: 0.700 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.052 ;acc: 0.575 ;iou_acc: 0.710 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.400 ;acc: 0.485 ;iou_acc: 0.610 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.582 ;acc: 0.405 ;iou_acc: 0.525 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 3.158 ;acc: 0.310 ;iou_acc: 0.425 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.651 ;acc: 0.235 ;iou_acc: 0.370 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.859 ;Test accuracy 0.401 ;IOU accuracy: 0.515 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 89 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26434 ;lr: 0.0405 ;B loss: 1.016 ;acc: 0.655 ;iou: 0.730 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26484 ;lr: 0.0405 ;B loss: 1.869 ;acc: 0.730 ;iou: 0.775 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26534 ;lr: 0.0405 ;B loss: 1.730 ;acc: 0.750 ;iou: 0.800 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26584 ;lr: 0.0405 ;B loss: 1.676 ;acc: 0.780 ;iou: 0.855 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26634 ;lr: 0.0405 ;B loss: 2.142 ;acc: 0.710 ;iou: 0.755 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26684 ;lr: 0.0405 ;B loss: 1.091 ;acc: 0.770 ;iou: 0.820 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.379 ;Train accuracy: 0.753 ;IOU accuracy: 0.802 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 89\n",
      "batch: 0 ;B loss: 2.970 ;acc: 0.710 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.053 ;acc: 0.560 ;iou_acc: 0.695 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.385 ;acc: 0.475 ;iou_acc: 0.615 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.470 ;acc: 0.410 ;iou_acc: 0.520 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 2.920 ;acc: 0.330 ;iou_acc: 0.450 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.604 ;acc: 0.240 ;iou_acc: 0.340 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.820 ;Test accuracy 0.397 ;IOU accuracy: 0.513 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 90 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26731 ;lr: 0.0405 ;B loss: 0.951 ;acc: 0.820 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26781 ;lr: 0.0405 ;B loss: 1.022 ;acc: 0.700 ;iou: 0.775 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26831 ;lr: 0.0405 ;B loss: 1.071 ;acc: 0.680 ;iou: 0.725 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26881 ;lr: 0.0405 ;B loss: 1.341 ;acc: 0.785 ;iou: 0.845 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26931 ;lr: 0.0405 ;B loss: 1.325 ;acc: 0.800 ;iou: 0.850 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26981 ;lr: 0.0405 ;B loss: 1.047 ;acc: 0.800 ;iou: 0.835 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.358 ;Train accuracy: 0.759 ;IOU accuracy: 0.809 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 90\n",
      "batch: 0 ;B loss: 3.137 ;acc: 0.750 ;iou_acc: 0.855 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.046 ;acc: 0.555 ;iou_acc: 0.695 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.526 ;acc: 0.490 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.403 ;acc: 0.445 ;iou_acc: 0.550 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 3.170 ;acc: 0.290 ;iou_acc: 0.430 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.716 ;acc: 0.210 ;iou_acc: 0.340 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.882 ;Test accuracy 0.401 ;IOU accuracy: 0.517 ;Time: 0:00:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 91 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27028 ;lr: 0.0405 ;B loss: 0.922 ;acc: 0.755 ;iou: 0.815 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27078 ;lr: 0.0405 ;B loss: 1.415 ;acc: 0.815 ;iou: 0.870 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27128 ;lr: 0.0405 ;B loss: 1.091 ;acc: 0.850 ;iou: 0.890 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27178 ;lr: 0.0405 ;B loss: 1.480 ;acc: 0.795 ;iou: 0.815 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27228 ;lr: 0.0405 ;B loss: 1.818 ;acc: 0.785 ;iou: 0.815 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27278 ;lr: 0.0405 ;B loss: 1.863 ;acc: 0.745 ;iou: 0.770 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.347 ;Train accuracy: 0.759 ;IOU accuracy: 0.809 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 91\n",
      "batch: 0 ;B loss: 3.109 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.109 ;acc: 0.565 ;iou_acc: 0.715 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.366 ;acc: 0.465 ;iou_acc: 0.605 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.460 ;acc: 0.420 ;iou_acc: 0.550 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.163 ;acc: 0.305 ;iou_acc: 0.425 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.654 ;acc: 0.255 ;iou_acc: 0.365 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.829 ;Test accuracy 0.404 ;IOU accuracy: 0.520 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 92 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27325 ;lr: 0.0405 ;B loss: 0.947 ;acc: 0.845 ;iou: 0.885 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27375 ;lr: 0.0405 ;B loss: 0.905 ;acc: 0.785 ;iou: 0.815 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27425 ;lr: 0.0405 ;B loss: 1.930 ;acc: 0.765 ;iou: 0.780 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27475 ;lr: 0.0405 ;B loss: 1.895 ;acc: 0.720 ;iou: 0.765 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27525 ;lr: 0.0405 ;B loss: 1.048 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27575 ;lr: 0.0405 ;B loss: 1.406 ;acc: 0.865 ;iou: 0.885 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.328 ;Train accuracy: 0.761 ;IOU accuracy: 0.810 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 92\n",
      "batch: 0 ;B loss: 3.093 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:00:27\n",
      "batch: 50 ;B loss: 2.098 ;acc: 0.555 ;iou_acc: 0.700 ;time: 0:00:30\n",
      "batch: 100 ;B loss: 2.410 ;acc: 0.490 ;iou_acc: 0.605 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.411 ;acc: 0.470 ;iou_acc: 0.585 ;time: 0:00:37\n",
      "batch: 200 ;B loss: 3.125 ;acc: 0.320 ;iou_acc: 0.450 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.583 ;acc: 0.255 ;iou_acc: 0.360 ;time: 0:00:45\n",
      "\n",
      "*BTrain: False ;Test loss: 2.871 ;Test accuracy 0.405 ;IOU accuracy: 0.522 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 93 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27622 ;lr: 0.0405 ;B loss: 0.809 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27672 ;lr: 0.0405 ;B loss: 1.716 ;acc: 0.495 ;iou: 0.680 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27722 ;lr: 0.0405 ;B loss: 2.188 ;acc: 0.580 ;iou: 0.625 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27772 ;lr: 0.0405 ;B loss: 1.383 ;acc: 0.825 ;iou: 0.860 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27822 ;lr: 0.0405 ;B loss: 1.768 ;acc: 0.810 ;iou: 0.840 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27872 ;lr: 0.0405 ;B loss: 2.004 ;acc: 0.700 ;iou: 0.730 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.312 ;Train accuracy: 0.766 ;IOU accuracy: 0.815 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 93\n",
      "batch: 0 ;B loss: 3.281 ;acc: 0.730 ;iou_acc: 0.840 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.217 ;acc: 0.560 ;iou_acc: 0.695 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.468 ;acc: 0.495 ;iou_acc: 0.600 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.523 ;acc: 0.435 ;iou_acc: 0.570 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.119 ;acc: 0.320 ;iou_acc: 0.460 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.751 ;acc: 0.260 ;iou_acc: 0.390 ;time: 0:00:47\n",
      "\n",
      "*BTrain: True ;Test loss: 2.922 ;Test accuracy 0.406 ;IOU accuracy: 0.522 ;Time: 0:00:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 94 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27919 ;lr: 0.0405 ;B loss: 1.098 ;acc: 0.725 ;iou: 0.790 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27969 ;lr: 0.0405 ;B loss: 1.384 ;acc: 0.810 ;iou: 0.840 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28019 ;lr: 0.0405 ;B loss: 0.997 ;acc: 0.825 ;iou: 0.855 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28069 ;lr: 0.0405 ;B loss: 1.546 ;acc: 0.860 ;iou: 0.875 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28119 ;lr: 0.0405 ;B loss: 1.020 ;acc: 0.710 ;iou: 0.755 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28169 ;lr: 0.0405 ;B loss: 1.192 ;acc: 0.845 ;iou: 0.900 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.304 ;Train accuracy: 0.768 ;IOU accuracy: 0.816 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 94\n",
      "batch: 0 ;B loss: 3.185 ;acc: 0.735 ;iou_acc: 0.845 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.288 ;acc: 0.570 ;iou_acc: 0.700 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.543 ;acc: 0.470 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.680 ;acc: 0.440 ;iou_acc: 0.540 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.154 ;acc: 0.310 ;iou_acc: 0.460 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.783 ;acc: 0.250 ;iou_acc: 0.385 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.996 ;Test accuracy 0.402 ;IOU accuracy: 0.518 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 95 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28216 ;lr: 0.0405 ;B loss: 0.833 ;acc: 0.795 ;iou: 0.850 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28266 ;lr: 0.0405 ;B loss: 1.057 ;acc: 0.840 ;iou: 0.865 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28316 ;lr: 0.0405 ;B loss: 1.013 ;acc: 0.720 ;iou: 0.780 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28366 ;lr: 0.0405 ;B loss: 0.960 ;acc: 0.815 ;iou: 0.880 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28416 ;lr: 0.0405 ;B loss: 0.976 ;acc: 0.675 ;iou: 0.725 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28466 ;lr: 0.0405 ;B loss: 1.143 ;acc: 0.820 ;iou: 0.840 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.297 ;Train accuracy: 0.766 ;IOU accuracy: 0.815 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 95\n",
      "batch: 0 ;B loss: 3.244 ;acc: 0.725 ;iou_acc: 0.850 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.224 ;acc: 0.550 ;iou_acc: 0.705 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.453 ;acc: 0.445 ;iou_acc: 0.595 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.507 ;acc: 0.455 ;iou_acc: 0.550 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.261 ;acc: 0.335 ;iou_acc: 0.435 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.878 ;acc: 0.235 ;iou_acc: 0.360 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.935 ;Test accuracy 0.408 ;IOU accuracy: 0.524 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 96 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28513 ;lr: 0.0405 ;B loss: 1.669 ;acc: 0.485 ;iou: 0.615 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28563 ;lr: 0.0405 ;B loss: 1.695 ;acc: 0.600 ;iou: 0.705 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28613 ;lr: 0.0405 ;B loss: 1.277 ;acc: 0.825 ;iou: 0.845 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28663 ;lr: 0.0405 ;B loss: 1.297 ;acc: 0.760 ;iou: 0.805 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28713 ;lr: 0.0405 ;B loss: 1.544 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28763 ;lr: 0.0405 ;B loss: 1.077 ;acc: 0.740 ;iou: 0.775 ;time: 0:00:23\n",
      "\n",
      "*Training B: True ;B Train loss: 1.285 ;Train accuracy: 0.768 ;IOU accuracy: 0.816 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 96\n",
      "batch: 0 ;B loss: 3.379 ;acc: 0.715 ;iou_acc: 0.830 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.222 ;acc: 0.545 ;iou_acc: 0.685 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.393 ;acc: 0.475 ;iou_acc: 0.630 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.471 ;acc: 0.470 ;iou_acc: 0.595 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.205 ;acc: 0.330 ;iou_acc: 0.445 ;time: 0:00:41\n",
      "batch: 250 ;B loss: 3.712 ;acc: 0.245 ;iou_acc: 0.390 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 2.978 ;Test accuracy 0.411 ;IOU accuracy: 0.527 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 97 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28810 ;lr: 0.0405 ;B loss: 1.127 ;acc: 0.875 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28860 ;lr: 0.0405 ;B loss: 0.974 ;acc: 0.770 ;iou: 0.835 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28910 ;lr: 0.0405 ;B loss: 2.378 ;acc: 0.470 ;iou: 0.545 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28960 ;lr: 0.0405 ;B loss: 1.505 ;acc: 0.795 ;iou: 0.820 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29010 ;lr: 0.0405 ;B loss: 1.000 ;acc: 0.665 ;iou: 0.720 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29060 ;lr: 0.0405 ;B loss: 0.910 ;acc: 0.745 ;iou: 0.815 ;time: 0:00:23\n",
      "\n",
      "*Training B: False ;B Train loss: 1.269 ;Train accuracy: 0.769 ;IOU accuracy: 0.818 ;Time: 0:00:27 \n",
      "\n",
      "Testing, ephoc: 97\n",
      "batch: 0 ;B loss: 3.197 ;acc: 0.720 ;iou_acc: 0.835 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.299 ;acc: 0.545 ;iou_acc: 0.680 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.494 ;acc: 0.455 ;iou_acc: 0.600 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.507 ;acc: 0.445 ;iou_acc: 0.565 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.113 ;acc: 0.320 ;iou_acc: 0.435 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.795 ;acc: 0.265 ;iou_acc: 0.370 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 2.963 ;Test accuracy 0.411 ;IOU accuracy: 0.526 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 98 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 29107 ;lr: 0.0405 ;B loss: 0.947 ;acc: 0.845 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29157 ;lr: 0.0405 ;B loss: 1.380 ;acc: 0.830 ;iou: 0.865 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 29207 ;lr: 0.0405 ;B loss: 1.883 ;acc: 0.695 ;iou: 0.760 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 29257 ;lr: 0.0405 ;B loss: 1.581 ;acc: 0.825 ;iou: 0.855 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29307 ;lr: 0.0405 ;B loss: 0.947 ;acc: 0.830 ;iou: 0.860 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29357 ;lr: 0.0405 ;B loss: 0.928 ;acc: 0.835 ;iou: 0.875 ;time: 0:00:24\n",
      "\n",
      "*Training B: False ;B Train loss: 1.254 ;Train accuracy: 0.775 ;IOU accuracy: 0.822 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 98\n",
      "batch: 0 ;B loss: 3.338 ;acc: 0.720 ;iou_acc: 0.840 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.291 ;acc: 0.525 ;iou_acc: 0.685 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.375 ;acc: 0.485 ;iou_acc: 0.615 ;time: 0:00:35\n",
      "batch: 150 ;B loss: 2.555 ;acc: 0.430 ;iou_acc: 0.550 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.180 ;acc: 0.300 ;iou_acc: 0.445 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.887 ;acc: 0.250 ;iou_acc: 0.345 ;time: 0:00:46\n",
      "\n",
      "*BTrain: False ;Test loss: 3.000 ;Test accuracy 0.409 ;IOU accuracy: 0.525 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 99 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 29404 ;lr: 0.0405 ;B loss: 1.191 ;acc: 0.810 ;iou: 0.825 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29454 ;lr: 0.0405 ;B loss: 1.368 ;acc: 0.850 ;iou: 0.865 ;time: 0:00:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 29504 ;lr: 0.0405 ;B loss: 1.073 ;acc: 0.835 ;iou: 0.875 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 29554 ;lr: 0.0405 ;B loss: 1.052 ;acc: 0.755 ;iou: 0.795 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29604 ;lr: 0.0405 ;B loss: 0.957 ;acc: 0.800 ;iou: 0.840 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29654 ;lr: 0.0405 ;B loss: 0.896 ;acc: 0.805 ;iou: 0.835 ;time: 0:00:24\n",
      "\n",
      "*Training B: True ;B Train loss: 1.261 ;Train accuracy: 0.770 ;IOU accuracy: 0.817 ;Time: 0:00:28 \n",
      "\n",
      "Testing, ephoc: 99\n",
      "batch: 0 ;B loss: 3.236 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:00:28\n",
      "batch: 50 ;B loss: 2.295 ;acc: 0.560 ;iou_acc: 0.715 ;time: 0:00:31\n",
      "batch: 100 ;B loss: 2.590 ;acc: 0.490 ;iou_acc: 0.645 ;time: 0:00:34\n",
      "batch: 150 ;B loss: 2.612 ;acc: 0.425 ;iou_acc: 0.535 ;time: 0:00:38\n",
      "batch: 200 ;B loss: 3.281 ;acc: 0.310 ;iou_acc: 0.450 ;time: 0:00:42\n",
      "batch: 250 ;B loss: 3.849 ;acc: 0.265 ;iou_acc: 0.375 ;time: 0:00:46\n",
      "\n",
      "*BTrain: True ;Test loss: 3.028 ;Test accuracy 0.407 ;IOU accuracy: 0.523 ;Time: 0:00:51\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_res, train_res = [], []\n",
    "\n",
    "for num_hidden in [50, 100, 150, 200]:\n",
    "    params_dir = params_dir_tmp+'base/hidden:'+str(num_hidden)\n",
    "    tf.reset_default_graph()\n",
    "    m = Model(\n",
    "        batch_size=200, \n",
    "        num_hidden=num_hidden,\n",
    "        embed_size=embed_vecs.shape[1],\n",
    "        img_dims=trainset[0][0][1][0].shape[1], \n",
    "        bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "        lr=.05,\n",
    "        vocab=vocab, \n",
    "        decay_steps=10000, \n",
    "        decay_rate=0.9, \n",
    "        edit_reward=0.,\n",
    "        rnn_editProb=0.,\n",
    "        coefAlr=1,\n",
    "        bnorm=False\n",
    "    )\n",
    "\n",
    "\n",
    "    # start comp\n",
    "    print('params_dir:', params_dir)\n",
    "    print('num_hidden:', m.num_hidden)\n",
    "    print('learning rate:', m.lr)\n",
    "    tst, trn = m.train(trainset, testset,\n",
    "            ephocs_num=100,\n",
    "            start_ephoc=0,\n",
    "            startA=101,\n",
    "            activation_ephoc=101,\n",
    "            muteB=0, \n",
    "            activateAProb=0,\n",
    "            max_activateAProb=0,\n",
    "            editProb=0,\n",
    "            edit_reward=0)\n",
    "    \n",
    "    test_res.append(tst)\n",
    "    train_res.append(trn)\n",
    "    print('\\n'+'*'*100)\n",
    "    print('*'*100)\n",
    "    print('*'*100,'\\n')\n",
    "    \n",
    "np.save(open('../data/training/results/train_res.bin', 'wb'), train_res)\n",
    "np.save(open('../data/training/results/test_res.bin', 'wb'), test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_hidden: 50\n",
      "==============\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa457cb4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train max accuracy:0.769\n",
      "Test max accuracy:0.494\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa457abd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train max IOU:0.828\n",
      "Test max IOU:0.619\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niATl/wFA1X8ZBd+6gAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa45722748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min loss:1.293\n",
      "Test min loss:2.298\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "num_hidden: 100\n",
      "==============\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAAlJREFUiATl/wHgndKi2KkZ8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa45693dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train max accuracy:0.771\n",
      "Test max accuracy:0.442\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa45693e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train max IOU:0.823\n",
      "Test max IOU:0.565\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIBUWgQERGRgPw/vYv213xMkksAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa455f0eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min loss:1.277\n",
      "Test min loss:2.345\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "num_hidden: 150\n",
      "==============\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRETCoqRBREREwvL/oYELs+5XAnYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa45564588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train max accuracy:0.780\n",
      "Test max accuracy:0.428\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVx1/+rvcBukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa454d3cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train max IOU:0.828\n",
      "Test max IOU:0.541\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB1fQBZR1MkQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa4544b5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min loss:1.210\n",
      "Test min loss:2.345\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "num_hidden: 200\n",
      "==============\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa45468400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train max accuracy:0.775\n",
      "Test max accuracy:0.411\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa454685c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train max IOU:0.822\n",
      "Test max IOU:0.527\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFyCAYAAAB2hOkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xd4lMXax/HvJCRAIIQSIHRCCBDphCMgUgRpQZoIAqKi\nKKKCCnqwHQvYjoig6LGAiiICFtAIAqEpioivhiYKIbQASu+9Zd4/JoEkJJBAwqb8Pte1V9hnZ59n\ndo3Ze2fuucdYaxERERG5FC9Pd0BERERyBgUNIiIiki4KGkRERCRdFDSIiIhIuihoEBERkXRR0CAi\nIiLpoqBBRERE0kVBg4iIiKSLggYRERFJFwUNIrmUMWazMebbdLRrYYyJN8Y0T0fbH4wxCzPznCKS\ncyhoEMm9MlIjPr1ts+KcmcoYU94Y85wx5ldjzD5jzG5jzPfGmNZptA8wxowzxuwyxhwxxiw0xtRP\no+11xpjFxpijxpjtxpg3jTGFsvYViWQfChpE8jhr7SKgoLX2R0/3JZN0Af4NxAJPAyOAwsA8Y8yd\nSRsaYwwwC+gFjE14XkngB2NMSIq29YD5QAFgCDAeGAB8kZUvRiQ7yefpDoiI51lrT3m6D5loIVDR\nWrsv8YAx5n1gBS6A+CRJ2x5AE6C7tfbrhLZfAuuA4UDfJG1fBvYBLay1RxPaxgHjjDE3WmvnZ91L\nEskeNNIgkg7GmOcT5uhDjDEfG2P2G2MOGGM+MsYUSGhTKaHNHak8P94Y82wq5ws1xkxKONcuY8yI\nhMcrGGO+McYcTBgGH3oFfW+aMFR/3BizwRhze4rHU80/MMYMMMasN8YcM8YsNcZcn8b5yyX09Ygx\nZqcxZjSQHzCptG1kjJmT8HqPJuRIXJeizSXf6yRtSxhjqhtjCiYes9auSRowJBw7hRtRKJ9iOqE7\nsCMxYEhouwc3etDFGOOTcB1/4Ebg08SAIcFE4CjQM7X3RiS3UdAgkj6J8/NfAIWAJ4DPgX7Ac1dw\nvs8Tfj4OLAWeNsY8AswFtgHDcMPsr6X1oX0JocCXCecbivumPMEYE5ZGfwAwxvQH3gP+wQ3Z/wx8\nC1RI0a4A7pt9G9zw/ovA9cDIVM7ZCliEmyp4HngSCAAWGmMaptKXlO/1nVz4Xg8G1gD/utibkKAM\ncCzhlqg+sCyVtv8H+AHVEu7Xxo3MRidtZK09jRvBSDUHQiS30fSESMZEW2sHJN4xxgQC/XEfgJdj\nqbX2gYRzjQc2A6OAJ6y1oxKOT8V9eN8NLM7g+asBzay1SxLO9SWwFbgLF5BcwBiTD3gJ92Haylp7\nJuH4X7h5/C1Jmt8HVAV6WGunJ3kdq1I59bvAAmttxyTXeh/4CxdstE/RPj3vtSUdCZfGmKpAN+Bz\na23S9mVwgUxK2xN+lgX+TGhnkxxP2fZyAjqRHEcjDSLpZ4H3Uxz7CShhjCl8mef78Nwda+OB33HD\n+h8lOX4QiAGqXMY1/koMGBLOtScd52oIlALeSwwYEnwCHEzRtgOwPTFgSLjGCWBc0kYJSYShwJSE\nKYUSxpgSgD+wAEi5NDNd77W1dri11vtiSZwJUxdf4kYYUgZ3BYGTqTztBO6/Q8Ek7bhI24KpHBfJ\ndTTSIJIxW1Lc35/ws1gmne8gcCLlnHzC8eKZcH5wfb5YfyvhPrTXJz1orT1jjNmYStv1XCgmxf3Q\nhJ8T07hmvDEmICFASnSx9/pIGudJxhjjhZvaqAG0t9buSNHkOC7/IqUCuPfgeJJ2XKTt8VSOi+Q6\nChpEMuZsGscNaQyTJ3xwZeR8F7tGRmXmua5E4nvwKLAyjTYpA4HM6PsHQATQJ2FpaUrbcVMPKSUe\n+ydJO3ORtv+kclwk11HQIJJ5Er8JF01xvNLV7sgVisN9QIYCPyQeTMh1CMYl/iVtWzOVc9RIcX9D\nws/D1tpLVpTMDMaY13DJkw9ba9OqpbCC1PMRGuOmM9Yl3F8NnMFN3XyV5Bo+QD3OJ7SK5GrKaRDJ\nJNbaw8AeLpyffxAPVUe8TL8Du4GBCYFCoru4MCCaBZQ1xnRPPGCM8QPuTdEuGhc4PJZaBcWEJMcM\nS23JZcLxf+NGNV6y1r59kVN8BZQ2xtycoi+3AN8mrI7AWnsIV9ipb4r+34Fb4aECT5InaKRBJHN9\nADyRsILgd1wAEcrVnw7IqHP9S8hd+A9uyeX3xpjPcSMMd3F+xCDReGAQ8GnCssntwO242gXnWGut\nMeYeXJDxpzFmAvA3UA64AZez0eUy+j0YeBZoCfwIYIzpBryKGyWIMcbcluI5c621uxP+/RXwCG4Z\nak1c0PcA7gvV8yme9zRu6emPxphxuOWnQ4Eoa+28y+i7SI6joEEkc40AEr+p9sB9SHYAdnHl+ztk\ndLTiYssRUx5Pdt9aOz4hF+PfuJoLfwCdgBeStrXWHk+ov/AWLng4BkwC5iTckp5zkTGmCfAMbvSl\nMLAD+JULV0qkV2qvsU7CsVBST7y8ATeSgrU23hjTAXgNF4AUxNVouMNaG5ui/8uNMTfiApLRwGFc\n0PTUZfZdJMcxyZcsi4iIiKQuQzkNxpiBxpiVCaVtDxpjlhhjUhZkSdo+sTxt0ttZY0ypK++6iIiI\nXE0ZnZ7Yiit3G4ubA+0HRBpj6llr16TxHIurSnf43AFrd2W8qyIC5xL1vC/S5JS1dv9FHhcRuSxX\nPD1hjNkLPGatnZDKYy1wdemLJWQfi8gVMsZs4uLLOH+w1ra6Wv0RkbzjshMhE5KkeuI2dfnlYk2B\nFQkb26wGnk9a1lZEMqwPFy9brFEGEckSGR5pMMbUwgUJBXBTDn2stXPSaFsNaIFbepYft3b7duBa\na+2K1J6T8LwSQDvc5j0nMtRBERGRvK0AUBm3HHhvZp74coKGfEBF3Ja2t+ACgebW2rXpfP4PQJy1\n9s6LtOkDfJahjomIiEhSt1lrJ2fmCTM8PZGw613ipjXLjTHXAg8D96fzFP8HNL1Em80AkyZNIiws\nLKNdlMs0ZMgQxowZ4+lu5Cl6z68+vedXn97zq2vNmjX07dsXEj5LM1NmFHfyIvWd39JSj9T3pE/q\nBEBYWBgNGjS43H5JBgUEBOj9vsr0nl99es+vPr3nHpPp0/sZChqMMS8Ds3Fb1voDt+FyFtomPP4K\nUDZx6sEY8zCwCfgTN8dyL64aW5tM6r+IiIhcJRkdaSgFfILbCvYgsApom2TXuiBcPfZEvsDrQFlc\nedlVQGtr7Y9X0mkRERG5+jIUNFhr77nE43eluP8arqa7iIiI5HDaGlvO6d27t6e7kOfoPb/69J5f\nfXrPc49suWGVMaYBEB0dHa3kGRERkQxYtmwZ4eHhAOHW2mWZee4cuzX2li1b2LNnj6e7IdlUYGAg\nFStW9HQ3RERylRwZNGzZsoWwsDCOHTvm6a5INuXn58eaNWsUOIiIZKIcGTTs2bOHY8eOqfiTpCqx\nsMmePXsUNIiIZKIcGTQkUvEnERGRq0erJ0RERCRdFDSIiIhIuihoEBERkXRR0CAiIiLpoqBBLiku\nLg4vLy8mTpzo6a6IiIgHKWjIZn755ReGDx/OoUOHsvQ6r7zyCpGRkVl6DRERyV0UNGQzS5YsYcSI\nERw4cCBLr/Pyyy8raBARkQxR0JDNZMe9QEREREBBQ7YyfPhwhg0bBkDlypXx8vLC29ubLVu2nGsz\nadIkGjZsiJ+fHyVKlKB3795s27Yt2XnWr19P9+7dKVOmDAULFqRChQr07t2bw4cPA+Dl5cWxY8f4\n+OOP8fLywsvLi7vvvjvD/V24cCHNmjWjcOHCFCtWjK5du7J27dpkbY4cOcIjjzxCcHAwBQoUoHTp\n0rRt25YVK1aku78iIpI95OiKkLlN9+7dWbduHVOnTuXNN9+kRIkSAJQsWRKAl156iWeffZZevXpx\n7733snv3bsaOHUuLFi1Yvnw5RYoU4fTp07Rt25bTp0/z0EMPERQUxN9//83MmTM5cOAA/v7+TJo0\nif79+9OoUSMGDBgAQEhISIb6On/+fCIiIggJCWH48OEcP36csWPHcv3117Ns2bJz5Zvvu+8+pk+f\nzuDBgwkLC2Pv3r0sXryYNWvWUK9evXT1V0REsglrbba7AQ0AGx0dbVMTHR1tL/Z4TjZq1Cjr5eVl\n4+Likh2Pi4uz+fLls//973+THf/zzz+tj4+PfeWVV6y11q5YscIaY+z06dMvep3ChQvbu+66K119\n2rx5szXG2E8++eTcsXr16tmgoCB74MCBc8dWrVplvb29bb9+/c4dK1q0qB08eHCa505vfzMiN/9+\niIhcSuLfQKCBzeTP5zwx0nDsGKQYNc90NWqAn1/WnX/atGlYa+nRowd79+49d7xUqVKEhoby/fff\n88QTTxAQEADAnDlzaN++PQULFsz0vuzYsYOVK1cmux5A7dq1adOmDbNmzTp3rGjRovz6669s376d\nMmXKXHCuq9FfERHJHHkiaFi7FsLDs/Ya0dGQlXtnrV+/nvj4eKpWrXrBY8YYfH19AZcL8eijjzJ6\n9GgmTZpEs2bN6Ny5M3379qVIkSKZ0pe4uDgAqlWrdsFjYWFhzJ07l+PHj1OwYEFGjhxJv379qFCh\nAuHh4URERHDHHXcQHBx81forIiKZI08EDTVquA/1rL5GVoqPj8fLy4s5c+bg5XVh/mrhwoXP/fu1\n116jX79+REZGMnfuXB566CH++9//snTpUsqWLZu1HU2hR48eNG/enK+//pq5c+cyatQoXn31Vb7+\n+mvatWuX7forIiJpyxNBg59f1o4CZCZjTKrHQ0JCsNZSuXLlVEcbUqpZsyY1a9bkqaeeYunSpVx3\n3XW89957jBgx4qLXSY9KlSoBEBMTc8Fja9euJTAwMNk0Q+nSpRk4cCADBw5kz5491K9fn5deeulc\n0JCe/oqIiOdpyWU2U6hQIYALijvdfPPNeHl5MXz48FSft2/fPgAOHz7M2bNnkz1Ws2ZNvLy8OHny\nZLLrXG4BqaCgIOrVq8cnn3ySrHLl6tWrmTt3Lh07dgTc6EjKypaBgYGULVv2XF/S218REfG8PDHS\nkJOEh4djreWpp56iV69e+Pj40LlzZ6pUqcKLL77IU089xaZNm+jatSv+/v5s3LiRb775hvvuu4+h\nQ4eycOFCBg0aRI8ePahWrRpnzpxh4sSJ5MuXj+7duye7zvz58xkzZgxly5YlODiYa6+9Nt39fO21\n14iIiKBx48b079+fY8eO8fbbb1OsWDGee+45wAUE5cuX55ZbbqFu3boULlyYefPm8fvvvzN69GiA\ndPdXRESygcxejpEZN/LwkktrrX3ppZdshQoVbL58+S5Yfvn111/b5s2bW39/f+vv72+vueYa+9BD\nD9nY2FhrrbWbNm2y99xzjw0NDbV+fn42MDDQtm7d2n7//ffJrhETE2NbtmxpCxUqZL28vC66/HLz\n5s3Wy8sr2ZJLa61duHChbdasmS1UqJAtWrSo7dq1q127du25x0+dOmUff/xxW79+fRsQEGD9/f1t\n/fr17fvvv3+uTXr7mxG5/fdDRORisnLJpbHZsGyxMaYBEB0dHU2DVJIRli1bRnh4OGk9Lnmbfj9E\nJC9L/BsIhFtrl2XmuZXTICIiIumioEFERETSRUGDiIiIpIuCBhEREUkXBQ0iIiKSLgoaREREJF0U\nNIiIiEi6KGgQERGRdFHQICIiIumioEFERETSRUGDiIiIpIuChjymcuXK3H333Zl2vueffx4vL/0a\niYjkBfprn8388ssvDB8+nEOHDmXJ+b28vDDGZNr5jDGZej4REcm+8nm6A5LckiVLGDFiBHfddRdF\nihTJ9PPHxMRoZEBERC6LPj2ymYxsVW6t5eTJkxk6v4+PD97e3hntloiIiIKG7GT48OEMGzYMcLkH\nXl5eeHt7s2XLFsBNLTz00ENMnjyZWrVqUaBAAaKiogAYNWoUTZs2JTAwED8/Pxo2bMi0adMuuEbK\nnIZPPvkELy8vlixZwtChQylVqhSFCxfm5ptvZu/evZf1Os6ePcsLL7xA1apVKVCgAMHBwTz99NOc\nOnUqWbvff/+ddu3aUbJkSfz8/KhSpQr9+/dP1mbq1Kk0bNiQIkWKEBAQQJ06dRg7duxl9UtERK6M\npieyke7du7Nu3TqmTp3Km2++SYkSJQAoWbLkuTYLFizgiy++YNCgQQQGBlK5cmUAxo4dS5cuXejb\nty+nTp1i6tSp9OzZk5kzZ9KhQ4dzz08r/2Dw4MEUL16c559/ns2bNzNmzBgGDRrElClTMvw6+vfv\nz8SJE+nZsyePPfYYv/76K6+88gpr1649F8js3r2bdu3aUapUKZ588kmKFi3K5s2bmT59+rnzzJs3\njz59+tCmTRtGjhwJwJo1a1iyZAkPPfRQhvslIiJXRkFDNlKrVi0aNGjA1KlT6dKlCxUrVrygzbp1\n61i9ejXVq1dPdjw2Npb8+fOfuz9o0CDq16/P6NGjkwUNaSlZsiRz5sw5d//s2bO89dZbHD58GH9/\n/3S/hlWrVjFx4kQGDBjAe++9B8DAgQMpWbIkr7/+OosWLaJFixYsWbKEAwcOMH/+fOrXr3/u+SNG\njDj371mzZhEQEHBuNEVERDwrTwQNx04fY+2etVl6jRqBNfDz8cvSawC0bNnygoABSBYwHDhwgDNn\nztCsWTOmTp16yXMaYxgwYECyY82aNeONN94gLi6OWrVqpbt/s2bNwhjDkCFDkh1/9NFHGTVqFN99\n9x0tWrSgaNGiWGv59ttvqV27NvnyXfirWLRoUY4ePUpUVBTt2rVLdx9ERCRr5ImgYe2etYSPC8/S\na0QPiKZBmQZZeg3g3HRESjNnzuSll15ixYoVyZIj07tSokKFCsnuFytWDID9+/dnqH9xcXF4eXlR\ntWrVZMdLly5N0aJFiYuLA6BFixbccsstjBgxgjFjxtCyZUu6du1Knz598PX1BeCBBx7gyy+/JCIi\ngrJly9K2bVt69uypAEJExEPyRNBQI7AG0QOis/waV0PBggUvOPbTTz/RpUsXWrZsybvvvkuZMmXw\n8fHho48+SndOQlorKjKymiOp9NRu+OKLL/i///s/ZsyYQVRUFHfffTejR49m6dKl+Pn5UbJkSVas\nWEFUVBSzZ89m9uzZTJgwgTvvvJMJEyZcVr9EROTy5Ymgwc/H76qMAmSGyymUNH36dAoWLEhUVFSy\nYf4PP/wwM7uWLpUqVSI+Pp7Y2Nhk0yi7du3iwIEDVKpUKVn7a6+9lmuvvZYXXniBKVOmcNtttzF1\n6tRzKzzy5ctHx44d6dixIwD3338/48aN45lnnqFKlSpX74WJiIiWXGY3hQoVAlxeQnp5e3tjjOHM\nmTPnjm3evJnIyMhM79+lREREYK3ljTfeSHb89ddfxxjDTTfdBKT++urWrQtwbnpl3759F7SpXbt2\nsjYiInL15ImRhpwkPDwcay1PPfUUvXr1wsfHh86dO6c6LZGoY8eOjB49mnbt2tGnTx927tzJO++8\nQ2hoKKtWrbrkNdOagricqYk6depw5513Mm7cOPbv30+LFi349ddfmThxIjfffDPNmzcHXH2Id955\nh27duhESEsLhw4cZP348AQEBREREAHDPPfewb98+WrVqRfny5dm8eTNvv/029evXJywsLMN9ExGR\nK6OgIZtp2LAhL774Iu+99x5RUVHEx8ezadMmKlasmOY+DzfccAMfffQR//3vfxkyZAjBwcGMHDmS\nTZs2XRA0pHaOtKZE0jtVkrLdhx9+SEhICB9//DHffPMNQUFBPP300zz77LPn2rRo0YLffvuNzz//\nnJ07dxIQEECjRo2YPHnyuSmM22+/nXHjxvHuu+9y4MABgoKC6N27N88991y6+iUiIpnLXG6iW1Yy\nxjQAoqOjo2nQ4MJchGXLlhEeHk5aj0vept8PEcnLEv8GAuHW2mWZee4M5TQYYwYaY1YaYw4m3JYY\nY9pf4jktjTHRxpgTxph1xpg7r6zLIiIikuhqfvfPaCLkVuBxoAEQDiwEIo0xqU4wG2MqAzOBBUBd\n4E3gA2NMm8vsr4iIiACnT8Njj8HVrKqfoaDBWvudtXaOtXaDtXa9tfY/wBGgcRpPuR/YaK0dZq2N\nsdb+D/gKGJJGexEREbmELVugeXN4800IDr56ow2XnQhpjPECegJ+wC9pNGsMzE9xLAoYc7nXFRER\nycu++w7uuAMKF4affoLGaX1tzwIZrtNgjKlljDkMnATeAbpZa9Pa2CEI2Jni2E6giDEmfyrtRURE\nJBVnzsDjj8NNN0HTprB8+dUNGODyRhrW4vITAoBbgInGmOYXCRwu25AhQwgICEh2rHfv3qlu2CQi\nIpLdWAv33w9dukA6NhxO0+nTcNttMH06vPYaPPooGANTpky5YLuAgwcPXmGv05bhoMFaewbYmHB3\nuTHmWuBhXP5CSjuA0imOlQYOWWsvWdJvzJgxaS65FBERye4iI+H99+HrryEmBooWzfg5EgOGr7+G\nadNcAJKod+/e9O7dO1n7JEsuM11mlJH2AtKaavgFaJ3iWFvSzoEQERHJFeLj4fnnoWFDOH4cnn46\n7bZLl8KHH8Lhw8mPJw0YvvoqecDgCRkaaTDGvAzMBrYA/sBtQAtcIIAx5hWgrLU2sRbDe8CDxphX\ngY9wAcQtQERmdH7NmjWZcRrJZfR7ISLZwTffwMqVsGgRLFsGQ4dCv37wr38lb7diBbRpA0eOwCOP\nQN++MHAgXHNN9goYIOPTE6WAT4AywEFgFdDWWrsw4fEgoEJiY2vtZmNMR9xqiYeAbUB/a23KFRUZ\nEhgYiJ+fH3379r2S00gu5ufnR2BgoKe7ISJ5VOIoQ+vWbmnkddfBJ5+4/IZffwVvb9du61bo2BGq\nVYNJk2DqVBg/Ht57D8qVg507s0/AADm0jDTAli1b2LNnz9XtmOQYgYGBVKxY0dPdEJE86ssvoWdP\nWLzYrXQANwVx3XUwdiwMGgQHDkCzZm5KYulSCApy7U6fhhkzXBBx991utURGZGUZ6RwbNIiIiGRH\n8fFQpw6ULQtz5yZ/7L773GjCH3/AXXe5aYslSyAzN+7NyqBBu1yKiIhkoi+/hD//dNMMKb3yils2\nWa8eHD0K8+ZlbsCQ1TJj9YSIiIgAZ8/C8OHQvj00aXLh48WLw+jRcPCgy3Fo3vzq9/FKaKRBREQk\nk0yZAmvWwMcfp93m9tuhU6fLq9ngaRppEBERyQR//+2WTN58M1x77cXb5sSAARQ0iIiIXLGzZ11N\nhfz5XQXI3ErTEyIiIlfo5Zfhxx9h4ULIzSViNNIgIiJyBRYvdoWc/vMfaNnS073JWgoaREREUliz\nBiZPvnS7ffugTx9XtOnZZ7O+X56m6QkREcm1jh+H2FioVQu80vk1+dQp6N7dBQ5FiqRdkdFauPde\nt2fEZ59BvjzwiaqRBhERybWeegrq1oXy5d2+D1FRLii4mDfegHXroHFjV7Vxx47U2730kivU9MEH\nkFeq1itoEBGRXOnAAfeBfscd0KuXCxjat4eSJWHMmNSfs3WrK840eDBERrqNpfr1c6Whk/rgA3jm\nGXjhBbfEMq9Q0CAiIjnSE0/AO++k/fi4cW5U4dVXXRXGDRvcVtV9+rhtqt9++8LnDBnipiSefx5K\nlXJFmqKi4K23zreZMcPtIXH//fD005n9qrK3PDADIyIiuU1UlAsGfH2hbVuoWjX546dPu90kb7vt\n/O6RxriNpN55BwoWdKMJRYq4kYjEc06b5vITAgLcsfbt4eGHYdgwuOEGt1/ErbdC164ukDDm6r3m\n7EC7XIqISI5y/DjUru3yFDZtcjkL336bvM1nn0HfvrBqlWubUmIS44QJ8NVX0KGDa1ehAixYkDwY\nOHECGjWCkydh926oWdPtXlmgQNa+zsulXS5FREQSvPoqbNkCM2e6LaZ79oQ5c9yoALiAYPRoNwKR\nWsAALih4/304fNjlO9x0E2ze7PIYUo4eFCjgll82bAghIa5Ndg0YspqCBhERyTFiY9320sOGQY0a\nUL06tGjh9nxYtcpNVyxaBMuWuUDiYry94dNPoVs3twpi2DC45prU29asCb//DmXKQLFimf+6cgol\nQoqISI5gLTz4IJQt65ZSghsVGDvWBROJiY2jR7sP+bZtL31OX183PTF+PDz33MXb1qzptrbOyzTS\nICIiOcIXX8C8eW71gp/f+eN16sDAgW6p5L/+5R7/8MP0JykWLAj33JM1fc5tNNIgIiLZ3qFDbjlk\n166pV2gcMcJNN3ToAKVLu1UTkvkUNIiISLb33HNw8CC8+Wbqj5co4QotHT3qpjDy57+6/csrND0h\nIiLZ2qpVribCSy9dvFzzffeBv7/bN0KyhkYaREQkS5w44ZYzLl58+eeIj4cHHoBq1dz0xMXky+cK\nNRUqdPnXk4vTSIOIiGSJ//0PPv8cli6F1auhcOGMn2PiRPj5Z1i40K10EM/SSIOIiGS6gwfh5Zeh\nUydXRTFxiWRG7N/vaif07u1KOIvnKWgQEZFMN3KkK/f83nsuF+GttzI+TfGf/7gpjlGjsqaPknEK\nGkREJFNt3+62nn74YVeIafBgaNIE+vd3gURKP//spjFiYuDsWXcsOhrefdfVXihb9ur2X9KmnAYR\nEclUI0a4vRkef9zd9/Z2xZbq1XNbTr/6qju+eTM8+qgr4ZyoUCFXrGnXLqhVywUckn0oaBARkUwT\nG+tKMr/yChQtev54WJirtfDMM9Cxo9tJcuRIV19h8mRo0wZWroQVK2D5cre19VtvuRURkn3oP4eI\niGSa//zHbeo0aNCFj/373/Dll26DKV9feOwxePLJ86sqWrd2N8m+FDSIiEimiI52+0N88IHbzyEl\nHx83qvD22zB0qNtmWnIWBQ0iInLZjh2D2bNdsDBzppuGuPPOtNuHhbn6DZIzKWgQEZFLshb27oVN\nm9xt40aXe/Ddd26/h3r13NREv37KQ8jN9J9WRCQP2bMHihS5eHXF/fvhxx9hzRpYu/b8z0OHzrcp\nWtSVdn7qKejRA0JDs77v4nkKGkRE8oitW6F2bQgMdCsXunUDY84/fvo0vPOOWxZ54IALLsLC3K1b\nNxcYBAd8OTKzAAAgAElEQVS7W7FiHnsZ4kEKGkRE8gBrYcAAVwehWjW3E2Tz5jB6NISHu7yEoUNd\ngaV773UjCBUrJg8qRFQRUkQkD/j4Y5gzB8aNg1mz3L/37IF//cvlI0REQFCQy1N4/32oVEkBg1xI\nQYOISC73999uW+k773SFlQDatXPFlP73PyhVCqZNcztJ1q3r2b5K9qbpCRGRXMxauO8+8PNz+0Ek\nlS8f3H+/u4mkh0YaRESymV27Lv74vn1uf4batV1p5pUrXXCQmk8/dcsi339fyYty5TTSICKSDZw4\n4XZ6fPtt+P13ePFFePrpC9udOuWSGP/5B9q3hzffdBtEVakCnTq5XITixd2tQAG302Tfvu4xkSul\noEFExIO2bXMbM334oSue1K6dmy74z39cIuJTT51va6177OefYf58t/rh1Cn4/nu3U+SMGW6U4siR\n888pU8YFFiKZQUGDiIiHHD0KTZrA4cNw990uIEgsklS6tBtpMMZt6gTw+uvw0UduJUTz5u6Yr68L\nNNq1O3/eU6fcFMa+fVC2bPLdJkWuhIIGEREPGTnSjQysWeOmF5J67jk3svDUUy5wCAuDYcNcAHGx\nvR3ABRJBQe4mkpkUNIiIeMCWLS5oGDr0woAh0fPPu59PPul2iOzWzeU6iHiKggYREQ944gkICEie\ns5Ca55+H/PldHsPEieClNW/iQQoaRESusiVLYMoUl/zo73/p9ok5DSKepphVROQqio+HRx6B+vXd\nNtIiOYmCBhGRTHb2rNvjoXZtuOce+PXX88WXPvsMfvvNLYPUVIPkNPqVFRFJYt8+2LHj8p//449u\n18j77nMJjvPmQePGbk+HsWNdLkOPHtCsWeb1WeRqUdAgIpLg8GFo1MjVNmjZEt5999IlncFNOaxe\nDbfeCi1auMTFpUshMhI2bnTbToeGwqOPugJOr76a5S9FJEtkKBHSGPMk0A2oARwHlgCPW2vXXeQ5\nLYDvUxy2QBlrbTr+dxQRyXrWwsCBsHOnmzr47jsYPBgGDXIBRLVqbu+G4sXdz/h4t+fD8uXu59Gj\nri7CJ5+4ss2JUw/e3q7cc/v2bgRj3z4IDvboSxW5bBldPdEMeAv4PeG5rwBzjTFh1trjF3meBaoB\nh88dUMAgItnIxx/D5Mnu1ru3Cxj27HHlmb/91uUl7NsH+/fDoUOu4FL16i6hsWtXqFcPrrsOChVK\n+xoquCQ5XYaCBmttRNL7xph+wC4gHFh8iafvttYeylDvRESugjVr3IhC//4uYEgUGAgDBrhbUmfO\nuFuBAle3nyKedqU5DUVxowj7LtHOACuMMf8YY+YaY667wuuKiGSK48ehVy+3O2R6N3bKl08Bg+RN\nlx00GGMM8Aaw2Fr710WabgfuA7oDNwNbgR+MMfUu99oiImmxFn74wQUCt97qEhIv5tFHYd06ty31\nxaYWROTKKkK+A1wDNL1Yo4QkyaSJkkuNMSHAEOCi264MGTKEgICAZMd69+5N76TjhyKSZ2zc6HIM\nZs1yCYnh4edv+fPDp5/C//4Hf/4JNWq4AKJJE7e8cdgwiEiYYP3jD7e19Lx5EBUF773naiqI5DRT\npkxhypQpyY4dPHgwy65nbGLFkYw8yZi3gU5AM2vtlst4/kigqbU21YDDGNMAiI6OjqZBgwYZ7p+I\n5B5r18KXX7pgYcUKNy3QurVbrRAd7ZZJgtvZ8cwZ6NLF5SfccIMLGr791i1xXLoUqlaFAwdcgmOB\nAi6Y6NbNrZowxrOvUySzLFu2jPDwcIBwa+2yzDx3hkcaEgKGLkCLywkYEtTDTVuIiFxg61aYOtXt\nz7B8ORQuDDfdBE8/7ZYuFi7s2sXHw/r1LnjYvh1uuQUqVjx/HmPcyoYuXdyGTx98AOXLu6CjSRPl\nJYhkVEbrNLwD9AY6A0eNMaUTHjporT2R0OZloJy19s6E+w8Dm4A/gQLAvcANQJtMeQU5zMmTsHs3\nlCt38W821uqbj+Qtmze7YkjTpsFPP7nphk6d4JlnoEOH1D/gvbxc/YRq1S5+bmPg+uvdTUQuX0ZH\nGgbiVkv8kOL4XcDEhH+XASokecwXeB0oCxwDVgGtrbU/ZrSz2cGJE66i2969bohzyxb3xy4uzv08\ncgRKloRSpaB0abdka88et6RrzRo3JxsfD7VqwV13wW23uXYAp0+7OdbPPoMZM9y3oQ8+gBIlPPmK\nRTLfiROuiNK2bS634Jtv3NSDr6/7vf/kEzdCUKSIp3sqIkldVk5DVsuqnAZr3fzn0aPuG//Jk+6P\n1/Hj7sN/06bzt5074dQp90Ge+PPQIffclIKCoHJlt2SrSBE3krBzpys/u2uXS9gKC3OJWWFhULQo\nfPWV+1YVH++Ss8qWdcf27IFrroGOHeGjj9y3q0mTXEU6EU+Lj4cRI1y1xNat3ZRBkyau6uHF7N0L\nL73kEhh37ICkeVpFirjf965d3dSDAgWRK5Otchqupq07D1NhtxtajI9P/kF/8qT7sD96FI4dc7cj\nR9wfp927z9/27nUV3A4ccLf4+LSvFxDgyrsGB0PTpm541MfHffvx8XH73pcocf4WGOjmRy9nXrRn\nT9e3qVNdJbqVK902ubfd5ja2MQYeftiVo23VCv7zH3j2Wbc+XMQTTp6Eu+92FRM7dXJB7auvuv8X\nOnRwwe+NN7qRtqTPefttePFFt/PjHXe44DooyI2wBQW5YNrX13OvS0TSL1uPNNA/HxzpBH/0gXUd\n4UzBSzzPfasvWfL8FEGJEq5OfLFi7ht+QIBLosqf333Y588PBQu6D/9ixa7O68uIs2fhlVfg+edd\nudobb3Q75yXeypd3AU1m++03l4DWs6d73yRv2LfP/X/h55f8+IEDbpXBL7+4ZY09erjfzd9+c1Np\nM2fCqlXu/8EGDaBtWxcc/Pe/LqlxwAD3O1yqlEdelkiekpUjDdk6aOj89FD+KvIj64//Tj7jQ6Bv\neUoVKE+QXwXKFCpPhSIVqVK8ElUDK1GtdCVKBRTJtcmDP/8Mw4dDbKybSkkcMTHGjXiUKeO+tZUp\n47LHg4PdlElwsPvQ/+MPl2G+bJm7+fq6IeFOnaBhQ5dQdvKkW9r29tuuzj64IOuRR9xNwUPuc/y4\nSzqcN8/lFqxY4QLpG25wIwcRES4o7dDBrU749tu0kwn/+cedIyrKnW/3bujc2Y1G1KhxdV+XSF6W\nZ4OGxJyGmD0xzN84n62HtrL10Fa2HdrG1oPu5+n40+eeV6xAMSoXrUxwsWCqFK3ifharQmjxUCoV\nrUQ+r9wxtn/6tAscNmxw3+K2b3e3HTvcH+4tW9zPlPLnd1MfDRq4/IzZs93UTVCQ2873hx9cLsaN\nN7rNesLD4fXX3fbA+fO76ZLevc+P3qQ1VXLmjDtv4uY++/a5xM+kS+Hk6jp71m3d/NdfEBNz/vbX\nXy5YLFMG2rRxeQp797rcg0WL3O+ar6/LuZk9O/0f/vHxLmhITPIVkasnzwcNaYm38Ww/vJ24g3HE\nHYgj7mAcm/ZvYtOBTWzcv5G4g3GciT8DgI+XD8HFggktHkq1EtWoXqI61UpUo1qJapT1L4vJZUMU\nJ06cT+5M/NCuUSP5VMaZM24EY8YMFzA0bgwPPuiSNZPasQNee80FD8eT7GXq7+9GH1Lmm5w+zQXy\n53ejFU89pUS3jDh2zL2/iXUJUoqOhvHj3c+aNV1A2KCBCw737nXf+OfNgwUL3O8BuCmC6tXdrXZt\nFyhcc82FS3wPH3bPW7XKTS9od0aRnEFBw2U6G3+WrYe2Ers3lth9scTujWXdvnXE7o1l4/6NnLVn\nASjkU4jQEqGEFk+4Jfw7pHgIpQuVznUBxeXas8eV5006inDggJvayJ///M3Pz+WWJN78/WHCBBg5\n0v37hRfcboKXyrjPq06fhrlz3aqZyEi3eqd+fWje3N3q1nUjAR984PJOypVz0wlr17oP+FOnzp/L\nywuuvfb8KELduppmEsntFDRkgVNnT7Fp/ybW7V1HzN6Y84HFvli2Hdp2rp2fjx9VilUhpFgI1UpU\nIywwjLCSYYQFhhFQIOAiV5CUtm1zIw2ffuq+4T75JHTvrsz5RP/845Jep051AVrNmnD77W4q6Kef\n3HTB1q2urbe3y0m59163TDFxquj0aVcPZPlyN6Jzww0KEkTyGgUNV9mx08fYsG8DG/dvZMP+DWzY\nt4EN+zcQszeGuANxWNx7VqZwGaoWr0pI8RCqFK1CSPEQqhavSvUS1RVQXMRvv7ngYf58N5f+wANu\n+DtlZv2pU246Ja2BnhMnXHZ+bCy8845L2syuFi500zft26f+er7/3u3KCHDnnW7pbZ06F7aNi3NT\nEY0buzwDEZGUFDRkI8dOHyNmTwxr9qxh7Z61yYKKPcf2nGtX1r8sNQJrUKNEDWqWqknd0nWpU7oO\n/vn9Pdj77GX1anjrLTfycPas2zzoyJHzNTYOH3Zz7f/+N/Tpk3xEYsECuP9+V4WzQAG3SmTWLDdU\nn53ExsKQIa4YEriVB6NHw7/+5e5b66ZtnnrKjQpMmZK8zoGISEYpaMghDp08ROzeWNbuWetue9ey\nZvcaYvbGnEvIrFKsCvWD6tO8UnNaB7fmmpLX5PmciX373Pz8L7+cr7MRGOiG1b/91iVqlivnEim7\ndXPr/SdNcvP7773nEgU7dHAfwHPmuGH9K3X2rKs9MH++qznQvn3G6mEcPuwqII4e7UZTRo92+RyP\nPuqCpb594fHH3b4K33zjNmIaPlx5HiJy5RQ05HAnz5xkzZ41rNyxkpU7V/L7P7/z69+/cursKUoV\nKkWr4Fa0qdKGm6rdRKlCqn6T0l9/wahRLlA4fdoFFqNGuQqaifHW33+7mgJxcS55sEULN1qxdKkL\nRmJiXD2KNm3c6gIvr9SvtW8ffPihm+7YvNl94G/f7oKYXr1cjsE117i8gdWrzy9jPHrUBS2JYmNd\nqeQnnnAjJYnFks6ccZUUn3nGlRgPCHAjLZ06ZeU7KCJ5iYKGXOjY6WMs2bqEhZsWsmDTAn77+zcA\nmlZsStfqXelSowtVi1f1cC+zl7//diMJnTunPoR/6BDcfLNLGqxQwdWxALdUsHp1lwtw5IgLOlq3\ndstQjx93yxqPHnWrQWbPdqMMvXq5WhUNG7oVCZ9+6jYS255kQ3djICTEBRGJ+RTGuFvRom5aolKl\n1F/LoUOufPhNN7nKniIimUVBQx6w6+guZq6bSWRMJHM3zOXEmRPUKlWL7mHduTnsZmqXqp3npzHS\n49Qpt6HSkSMuWbBJE1dUyhg3SrF06fnaBZs2uRGAQoXO/2zVKvWkTHDBxPffu+ClVi1XzyJluWUR\nEU9T0JDHHD11lLkb5jJ97XRmxMzg4MmDVC1elZtr3ExEaATXVbgOH+8s2HBCRERyvDy7y2VeVci3\nEN3CutEtrBunzp5iwcYFTF8znQkrJjByyUj8ff1pXaU1Hap2oEPVDlQIqODpLouISB6goCGb8/X2\npUNoBzqEduB9+z7Lty9nzvo5zF4/m/u/u594G0+9oHp0qtaJTtU6EV42HC+TRpafiIjIFdD0RA62\n//h+5m6Yy7frvmVW7CwOnDhAmcJl6BjakY7VOtI6uLXqQoiI5DGanpBUFStYjFtr3cqttW7l9NnT\n/Lz1Z76NcQHEB8s/wNfbl+aVmhNRNYLmlZpTN6hurtnpU0RErj59guQSPt4+tKzckpaVWzK63WjW\n71vPrNhZzIqdxZMLnuTk2ZMU9i1Mk/JNuL7i9bSo1IImFZrg662NH0REJH00PZEHnDhzguh/olm8\nZTGLty7m5y0/s//Efgr7FuaGyjfQNqQtbUPaElo8VMs6RURyOE1PyBUpkK8ATSs2pWnFpjzO48Tb\neFbsWMHcDXOZu2EuQ6OGcjr+NBWKVKB1lda0Dna3Mv5lPN11ERHJRhQ05EFexosGZRrQoEwDnrj+\nCY6cOsKizYtYsGkBCzYt4OMVHwNwTclraBfSjnYh7WheqTkFfQp6tuMiIuJRChqEwr6F6VjNrbgA\nV53y+03fM2/jPL7860vGLB1DgXwFaFGpBW1D2nJjlRupVaqWlnaKiOQxymmQi7LW8tfuv4jaEMWc\n9XP4actPnDhzglKFStE6uDU3VrmRztU7E+gX6OmuiogIymkQDzLGULNUTWqWqsnQJkM5ceYES7Yu\nYf7G+czfOJ+pq6fi7eVNh6oduL3O7dxU7SZNY4iI5FIKGiRDCuQrQKvgVrQKbsXLrV9m19FdfL76\ncyb9MYmeX/WkSP4i9LimB31q96FFpRZ4e3l7ussiIpJJNCktV6RUoVIMbjSYX+/5lbUPruXhRg+z\ncNNCWk9sTcU3KvJo1KNE/xNNdpwGExGRjFHQIJmmemB1Rtwwgg0PbeCX/r/QPaw7k/6YRMPxDanz\nXh3e/e1dDp887OluiojIZVLQIJnOGEPj8o0Z22Esfw/9m9m3zaZaiWoMnj2YsqPL8uB3D7J612pP\nd1NERDJIQYNkqXxe+WhftT3Tek5j8yObGdJ4CNPWTKP2u7Xp8WUPNuzb4OkuiohIOilokKumfJHy\njLhhBFuGbGFClwn8svUXwv4XxtCooew7vs/T3RMRkUtQ0CBXna+3L/3q9WPd4HU81+I5xi8bT8jY\nEEb+PJJDJw95unsiIpIGBQ3iMX4+fjzd/GnWD15Pr5q9eHrh01QYU4Fh84ax7dA2T3dPRERSUNAg\nHle6cGneveldNj28iYHhAxkXPY7gN4PpO70vK3es9HT3REQkgYIGyTbKFynPq21eZeuQrbzW5jUW\nb1lMvffr0XlKZ37d9qunuycikucpaJBsxz+/P480foTYwbF80vUT1u1dR+MPG9Pm0zb8sPkHFYoS\nEfEQBQ2Sbfl4+3BH3Tv484E/+eKWL9h1dBc3fHID135wLVP+mMLps6c93UURkTxFQYNke95e3vSo\n2YMV963guz7fUbRAUfpM70OVsVV4dfGr7D++39NdFBHJExQ0SI5hjCEiNIJ5t89j5cCVtKnShmd/\neJayo8vSe1pvZsfO5kz8GU93U0Qk11LQIDlSndJ1+KjLR8Q9EsfwlsNZtXMVEZMjqDCmAo/NfYx1\ne9d5uosiIrmOggbJ0YIKBzGs6TBW37+a3+/9nR7X9ODjFR9T4+0adJnahZ/iflLipIhIJlHQILmC\nMYbwsuGM7TCWbUO3Mb7TeNbvW0/zj5vT6INGfL76c06dPeXpboqI5GgKGiTXKZCvAP0b9OeP+/9g\nVp9Z+Of3p9e0XpQbXY4hc4awaucqT3dRRCRHUtAguZaX8aJDaAcW3LGA1fev5s66dzJ59WTqvleX\n8HHhjI8er2WbIiIZoKBB8oSapWoyqu0otg3ZRmSvSMoXKc99M+8j7H9hTF09lXgb7+kuiohkewoa\nJE/x8fahc/XORPaKZOXAlYSVDKP3tN40HNeQqPVRSpoUEbkIBQ2SZ9UuXZsZvWfw010/4efjR/vP\n2hP6ViiDZg1i5rqZHD111NNdFBHJVvJ5ugMinnZ9xev56a6fmL9xPt+s/YZZsbP432//w9fbl2YV\nm3FTtZvoVK0TIcVDPN1VERGPUtAggluy2SakDW1C2mCtZf2+9cxZP4dZ62fx+PzHGRI1hBqBNehU\nrRMdqnagSYUmFMhXwNPdFhG5qhQ0iKRgjCG0RCihJUIZ3GgwR04dYf7G+cyImcHElRN5bclr5PfO\nT+Pyjbmh8g20rNySJhWa4Ovt6+mui4hkKZMdE7+MMQ2A6OjoaBo0aODp7oicE2/j+WPnH/yw+Qe+\n3/w9i+IWceDEAQLyBxARGkGX6l3oENqBIvmLeLqrIpJHLVu2jPDwcIBwa+2yzDx3hkYajDFPAt2A\nGsBxYAnwuLX2ooX+jTEtgdeBmsAW4CVr7SeX02ERT/IyXtQNqkvdoLo83PhhzsafZcWOFcxYN4PI\nmEimrJ6Cj5cPrYJb0b5qe9qFtKNGYA2MMZ7uuojIFcvQSIMxZhYwBfgdF3C8AtQCwqy1x9N4TmVg\nNfAO8CFwI/AGEGGtnZfGczTSIDnS5gObiVwbyYx1M/hpy0+cOnuKigEVaRfSjjZV2tCycktKFirp\n6W6KSC6WlSMNVzQ9YYwJBHYBza21i9No8yrQwVpbJ8mxKUCAtTYijecoaJAc7+ipoyyKW0TU+iii\nNkQRszcGgJola57LhWgV3IpiBYt5uKcikptkm+mJVBQFLLDvIm0aA/NTHIsCxlzhtUWytUK+hYgI\njSAi1MXG2w5tY9HmRfyw+QfmbJjD27+9jZfxokn5JrSv2p4OVTtQv0x9vIzKp4hI9nTZQYNxk7Rv\nAIuttX9dpGkQsDPFsZ1AEWNMfmvtycvtg0hOUr5IeW6rcxu31bkNgC0HtxC1Poo5G+Yw8ueRPPP9\nM5QuVJqbqt1E5+qdubHKjfj5+Hm41yIi513JSMM7wDVA00zqywWGDBlCQEBAsmO9e/emd+/eWXVJ\nkaumYkBF7g2/l3vD7+X02dMs2bqE72K/IzImkg+Xf0jBfAVpG9KWiNAIWge3pkqxKkqoFJFkpkyZ\nwpQpU5IdO3jwYJZd77JyGowxbwOdgGbW2i2XaLsIiLbWDk1yrB8wxlqb6mSuchokr1u7Zy3fxnxL\nZEwkS7ctJd7GUymgEq2DW9O6SmtaVGpBuSLlPN1NEcmGslVOQ0LA0AVocamAIcEvQIcUx9omHBeR\nVNQIrEGNwBoMazqMgycOsihuEQs2LmDBpgV8tOIjAIKLBtOsUjOaVWxGy8otqVq8qod7LSK5XUbr\nNLwD9AY6A0eNMaUTHjporT2R0OZloJy19s6Ex94DHkxYRfER0Bq4BUh15YSIJBdQIIDO1TvTuXpn\nAHYe2cniLYv5Me5HftryE5NWTSLexlMjsAZdqnehS/UuNCrfSAmVIpLpMlqnIR63WiKlu6y1ExPa\nTAAqWWtbJXlec9xqiWuAbcAIa+2nF7mOpidE0unQyUN8v+l7ImMimbluJruP7aZ0odJ0CO1A2ypt\nubHKjaoNIZKHZJvpCWvtJb+6WGvvSuXYj0B4Rq4lIulTJH8RutToQpcaXTgbf5al25YSGRPJnPVz\n+HjFxwDUC6pH2yptaRvSlusrXk/+fPk922kRyZG094RILrb98Hbmb5zPvI3zmLthLjuP7sTPx4+W\nlVvSLqQd7au2p1qJap7upohkomxbETKrKGgQyXzWWlbtXEXUhijmbph7rsx1WGAYXWt0pVuNbjQs\n21DLOkVyOAUNIpLpjp46yvyN8/km5htmxMxg7/G9lPMv55Ipa3ShZeWW2u5bJAfKNjkNIpJ7FPIt\ndC4X4kz8GX7e8jNfr/2ayJhI3vn9Hfx9/ekQ2oEu1btwY5UbKVWolKe7LCIepqBBRMjnlY8WlVvQ\nonILxrQbwx+7/iBybSSRMZHcNt2Vva5dqjatg1vTKrgVLSq3oEj+Ih7utYhcbQoaRCQZYwx1Steh\nTuk6PNPiGf45/A/fb/qeBZsWMH3tdN749Q28jTeNyzembYhbkdGwbEPyeenPiUhup5wGEUk3ay0b\n9m84tyJjwcYFHDx5kKIFitI2pC03hd5ERGgEJfxKeLqrInmWchpEJFswxlC1eFWqFq/KwIYDORN/\nht/+/o2oDVF8F/sdd3xzx7ntvjtV60SvWr2oVLSSp7stIplEIw0ikmm2H97OrNhZzFg3g7kb5nL8\nzHGaV2rO7XVup8c1PQgoEHDpk4jIFcnKkQYVpxeRTFPGvwz9G/Tnm17fsOvfu5jYdSK+3r4MmDGA\n0qNK0/2L7ny84mN2Htnp6a6KyGXQ9ISIZInCvoW5ve7t3F73dv4+9DeT/5jM9LXTuTvybiyWa8td\nS8fQjnQM7Uj9MvW1wZZIDqDpCRG5qnYf3c3s9bOZuW4mURuiOHTyEEGFg+hQtQMRoRG0qdJG0xgi\nV0CJkCKSa5QsVJI76t7BHXXv4PTZ0/y89Wdmxc5iVuwsJqyYgK+3Lz2u6cGgawfRqFwjlbUWyUY0\nHigiHuPj7UPLyi0Z2WYkqx9YzeaHN/Nyq5f5ZdsvNPmwCQ3HN2TC8gkcP33c010VERQ0iEg2Uqlo\nJR697lFiB8fyXZ/vCCocRP9v+1N6VGlum34b36z9hhNnTni6myJ5lqYnRCTb8TJeRIRGEBEawYZ9\nG5j8x2S++OsLJv8xmcK+helUrRPdw7rTvmp7CvkW8nR3RfIMJUKKSI6xds9avvzzS77860v+2PUH\nBfIVoG1IW7rV6Eanap1UiVIE1WkQEQGgRmANnmnxDKvuX0Xs4FheuOEFdh/dzV2RdxH0ehBdpnZh\n+prpnDxz0tNdFcmVFDSISI5UtXhVHrvuMZb0X8I/Q/9hdNvR/HP4H7p/0Z2yo8syaNYglm3P1C9Z\nInmeggYRyfHK+JdhcKPB/Hbvb6y+fzX31L+Hr9d+Tfi4cBp90IhPVnyiFRgimUBBg4jkKjVL1eTV\nNq8S90gckb0iKVagGP0i+1F+THn+PfffrNyxkuyYyyWSE2j1hIjkSvm88tG5emc6V+9M7N5Y3o9+\nnw+Xf8ioX0YRXDSYm8NupluNbjSp0EQlrEXSSf+niEiuF1oilFFtR7HjsR1E9Y2ibUhbJq2axPUT\nrqfc6HIMmjWIRZsXcTb+rKe7KpKtacmliORJZ+PPsnTbUr766yu+WvMV2w5tI6hwEN3DunN7ndtp\nVL6Rp7soclm05FJEJJN5e3nTtGJTxrQfQ9wjcSy5ewm9a/UmMiaSxh82pulHTZn21zSNPogkoaBB\nRPI8L+NFkwpNGN1uNJsf3sw3t35DPq983PLlLYS+FcrYX8dy+ORhT3dTxOMUNIiIJOHt5U2XGl1Y\n1G8Rv937G43LN2Zo1FAqjKnAsHnD2Hpwq6e7KOIxChpERNLQsGxDJnefzKaHNzEgfADjoscR/GYw\nfab1Yem2pVq6KXmOggYRkUuoEFCBkW1GsnXIVsa0G8Ovf/9Kkw+bUPWtqjw5/0lW7FihAELyBAUN\nIlgmKfIAABOySURBVCLp5J/fn8GNBrNu0Drm3T6PVpVbMW7ZOOq/X58a/6vB8z88z4Z9GzzdTZEs\no6BBRCSDvL28ubHKjYzvPJ4dj+5g9m2zua7CdYz+ZTRV36pKswnNGB89ngMnDni6qyKZSkGDiMgV\n8PH2oX3V9kzoMoEdj+3gs5s/o5BPIQZ+N5Ayr5fhjaVvaOpCcg0FDSIimcTPx48+tfswp+8ctg7Z\nyoAGAxgSNYRun3dj3/F9nu6eyBVT0CAikgXK+pflzQ5vEtkrkh/jfqT++/VZum2pp7slckUUNIiI\nZKHO1Tuz/L7llPMvR7MJzXh9yeuarpAcS0GDiEgWq1S0Eov6LWJI4yE8Nu8xbv3qVo6cOuLpbolk\nmIIGEZGrwMfbh5FtRjKt5zRmr59Now8asW7vOk93SyRDFDSIiFxFN4fdzP/d83+cjT/Lv8b/i29j\nvvV0l0TSLZ+nOyAikteElQzj/+79P+785k66TO1C+6rtCS8TTr2getQLqkeVYlXwMvpOJ9mPggYR\nEQ8okr8I03pO493f3uW72O/4aPlHbD+y/dxjN1W7id61etM2pC2+3r4e7q2Io6BBRMRDvIwXD177\nIA9e+yAAO4/sZOXOlfyy9Re++OsLJv8xmWIFitE9rDv96vWjacWmHu6x5HUa/xIRySZKFy5N25C2\nPNfyOVbfv5pVA1dxf8P7Wbh5IddPuJ5OUzqxZvcaT3dT8jAFDSIi2ZAxhtqla/NS65dYP3g9n9/y\nOX/u+pPa79Zm4MyB7Dyy09NdlDxI0xMiItmcMYaeNXvSpXoX3vntHV748QU+++MzWgW3orx/ecoV\nKUf5IuUJLhrMdRWuw9vL29NdllxKQYOISA6RP19+hjQZwp317mT0L6NZvmM5i7cu5u9Df7P3+F4A\nQouH8miTR7mj7h0U9Cno4R5LbqOgQUQkhylesDgvtnox2bHjp4+zbPsyxiwdw/3f3c+zPzzL4GsH\n88C/HqB4weIe6qnkNsppEBHJBQr6FKRpxaZ81fMrYgbF8P/t3Xl0VGWax/HvQ0hAIoKCCBlZJazS\nkQRQhh3EHhGjpDko2OrYB3AQlMUVFafBQzeNgqBgo7ihw9AuaCsMog0BHNzARGBaI4tEdlRQAUEI\nJu/8cQu7Oga5CVV1i+L3OeeeQ9373qqHpyrJU/e+S06LHCb+70QaPNKAUYtHseW7LUGHKAlARYOI\nSIJJr5XOn/v+mS2jtjCm4xieX/s8Fzx6Ade/dj3rvlwXdHhyClPRICKSoOqk1mFCjwlsHb2Vqb+e\nyjtb3iFjVgYZszIYvXg0C9YvYN/hfUGHKacQ9WkQEUlwZ6acyW0X38awdsP462d/5c1Nb/LqZ68y\n7cNpVLJKtE9rz1XNr6J/q/6k10oPOlyJYxaP67qbWSaQl5eXR2ZmZtDhiIgkHOcchd8VkluYy+JN\ni3lz05scOnqINnXa0L9Vfwa1GUTTc5oGHaZUQH5+PllZWQBZzrn8SD53uW9PmFkXM3vDzHaYWYmZ\nZZ+gfbdQu/Ct2MzqVDxsERE5GWZGk7ObMDhzMK8MeIWv7/ya+QPm0+a8Njz83sO0mNGCwW8MZtu+\nbUGHKnGkIn0aUoE1wC2A38sUDkgH6oa2es65ryrw2iIiEgXVkquR0zKHuTlz+erOr5hy2RReX/86\n6Y+lc/tbt7Pn0J6gQ5Q4UO6iwTm32Dn3gHPudcDKcerXzrmvjm3lfV0REYmNqpWrMvKSkWy+bTP3\ndrmX2fmzaTK9CbcuupXVO1YTj7e1JTZiNXrCgDVmttPM3jazf43R64qISAVVr1KdB7o9wOaRmxnR\nYQSvfvYqHZ7qQOvHWzNp5STdujgNxaJo2AXcDPwGyAG2AcvN7KIYvLaIiJyk2tVq84def2DrqK28\n9du3yKyXyYQVE2gwrQGtZrZixKIRzP90PnsP7Q06VImykxo9YWYlwNXOuTfKed5yYItz7sbjHM8E\n8rp27UqNGjX+6djAgQMZOHBgBSMWEZFI2H9kP4s2LmJZ4TJyv8hl0zebAGh9bms6/EuHn7Y2ddqQ\nnJQccLSJa968ecybN++f9u3bt4933nkHojB6IqiiYTLQyTnX6TjHNeRSROQUsm3fNpZ9sYz3t73P\nqp2rWPflOn4s+ZGqlaty7YXXcnenu2lRu0XQYZ4WojnkMqjJnS7Cu20hIiIJoH6N+tyQcQM3ZNwA\neAtordm9huVfLGfG6hnMWTOHnJY5jO08lqy0rICjlYoqd9FgZqlAU/4xcqKJmWUA3zjntpnZH4G0\nY7cezGwkUAh8AlQFhgA9gN4RiF9EROLQGcln0LF+RzrW7/jT+heT35tMu9nt6N6oO32a9qFH4x60\nrduWpEpJQYcrPlWkI2Q74GMgD2/+hSlAPjA+dLwuUD+sfUqozTpgOdAG6OWcW16hiEVE5JRSpXIV\nhmQN4bPhn/Fi/xdJSUrh9yt+T/vZ7ak1uRbZ87KZs2YORcVFQYcqJ6BppEVEJOaKiotYvWM1uYW5\nLC1cyootKzj/rPO5vePtDMkcQmpKatAhnrLiahppERGRk5WSlEKnBp0Y120cy/99OX8f9nd6Nu7J\nHW/fQcNpDZmwYgI79u8IOkwpRUWDiIgErnWd1sy5eg6f3/Y5g9oMYtLKSdR/pD495/Tk6fyn+faH\nb4MOUdDtCRERiUPfHf6O1wpeY+7/zSW3MJfkpGQubXIp7dPak1kvk7Z123L+WedjVp7VDE4PiTjk\nUkRE5LhqVq3JTW1v4qa2N7HrwC5e/ORFFm1cxMzVM39aPKt2tdpc2exKxnYeS3qt9IAjPj2oaBAR\nkbhWr3o9Rl0yilGXjMI5x/b92/l498es3rGapz9+mjlr5zCozSDu63KfJpCKMvVpEBGRU4aZUb9G\nfbKbZ/NgzwfZPHIzj/7boyz/YjmtZrbi2leuJX9XRK/ISxgVDSIicsqqWrkqwzsMZ9Otm5jVdxYf\n7viQrCez6PZcN14reI3ikuKgQ0woKhpEROSUV6VyFYZmDWXjrRuZP2A+Ja6EnJdySH8snYfefYiN\nezcGHWJCUJ8GERFJGJUrVSanZQ45LXP4aOdHPPLBI4xbNo67ltxFs1rN6JvelyuaXUHjmo05WnKU\nouIiioqLSLIkfnXerzQa4wQ05FJERBLawaKDLC1cysINC1m4YSG7vi97vcRLzr+Eh3s/TKcGZS7A\nfMrQkEsREZEKSk1JJbt5NtnNs3HOsfbLtew9tJeUpBRSklJITkpm14FdjFs2js7PdianZQ6Tek3S\nMM4yqGgQEZHThplxUd2Lfn6gHlyefjlz183l3tx7afV4K27MuJF+LfrRo3EPqiVXi32wcUgdIUVE\nRIBKVonrM65nw4gNPNjjQXILc+k7ry+1Jteiz9w+zFg1g68OfhV0mIFS0SAiIhLmjOQzuKfzPXx+\n2+cUDC9gYs+JFBUXMeatMTSe3ph7ltzD3kN7gw4zECoaREREymBmtKjdgjEdx7DkhiXsvmM3oy4e\nxYxVM2g8vTEPLHuA7w5/F3SYMaWiQURExIdzzjiHib0mUjiykJuzbubh9x6m0bRG3PH2HRR+Wxh0\neDGhokFERKQczk09l4cue4jPb/ucoVlDeebjZ7jg0Qu46i9XsXTzUuJxKoNIUdEgIiJSAfWq12Ny\n78lsH7OdJ/o+QeG3hVz6wqU0nNaQAS8P4KF3H2L5F8s5cORA0KFGjIZcioiInIRqydUYkjWEwZmD\nWbFlBQvWL2D1ztWMXzGeg0cPYhjNazenXVo72tVrR1ZaFm3rtiU1JTXo0MtNRYOIiEgEmBndG3Wn\ne6PuABSXFFOwp4DVO1aTtyuPj3Z+xMufvMyR4iNUrlSZrg27kt0smyubX0mTs5sEG7xPmkZaREQk\nRo4WH+XTrz9l5daVLNy4kNzCXIqKi2h9bmv6t+rP0KyhpFVPO6nXiOY00urTICIiEiPJSclk1M1g\neIfhvHndm+y5cw/zB8ynXVo7prw/hYbTGnLNK9ewcuvKuOxQqaJBREQkINWrVCenZQ7PXf0c20dv\nZ+plU1mzew1dnu1C2yfa8mTek3xf9H3QYf5ERYOIiEgcqFG1BrdefCsFwwt4+7dv07BmQ4b9zzDS\npqQxbOEw1u5eC3h9JTbs3cCrBa8yYcUEZq6aGbMY1RFSREQkjlSySvS+oDe9L+jNtn3beCr/KWbn\nz2ZW3iyanN2EnQd2cvjHwwDUrlab/i37xyw2FQ0iIiJxqn6N+ozvMZ77u97Pwg1ex8mm5zTlwjoX\ncmGdC6mTWgczi1k8KhpERETiXHJSMv1a9qNfy36BxqE+DSIiIuKLigYRERHxRUWDiIiI+KKiQURE\nRHxR0SAiIiK+qGgQERERX1Q0iIiIiC8qGkRERMQXFQ0iIiLii4oGERER8UVFg4iIiPiiokFERER8\nUdEgIiIivqhoEBEREV9UNIiIiIgvKhpERETEFxUNIiIi4ouKBhEREfFFRYOIiIj4oqJBREREfFHR\nICIiIr6oaBARERFfVDSIiIiILyoa5Cfz5s0LOoTTjnIee8p57CnniaPcRYOZdTGzN8xsh5mVmFm2\nj3O6m1memR02sw1mdmPFwpVo0g927Cnnsaecx55ynjgqcqUhFVgD3AK4EzU2s0bAQmApkAFMB54y\ns94VeG0REREJSOXynuCcWwwsBjAz83HKMGCzc+6u0OP1ZtYZGA38rbyvLyIiIsGIRZ+GS4Alpfa9\nBXSMwWuLiIhIhJT7SkMF1AW+LLXvS+AsM6vinDtSxjlVAQoKCqIdm4TZt28f+fn5QYdxWlHOY085\njz3lPLbC/nZWjfRzm3Mn7JZw/JPNSoCrnXNv/EKb9cAzzrk/he27HK+fQ7WyigYzGwTMrXBgIiIi\ncp1z7r8j+YSxuNKwGziv1L7zgP3HucoA3u2L64AvgMPRC01ERCThVAUa4f0tjahYFA3vA5eX2ndZ\naH+ZnHN7gYhWRyIiIqeR96LxpBWZpyHVzDLM7KLQriahx/VDx/9oZnPCTpkVavMnM2tuZrcA/YGp\nJx29iIiIxEy5+zSYWTdgGT+fo2GOc+53ZvYs0NA51zPsnK7AI0ArYDswwTn3wklFLiIiIjF1Uh0h\nRURE5PShtSdERETEFxUNIiIi4kvcFQ1mNtzMCs3sBzP7wMzaBx1TojCzsWa2ysz2m9mXZvaamTUr\no90EM9tpZofM7G9m1jSIeBONmd0TWuRtaqn9yneEmVmamb1gZntCeV1rZpml2ijvEWJmlczsQTPb\nHMrnJjO7v4x2ynkF+Vks8kT5NbMqZjYz9HNxwMxeMbM65YkjrooGM7sGmAL8J9AWWAu8ZWa1Aw0s\ncXQBHgMuBi4FkoG3zeyMYw3M7G5gBDAU6AAcxHsPUmIfbuIIFb9D8T7T4fuV7wgzs5rAu8AR4NdA\nS+B24NuwNsp7ZN0D3Iy3kGEL4C7gLjMbcayBcn7SfnGxSJ/5nQZcAfwG6AqkAfPLFYVzLm424ANg\nethjwxttcVfQsSXiBtQGSoDOYft2AqPDHp8F/AAMCDreU3UDzgTWAz3xRh5NVb6jmu9JwIoTtFHe\nI5vzBcDsUvteAZ5XzqOS7xIgu9S+X8xv6PERoF9Ym+ah5+rg97Xj5kqDmSUDWXhLaAPgvP/VErS4\nVbTUxKtYvwEws8Z4a4WEvwf7gQ/Re3AyZgILnHO54TuV76i5EvjIzF4K3YbLN7PBxw4q71HxHtDL\nzNIBzCwD6AQsCj1WzqPIZ37b4U3oGN5mPbCVcrwHsZgR0q/aQBJlL27VPPbhJLbQsubTgJXOuU9D\nu+viFRFlvQd1YxhewjCza4GL8H5gS1O+o6MJMAzvVudEvEu1j5rZEefND6O8R94kvG+yn5lZMd6t\n7/ucc38JHVfOo8tPfs8DikLFxPHanFA8FQ0SW4/jTbbVKehAEpWZnY9XmF3qnDsadDynkUrAKufc\nuNDjtWZ2IfAfgCaVi45rgEHAtcCneIXydDPb6TSRX0KJm9sTwB6gmLIXt9od+3ASl5nNAPoA3Z1z\nu8IO7cbrR6L3IDKygHOBfDM7amZHgW7ASDMrwqvwle/I2wUUlNpXADQI/Vuf88ibDExyzr3snPvE\nOTcXbxbgsaHjynl0+cnvbiDFzM76hTYnFDdFQ+ibWB7Q69i+0CX0XkRp4Y3TUahguAro4ZzbGn7M\nOVeI9+EJfw/Owhttofeg/JYAbfC+dWWEto+A/wIynHObUb6j4V1+fkuzObAF9DmPkmp4X/rClRD6\nG6OcR5fP/OYBP5Zq0xyvmD7uApKlxdvtianAc2aWB6wCRuN9GJ8LMqhEYWaPAwOBbOCgmR2rSvc5\n544tQT4NuN/MNuEtTf4g3giW12Mc7inPOXcQ71LtT8zsILDXOXfsm7DyHXmPAO+a2VjgJbxfnIOB\nIWFtlPfIWoCXz+3AJ0Am3u/vp8LaKOcnwcxSgaZ4VxQgtFgk8I1zbhsnyK9zbr+ZPQ1MNbNvgQPA\no8C7zrlVvgMJeuhIGUNJbgn9h3/Aq37aBR1Tomx4lX9xGdsNpdr9Hm/4ziG89dibBh17omxALmFD\nLpXvqOW5D7AulNNPgN+V0UZ5j1y+U/G+9BXizQ+wERgPVFbOI5bjbsf5Hf6M3/wCVfDm6tkTKhpe\nBuqUJw4tWCUiIiK+xE2fBhEREYlvKhpERETEFxUNIiIi4ouKBhEREfFFRYOIiIj4oqJBREREfFHR\nICIiIr6oaBARERFfVDSIiIiILyoaRERExBcVDSIiIuLL/wNXK0nFboygVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa45311c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min loss:1.254\n",
      "Test min loss:2.357\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats(test_res, train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grounder with bi-directional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/All/base/Bi_hidden:50\n",
      "num_hidden: 50\n",
      "learning rate: 0.05\n",
      "# Train set size: 297\n",
      "# Training batches: 297\n",
      "# Test set size: 297\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 1.845 ;acc: 0.360 ;iou: 0.485 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 1.910 ;acc: 0.310 ;iou: 0.370 ;time: 0:00:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 3.016 ;acc: 0.095 ;iou: 0.195 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 3.329 ;acc: 0.130 ;iou: 0.215 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.889 ;acc: 0.140 ;iou: 0.265 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 1.927 ;acc: 0.285 ;iou: 0.385 ;time: 0:00:31\n",
      "\n",
      "*Training B: True ;B Train loss: 2.437 ;Train accuracy: 0.218 ;IOU accuracy: 0.314 ;Time: 0:00:36 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 1.388 ;acc: 0.470 ;iou_acc: 0.660 ;time: 0:00:37\n",
      "batch: 50 ;B loss: 1.862 ;acc: 0.285 ;iou_acc: 0.395 ;time: 0:00:40\n"
     ]
    }
   ],
   "source": [
    "# Base with bidirectional rnn\n",
    "bi_test_res, bi_train_res = [], []\n",
    "\n",
    "for num_hidden in [50, 100, 150, 200]:\n",
    "    params_dir = params_dir_tmp+'base/Bi_hidden:'+str(num_hidden)\n",
    "    tf.reset_default_graph()\n",
    "    m = Model(\n",
    "        batch_size=200, \n",
    "        num_hidden=num_hidden,\n",
    "        embed_size=embed_vecs.shape[1],\n",
    "        img_dims=trainset[0][0][1][0].shape[1], \n",
    "        bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "        lr=.05,\n",
    "        vocab=vocab, \n",
    "        decay_steps=10000, \n",
    "        decay_rate=0.9, \n",
    "        edit_reward=0.,\n",
    "        rnn_editProb=0.,\n",
    "        coefAlr=1,\n",
    "        useBidirectionalRnn=True,\n",
    "        bnorm=False\n",
    "    )\n",
    "\n",
    "\n",
    "    # start comp\n",
    "    print('params_dir:', params_dir)\n",
    "    print('num_hidden:', m.num_hidden)\n",
    "    print('learning rate:', m.lr)\n",
    "    tst, trn = m.train(trainset, testset,\n",
    "            ephocs_num=100,\n",
    "            start_ephoc=0,\n",
    "            startA=101,\n",
    "            activation_ephoc=101,\n",
    "            muteB=0, \n",
    "            activateAProb=0,\n",
    "            max_activateAProb=0,\n",
    "            editProb=0,\n",
    "            edit_reward=0)\n",
    "    \n",
    "    bi_test_res.append(tst)\n",
    "    bi_train_res.append(trn)\n",
    "    print('\\n'+'*'*100)\n",
    "    print('*'*100)\n",
    "    print('*'*100,'\\n')\n",
    "    \n",
    "    \n",
    "np.save(open('../data/training/results/bi_test_res.bin', 'wb'), bi_test_res)\n",
    "np.save(open('../data/training/results/bi_test_res.bin', 'wb'), bi_test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/All/base/BiAttn_hidden:50\n",
      "num_hidden: 50\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.487 ;acc: 0.215 ;iou: 0.310 ;time: 0:00:01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-40f0080088d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mmax_activateAProb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0meditProb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             edit_reward=0)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mbiAttn_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-3dad1920a7af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, addNoise)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                                                                             \u001b[0mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                                                                             \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m                                                                                             addNoise=addNoise)\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                         \u001b[0mreward_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dummy holder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-3dad1920a7af>\u001b[0m in \u001b[0;36mbuild_data\u001b[0;34m(self, data, start, end, addNoise)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             padded_im.append(np.concatenate([data[i][j][0] for j in range(1, len(data[i])-1)] + \n\u001b[0;32m--> 337\u001b[0;31m                                        [np.full((imlen-(len(data[i])-2), im_dim), vocab['<pad>'], dtype=np.float32)], axis=0))\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             padded_bbox.append(np.concatenate([data[i][j][1] for j in range(1, len(data[i])-1)] + \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Base with bidirectional rnn and word level attention\n",
    "biAttn_test_res, biAttn_train_res = [], []\n",
    "\n",
    "for num_hidden in [50, 100, 150, 200]:\n",
    "    params_dir = params_dir_tmp+'base/BiAttn_hidden:'+str(num_hidden)\n",
    "    tf.reset_default_graph()\n",
    "    m = Model(\n",
    "        batch_size=200, \n",
    "        num_hidden=num_hidden,\n",
    "        embed_size=embed_vecs.shape[1],\n",
    "        img_dims=trainset[0][0][1][0].shape[1], \n",
    "        bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "        lr=.05,\n",
    "        vocab=vocab, \n",
    "        decay_steps=10000, \n",
    "        decay_rate=0.99, \n",
    "        edit_reward=0.,\n",
    "        rnn_editProb=0.,\n",
    "        coefAlr=1,\n",
    "        useBidirectionalRnn=True,\n",
    "        bnorm=False,\n",
    "        use_wordAttn=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # start comp\n",
    "    print('params_dir:', params_dir)\n",
    "    print('num_hidden:', m.num_hidden)\n",
    "    print('learning rate:', m.lr)\n",
    "    tst, trn = m.train(trainset, testset,\n",
    "            ephocs_num=100,\n",
    "            start_ephoc=0,\n",
    "            startA=51,\n",
    "            activation_ephoc=51,\n",
    "            muteB=0, \n",
    "            activateAProb=0,\n",
    "            max_activateAProb=0,\n",
    "            editProb=0,\n",
    "            edit_reward=0)\n",
    "    \n",
    "    biAttn_test_res.append(tst)\n",
    "    biAttn_train_res.append(trn)\n",
    "    print('\\n'+'*'*100)\n",
    "    print('*'*100)\n",
    "    print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization\n",
    "<p>Here we use one directional RNN and no words level attention.<br>\n",
    "We use batch normalization to both the images and the RNN's final outputs before the final attention layer. Again, we test for the same hidden units sizes and we run for 50 ephocs.</p>\n",
    "\n",
    "<p> Here the test set IOU is gtes up to 79.9% while the train set IOU gets to 100% in all tests.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/hidden:50\n",
      "num_hidden: 50\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.759 ;acc: 0.325 ;iou: 0.395 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.695 ;acc: 0.240 ;iou: 0.375 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.664 ;acc: 0.285 ;iou: 0.405 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.671 ;acc: 0.320 ;iou: 0.435 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.539 ;acc: 0.380 ;iou: 0.455 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.474 ;acc: 0.400 ;iou: 0.470 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 2.625 ;Train accuracy: 0.319 ;IOU accuracy: 0.419 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.466 ;acc: 0.300 ;iou_acc: 0.425 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 2.498 ;acc: 0.350 ;iou_acc: 0.430 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.600 ;acc: 0.295 ;iou_acc: 0.365 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 2.520 ;acc: 0.295 ;iou_acc: 0.435 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 2.480 ;acc: 0.330 ;iou_acc: 0.415 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 2.516 ;acc: 0.345 ;iou_acc: 0.470 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 2.473 ;Test accuracy 0.329 ;IOU accuracy: 0.439 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.433 ;acc: 0.355 ;iou: 0.445 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.341 ;acc: 0.395 ;iou: 0.505 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.279 ;acc: 0.450 ;iou: 0.565 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.278 ;acc: 0.465 ;iou: 0.570 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.252 ;acc: 0.510 ;iou: 0.610 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.352 ;acc: 0.470 ;iou: 0.570 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 2.325 ;Train accuracy: 0.455 ;IOU accuracy: 0.547 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.290 ;acc: 0.380 ;iou_acc: 0.490 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.286 ;acc: 0.390 ;iou_acc: 0.450 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 2.418 ;acc: 0.395 ;iou_acc: 0.485 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.285 ;acc: 0.370 ;iou_acc: 0.510 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 2.248 ;acc: 0.450 ;iou_acc: 0.530 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.299 ;acc: 0.400 ;iou_acc: 0.510 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 2.239 ;Test accuracy 0.420 ;IOU accuracy: 0.524 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.228 ;acc: 0.525 ;iou: 0.605 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.322 ;acc: 0.485 ;iou: 0.600 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 1.988 ;acc: 0.535 ;iou: 0.625 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.193 ;acc: 0.515 ;iou: 0.580 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.134 ;acc: 0.535 ;iou: 0.600 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 1.978 ;acc: 0.620 ;iou: 0.690 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 2.095 ;Train accuracy: 0.550 ;IOU accuracy: 0.637 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.109 ;acc: 0.445 ;iou_acc: 0.550 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.096 ;acc: 0.455 ;iou_acc: 0.530 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.205 ;acc: 0.450 ;iou_acc: 0.520 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.144 ;acc: 0.410 ;iou_acc: 0.525 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.104 ;acc: 0.425 ;iou_acc: 0.555 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.131 ;acc: 0.475 ;iou_acc: 0.580 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 2.044 ;Test accuracy 0.480 ;IOU accuracy: 0.581 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.028 ;acc: 0.575 ;iou: 0.640 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.046 ;acc: 0.570 ;iou: 0.655 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.946 ;acc: 0.600 ;iou: 0.665 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.864 ;acc: 0.610 ;iou: 0.730 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.951 ;acc: 0.550 ;iou: 0.660 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.947 ;acc: 0.580 ;iou: 0.670 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 1.921 ;Train accuracy: 0.614 ;IOU accuracy: 0.693 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.983 ;acc: 0.495 ;iou_acc: 0.600 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.007 ;acc: 0.480 ;iou_acc: 0.555 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.109 ;acc: 0.490 ;iou_acc: 0.565 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.052 ;acc: 0.480 ;iou_acc: 0.600 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.018 ;acc: 0.465 ;iou_acc: 0.595 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.015 ;acc: 0.535 ;iou_acc: 0.630 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 1.949 ;Test accuracy 0.508 ;IOU accuracy: 0.609 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.986 ;acc: 0.590 ;iou: 0.690 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.731 ;acc: 0.650 ;iou: 0.740 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.761 ;acc: 0.670 ;iou: 0.720 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.816 ;acc: 0.680 ;iou: 0.740 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.587 ;acc: 0.715 ;iou: 0.755 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.925 ;acc: 0.640 ;iou: 0.705 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.796 ;Train accuracy: 0.657 ;IOU accuracy: 0.729 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.883 ;acc: 0.525 ;iou_acc: 0.630 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.874 ;acc: 0.545 ;iou_acc: 0.615 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.012 ;acc: 0.505 ;iou_acc: 0.555 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.898 ;acc: 0.515 ;iou_acc: 0.610 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.900 ;acc: 0.480 ;iou_acc: 0.600 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.893 ;acc: 0.555 ;iou_acc: 0.630 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.858 ;Test accuracy 0.536 ;IOU accuracy: 0.634 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.639 ;acc: 0.715 ;iou: 0.775 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.710 ;acc: 0.685 ;iou: 0.765 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.841 ;acc: 0.695 ;iou: 0.760 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.763 ;acc: 0.645 ;iou: 0.745 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.759 ;acc: 0.670 ;iou: 0.720 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.506 ;acc: 0.750 ;iou: 0.810 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 1.694 ;Train accuracy: 0.698 ;IOU accuracy: 0.765 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.836 ;acc: 0.520 ;iou_acc: 0.640 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.791 ;acc: 0.540 ;iou_acc: 0.640 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.944 ;acc: 0.445 ;iou_acc: 0.545 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.825 ;acc: 0.535 ;iou_acc: 0.635 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.876 ;acc: 0.505 ;iou_acc: 0.620 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.908 ;acc: 0.540 ;iou_acc: 0.630 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.817 ;Test accuracy 0.547 ;IOU accuracy: 0.647 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.616 ;acc: 0.740 ;iou: 0.805 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.477 ;acc: 0.785 ;iou: 0.850 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.653 ;acc: 0.765 ;iou: 0.810 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.586 ;acc: 0.760 ;iou: 0.810 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.470 ;acc: 0.755 ;iou: 0.830 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.635 ;acc: 0.775 ;iou: 0.830 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 1.591 ;Train accuracy: 0.747 ;IOU accuracy: 0.808 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.795 ;acc: 0.555 ;iou_acc: 0.675 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.690 ;acc: 0.580 ;iou_acc: 0.665 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.924 ;acc: 0.460 ;iou_acc: 0.545 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.763 ;acc: 0.575 ;iou_acc: 0.690 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.764 ;acc: 0.550 ;iou_acc: 0.655 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.747 ;acc: 0.590 ;iou_acc: 0.670 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 1.725 ;Test accuracy 0.583 ;IOU accuracy: 0.684 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.543 ;acc: 0.775 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.470 ;acc: 0.745 ;iou: 0.790 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.463 ;acc: 0.825 ;iou: 0.855 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.415 ;acc: 0.800 ;iou: 0.860 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.226 ;acc: 0.860 ;iou: 0.900 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.401 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.461 ;Train accuracy: 0.797 ;IOU accuracy: 0.854 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.722 ;acc: 0.600 ;iou_acc: 0.710 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.624 ;acc: 0.590 ;iou_acc: 0.670 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.791 ;acc: 0.565 ;iou_acc: 0.650 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 1.715 ;acc: 0.610 ;iou_acc: 0.710 ;time: 0:01:09\n",
      "batch: 200 ;B loss: 1.669 ;acc: 0.595 ;iou_acc: 0.700 ;time: 0:01:16\n",
      "batch: 250 ;B loss: 1.667 ;acc: 0.625 ;iou_acc: 0.715 ;time: 0:01:22\n",
      "\n",
      "*BTrain: False ;Test loss: 1.654 ;Test accuracy 0.605 ;IOU accuracy: 0.706 ;Time: 0:01:28\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.379 ;acc: 0.825 ;iou: 0.880 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.382 ;acc: 0.830 ;iou: 0.860 ;time: 0:00:07\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.374 ;acc: 0.835 ;iou: 0.860 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.204 ;acc: 0.830 ;iou: 0.885 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.389 ;acc: 0.785 ;iou: 0.855 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.345 ;acc: 0.825 ;iou: 0.880 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.335 ;Train accuracy: 0.835 ;IOU accuracy: 0.883 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.687 ;acc: 0.620 ;iou_acc: 0.735 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.579 ;acc: 0.610 ;iou_acc: 0.700 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.757 ;acc: 0.590 ;iou_acc: 0.655 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.550 ;acc: 0.635 ;iou_acc: 0.750 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.546 ;acc: 0.615 ;iou_acc: 0.740 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.581 ;acc: 0.640 ;iou_acc: 0.750 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.567 ;Test accuracy 0.635 ;IOU accuracy: 0.736 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.117 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.277 ;acc: 0.860 ;iou: 0.885 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.061 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.063 ;acc: 0.915 ;iou: 0.930 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.317 ;acc: 0.820 ;iou: 0.870 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.330 ;acc: 0.820 ;iou: 0.860 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 1.244 ;Train accuracy: 0.856 ;IOU accuracy: 0.901 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.630 ;acc: 0.615 ;iou_acc: 0.715 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.436 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.772 ;acc: 0.560 ;iou_acc: 0.630 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.499 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.481 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.521 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.493 ;Test accuracy 0.653 ;IOU accuracy: 0.753 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.004 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.180 ;acc: 0.885 ;iou: 0.900 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.325 ;acc: 0.845 ;iou: 0.905 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.147 ;acc: 0.865 ;iou: 0.925 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.165 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.045 ;acc: 0.895 ;iou: 0.955 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 1.167 ;Train accuracy: 0.873 ;IOU accuracy: 0.913 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.510 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.451 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.726 ;acc: 0.575 ;iou_acc: 0.660 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.522 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.442 ;acc: 0.635 ;iou_acc: 0.755 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.468 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.480 ;Test accuracy 0.661 ;IOU accuracy: 0.760 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.104 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.174 ;acc: 0.855 ;iou: 0.885 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.148 ;acc: 0.870 ;iou: 0.895 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.125 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.145 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.072 ;acc: 0.895 ;iou: 0.945 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.103 ;Train accuracy: 0.888 ;IOU accuracy: 0.924 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.626 ;acc: 0.635 ;iou_acc: 0.740 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.465 ;acc: 0.640 ;iou_acc: 0.745 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.658 ;acc: 0.595 ;iou_acc: 0.660 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.401 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.457 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.528 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.484 ;Test accuracy 0.663 ;IOU accuracy: 0.762 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.051 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 1.171 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 0.920 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.055 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.178 ;acc: 0.860 ;iou: 0.890 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 1.050 ;Train accuracy: 0.898 ;IOU accuracy: 0.931 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.559 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.431 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.589 ;acc: 0.605 ;iou_acc: 0.685 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.408 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.437 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.393 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 1.455 ;Test accuracy 0.673 ;IOU accuracy: 0.768 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 0.969 ;acc: 0.915 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.041 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 0.908 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 1.035 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 0.941 ;acc: 0.920 ;iou: 0.960 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 0.880 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 1.007 ;Train accuracy: 0.907 ;IOU accuracy: 0.938 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.407 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.376 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.567 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.508 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.347 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.445 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.421 ;Test accuracy 0.678 ;IOU accuracy: 0.776 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.831 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.041 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 1.145 ;acc: 0.885 ;iou: 0.920 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 0.962 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.955 ;Train accuracy: 0.916 ;IOU accuracy: 0.945 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.516 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.518 ;acc: 0.620 ;iou_acc: 0.745 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.539 ;acc: 0.620 ;iou_acc: 0.690 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.603 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.427 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.474 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.470 ;Test accuracy 0.675 ;IOU accuracy: 0.771 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.820 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.863 ;acc: 0.940 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.962 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 0.922 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 0.783 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.758 ;acc: 0.925 ;iou: 0.965 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.921 ;Train accuracy: 0.923 ;IOU accuracy: 0.949 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.597 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.443 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.572 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.587 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.376 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.356 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.480 ;Test accuracy 0.674 ;IOU accuracy: 0.771 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.783 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.845 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.867 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.931 ;acc: 0.915 ;iou: 0.960 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.813 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.935 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.875 ;Train accuracy: 0.930 ;IOU accuracy: 0.954 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.559 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.390 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.744 ;acc: 0.620 ;iou_acc: 0.700 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.628 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.412 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.563 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.560 ;Test accuracy 0.666 ;IOU accuracy: 0.765 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.881 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.895 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.557 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.879 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.890 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.950 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.847 ;Train accuracy: 0.935 ;IOU accuracy: 0.957 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.461 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.428 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.507 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.544 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.425 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.404 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.458 ;Test accuracy 0.686 ;IOU accuracy: 0.780 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.832 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.712 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.817 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.723 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.747 ;acc: 0.945 ;iou: 0.990 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.875 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.814 ;Train accuracy: 0.942 ;IOU accuracy: 0.962 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.533 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.438 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.598 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.580 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.332 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.441 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.487 ;Test accuracy 0.686 ;IOU accuracy: 0.781 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.715 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.749 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.878 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.732 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.829 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.735 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.776 ;Train accuracy: 0.947 ;IOU accuracy: 0.965 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.604 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.357 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.571 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.593 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.466 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.430 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.473 ;Test accuracy 0.690 ;IOU accuracy: 0.784 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.955 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.712 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.847 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.898 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.867 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.922 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.747 ;Train accuracy: 0.951 ;IOU accuracy: 0.968 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.538 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.551 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.602 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.595 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.475 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.522 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.518 ;Test accuracy 0.686 ;IOU accuracy: 0.784 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.765 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.629 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.652 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.612 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.694 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.667 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.721 ;Train accuracy: 0.956 ;IOU accuracy: 0.971 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.607 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.497 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.653 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.604 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.413 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.572 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.537 ;Test accuracy 0.688 ;IOU accuracy: 0.782 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.643 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.733 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.723 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.628 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.607 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.557 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.694 ;Train accuracy: 0.960 ;IOU accuracy: 0.974 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.472 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.509 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.506 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.666 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.393 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.421 ;acc: 0.740 ;iou_acc: 0.840 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.526 ;Test accuracy 0.691 ;IOU accuracy: 0.785 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.677 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.633 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.605 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.598 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.787 ;acc: 0.930 ;iou: 0.975 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.438 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.667 ;Train accuracy: 0.964 ;IOU accuracy: 0.977 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.562 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.510 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.583 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.657 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.408 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.482 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.556 ;Test accuracy 0.690 ;IOU accuracy: 0.785 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.780 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.656 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.518 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.704 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.852 ;acc: 0.945 ;iou: 0.970 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.826 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.641 ;Train accuracy: 0.964 ;IOU accuracy: 0.977 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.550 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.573 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.665 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.691 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.387 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.549 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:27\n",
      "\n",
      "*BTrain: True ;Test loss: 1.563 ;Test accuracy 0.690 ;IOU accuracy: 0.784 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.581 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.463 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.712 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.678 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.811 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.800 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.620 ;Train accuracy: 0.969 ;IOU accuracy: 0.980 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.621 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.740 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.581 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.669 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.434 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.666 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.611 ;Test accuracy 0.690 ;IOU accuracy: 0.783 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.583 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.619 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.464 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.538 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.557 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.651 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.593 ;Train accuracy: 0.971 ;IOU accuracy: 0.982 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.562 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.594 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.673 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.649 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.356 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.444 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.548 ;Test accuracy 0.696 ;IOU accuracy: 0.789 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.473 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.518 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.595 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.674 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.532 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.565 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.570 ;Train accuracy: 0.973 ;IOU accuracy: 0.982 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.586 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.613 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.616 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.634 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.367 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.597 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.596 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.464 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.522 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.722 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.519 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.628 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.705 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.548 ;Train accuracy: 0.975 ;IOU accuracy: 0.984 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.659 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.656 ;acc: 0.675 ;iou_acc: 0.805 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.632 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.567 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.481 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.606 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.602 ;Test accuracy 0.695 ;IOU accuracy: 0.790 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.501 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.466 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.629 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.428 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.565 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.750 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.531 ;Train accuracy: 0.978 ;IOU accuracy: 0.986 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.588 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.681 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.678 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.746 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.298 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.651 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.618 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.387 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.502 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.365 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.579 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.585 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.667 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.508 ;Train accuracy: 0.979 ;IOU accuracy: 0.986 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.701 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.656 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.752 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.893 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.576 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.672 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.701 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.430 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.424 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.513 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.613 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.607 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.558 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:40\n",
      "\n",
      "*Training B: False ;B Train loss: 0.496 ;Train accuracy: 0.980 ;IOU accuracy: 0.987 ;Time: 0:00:47 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.749 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:00:47\n",
      "batch: 50 ;B loss: 1.722 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:00:54\n",
      "batch: 100 ;B loss: 1.768 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:01:01\n",
      "batch: 150 ;B loss: 1.768 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:08\n",
      "batch: 200 ;B loss: 1.369 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:15\n",
      "batch: 250 ;B loss: 1.715 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:22\n",
      "\n",
      "*BTrain: False ;Test loss: 1.686 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:29\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.534 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.441 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.446 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.445 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.490 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.549 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.475 ;Train accuracy: 0.982 ;IOU accuracy: 0.988 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.797 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.913 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.806 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.799 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.577 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.737 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.721 ;Test accuracy 0.695 ;IOU accuracy: 0.788 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.551 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.577 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.489 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.348 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.544 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.304 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.461 ;Train accuracy: 0.983 ;IOU accuracy: 0.989 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.703 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.855 ;acc: 0.655 ;iou_acc: 0.780 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.860 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.859 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.602 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.755 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:27\n",
      "\n",
      "*BTrain: True ;Test loss: 1.739 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.492 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.303 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.374 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.391 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.571 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.441 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.435 ;Train accuracy: 0.984 ;IOU accuracy: 0.990 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.709 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.755 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.860 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.897 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.552 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.801 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.745 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.372 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.281 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.514 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.349 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.417 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.437 ;acc: 0.980 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.421 ;Train accuracy: 0.986 ;IOU accuracy: 0.991 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.641 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.810 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.878 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.772 ;acc: 0.730 ;iou_acc: 0.825 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.649 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.713 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.756 ;Test accuracy 0.696 ;IOU accuracy: 0.789 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.369 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.328 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.353 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.350 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.486 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.503 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.405 ;Train accuracy: 0.987 ;IOU accuracy: 0.992 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.890 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.046 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.033 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.903 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.607 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.899 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.867 ;Test accuracy 0.693 ;IOU accuracy: 0.788 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.280 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.436 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.220 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.367 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.406 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.457 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.389 ;Train accuracy: 0.988 ;IOU accuracy: 0.992 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.821 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.958 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.962 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.000 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.538 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.930 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.861 ;Test accuracy 0.691 ;IOU accuracy: 0.786 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.391 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.409 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.409 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.377 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.438 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.441 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.378 ;Train accuracy: 0.989 ;IOU accuracy: 0.993 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.826 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.105 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.946 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.060 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.809 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.024 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.921 ;Test accuracy 0.690 ;IOU accuracy: 0.782 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.362 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.296 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.313 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.371 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.260 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.287 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.363 ;Train accuracy: 0.990 ;IOU accuracy: 0.994 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.824 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.970 ;acc: 0.640 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.899 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 2.127 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.627 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.030 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 1.892 ;Test accuracy 0.692 ;IOU accuracy: 0.786 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.340 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.220 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.315 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.349 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.307 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.268 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.348 ;Train accuracy: 0.991 ;IOU accuracy: 0.994 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.801 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.872 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.875 ;acc: 0.725 ;iou_acc: 0.785 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.008 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.552 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.808 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.871 ;Test accuracy 0.696 ;IOU accuracy: 0.789 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.278 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.240 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.398 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.272 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.286 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.286 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.338 ;Train accuracy: 0.992 ;IOU accuracy: 0.995 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.872 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.031 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.955 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.183 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.624 ;acc: 0.705 ;iou_acc: 0.815 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.153 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.961 ;Test accuracy 0.692 ;IOU accuracy: 0.786 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.260 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.472 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.296 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.295 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.399 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.285 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.327 ;Train accuracy: 0.992 ;IOU accuracy: 0.995 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 2.040 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.128 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.912 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.259 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.771 ;acc: 0.705 ;iou_acc: 0.815 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.899 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.952 ;Test accuracy 0.695 ;IOU accuracy: 0.788 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.240 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.246 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.252 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.361 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.296 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.273 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.309 ;Train accuracy: 0.993 ;IOU accuracy: 0.995 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.884 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 2.093 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:00:55\n",
      "batch: 100 ;B loss: 2.051 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:01:00\n",
      "batch: 150 ;B loss: 2.086 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:07\n",
      "batch: 200 ;B loss: 1.722 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:13\n",
      "batch: 250 ;B loss: 2.031 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "\n",
      "*BTrain: False ;Test loss: 1.971 ;Test accuracy 0.693 ;IOU accuracy: 0.786 ;Time: 0:01:26\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.287 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.233 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.251 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.337 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.242 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.396 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.300 ;Train accuracy: 0.994 ;IOU accuracy: 0.996 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.778 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.936 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.926 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 2.110 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.744 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.957 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.931 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.256 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.294 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.347 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.314 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.195 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.320 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.290 ;Train accuracy: 0.994 ;IOU accuracy: 0.996 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.872 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.051 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.058 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.255 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.736 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.059 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 2.017 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.248 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.299 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.203 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.154 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.175 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.246 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.278 ;Train accuracy: 0.995 ;IOU accuracy: 0.996 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.857 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.201 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.125 ;acc: 0.710 ;iou_acc: 0.770 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.034 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.784 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.139 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.007 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.170 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.331 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.257 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.284 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.235 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.205 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.269 ;Train accuracy: 0.994 ;IOU accuracy: 0.996 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.949 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.245 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.047 ;acc: 0.730 ;iou_acc: 0.785 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.114 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.654 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.311 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.042 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.196 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.232 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.319 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.327 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.122 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.418 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.259 ;Train accuracy: 0.995 ;IOU accuracy: 0.996 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.758 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.110 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.139 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.016 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.978 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.315 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 2.060 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.291 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.336 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.184 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.178 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.167 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.301 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.240 ;Train accuracy: 0.996 ;IOU accuracy: 0.997 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.904 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.235 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.099 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.259 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.766 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.107 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.124 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/hidden:100\n",
      "num_hidden: 100\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.924 ;acc: 0.350 ;iou: 0.405 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.643 ;acc: 0.365 ;iou: 0.455 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.691 ;acc: 0.280 ;iou: 0.410 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.737 ;acc: 0.300 ;iou: 0.405 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.499 ;acc: 0.410 ;iou: 0.505 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.417 ;acc: 0.385 ;iou: 0.460 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 2.598 ;Train accuracy: 0.352 ;IOU accuracy: 0.451 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.376 ;acc: 0.370 ;iou_acc: 0.475 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.440 ;acc: 0.335 ;iou_acc: 0.450 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.548 ;acc: 0.285 ;iou_acc: 0.360 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.457 ;acc: 0.370 ;iou_acc: 0.485 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.414 ;acc: 0.385 ;iou_acc: 0.470 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.443 ;acc: 0.365 ;iou_acc: 0.505 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 2.397 ;Test accuracy 0.356 ;IOU accuracy: 0.466 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.429 ;acc: 0.420 ;iou: 0.510 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.207 ;acc: 0.510 ;iou: 0.590 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.279 ;acc: 0.490 ;iou: 0.560 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.328 ;acc: 0.430 ;iou: 0.530 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.137 ;acc: 0.550 ;iou: 0.610 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.177 ;acc: 0.540 ;iou: 0.645 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 2.254 ;Train accuracy: 0.505 ;IOU accuracy: 0.596 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.137 ;acc: 0.475 ;iou_acc: 0.550 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.198 ;acc: 0.450 ;iou_acc: 0.545 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.345 ;acc: 0.395 ;iou_acc: 0.465 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.213 ;acc: 0.420 ;iou_acc: 0.515 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.155 ;acc: 0.450 ;iou_acc: 0.600 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.199 ;acc: 0.415 ;iou_acc: 0.555 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.151 ;Test accuracy 0.448 ;IOU accuracy: 0.553 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.047 ;acc: 0.545 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.199 ;acc: 0.525 ;iou: 0.585 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.212 ;acc: 0.510 ;iou: 0.585 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.139 ;acc: 0.565 ;iou: 0.640 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 1.948 ;acc: 0.610 ;iou: 0.685 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 1.995 ;acc: 0.605 ;iou: 0.655 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 2.020 ;Train accuracy: 0.593 ;IOU accuracy: 0.673 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.042 ;acc: 0.470 ;iou_acc: 0.565 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.025 ;acc: 0.530 ;iou_acc: 0.610 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.183 ;acc: 0.445 ;iou_acc: 0.505 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.034 ;acc: 0.510 ;iou_acc: 0.605 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.047 ;acc: 0.500 ;iou_acc: 0.605 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.051 ;acc: 0.475 ;iou_acc: 0.595 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.985 ;Test accuracy 0.500 ;IOU accuracy: 0.602 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.886 ;acc: 0.630 ;iou: 0.690 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.815 ;acc: 0.670 ;iou: 0.740 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.832 ;acc: 0.655 ;iou: 0.720 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.738 ;acc: 0.690 ;iou: 0.760 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.707 ;acc: 0.715 ;iou: 0.755 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.847 ;acc: 0.675 ;iou: 0.760 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 1.847 ;Train accuracy: 0.655 ;IOU accuracy: 0.728 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.883 ;acc: 0.500 ;iou_acc: 0.595 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.903 ;acc: 0.525 ;iou_acc: 0.610 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.107 ;acc: 0.505 ;iou_acc: 0.565 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.966 ;acc: 0.495 ;iou_acc: 0.585 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.903 ;acc: 0.535 ;iou_acc: 0.670 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.998 ;acc: 0.485 ;iou_acc: 0.590 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.884 ;Test accuracy 0.530 ;IOU accuracy: 0.630 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.603 ;acc: 0.715 ;iou: 0.770 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.795 ;acc: 0.675 ;iou: 0.730 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.636 ;acc: 0.725 ;iou: 0.800 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.789 ;acc: 0.665 ;iou: 0.735 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.872 ;acc: 0.705 ;iou: 0.745 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.597 ;acc: 0.735 ;iou: 0.780 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 1.705 ;Train accuracy: 0.713 ;IOU accuracy: 0.778 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.761 ;acc: 0.560 ;iou_acc: 0.640 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.853 ;acc: 0.565 ;iou_acc: 0.640 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.009 ;acc: 0.500 ;iou_acc: 0.570 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.866 ;acc: 0.560 ;iou_acc: 0.640 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.939 ;acc: 0.525 ;iou_acc: 0.650 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.830 ;acc: 0.590 ;iou_acc: 0.690 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.803 ;Test accuracy 0.562 ;IOU accuracy: 0.660 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.605 ;acc: 0.790 ;iou: 0.845 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.562 ;acc: 0.800 ;iou: 0.845 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.440 ;acc: 0.750 ;iou: 0.835 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.314 ;acc: 0.815 ;iou: 0.890 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.507 ;acc: 0.800 ;iou: 0.850 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.447 ;acc: 0.790 ;iou: 0.855 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.547 ;Train accuracy: 0.780 ;IOU accuracy: 0.839 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.691 ;acc: 0.575 ;iou_acc: 0.680 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.682 ;acc: 0.560 ;iou_acc: 0.675 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.852 ;acc: 0.565 ;iou_acc: 0.615 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.725 ;acc: 0.610 ;iou_acc: 0.715 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.701 ;acc: 0.585 ;iou_acc: 0.715 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.633 ;acc: 0.615 ;iou_acc: 0.735 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.668 ;Test accuracy 0.605 ;IOU accuracy: 0.706 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.403 ;acc: 0.820 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.494 ;acc: 0.840 ;iou: 0.895 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.320 ;acc: 0.835 ;iou: 0.880 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.453 ;acc: 0.795 ;iou: 0.860 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.318 ;acc: 0.835 ;iou: 0.880 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.291 ;acc: 0.845 ;iou: 0.905 ;time: 0:00:38\n",
      "\n",
      "*Training B: True ;B Train loss: 1.397 ;Train accuracy: 0.826 ;IOU accuracy: 0.877 ;Time: 0:00:44 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.675 ;acc: 0.590 ;iou_acc: 0.695 ;time: 0:00:45\n",
      "batch: 50 ;B loss: 1.586 ;acc: 0.615 ;iou_acc: 0.710 ;time: 0:00:51\n",
      "batch: 100 ;B loss: 1.774 ;acc: 0.595 ;iou_acc: 0.670 ;time: 0:00:58\n",
      "batch: 150 ;B loss: 1.668 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 200 ;B loss: 1.637 ;acc: 0.585 ;iou_acc: 0.710 ;time: 0:01:10\n",
      "batch: 250 ;B loss: 1.652 ;acc: 0.630 ;iou_acc: 0.715 ;time: 0:01:17\n",
      "\n",
      "*BTrain: True ;Test loss: 1.587 ;Test accuracy 0.629 ;IOU accuracy: 0.729 ;Time: 0:01:23\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.247 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.339 ;acc: 0.830 ;iou: 0.885 ;time: 0:00:07\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.144 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.282 ;acc: 0.905 ;iou: 0.925 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.291 ;acc: 0.835 ;iou: 0.855 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.229 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:40\n",
      "\n",
      "*Training B: False ;B Train loss: 1.280 ;Train accuracy: 0.858 ;IOU accuracy: 0.902 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.626 ;acc: 0.590 ;iou_acc: 0.685 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.524 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.702 ;acc: 0.600 ;iou_acc: 0.670 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 1.555 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:09\n",
      "batch: 200 ;B loss: 1.559 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:15\n",
      "batch: 250 ;B loss: 1.559 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:01:21\n",
      "\n",
      "*BTrain: False ;Test loss: 1.517 ;Test accuracy 0.649 ;IOU accuracy: 0.749 ;Time: 0:01:27\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.097 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.028 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.169 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.074 ;acc: 0.865 ;iou: 0.925 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.164 ;acc: 0.875 ;iou: 0.930 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.358 ;acc: 0.865 ;iou: 0.920 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.183 ;Train accuracy: 0.880 ;IOU accuracy: 0.916 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.495 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.420 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.756 ;acc: 0.615 ;iou_acc: 0.680 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.556 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.579 ;acc: 0.630 ;iou_acc: 0.780 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.539 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.480 ;Test accuracy 0.658 ;IOU accuracy: 0.757 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.118 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 0.913 ;acc: 0.930 ;iou: 0.940 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.184 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.115 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.134 ;acc: 0.870 ;iou: 0.900 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 0.966 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 1.107 ;Train accuracy: 0.896 ;IOU accuracy: 0.928 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.575 ;acc: 0.630 ;iou_acc: 0.730 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.427 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.625 ;acc: 0.595 ;iou_acc: 0.685 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.484 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.489 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.470 ;acc: 0.680 ;iou_acc: 0.730 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.451 ;Test accuracy 0.670 ;IOU accuracy: 0.765 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.028 ;acc: 0.925 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.049 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.053 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.160 ;acc: 0.880 ;iou: 0.905 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.089 ;acc: 0.895 ;iou: 0.955 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.193 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 1.044 ;Train accuracy: 0.909 ;IOU accuracy: 0.939 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.565 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.476 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.568 ;acc: 0.605 ;iou_acc: 0.675 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 1.413 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.488 ;acc: 0.665 ;iou_acc: 0.800 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.467 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 1.438 ;Test accuracy 0.678 ;IOU accuracy: 0.773 ;Time: 0:01:30\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 0.761 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.021 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.064 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 0.924 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.013 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 0.884 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.978 ;Train accuracy: 0.922 ;IOU accuracy: 0.947 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.489 ;acc: 0.640 ;iou_acc: 0.755 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.337 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:00:55\n",
      "batch: 100 ;B loss: 1.678 ;acc: 0.605 ;iou_acc: 0.680 ;time: 0:01:02\n",
      "batch: 150 ;B loss: 1.493 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:08\n",
      "batch: 200 ;B loss: 1.463 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:14\n",
      "batch: 250 ;B loss: 1.457 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:21\n",
      "\n",
      "*BTrain: False ;Test loss: 1.429 ;Test accuracy 0.682 ;IOU accuracy: 0.776 ;Time: 0:01:27\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 0.854 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 0.791 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 0.891 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 0.720 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 0.886 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 0.906 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.920 ;Train accuracy: 0.932 ;IOU accuracy: 0.954 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.536 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.373 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.675 ;acc: 0.605 ;iou_acc: 0.665 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 1.565 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.437 ;acc: 0.675 ;iou_acc: 0.815 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.530 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 1.459 ;Test accuracy 0.683 ;IOU accuracy: 0.777 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 0.837 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 0.908 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 0.909 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 0.889 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 0.740 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 0.800 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.871 ;Train accuracy: 0.941 ;IOU accuracy: 0.960 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.514 ;acc: 0.635 ;iou_acc: 0.755 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.459 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.558 ;acc: 0.610 ;iou_acc: 0.695 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.501 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.458 ;acc: 0.685 ;iou_acc: 0.815 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.447 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.423 ;Test accuracy 0.690 ;IOU accuracy: 0.784 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.737 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 0.834 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 1.100 ;acc: 0.925 ;iou: 0.935 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 0.862 ;acc: 0.945 ;iou: 0.950 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 0.845 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 0.906 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.820 ;Train accuracy: 0.950 ;IOU accuracy: 0.967 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.489 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.400 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.641 ;acc: 0.610 ;iou_acc: 0.685 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.563 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.521 ;acc: 0.655 ;iou_acc: 0.805 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.654 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:23\n",
      "\n",
      "*BTrain: False ;Test loss: 1.504 ;Test accuracy 0.683 ;IOU accuracy: 0.779 ;Time: 0:01:29\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.682 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.728 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.727 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 0.765 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 0.766 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.758 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:40\n",
      "\n",
      "*Training B: True ;B Train loss: 0.778 ;Train accuracy: 0.955 ;IOU accuracy: 0.970 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.586 ;acc: 0.620 ;iou_acc: 0.725 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.410 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.529 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 1.583 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.470 ;acc: 0.690 ;iou_acc: 0.845 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.718 ;acc: 0.640 ;iou_acc: 0.745 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 1.502 ;Test accuracy 0.687 ;IOU accuracy: 0.781 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.728 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.618 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.549 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.682 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.775 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.875 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.731 ;Train accuracy: 0.962 ;IOU accuracy: 0.975 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.544 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.519 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.589 ;acc: 0.645 ;iou_acc: 0.700 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.556 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.403 ;acc: 0.705 ;iou_acc: 0.840 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.531 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.461 ;Test accuracy 0.697 ;IOU accuracy: 0.789 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.800 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.545 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.656 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.697 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.625 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.744 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.690 ;Train accuracy: 0.967 ;IOU accuracy: 0.979 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.532 ;acc: 0.635 ;iou_acc: 0.750 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.508 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.606 ;acc: 0.625 ;iou_acc: 0.690 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.480 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.502 ;acc: 0.680 ;iou_acc: 0.810 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.678 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.496 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.501 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.531 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.573 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.607 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.495 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.622 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.654 ;Train accuracy: 0.970 ;IOU accuracy: 0.981 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.702 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.508 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.655 ;acc: 0.625 ;iou_acc: 0.690 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.618 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.475 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.751 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.511 ;Test accuracy 0.696 ;IOU accuracy: 0.789 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.560 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.697 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.746 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.726 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.493 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.512 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.615 ;Train accuracy: 0.975 ;IOU accuracy: 0.984 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.522 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.580 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.549 ;acc: 0.645 ;iou_acc: 0.705 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.577 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.456 ;acc: 0.685 ;iou_acc: 0.825 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.637 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.506 ;Test accuracy 0.700 ;IOU accuracy: 0.791 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.484 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.542 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.534 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.581 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.655 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.906 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.585 ;Train accuracy: 0.978 ;IOU accuracy: 0.985 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.647 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.690 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.596 ;acc: 0.690 ;iou_acc: 0.750 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.612 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.550 ;acc: 0.685 ;iou_acc: 0.815 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.710 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.588 ;Test accuracy 0.695 ;IOU accuracy: 0.787 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.511 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.521 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.494 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.415 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.503 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.679 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.539 ;Train accuracy: 0.982 ;IOU accuracy: 0.988 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.583 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.645 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.718 ;acc: 0.635 ;iou_acc: 0.695 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.671 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.508 ;acc: 0.715 ;iou_acc: 0.850 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.872 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.575 ;Test accuracy 0.699 ;IOU accuracy: 0.790 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.368 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.554 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.629 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.541 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.447 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.431 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.509 ;Train accuracy: 0.984 ;IOU accuracy: 0.989 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.492 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.512 ;acc: 0.730 ;iou_acc: 0.825 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.546 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.725 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.647 ;acc: 0.680 ;iou_acc: 0.815 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.733 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.571 ;Test accuracy 0.701 ;IOU accuracy: 0.794 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.414 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.462 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.423 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.661 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.319 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.511 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.487 ;Train accuracy: 0.986 ;IOU accuracy: 0.991 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.786 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.662 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.788 ;acc: 0.630 ;iou_acc: 0.695 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.762 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.549 ;acc: 0.690 ;iou_acc: 0.825 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.918 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.658 ;Test accuracy 0.697 ;IOU accuracy: 0.790 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.408 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.421 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.357 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.448 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.513 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.509 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.458 ;Train accuracy: 0.988 ;IOU accuracy: 0.992 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.519 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.535 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.764 ;acc: 0.660 ;iou_acc: 0.720 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 1.662 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.526 ;acc: 0.715 ;iou_acc: 0.840 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.794 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.628 ;Test accuracy 0.702 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.389 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.279 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.469 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.497 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.444 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.387 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.421 ;Train accuracy: 0.990 ;IOU accuracy: 0.994 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.675 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.708 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.729 ;acc: 0.685 ;iou_acc: 0.735 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.783 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.681 ;acc: 0.715 ;iou_acc: 0.830 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.738 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.687 ;Test accuracy 0.703 ;IOU accuracy: 0.794 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.411 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.317 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.388 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.509 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.387 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.452 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.401 ;Train accuracy: 0.991 ;IOU accuracy: 0.994 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.793 ;acc: 0.640 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.667 ;acc: 0.750 ;iou_acc: 0.830 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.714 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.698 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.594 ;acc: 0.715 ;iou_acc: 0.855 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.981 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.688 ;Test accuracy 0.704 ;IOU accuracy: 0.795 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.380 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.301 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.402 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.505 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.416 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.351 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.370 ;Train accuracy: 0.992 ;IOU accuracy: 0.995 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.743 ;acc: 0.620 ;iou_acc: 0.735 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.863 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.816 ;acc: 0.685 ;iou_acc: 0.720 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.991 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.672 ;acc: 0.710 ;iou_acc: 0.845 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.950 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.745 ;Test accuracy 0.703 ;IOU accuracy: 0.794 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.340 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.334 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.437 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.406 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.317 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.309 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:40\n",
      "\n",
      "*Training B: False ;B Train loss: 0.355 ;Train accuracy: 0.994 ;IOU accuracy: 0.996 ;Time: 0:00:46 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.805 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:00:47\n",
      "batch: 50 ;B loss: 1.739 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:00:53\n",
      "batch: 100 ;B loss: 1.794 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:00:59\n",
      "batch: 150 ;B loss: 1.883 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:05\n",
      "batch: 200 ;B loss: 1.749 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:01:12\n",
      "batch: 250 ;B loss: 1.861 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "\n",
      "*BTrain: False ;Test loss: 1.727 ;Test accuracy 0.704 ;IOU accuracy: 0.795 ;Time: 0:01:24\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.179 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.421 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.221 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.431 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.276 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.337 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:38\n",
      "\n",
      "*Training B: False ;B Train loss: 0.331 ;Train accuracy: 0.995 ;IOU accuracy: 0.996 ;Time: 0:00:46 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.697 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:00:46\n",
      "batch: 50 ;B loss: 1.776 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:00:53\n",
      "batch: 100 ;B loss: 1.764 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:01:00\n",
      "batch: 150 ;B loss: 1.856 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:08\n",
      "batch: 200 ;B loss: 1.751 ;acc: 0.720 ;iou_acc: 0.835 ;time: 0:01:15\n",
      "batch: 250 ;B loss: 1.983 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:22\n",
      "\n",
      "*BTrain: False ;Test loss: 1.788 ;Test accuracy 0.702 ;IOU accuracy: 0.794 ;Time: 0:01:29\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.341 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.331 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.440 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.393 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.298 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.238 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.310 ;Train accuracy: 0.995 ;IOU accuracy: 0.997 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.882 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.756 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.780 ;acc: 0.700 ;iou_acc: 0.760 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.910 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.588 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.954 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.802 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.208 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.406 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.373 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.268 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.287 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.254 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.291 ;Train accuracy: 0.996 ;IOU accuracy: 0.997 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.898 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.813 ;acc: 0.750 ;iou_acc: 0.815 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.909 ;acc: 0.670 ;iou_acc: 0.720 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.015 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.788 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.989 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.861 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.295 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.263 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.198 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.217 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.191 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.209 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.275 ;Train accuracy: 0.996 ;IOU accuracy: 0.997 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.890 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.908 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.012 ;acc: 0.700 ;iou_acc: 0.760 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.120 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.749 ;acc: 0.725 ;iou_acc: 0.845 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.205 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.920 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.260 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.285 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.166 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.358 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.254 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.272 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.250 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.812 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.912 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.915 ;acc: 0.690 ;iou_acc: 0.740 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 2.017 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.821 ;acc: 0.725 ;iou_acc: 0.850 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.227 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 1.872 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.200 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.184 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.416 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.260 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.279 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.246 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.238 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 2.025 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.128 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.008 ;acc: 0.680 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.116 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.915 ;acc: 0.735 ;iou_acc: 0.840 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.383 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.018 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.239 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.121 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.161 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.170 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.209 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.239 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:40\n",
      "\n",
      "*Training B: False ;B Train loss: 0.226 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.875 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:00:48\n",
      "batch: 50 ;B loss: 1.987 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:00:55\n",
      "batch: 100 ;B loss: 1.895 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:01:02\n",
      "batch: 150 ;B loss: 2.113 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:09\n",
      "batch: 200 ;B loss: 1.700 ;acc: 0.730 ;iou_acc: 0.845 ;time: 0:01:16\n",
      "batch: 250 ;B loss: 2.259 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:23\n",
      "\n",
      "*BTrain: False ;Test loss: 1.926 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:01:30\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.142 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.302 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.242 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.144 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.200 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.181 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.203 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 2.040 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.035 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.290 ;acc: 0.670 ;iou_acc: 0.720 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.254 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.960 ;acc: 0.735 ;iou_acc: 0.840 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.346 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 2.077 ;Test accuracy 0.698 ;IOU accuracy: 0.789 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.305 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.138 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.146 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.201 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.239 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.235 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.207 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.911 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.991 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.164 ;acc: 0.690 ;iou_acc: 0.745 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.047 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.908 ;acc: 0.720 ;iou_acc: 0.840 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.330 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.989 ;Test accuracy 0.705 ;IOU accuracy: 0.795 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.144 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.187 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.225 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.173 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.106 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.152 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.173 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.976 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.042 ;acc: 0.740 ;iou_acc: 0.815 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.051 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.239 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.948 ;acc: 0.715 ;iou_acc: 0.835 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.334 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.036 ;Test accuracy 0.704 ;IOU accuracy: 0.795 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.169 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.086 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.197 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.201 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.136 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.159 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 2.283 ;acc: 0.655 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.178 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 2.190 ;acc: 0.690 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.433 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.985 ;acc: 0.695 ;iou_acc: 0.820 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.414 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 2.188 ;Test accuracy 0.695 ;IOU accuracy: 0.787 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.234 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.139 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.108 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.143 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.141 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.148 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.994 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.115 ;acc: 0.740 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.198 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.236 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.957 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.297 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.085 ;Test accuracy 0.702 ;IOU accuracy: 0.793 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.199 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.084 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.109 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.153 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.137 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.091 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.142 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 2.266 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.971 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.181 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.410 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.900 ;acc: 0.725 ;iou_acc: 0.835 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.220 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.166 ;Test accuracy 0.697 ;IOU accuracy: 0.788 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.094 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.102 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.068 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.135 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.134 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.116 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.127 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 2.300 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.120 ;acc: 0.720 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.014 ;acc: 0.700 ;iou_acc: 0.755 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.236 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.978 ;acc: 0.735 ;iou_acc: 0.845 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.230 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 2.124 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.088 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.144 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.117 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.098 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.074 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.135 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.120 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 2.221 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.168 ;acc: 0.735 ;iou_acc: 0.810 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.990 ;acc: 0.695 ;iou_acc: 0.750 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 2.445 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 2.071 ;acc: 0.720 ;iou_acc: 0.835 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.389 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 2.178 ;Test accuracy 0.702 ;IOU accuracy: 0.794 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.061 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.116 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.084 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.080 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.141 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.118 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 2.264 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.198 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.147 ;acc: 0.705 ;iou_acc: 0.770 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.247 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.992 ;acc: 0.745 ;iou_acc: 0.860 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.304 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.176 ;Test accuracy 0.706 ;IOU accuracy: 0.797 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.103 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.071 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.039 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.109 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.119 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.084 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.102 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 2.128 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 2.175 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 2.169 ;acc: 0.695 ;iou_acc: 0.755 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 2.543 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 2.354 ;acc: 0.695 ;iou_acc: 0.820 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.274 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 2.300 ;Test accuracy 0.696 ;IOU accuracy: 0.789 ;Time: 0:01:30\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.125 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.063 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.221 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.087 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.094 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.106 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.102 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 2.140 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.336 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.045 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.382 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.203 ;acc: 0.760 ;iou_acc: 0.870 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.490 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.258 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.091 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.049 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.082 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.096 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.124 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.155 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:40\n",
      "\n",
      "*Training B: False ;B Train loss: 0.095 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 2.122 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:00:48\n",
      "batch: 50 ;B loss: 2.226 ;acc: 0.740 ;iou_acc: 0.825 ;time: 0:00:55\n",
      "batch: 100 ;B loss: 2.136 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:02\n",
      "batch: 150 ;B loss: 2.530 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:09\n",
      "batch: 200 ;B loss: 2.165 ;acc: 0.725 ;iou_acc: 0.855 ;time: 0:01:16\n",
      "batch: 250 ;B loss: 2.547 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:22\n",
      "\n",
      "*BTrain: False ;Test loss: 2.252 ;Test accuracy 0.704 ;IOU accuracy: 0.795 ;Time: 0:01:29\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.070 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.077 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.069 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.081 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.115 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.064 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.092 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.990 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.247 ;acc: 0.735 ;iou_acc: 0.810 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.279 ;acc: 0.705 ;iou_acc: 0.755 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.575 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.121 ;acc: 0.710 ;iou_acc: 0.835 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.356 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 2.289 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.078 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.113 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.087 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.043 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.154 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.086 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 2.275 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.242 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.134 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 2.599 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 2.057 ;acc: 0.725 ;iou_acc: 0.840 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.584 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 2.298 ;Test accuracy 0.705 ;IOU accuracy: 0.797 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/hidden:150\n",
      "num_hidden: 150\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.947 ;acc: 0.395 ;iou: 0.475 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.762 ;acc: 0.315 ;iou: 0.430 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.640 ;acc: 0.345 ;iou: 0.470 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.585 ;acc: 0.400 ;iou: 0.480 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.483 ;acc: 0.425 ;iou: 0.515 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.293 ;acc: 0.515 ;iou: 0.585 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 2.585 ;Train accuracy: 0.381 ;IOU accuracy: 0.476 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.382 ;acc: 0.385 ;iou_acc: 0.475 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.523 ;acc: 0.290 ;iou_acc: 0.390 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.459 ;acc: 0.360 ;iou_acc: 0.430 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.456 ;acc: 0.335 ;iou_acc: 0.450 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.400 ;acc: 0.360 ;iou_acc: 0.470 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.436 ;acc: 0.345 ;iou_acc: 0.490 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 2.381 ;Test accuracy 0.362 ;IOU accuracy: 0.477 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.372 ;acc: 0.455 ;iou: 0.540 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.260 ;acc: 0.545 ;iou: 0.655 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.127 ;acc: 0.610 ;iou: 0.680 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.098 ;acc: 0.590 ;iou: 0.660 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.090 ;acc: 0.605 ;iou: 0.685 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.120 ;acc: 0.550 ;iou: 0.670 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 2.208 ;Train accuracy: 0.536 ;IOU accuracy: 0.622 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.160 ;acc: 0.450 ;iou_acc: 0.560 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.175 ;acc: 0.440 ;iou_acc: 0.520 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.248 ;acc: 0.445 ;iou_acc: 0.515 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.207 ;acc: 0.445 ;iou_acc: 0.530 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.202 ;acc: 0.420 ;iou_acc: 0.565 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.147 ;acc: 0.465 ;iou_acc: 0.575 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.116 ;Test accuracy 0.462 ;IOU accuracy: 0.566 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 1.930 ;acc: 0.620 ;iou: 0.715 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.059 ;acc: 0.605 ;iou: 0.695 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.021 ;acc: 0.640 ;iou: 0.705 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 1.977 ;acc: 0.620 ;iou: 0.690 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 1.839 ;acc: 0.675 ;iou: 0.755 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.091 ;acc: 0.595 ;iou: 0.650 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.957 ;Train accuracy: 0.625 ;IOU accuracy: 0.703 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.006 ;acc: 0.480 ;iou_acc: 0.590 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.976 ;acc: 0.520 ;iou_acc: 0.585 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.115 ;acc: 0.445 ;iou_acc: 0.550 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.989 ;acc: 0.535 ;iou_acc: 0.640 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.988 ;acc: 0.485 ;iou_acc: 0.595 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.966 ;acc: 0.535 ;iou_acc: 0.620 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.933 ;Test accuracy 0.517 ;IOU accuracy: 0.619 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.630 ;acc: 0.780 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.792 ;acc: 0.655 ;iou: 0.715 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.939 ;acc: 0.670 ;iou: 0.740 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.797 ;acc: 0.665 ;iou: 0.745 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.853 ;acc: 0.690 ;iou: 0.780 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 2.009 ;acc: 0.640 ;iou: 0.730 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 1.783 ;Train accuracy: 0.695 ;IOU accuracy: 0.762 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.840 ;acc: 0.515 ;iou_acc: 0.600 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.879 ;acc: 0.525 ;iou_acc: 0.605 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.982 ;acc: 0.495 ;iou_acc: 0.580 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.868 ;acc: 0.520 ;iou_acc: 0.630 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.817 ;acc: 0.565 ;iou_acc: 0.690 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.858 ;acc: 0.570 ;iou_acc: 0.650 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.811 ;Test accuracy 0.554 ;IOU accuracy: 0.654 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.666 ;acc: 0.735 ;iou: 0.800 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.781 ;acc: 0.690 ;iou: 0.770 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.752 ;acc: 0.710 ;iou: 0.795 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.708 ;acc: 0.700 ;iou: 0.785 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.731 ;acc: 0.770 ;iou: 0.805 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.643 ;acc: 0.755 ;iou: 0.815 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.604 ;Train accuracy: 0.767 ;IOU accuracy: 0.825 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.803 ;acc: 0.590 ;iou_acc: 0.660 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.768 ;acc: 0.570 ;iou_acc: 0.655 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.966 ;acc: 0.505 ;iou_acc: 0.610 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 1.694 ;acc: 0.580 ;iou_acc: 0.695 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.729 ;acc: 0.610 ;iou_acc: 0.725 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.744 ;acc: 0.645 ;iou_acc: 0.730 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 1.699 ;Test accuracy 0.596 ;IOU accuracy: 0.699 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.549 ;acc: 0.810 ;iou: 0.855 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.288 ;acc: 0.850 ;iou: 0.925 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.273 ;acc: 0.845 ;iou: 0.875 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.498 ;acc: 0.790 ;iou: 0.845 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.355 ;acc: 0.840 ;iou: 0.890 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.511 ;acc: 0.810 ;iou: 0.870 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.429 ;Train accuracy: 0.826 ;IOU accuracy: 0.876 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.711 ;acc: 0.605 ;iou_acc: 0.710 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.572 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.829 ;acc: 0.535 ;iou_acc: 0.635 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.615 ;acc: 0.620 ;iou_acc: 0.735 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.595 ;acc: 0.630 ;iou_acc: 0.745 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.627 ;acc: 0.640 ;iou_acc: 0.750 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.587 ;Test accuracy 0.628 ;IOU accuracy: 0.731 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.241 ;acc: 0.850 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.118 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.420 ;acc: 0.820 ;iou: 0.865 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.361 ;acc: 0.855 ;iou: 0.915 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.251 ;acc: 0.875 ;iou: 0.905 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.158 ;acc: 0.875 ;iou: 0.910 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 1.294 ;Train accuracy: 0.859 ;IOU accuracy: 0.902 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.617 ;acc: 0.605 ;iou_acc: 0.690 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.532 ;acc: 0.620 ;iou_acc: 0.725 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.697 ;acc: 0.590 ;iou_acc: 0.670 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.538 ;acc: 0.645 ;iou_acc: 0.730 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.545 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.632 ;acc: 0.635 ;iou_acc: 0.750 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.533 ;Test accuracy 0.644 ;IOU accuracy: 0.743 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.148 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.178 ;acc: 0.895 ;iou: 0.950 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.101 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.317 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.326 ;acc: 0.845 ;iou: 0.890 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.416 ;acc: 0.865 ;iou: 0.895 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.190 ;Train accuracy: 0.884 ;IOU accuracy: 0.920 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.661 ;acc: 0.580 ;iou_acc: 0.700 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.503 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.637 ;acc: 0.625 ;iou_acc: 0.695 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.502 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.512 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.593 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.489 ;Test accuracy 0.659 ;IOU accuracy: 0.756 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.043 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.114 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.342 ;acc: 0.875 ;iou: 0.895 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.215 ;acc: 0.885 ;iou: 0.920 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.053 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.093 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 1.104 ;Train accuracy: 0.903 ;IOU accuracy: 0.932 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.603 ;acc: 0.620 ;iou_acc: 0.710 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.463 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.658 ;acc: 0.600 ;iou_acc: 0.695 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.466 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.467 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.606 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.467 ;Test accuracy 0.665 ;IOU accuracy: 0.762 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.059 ;acc: 0.905 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 0.969 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.052 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 0.852 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.081 ;acc: 0.905 ;iou: 0.950 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.164 ;acc: 0.885 ;iou: 0.930 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 1.036 ;Train accuracy: 0.916 ;IOU accuracy: 0.942 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.562 ;acc: 0.605 ;iou_acc: 0.700 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.400 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.632 ;acc: 0.605 ;iou_acc: 0.680 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.422 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.467 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.633 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.449 ;Test accuracy 0.674 ;IOU accuracy: 0.769 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.018 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 0.860 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.065 ;acc: 0.915 ;iou: 0.915 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 0.838 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.059 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 0.875 ;acc: 0.940 ;iou: 0.980 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.961 ;Train accuracy: 0.929 ;IOU accuracy: 0.951 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.508 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.443 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.693 ;acc: 0.605 ;iou_acc: 0.695 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.503 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.451 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.614 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.450 ;Test accuracy 0.678 ;IOU accuracy: 0.774 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 0.984 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 0.908 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 0.879 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 0.904 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 0.942 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 0.991 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.903 ;Train accuracy: 0.940 ;IOU accuracy: 0.959 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.471 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.367 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.643 ;acc: 0.630 ;iou_acc: 0.710 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.351 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.430 ;acc: 0.650 ;iou_acc: 0.775 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.544 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.435 ;Test accuracy 0.685 ;IOU accuracy: 0.779 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 0.894 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 0.691 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 0.775 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 0.854 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 0.850 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 0.862 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.847 ;Train accuracy: 0.949 ;IOU accuracy: 0.966 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.442 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.414 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.523 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.434 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.527 ;acc: 0.640 ;iou_acc: 0.755 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.554 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.439 ;Test accuracy 0.689 ;IOU accuracy: 0.783 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 0.792 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 0.748 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 0.869 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 0.751 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 0.864 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 0.793 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.794 ;Train accuracy: 0.956 ;IOU accuracy: 0.971 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.480 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.448 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.633 ;acc: 0.630 ;iou_acc: 0.725 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.446 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.522 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.643 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.466 ;Test accuracy 0.688 ;IOU accuracy: 0.782 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.570 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 0.724 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.738 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 0.948 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 0.679 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.741 ;Train accuracy: 0.963 ;IOU accuracy: 0.975 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.505 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.473 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.569 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.452 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.437 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.684 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.463 ;Test accuracy 0.691 ;IOU accuracy: 0.785 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.782 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.647 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.560 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 0.610 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 0.814 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.679 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.691 ;Train accuracy: 0.969 ;IOU accuracy: 0.979 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.591 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.562 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.563 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.576 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.517 ;acc: 0.650 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.596 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.494 ;Test accuracy 0.693 ;IOU accuracy: 0.787 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.735 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.544 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.792 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.652 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.593 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.740 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.643 ;Train accuracy: 0.974 ;IOU accuracy: 0.983 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.591 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.452 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.557 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.528 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.607 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.744 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.518 ;Test accuracy 0.693 ;IOU accuracy: 0.786 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.611 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.697 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.613 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.637 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.657 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.716 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.601 ;Train accuracy: 0.979 ;IOU accuracy: 0.986 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.663 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.536 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.727 ;acc: 0.625 ;iou_acc: 0.715 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.503 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.772 ;acc: 0.645 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.736 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.565 ;Test accuracy 0.695 ;IOU accuracy: 0.789 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.357 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.453 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.510 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.507 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.535 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.657 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.561 ;Train accuracy: 0.982 ;IOU accuracy: 0.989 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.604 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.428 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.623 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.476 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.584 ;acc: 0.665 ;iou_acc: 0.800 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.766 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.553 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.535 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.450 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.483 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.585 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.557 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.449 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.516 ;Train accuracy: 0.985 ;IOU accuracy: 0.990 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.596 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.536 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.702 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.672 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.681 ;acc: 0.705 ;iou_acc: 0.850 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.851 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.576 ;Test accuracy 0.700 ;IOU accuracy: 0.793 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.379 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.415 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.451 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.604 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.549 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.416 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.482 ;Train accuracy: 0.987 ;IOU accuracy: 0.991 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.597 ;acc: 0.690 ;iou_acc: 0.750 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.474 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.619 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.589 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.746 ;acc: 0.675 ;iou_acc: 0.815 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.787 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.593 ;Test accuracy 0.701 ;IOU accuracy: 0.794 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.395 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.431 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.360 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.564 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.436 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.397 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.452 ;Train accuracy: 0.989 ;IOU accuracy: 0.993 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.674 ;acc: 0.695 ;iou_acc: 0.750 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.534 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.570 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.736 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.849 ;acc: 0.640 ;iou_acc: 0.790 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.836 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.658 ;Test accuracy 0.697 ;IOU accuracy: 0.789 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.422 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.320 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.444 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.377 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.539 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.479 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.417 ;Train accuracy: 0.991 ;IOU accuracy: 0.994 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.633 ;acc: 0.705 ;iou_acc: 0.770 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.509 ;acc: 0.740 ;iou_acc: 0.805 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.620 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.583 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.812 ;acc: 0.655 ;iou_acc: 0.800 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.839 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.635 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.358 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.436 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.324 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.443 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.556 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.353 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.390 ;Train accuracy: 0.992 ;IOU accuracy: 0.995 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.691 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.521 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.637 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.695 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.870 ;acc: 0.665 ;iou_acc: 0.815 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.785 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.662 ;Test accuracy 0.701 ;IOU accuracy: 0.794 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.347 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.283 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.396 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.335 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.342 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.434 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.356 ;Train accuracy: 0.994 ;IOU accuracy: 0.996 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.676 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.658 ;acc: 0.730 ;iou_acc: 0.790 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.838 ;acc: 0.640 ;iou_acc: 0.720 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.619 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.034 ;acc: 0.635 ;iou_acc: 0.800 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.837 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:27\n",
      "\n",
      "*BTrain: True ;Test loss: 1.716 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.287 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.299 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.285 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.299 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.401 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.469 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.328 ;Train accuracy: 0.995 ;IOU accuracy: 0.997 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.732 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.737 ;acc: 0.750 ;iou_acc: 0.815 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.843 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.741 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.993 ;acc: 0.645 ;iou_acc: 0.805 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.956 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.807 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.251 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.295 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.239 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.310 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.250 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.340 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.302 ;Train accuracy: 0.995 ;IOU accuracy: 0.997 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.732 ;acc: 0.685 ;iou_acc: 0.745 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.519 ;acc: 0.750 ;iou_acc: 0.805 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.626 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.755 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.921 ;acc: 0.660 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.992 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.775 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.264 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.325 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.248 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.264 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.233 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.296 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.287 ;Train accuracy: 0.996 ;IOU accuracy: 0.998 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.863 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.795 ;acc: 0.700 ;iou_acc: 0.760 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.850 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.743 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.999 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.029 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.854 ;Test accuracy 0.696 ;IOU accuracy: 0.788 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.343 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.281 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.226 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.349 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.427 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.384 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.271 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.745 ;acc: 0.695 ;iou_acc: 0.750 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.813 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.999 ;acc: 0.630 ;iou_acc: 0.705 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.694 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.047 ;acc: 0.685 ;iou_acc: 0.820 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.001 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.862 ;Test accuracy 0.699 ;IOU accuracy: 0.793 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.235 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.212 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.250 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.202 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.194 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.265 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.246 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.949 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.826 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.040 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.788 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.059 ;acc: 0.660 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.988 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.917 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.197 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.265 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.129 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.289 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.222 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.231 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.218 ;Train accuracy: 0.998 ;IOU accuracy: 0.998 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.763 ;acc: 0.725 ;iou_acc: 0.785 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.663 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.846 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.933 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.972 ;acc: 0.690 ;iou_acc: 0.835 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.031 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.888 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.206 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.300 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.236 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.124 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.197 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.279 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.194 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.890 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.807 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.901 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.827 ;acc: 0.740 ;iou_acc: 0.815 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.099 ;acc: 0.675 ;iou_acc: 0.815 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.046 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.956 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.153 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.129 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.171 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.135 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.177 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.190 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.183 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.891 ;acc: 0.705 ;iou_acc: 0.755 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.956 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.246 ;acc: 0.630 ;iou_acc: 0.690 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.933 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 2.283 ;acc: 0.665 ;iou_acc: 0.815 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 2.193 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 2.020 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.133 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.135 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.138 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.105 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.139 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.234 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.164 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.986 ;acc: 0.715 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.883 ;acc: 0.720 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.066 ;acc: 0.635 ;iou_acc: 0.710 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.975 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.253 ;acc: 0.665 ;iou_acc: 0.820 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.961 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 2.020 ;Test accuracy 0.702 ;IOU accuracy: 0.793 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.110 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.138 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.147 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.323 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.179 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.156 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.151 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.953 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.885 ;acc: 0.735 ;iou_acc: 0.795 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.098 ;acc: 0.645 ;iou_acc: 0.720 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.005 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.328 ;acc: 0.680 ;iou_acc: 0.815 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.153 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.044 ;Test accuracy 0.702 ;IOU accuracy: 0.794 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.062 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.112 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.137 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.177 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.142 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.134 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 2.227 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 2.126 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.084 ;acc: 0.640 ;iou_acc: 0.725 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.999 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.145 ;acc: 0.700 ;iou_acc: 0.840 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.160 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.139 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.120 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.171 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.093 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.085 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.120 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.116 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.126 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 2.179 ;acc: 0.695 ;iou_acc: 0.755 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.009 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.291 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.944 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.306 ;acc: 0.680 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.258 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 2.153 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.075 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.115 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.113 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.121 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.084 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.096 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.121 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 2.079 ;acc: 0.710 ;iou_acc: 0.765 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 2.043 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 2.218 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 2.080 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 2.355 ;acc: 0.700 ;iou_acc: 0.845 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.220 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "\n",
      "*BTrain: False ;Test loss: 2.143 ;Test accuracy 0.702 ;IOU accuracy: 0.795 ;Time: 0:01:30\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.113 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.110 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.050 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.088 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.088 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.126 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.113 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.960 ;acc: 0.705 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.016 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.114 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.071 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.387 ;acc: 0.695 ;iou_acc: 0.825 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.300 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.147 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.064 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.100 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.047 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.066 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.127 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.095 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 2.174 ;acc: 0.690 ;iou_acc: 0.750 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.160 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 2.234 ;acc: 0.640 ;iou_acc: 0.705 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 1.979 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 2.559 ;acc: 0.665 ;iou_acc: 0.800 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.180 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 2.198 ;Test accuracy 0.700 ;IOU accuracy: 0.793 ;Time: 0:01:30\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.076 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.059 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.159 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.054 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.058 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.113 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.082 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.952 ;acc: 0.705 ;iou_acc: 0.745 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.081 ;acc: 0.735 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.347 ;acc: 0.625 ;iou_acc: 0.705 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.176 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.613 ;acc: 0.665 ;iou_acc: 0.810 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.416 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.246 ;Test accuracy 0.702 ;IOU accuracy: 0.794 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.036 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.074 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.048 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.075 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.035 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.051 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.081 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 2.116 ;acc: 0.695 ;iou_acc: 0.750 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.204 ;acc: 0.750 ;iou_acc: 0.805 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.309 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.042 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.569 ;acc: 0.675 ;iou_acc: 0.810 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.348 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.252 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.034 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.063 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.052 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.080 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.043 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.072 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.074 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.984 ;acc: 0.700 ;iou_acc: 0.750 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.000 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.397 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.128 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.491 ;acc: 0.695 ;iou_acc: 0.830 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.300 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 2.249 ;Test accuracy 0.702 ;IOU accuracy: 0.794 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.039 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.086 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.102 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.063 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.071 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.075 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.066 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 2.047 ;acc: 0.695 ;iou_acc: 0.745 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.087 ;acc: 0.735 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.582 ;acc: 0.630 ;iou_acc: 0.685 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.059 ;acc: 0.745 ;iou_acc: 0.835 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.663 ;acc: 0.665 ;iou_acc: 0.815 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.409 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.306 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.055 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.049 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.034 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.062 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.039 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.028 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.058 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 2.065 ;acc: 0.705 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.046 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.359 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.310 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.611 ;acc: 0.685 ;iou_acc: 0.820 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.500 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.300 ;Test accuracy 0.702 ;IOU accuracy: 0.793 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.116 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.033 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.062 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.045 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.057 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.068 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.051 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 2.265 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.165 ;acc: 0.730 ;iou_acc: 0.795 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.481 ;acc: 0.655 ;iou_acc: 0.710 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.142 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.839 ;acc: 0.675 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.609 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 2.377 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.053 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.021 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.049 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.086 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.023 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.094 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.053 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 2.114 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.308 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.479 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.282 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.649 ;acc: 0.695 ;iou_acc: 0.835 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.557 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.348 ;Test accuracy 0.702 ;IOU accuracy: 0.796 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.056 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.023 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.016 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.046 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.032 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.060 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.048 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 2.292 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.232 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.596 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.194 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.782 ;acc: 0.670 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.645 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.414 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.183 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.032 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.021 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.064 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.047 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.116 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.095 ;Train accuracy: 0.998 ;IOU accuracy: 0.998 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.987 ;acc: 0.730 ;iou_acc: 0.780 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.233 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.497 ;acc: 0.645 ;iou_acc: 0.710 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.375 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.561 ;acc: 0.675 ;iou_acc: 0.810 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.456 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 2.326 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.040 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.083 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.051 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.070 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.044 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.104 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.068 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 2.244 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.210 ;acc: 0.730 ;iou_acc: 0.795 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 2.415 ;acc: 0.690 ;iou_acc: 0.750 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 2.133 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 2.650 ;acc: 0.705 ;iou_acc: 0.830 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.635 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 2.388 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.987 ;acc: 0.385 ;iou: 0.500 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.767 ;acc: 0.315 ;iou: 0.430 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.674 ;acc: 0.335 ;iou: 0.430 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.430 ;acc: 0.430 ;iou: 0.525 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.321 ;acc: 0.485 ;iou: 0.570 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.442 ;acc: 0.445 ;iou: 0.555 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 2.550 ;Train accuracy: 0.413 ;IOU accuracy: 0.509 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.415 ;acc: 0.330 ;iou_acc: 0.465 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.473 ;acc: 0.315 ;iou_acc: 0.410 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.523 ;acc: 0.315 ;iou_acc: 0.405 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.354 ;acc: 0.405 ;iou_acc: 0.495 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.384 ;acc: 0.370 ;iou_acc: 0.460 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.321 ;acc: 0.415 ;iou_acc: 0.535 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 2.347 ;Test accuracy 0.377 ;IOU accuracy: 0.489 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.324 ;acc: 0.510 ;iou: 0.595 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.181 ;acc: 0.560 ;iou: 0.600 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 1.987 ;acc: 0.615 ;iou: 0.680 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.226 ;acc: 0.585 ;iou: 0.635 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.065 ;acc: 0.565 ;iou: 0.615 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.126 ;acc: 0.560 ;iou: 0.680 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 2.172 ;Train accuracy: 0.558 ;IOU accuracy: 0.642 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.244 ;acc: 0.410 ;iou_acc: 0.540 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.167 ;acc: 0.465 ;iou_acc: 0.550 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.261 ;acc: 0.390 ;iou_acc: 0.480 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.158 ;acc: 0.445 ;iou_acc: 0.550 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.178 ;acc: 0.435 ;iou_acc: 0.555 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.056 ;acc: 0.535 ;iou_acc: 0.645 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.099 ;Test accuracy 0.468 ;IOU accuracy: 0.570 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.077 ;acc: 0.625 ;iou: 0.675 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.074 ;acc: 0.595 ;iou: 0.655 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 1.871 ;acc: 0.645 ;iou: 0.710 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.053 ;acc: 0.625 ;iou: 0.705 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 1.875 ;acc: 0.680 ;iou: 0.760 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.028 ;acc: 0.645 ;iou: 0.725 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 1.925 ;Train accuracy: 0.644 ;IOU accuracy: 0.716 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 1.997 ;acc: 0.515 ;iou_acc: 0.605 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.931 ;acc: 0.535 ;iou_acc: 0.600 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.148 ;acc: 0.440 ;iou_acc: 0.505 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.999 ;acc: 0.495 ;iou_acc: 0.605 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 2.033 ;acc: 0.485 ;iou_acc: 0.625 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.920 ;acc: 0.550 ;iou_acc: 0.645 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 1.924 ;Test accuracy 0.518 ;IOU accuracy: 0.621 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.804 ;acc: 0.645 ;iou: 0.715 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.915 ;acc: 0.675 ;iou: 0.735 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.734 ;acc: 0.705 ;iou: 0.765 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.686 ;acc: 0.720 ;iou: 0.795 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.780 ;acc: 0.705 ;iou: 0.775 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.871 ;acc: 0.715 ;iou: 0.785 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 1.742 ;Train accuracy: 0.715 ;IOU accuracy: 0.778 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.864 ;acc: 0.560 ;iou_acc: 0.655 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.838 ;acc: 0.570 ;iou_acc: 0.635 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 2.027 ;acc: 0.480 ;iou_acc: 0.580 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.857 ;acc: 0.545 ;iou_acc: 0.635 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.877 ;acc: 0.530 ;iou_acc: 0.645 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.773 ;acc: 0.595 ;iou_acc: 0.700 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.806 ;Test accuracy 0.558 ;IOU accuracy: 0.655 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.659 ;acc: 0.750 ;iou: 0.800 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.481 ;acc: 0.795 ;iou: 0.860 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.373 ;acc: 0.840 ;iou: 0.865 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.594 ;acc: 0.770 ;iou: 0.825 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.471 ;acc: 0.820 ;iou: 0.885 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.637 ;acc: 0.795 ;iou: 0.845 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.561 ;Train accuracy: 0.786 ;IOU accuracy: 0.841 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.766 ;acc: 0.565 ;iou_acc: 0.670 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.686 ;acc: 0.575 ;iou_acc: 0.670 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.959 ;acc: 0.540 ;iou_acc: 0.645 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.744 ;acc: 0.590 ;iou_acc: 0.710 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.758 ;acc: 0.575 ;iou_acc: 0.675 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.711 ;acc: 0.615 ;iou_acc: 0.740 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.715 ;Test accuracy 0.590 ;IOU accuracy: 0.690 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.386 ;acc: 0.855 ;iou: 0.895 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.386 ;acc: 0.855 ;iou: 0.890 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.500 ;acc: 0.835 ;iou: 0.895 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.477 ;acc: 0.845 ;iou: 0.920 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.500 ;acc: 0.815 ;iou: 0.860 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.466 ;acc: 0.870 ;iou: 0.880 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.395 ;Train accuracy: 0.841 ;IOU accuracy: 0.886 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.629 ;acc: 0.590 ;iou_acc: 0.710 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.559 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.842 ;acc: 0.550 ;iou_acc: 0.650 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.635 ;acc: 0.635 ;iou_acc: 0.725 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.569 ;acc: 0.630 ;iou_acc: 0.750 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.572 ;acc: 0.630 ;iou_acc: 0.725 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.583 ;Test accuracy 0.628 ;IOU accuracy: 0.728 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.097 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.179 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.281 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.251 ;acc: 0.840 ;iou: 0.890 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.263 ;acc: 0.865 ;iou: 0.900 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.469 ;acc: 0.870 ;iou: 0.915 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 1.252 ;Train accuracy: 0.875 ;IOU accuracy: 0.913 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.579 ;acc: 0.585 ;iou_acc: 0.665 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.446 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.736 ;acc: 0.600 ;iou_acc: 0.700 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.526 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.458 ;acc: 0.650 ;iou_acc: 0.740 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.573 ;acc: 0.645 ;iou_acc: 0.775 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.500 ;Test accuracy 0.652 ;IOU accuracy: 0.752 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 0.813 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.215 ;acc: 0.870 ;iou: 0.900 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.067 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.081 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.186 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.038 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.140 ;Train accuracy: 0.899 ;IOU accuracy: 0.930 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.487 ;acc: 0.605 ;iou_acc: 0.740 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.444 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.655 ;acc: 0.590 ;iou_acc: 0.680 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.540 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.514 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.584 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.472 ;Test accuracy 0.661 ;IOU accuracy: 0.758 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 0.977 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 0.988 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 0.945 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.091 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.170 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.108 ;acc: 0.890 ;iou: 0.920 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.052 ;Train accuracy: 0.917 ;IOU accuracy: 0.943 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.577 ;acc: 0.640 ;iou_acc: 0.755 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.444 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.633 ;acc: 0.595 ;iou_acc: 0.690 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.598 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.438 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.516 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.466 ;Test accuracy 0.669 ;IOU accuracy: 0.766 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 0.972 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 0.869 ;acc: 0.935 ;iou: 0.940 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.071 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 0.774 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 0.872 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 0.994 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.970 ;Train accuracy: 0.933 ;IOU accuracy: 0.954 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.523 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.416 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.762 ;acc: 0.615 ;iou_acc: 0.690 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.557 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.538 ;acc: 0.645 ;iou_acc: 0.755 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.535 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.478 ;Test accuracy 0.671 ;IOU accuracy: 0.767 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 0.838 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 0.798 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 0.727 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 0.855 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 0.981 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 0.850 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.896 ;Train accuracy: 0.945 ;IOU accuracy: 0.963 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.531 ;acc: 0.645 ;iou_acc: 0.740 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.479 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.626 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.417 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.382 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.510 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.430 ;Test accuracy 0.685 ;IOU accuracy: 0.781 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 0.892 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 0.689 ;acc: 0.965 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 0.863 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 0.749 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.029 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 0.761 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.832 ;Train accuracy: 0.955 ;IOU accuracy: 0.970 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.529 ;acc: 0.630 ;iou_acc: 0.725 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.506 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.670 ;acc: 0.620 ;iou_acc: 0.700 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.516 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.449 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.576 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.457 ;Test accuracy 0.686 ;IOU accuracy: 0.780 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 0.814 ;acc: 0.955 ;iou: 0.985 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 0.663 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 0.653 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 0.794 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 0.800 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 1.023 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.767 ;Train accuracy: 0.964 ;IOU accuracy: 0.976 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.637 ;acc: 0.615 ;iou_acc: 0.735 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.496 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.684 ;acc: 0.635 ;iou_acc: 0.705 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.565 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.611 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.590 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.481 ;Test accuracy 0.687 ;IOU accuracy: 0.781 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 0.607 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 0.533 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 0.767 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 0.739 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 0.632 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 0.671 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.712 ;Train accuracy: 0.970 ;IOU accuracy: 0.980 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.596 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.512 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.663 ;acc: 0.645 ;iou_acc: 0.705 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.595 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.498 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.566 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.481 ;Test accuracy 0.689 ;IOU accuracy: 0.783 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.567 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 0.640 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.568 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 0.810 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 0.764 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 0.643 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.655 ;Train accuracy: 0.976 ;IOU accuracy: 0.983 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.542 ;acc: 0.675 ;iou_acc: 0.730 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.576 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.651 ;acc: 0.645 ;iou_acc: 0.710 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.704 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.516 ;acc: 0.670 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.628 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.506 ;Test accuracy 0.691 ;IOU accuracy: 0.785 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.586 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.655 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.563 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 0.620 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 0.550 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.582 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.603 ;Train accuracy: 0.981 ;IOU accuracy: 0.988 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.698 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.615 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.608 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.604 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.509 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.593 ;acc: 0.675 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.532 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.416 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.481 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.524 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.427 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.568 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.643 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.552 ;Train accuracy: 0.985 ;IOU accuracy: 0.990 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.617 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.713 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.781 ;acc: 0.675 ;iou_acc: 0.720 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.664 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.709 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.757 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 1.595 ;Test accuracy 0.692 ;IOU accuracy: 0.784 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.529 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.401 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.487 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.561 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.434 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.814 ;acc: 0.945 ;iou: 0.945 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.505 ;Train accuracy: 0.987 ;IOU accuracy: 0.991 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.704 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.692 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.882 ;acc: 0.625 ;iou_acc: 0.700 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.648 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.531 ;acc: 0.705 ;iou_acc: 0.815 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.798 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.631 ;Test accuracy 0.691 ;IOU accuracy: 0.784 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.326 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.473 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.644 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.414 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.451 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.425 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.464 ;Train accuracy: 0.989 ;IOU accuracy: 0.993 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.936 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.661 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.871 ;acc: 0.670 ;iou_acc: 0.720 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.762 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.582 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.872 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:27\n",
      "\n",
      "*BTrain: True ;Test loss: 1.615 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.376 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.320 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.424 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.364 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.534 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.342 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.433 ;Train accuracy: 0.992 ;IOU accuracy: 0.995 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.749 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.746 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.028 ;acc: 0.655 ;iou_acc: 0.710 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.727 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.546 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.775 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.662 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.539 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.465 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.382 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.382 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.415 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.562 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.389 ;Train accuracy: 0.994 ;IOU accuracy: 0.996 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.866 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.673 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.833 ;acc: 0.670 ;iou_acc: 0.730 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.819 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.561 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.712 ;acc: 0.695 ;iou_acc: 0.815 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.668 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.389 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.357 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.271 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.425 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.314 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.443 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.346 ;Train accuracy: 0.995 ;IOU accuracy: 0.997 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.847 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.783 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.030 ;acc: 0.645 ;iou_acc: 0.705 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.704 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.654 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.788 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.702 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.283 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.289 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.313 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.240 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.343 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.342 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.320 ;Train accuracy: 0.996 ;IOU accuracy: 0.997 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.778 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.980 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.999 ;acc: 0.695 ;iou_acc: 0.750 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.834 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.580 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.841 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.735 ;Test accuracy 0.695 ;IOU accuracy: 0.788 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.233 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.263 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.314 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.351 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.281 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.276 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.279 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.953 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.903 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.866 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.754 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.835 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.824 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.803 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.157 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.241 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.142 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.298 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.210 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.295 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.260 ;Train accuracy: 0.998 ;IOU accuracy: 0.998 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.970 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.831 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.038 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.865 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.649 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.787 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.796 ;Test accuracy 0.701 ;IOU accuracy: 0.794 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.188 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.193 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.155 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.298 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.218 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.224 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.225 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.937 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.832 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 2.134 ;acc: 0.650 ;iou_acc: 0.695 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 2.008 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.795 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.965 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 1.836 ;Test accuracy 0.701 ;IOU accuracy: 0.794 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.150 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.221 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.252 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.139 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.346 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.151 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.204 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 2.015 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.942 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.101 ;acc: 0.665 ;iou_acc: 0.720 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.033 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.934 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.076 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.978 ;Test accuracy 0.693 ;IOU accuracy: 0.786 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.168 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.190 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.249 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.207 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.223 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.291 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.186 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 2.068 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 2.013 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 2.176 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 2.036 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.671 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.053 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 1.913 ;Test accuracy 0.699 ;IOU accuracy: 0.793 ;Time: 0:01:30\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.134 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.172 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.176 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.154 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.156 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.205 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.166 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 2.018 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.068 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.135 ;acc: 0.690 ;iou_acc: 0.740 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.019 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.840 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.138 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.968 ;Test accuracy 0.700 ;IOU accuracy: 0.793 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.139 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.157 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.148 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.145 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.178 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.222 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.153 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 2.235 ;acc: 0.700 ;iou_acc: 0.755 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.223 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.118 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.124 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.846 ;acc: 0.740 ;iou_acc: 0.800 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.133 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 2.004 ;Test accuracy 0.700 ;IOU accuracy: 0.794 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.073 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.152 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.120 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.166 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.117 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.129 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.132 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 2.218 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.161 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 2.343 ;acc: 0.675 ;iou_acc: 0.730 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.116 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.149 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.122 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 2.058 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.150 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.100 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.086 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.082 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.083 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.142 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.121 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 2.397 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.102 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.360 ;acc: 0.660 ;iou_acc: 0.715 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.117 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.939 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.165 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.067 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.086 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.081 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.099 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.121 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.259 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.112 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 2.494 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.689 ;acc: 0.620 ;iou_acc: 0.725 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.447 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 2.671 ;acc: 0.650 ;iou_acc: 0.780 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 2.335 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 2.305 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 2.344 ;Test accuracy 0.674 ;IOU accuracy: 0.771 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.159 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.071 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.063 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.109 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.108 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.068 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.099 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 2.226 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.066 ;acc: 0.740 ;iou_acc: 0.815 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.304 ;acc: 0.695 ;iou_acc: 0.740 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.288 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.890 ;acc: 0.715 ;iou_acc: 0.830 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.254 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 2.099 ;Test accuracy 0.703 ;IOU accuracy: 0.796 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.085 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.078 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.065 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.083 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.075 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.102 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.087 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 2.126 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.287 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.380 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.290 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.128 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.283 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.181 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.081 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.155 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.051 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.040 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.052 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.103 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.078 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 2.234 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.227 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.362 ;acc: 0.690 ;iou_acc: 0.750 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.417 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.960 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.278 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.169 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.066 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.048 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.044 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.089 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.117 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.084 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.067 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 2.330 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.207 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.241 ;acc: 0.700 ;iou_acc: 0.755 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.418 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.062 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.312 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 2.171 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.049 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.030 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.086 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.024 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.045 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.073 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.059 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 2.284 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.425 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.353 ;acc: 0.690 ;iou_acc: 0.730 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.293 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.100 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.118 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.201 ;Test accuracy 0.704 ;IOU accuracy: 0.795 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.028 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.062 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.046 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.041 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.079 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.103 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.056 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 2.443 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.167 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.472 ;acc: 0.680 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.306 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.002 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.140 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.228 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.026 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.035 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.024 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.032 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.042 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.050 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 2.319 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.374 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.535 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.366 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.212 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.259 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 2.267 ;Test accuracy 0.702 ;IOU accuracy: 0.794 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.030 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.021 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.106 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.055 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.022 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.062 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.048 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 2.366 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.394 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.530 ;acc: 0.680 ;iou_acc: 0.730 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.371 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.277 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.381 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.277 ;Test accuracy 0.703 ;IOU accuracy: 0.794 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.019 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.027 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.023 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.101 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.043 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.097 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.044 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 2.363 ;acc: 0.725 ;iou_acc: 0.785 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.468 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.478 ;acc: 0.695 ;iou_acc: 0.745 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.478 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.256 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.317 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.314 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.066 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.019 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.015 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.059 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.027 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.022 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.042 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 2.424 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.382 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.542 ;acc: 0.700 ;iou_acc: 0.755 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.429 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 2.252 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.365 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:27\n",
      "\n",
      "*BTrain: True ;Test loss: 2.299 ;Test accuracy 0.705 ;IOU accuracy: 0.797 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.024 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.033 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.052 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.024 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.025 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.036 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.040 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 2.491 ;acc: 0.730 ;iou_acc: 0.790 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.330 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.423 ;acc: 0.680 ;iou_acc: 0.725 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.600 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.170 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.434 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.326 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.013 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.130 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.026 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.053 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.012 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.032 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.040 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 2.554 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.517 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.633 ;acc: 0.675 ;iou_acc: 0.710 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.698 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.367 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.290 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.399 ;Test accuracy 0.696 ;IOU accuracy: 0.789 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.058 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.085 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.013 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.039 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.034 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.058 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.034 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 2.499 ;acc: 0.725 ;iou_acc: 0.770 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.413 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.524 ;acc: 0.705 ;iou_acc: 0.760 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.544 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.357 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.467 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 2.378 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.012 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.019 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.030 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.016 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.033 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.031 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.036 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 2.620 ;acc: 0.705 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.275 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.459 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.448 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.299 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.500 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.341 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.015 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.035 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.019 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.034 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.022 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.026 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.036 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 2.514 ;acc: 0.695 ;iou_acc: 0.745 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.436 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 2.525 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 2.450 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 2.419 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.423 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 2.379 ;Test accuracy 0.705 ;IOU accuracy: 0.797 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.066 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.053 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.083 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.013 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.022 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.015 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.029 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 2.551 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.401 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.543 ;acc: 0.705 ;iou_acc: 0.745 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.598 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 2.214 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 2.436 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 2.435 ;Test accuracy 0.702 ;IOU accuracy: 0.793 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.010 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.015 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.015 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.017 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.025 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.019 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.031 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 2.481 ;acc: 0.715 ;iou_acc: 0.765 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.398 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.661 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.464 ;acc: 0.705 ;iou_acc: 0.830 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.310 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.549 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 2.430 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Base model with batch normailzation\n",
    "\n",
    "bnorm_test_res, bnorm_train_res = [], []\n",
    "\n",
    "for num_hidden in [50, 100, 150, 200]:\n",
    "    params_dir = params_dir_tmp+'bnorm_base/hidden:'+str(num_hidden)\n",
    "    tf.reset_default_graph()\n",
    "    m = Model(\n",
    "        batch_size=200, \n",
    "        num_hidden=num_hidden,\n",
    "        embed_size=nembed_vecs.shape[1],,\n",
    "        img_dims=trainset[0][0][1][0].shape[1], \n",
    "        bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "        lr=.05,\n",
    "        vocab=vocab, \n",
    "        decay_steps=10000, \n",
    "        decay_rate=0.99, \n",
    "        edit_reward=0.,\n",
    "        rnn_editProb=0.,\n",
    "        coefAlr=1,\n",
    "        bnorm=True)\n",
    "\n",
    "\n",
    "    # start comp\n",
    "    print('params_dir:', params_dir)\n",
    "    print('num_hidden:', m.num_hidden)\n",
    "    print('learning rate:', m.lr)\n",
    "    tst, trn = m.train(trainset, testset,\n",
    "            ephocs_num=50,\n",
    "            start_ephoc=0,\n",
    "            startA=51,\n",
    "            activation_ephoc=51,\n",
    "            muteB=0, \n",
    "            activateAProb=0,\n",
    "            max_activateAProb=0,\n",
    "            editProb=0,\n",
    "            edit_reward=0)\n",
    "    \n",
    "    bnorm_test_res.append(tst)\n",
    "    bnorm_train_res.append(trn)\n",
    "    print('\\n'+'*'*100)\n",
    "    print('*'*100)\n",
    "    print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "\n",
    "<p> We test the model (with batch normalization) for different numbers of hidden units and dropout ratio. We test dropout for the RNN's input, outputs and both.</p>\n",
    "<p> While there is no significant improvement (79.9% test IOU for dropout_in=0.5, dropout_out=1), it is interesting to see that here it is clear that the test IOU gets bigger as the number of hudden unit gets bigger. This indicates that dropout is crucial for investigating the model's parameters number.</p> \n",
    "<ul>\n",
    "<li>For dropout_in=0.5, dropout_out=1 we get 78.5, 79.4, 79.7, 79.9<\\li>\n",
    "<li>For dropout_in=1, dropout_out=0.5 we get 79.1, 79.3, 79.6, 79.7<\\li>\n",
    "<li>For dropout_in=0.5, dropout_out=0.5 we get 79.2, 79.3, 79.3, 79.6<\\li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout_in 0.5\n",
      "dropout_out 1.0\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_0.5,1.0_hidden:50\n",
      "num_hidden: 50\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.942 ;acc: 0.315 ;iou: 0.380 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.743 ;acc: 0.235 ;iou: 0.345 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.614 ;acc: 0.300 ;iou: 0.445 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.658 ;acc: 0.320 ;iou: 0.435 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.693 ;acc: 0.310 ;iou: 0.425 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.491 ;acc: 0.310 ;iou: 0.475 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 2.639 ;Train accuracy: 0.304 ;IOU accuracy: 0.406 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.478 ;acc: 0.305 ;iou_acc: 0.435 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.548 ;acc: 0.300 ;iou_acc: 0.370 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.597 ;acc: 0.275 ;iou_acc: 0.350 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.560 ;acc: 0.265 ;iou_acc: 0.385 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.516 ;acc: 0.300 ;iou_acc: 0.370 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.531 ;acc: 0.315 ;iou_acc: 0.430 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 2.488 ;Test accuracy 0.322 ;IOU accuracy: 0.429 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.551 ;acc: 0.370 ;iou: 0.470 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.474 ;acc: 0.385 ;iou: 0.515 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.382 ;acc: 0.390 ;iou: 0.480 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.475 ;acc: 0.420 ;iou: 0.560 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.318 ;acc: 0.445 ;iou: 0.530 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.341 ;acc: 0.450 ;iou: 0.575 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 2.388 ;Train accuracy: 0.416 ;IOU accuracy: 0.514 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.268 ;acc: 0.420 ;iou_acc: 0.500 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.341 ;acc: 0.415 ;iou_acc: 0.485 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.492 ;acc: 0.315 ;iou_acc: 0.415 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.379 ;acc: 0.375 ;iou_acc: 0.465 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.348 ;acc: 0.305 ;iou_acc: 0.455 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.337 ;acc: 0.385 ;iou_acc: 0.520 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 2.302 ;Test accuracy 0.393 ;IOU accuracy: 0.498 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.283 ;acc: 0.445 ;iou: 0.545 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.120 ;acc: 0.520 ;iou: 0.600 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.145 ;acc: 0.495 ;iou: 0.580 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.194 ;acc: 0.490 ;iou: 0.610 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.130 ;acc: 0.475 ;iou: 0.555 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.254 ;acc: 0.480 ;iou: 0.585 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 2.216 ;Train accuracy: 0.487 ;IOU accuracy: 0.586 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.168 ;acc: 0.415 ;iou_acc: 0.545 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.142 ;acc: 0.480 ;iou_acc: 0.570 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.301 ;acc: 0.425 ;iou_acc: 0.535 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.201 ;acc: 0.430 ;iou_acc: 0.555 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.210 ;acc: 0.405 ;iou_acc: 0.530 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.149 ;acc: 0.480 ;iou_acc: 0.585 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 2.125 ;Test accuracy 0.456 ;IOU accuracy: 0.560 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.119 ;acc: 0.530 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.095 ;acc: 0.535 ;iou: 0.670 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 2.011 ;acc: 0.535 ;iou: 0.620 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 2.110 ;acc: 0.545 ;iou: 0.625 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 2.068 ;acc: 0.570 ;iou: 0.670 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 2.146 ;acc: 0.560 ;iou: 0.635 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 2.063 ;Train accuracy: 0.546 ;IOU accuracy: 0.636 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 2.052 ;acc: 0.455 ;iou_acc: 0.560 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.071 ;acc: 0.495 ;iou_acc: 0.570 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.172 ;acc: 0.455 ;iou_acc: 0.565 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.142 ;acc: 0.390 ;iou_acc: 0.510 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.111 ;acc: 0.440 ;iou_acc: 0.555 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.027 ;acc: 0.525 ;iou_acc: 0.630 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 2.017 ;Test accuracy 0.489 ;IOU accuracy: 0.590 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.910 ;acc: 0.605 ;iou: 0.735 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 2.052 ;acc: 0.555 ;iou: 0.610 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.835 ;acc: 0.585 ;iou: 0.745 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 2.029 ;acc: 0.525 ;iou: 0.615 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.981 ;acc: 0.595 ;iou: 0.675 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.724 ;acc: 0.665 ;iou: 0.710 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.956 ;Train accuracy: 0.583 ;IOU accuracy: 0.665 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 2.005 ;acc: 0.480 ;iou_acc: 0.600 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.989 ;acc: 0.520 ;iou_acc: 0.600 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 2.148 ;acc: 0.445 ;iou_acc: 0.535 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.060 ;acc: 0.470 ;iou_acc: 0.575 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.003 ;acc: 0.490 ;iou_acc: 0.600 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.983 ;acc: 0.540 ;iou_acc: 0.660 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.946 ;Test accuracy 0.507 ;IOU accuracy: 0.608 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.865 ;acc: 0.605 ;iou: 0.700 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.805 ;acc: 0.595 ;iou: 0.685 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.917 ;acc: 0.560 ;iou: 0.640 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.856 ;acc: 0.635 ;iou: 0.705 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.819 ;acc: 0.625 ;iou: 0.700 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.747 ;acc: 0.680 ;iou: 0.750 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.869 ;Train accuracy: 0.609 ;IOU accuracy: 0.688 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.898 ;acc: 0.515 ;iou_acc: 0.615 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.889 ;acc: 0.510 ;iou_acc: 0.590 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.068 ;acc: 0.470 ;iou_acc: 0.545 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.988 ;acc: 0.480 ;iou_acc: 0.605 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.906 ;acc: 0.550 ;iou_acc: 0.665 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.927 ;acc: 0.525 ;iou_acc: 0.645 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.875 ;Test accuracy 0.530 ;IOU accuracy: 0.627 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.887 ;acc: 0.635 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.672 ;acc: 0.675 ;iou: 0.720 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.844 ;acc: 0.625 ;iou: 0.720 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.843 ;acc: 0.590 ;iou: 0.705 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.810 ;acc: 0.620 ;iou: 0.675 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.983 ;acc: 0.590 ;iou: 0.690 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 1.800 ;Train accuracy: 0.636 ;IOU accuracy: 0.710 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.812 ;acc: 0.560 ;iou_acc: 0.650 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.824 ;acc: 0.540 ;iou_acc: 0.610 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.010 ;acc: 0.475 ;iou_acc: 0.570 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.923 ;acc: 0.500 ;iou_acc: 0.610 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.831 ;acc: 0.560 ;iou_acc: 0.645 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.875 ;acc: 0.545 ;iou_acc: 0.655 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 1.825 ;Test accuracy 0.545 ;IOU accuracy: 0.640 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.824 ;acc: 0.610 ;iou: 0.655 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.849 ;acc: 0.665 ;iou: 0.705 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.694 ;acc: 0.685 ;iou: 0.775 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.795 ;acc: 0.640 ;iou: 0.745 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.777 ;acc: 0.685 ;iou: 0.735 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.589 ;acc: 0.685 ;iou: 0.725 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.731 ;Train accuracy: 0.660 ;IOU accuracy: 0.731 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.794 ;acc: 0.550 ;iou_acc: 0.660 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.817 ;acc: 0.525 ;iou_acc: 0.610 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.963 ;acc: 0.465 ;iou_acc: 0.560 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.870 ;acc: 0.520 ;iou_acc: 0.615 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.797 ;acc: 0.560 ;iou_acc: 0.655 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.818 ;acc: 0.525 ;iou_acc: 0.650 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.791 ;Test accuracy 0.556 ;IOU accuracy: 0.652 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.672 ;acc: 0.655 ;iou: 0.755 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.661 ;acc: 0.730 ;iou: 0.785 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.605 ;acc: 0.715 ;iou: 0.810 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.720 ;acc: 0.635 ;iou: 0.740 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.618 ;acc: 0.655 ;iou: 0.665 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.713 ;acc: 0.685 ;iou: 0.785 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.671 ;Train accuracy: 0.687 ;IOU accuracy: 0.754 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.750 ;acc: 0.565 ;iou_acc: 0.680 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.770 ;acc: 0.570 ;iou_acc: 0.650 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.932 ;acc: 0.510 ;iou_acc: 0.605 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.857 ;acc: 0.540 ;iou_acc: 0.625 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.765 ;acc: 0.575 ;iou_acc: 0.680 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.775 ;acc: 0.585 ;iou_acc: 0.695 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.747 ;Test accuracy 0.571 ;IOU accuracy: 0.671 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.459 ;acc: 0.740 ;iou: 0.800 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.829 ;acc: 0.640 ;iou: 0.735 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.562 ;acc: 0.740 ;iou: 0.795 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.756 ;acc: 0.705 ;iou: 0.725 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.369 ;acc: 0.760 ;iou: 0.820 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.349 ;acc: 0.780 ;iou: 0.825 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.583 ;Train accuracy: 0.716 ;IOU accuracy: 0.784 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.670 ;acc: 0.600 ;iou_acc: 0.685 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.676 ;acc: 0.605 ;iou_acc: 0.700 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.885 ;acc: 0.530 ;iou_acc: 0.610 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.760 ;acc: 0.540 ;iou_acc: 0.660 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.697 ;acc: 0.600 ;iou_acc: 0.705 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.739 ;acc: 0.585 ;iou_acc: 0.690 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.665 ;Test accuracy 0.599 ;IOU accuracy: 0.697 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.478 ;acc: 0.745 ;iou: 0.820 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.388 ;acc: 0.735 ;iou: 0.830 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.398 ;acc: 0.760 ;iou: 0.795 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.361 ;acc: 0.765 ;iou: 0.840 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.535 ;acc: 0.750 ;iou: 0.810 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.711 ;acc: 0.710 ;iou: 0.780 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.502 ;Train accuracy: 0.746 ;IOU accuracy: 0.810 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.621 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.544 ;acc: 0.645 ;iou_acc: 0.755 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.787 ;acc: 0.570 ;iou_acc: 0.645 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.716 ;acc: 0.575 ;iou_acc: 0.680 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.595 ;acc: 0.590 ;iou_acc: 0.725 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.661 ;acc: 0.595 ;iou_acc: 0.675 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.616 ;Test accuracy 0.615 ;IOU accuracy: 0.714 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.445 ;acc: 0.750 ;iou: 0.815 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.325 ;acc: 0.790 ;iou: 0.860 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.563 ;acc: 0.740 ;iou: 0.810 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.343 ;acc: 0.780 ;iou: 0.850 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.435 ;acc: 0.785 ;iou: 0.840 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.385 ;acc: 0.790 ;iou: 0.835 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.428 ;Train accuracy: 0.770 ;IOU accuracy: 0.828 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.598 ;acc: 0.615 ;iou_acc: 0.725 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.554 ;acc: 0.635 ;iou_acc: 0.750 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.701 ;acc: 0.610 ;iou_acc: 0.685 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.685 ;acc: 0.620 ;iou_acc: 0.715 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.546 ;acc: 0.640 ;iou_acc: 0.745 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.619 ;acc: 0.610 ;iou_acc: 0.720 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.561 ;Test accuracy 0.632 ;IOU accuracy: 0.731 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.256 ;acc: 0.805 ;iou: 0.830 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 1.360 ;acc: 0.735 ;iou: 0.845 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.492 ;acc: 0.755 ;iou: 0.820 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.473 ;acc: 0.740 ;iou: 0.830 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.300 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 1.433 ;acc: 0.790 ;iou: 0.830 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.361 ;Train accuracy: 0.789 ;IOU accuracy: 0.846 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.552 ;acc: 0.615 ;iou_acc: 0.725 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.456 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.687 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.594 ;acc: 0.625 ;iou_acc: 0.730 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.487 ;acc: 0.635 ;iou_acc: 0.720 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.474 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.496 ;Test accuracy 0.650 ;IOU accuracy: 0.748 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.123 ;acc: 0.825 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.207 ;acc: 0.855 ;iou: 0.875 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.248 ;acc: 0.820 ;iou: 0.860 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 1.630 ;acc: 0.745 ;iou: 0.795 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.434 ;acc: 0.740 ;iou: 0.875 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 1.262 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.297 ;Train accuracy: 0.804 ;IOU accuracy: 0.859 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.512 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.500 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.715 ;acc: 0.635 ;iou_acc: 0.725 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.539 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.481 ;acc: 0.630 ;iou_acc: 0.755 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.530 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.476 ;Test accuracy 0.658 ;IOU accuracy: 0.753 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 1.134 ;acc: 0.795 ;iou: 0.845 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.066 ;acc: 0.870 ;iou: 0.915 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 1.273 ;acc: 0.790 ;iou: 0.865 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 1.158 ;acc: 0.850 ;iou: 0.860 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.250 ;acc: 0.810 ;iou: 0.865 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.214 ;acc: 0.800 ;iou: 0.870 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.250 ;Train accuracy: 0.819 ;IOU accuracy: 0.868 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.511 ;acc: 0.630 ;iou_acc: 0.750 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.412 ;acc: 0.635 ;iou_acc: 0.755 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.622 ;acc: 0.620 ;iou_acc: 0.715 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.534 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.518 ;acc: 0.640 ;iou_acc: 0.765 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.492 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.453 ;Test accuracy 0.664 ;IOU accuracy: 0.760 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 1.174 ;acc: 0.880 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 1.043 ;acc: 0.830 ;iou: 0.885 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 1.089 ;acc: 0.840 ;iou: 0.890 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 1.170 ;acc: 0.815 ;iou: 0.855 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.415 ;acc: 0.815 ;iou: 0.860 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 1.118 ;acc: 0.785 ;iou: 0.865 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.206 ;Train accuracy: 0.826 ;IOU accuracy: 0.876 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.475 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.381 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.659 ;acc: 0.610 ;iou_acc: 0.700 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.501 ;acc: 0.635 ;iou_acc: 0.725 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.456 ;acc: 0.640 ;iou_acc: 0.765 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.395 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.449 ;Test accuracy 0.667 ;IOU accuracy: 0.763 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.976 ;acc: 0.860 ;iou: 0.885 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 1.269 ;acc: 0.830 ;iou: 0.870 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 1.134 ;acc: 0.815 ;iou: 0.875 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 1.217 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 1.439 ;acc: 0.770 ;iou: 0.830 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 1.082 ;acc: 0.850 ;iou: 0.890 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.166 ;Train accuracy: 0.835 ;IOU accuracy: 0.881 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.498 ;acc: 0.630 ;iou_acc: 0.720 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.347 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.669 ;acc: 0.610 ;iou_acc: 0.705 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.439 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.448 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.442 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.430 ;Test accuracy 0.670 ;IOU accuracy: 0.766 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 1.178 ;acc: 0.845 ;iou: 0.900 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 1.126 ;acc: 0.810 ;iou: 0.875 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 1.116 ;acc: 0.865 ;iou: 0.880 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 1.322 ;acc: 0.820 ;iou: 0.875 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 1.056 ;acc: 0.855 ;iou: 0.885 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 1.228 ;acc: 0.785 ;iou: 0.870 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.139 ;Train accuracy: 0.840 ;IOU accuracy: 0.888 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.396 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.408 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.679 ;acc: 0.595 ;iou_acc: 0.685 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.536 ;acc: 0.640 ;iou_acc: 0.740 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.427 ;acc: 0.660 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.444 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.440 ;Test accuracy 0.674 ;IOU accuracy: 0.771 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.927 ;acc: 0.885 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 1.009 ;acc: 0.855 ;iou: 0.880 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 1.187 ;acc: 0.810 ;iou: 0.885 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 1.250 ;acc: 0.820 ;iou: 0.900 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 1.139 ;acc: 0.815 ;iou: 0.890 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 1.142 ;acc: 0.815 ;iou: 0.855 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 1.108 ;Train accuracy: 0.848 ;IOU accuracy: 0.892 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.423 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.352 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.604 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.434 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.376 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.477 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.394 ;Test accuracy 0.681 ;IOU accuracy: 0.776 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.980 ;acc: 0.890 ;iou: 0.910 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 1.102 ;acc: 0.840 ;iou: 0.880 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.984 ;acc: 0.870 ;iou: 0.900 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.982 ;acc: 0.855 ;iou: 0.935 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.900 ;iou: 0.900 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 1.197 ;acc: 0.855 ;iou: 0.905 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.079 ;Train accuracy: 0.854 ;IOU accuracy: 0.896 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.455 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.340 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.525 ;acc: 0.650 ;iou_acc: 0.735 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.432 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.391 ;acc: 0.660 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.437 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.395 ;Test accuracy 0.683 ;IOU accuracy: 0.777 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.885 ;acc: 0.870 ;iou: 0.865 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.935 ;acc: 0.880 ;iou: 0.935 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 1.238 ;acc: 0.840 ;iou: 0.880 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.988 ;acc: 0.865 ;iou: 0.925 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 1.047 ;acc: 0.865 ;iou: 0.885 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 1.056 ;acc: 0.850 ;iou: 0.925 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.044 ;Train accuracy: 0.858 ;IOU accuracy: 0.901 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.438 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.375 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.561 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.435 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.417 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.461 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.398 ;Test accuracy 0.683 ;IOU accuracy: 0.778 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.966 ;acc: 0.855 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 1.213 ;acc: 0.845 ;iou: 0.875 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 1.051 ;acc: 0.890 ;iou: 0.870 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 1.043 ;acc: 0.895 ;iou: 0.875 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 1.071 ;acc: 0.855 ;iou: 0.875 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 1.073 ;acc: 0.840 ;iou: 0.905 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 1.029 ;Train accuracy: 0.866 ;IOU accuracy: 0.905 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.401 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.400 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.605 ;acc: 0.630 ;iou_acc: 0.725 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.457 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.352 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.569 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.422 ;Test accuracy 0.685 ;IOU accuracy: 0.779 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.887 ;acc: 0.905 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 1.098 ;acc: 0.875 ;iou: 0.885 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.744 ;acc: 0.945 ;iou: 0.930 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.966 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 1.076 ;acc: 0.850 ;iou: 0.885 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 1.137 ;acc: 0.875 ;iou: 0.890 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.009 ;Train accuracy: 0.869 ;IOU accuracy: 0.907 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.502 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.427 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.600 ;acc: 0.635 ;iou_acc: 0.720 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.443 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.417 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.508 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.417 ;Test accuracy 0.680 ;IOU accuracy: 0.776 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 1.003 ;acc: 0.890 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.901 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.969 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 1.027 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.981 ;acc: 0.875 ;iou: 0.860 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.900 ;acc: 0.870 ;iou: 0.935 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.988 ;Train accuracy: 0.873 ;IOU accuracy: 0.911 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.458 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.400 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.460 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.433 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.305 ;acc: 0.710 ;iou_acc: 0.830 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.433 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.397 ;Test accuracy 0.687 ;IOU accuracy: 0.782 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.923 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.919 ;acc: 0.860 ;iou: 0.905 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.999 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.912 ;acc: 0.855 ;iou: 0.915 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.912 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 1.069 ;acc: 0.900 ;iou: 0.905 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.968 ;Train accuracy: 0.876 ;IOU accuracy: 0.914 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.348 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.443 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.556 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.430 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.423 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.484 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.419 ;Test accuracy 0.686 ;IOU accuracy: 0.781 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.915 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 1.031 ;acc: 0.850 ;iou: 0.885 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 1.051 ;acc: 0.840 ;iou: 0.900 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 1.040 ;acc: 0.845 ;iou: 0.905 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.981 ;acc: 0.880 ;iou: 0.900 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.948 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.945 ;Train accuracy: 0.881 ;IOU accuracy: 0.915 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.367 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.390 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.597 ;acc: 0.645 ;iou_acc: 0.715 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.422 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.351 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.419 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.417 ;Test accuracy 0.690 ;IOU accuracy: 0.784 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.867 ;acc: 0.895 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.980 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.973 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 1.112 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.877 ;acc: 0.890 ;iou: 0.905 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 1.019 ;acc: 0.845 ;iou: 0.950 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.929 ;Train accuracy: 0.885 ;IOU accuracy: 0.918 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.403 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.383 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.577 ;acc: 0.640 ;iou_acc: 0.705 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.488 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.419 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.571 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.437 ;Test accuracy 0.686 ;IOU accuracy: 0.780 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.746 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.886 ;acc: 0.910 ;iou: 0.915 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.889 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 1.044 ;acc: 0.845 ;iou: 0.910 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.920 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.873 ;acc: 0.895 ;iou: 0.910 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.906 ;Train accuracy: 0.887 ;IOU accuracy: 0.921 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.414 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.385 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.612 ;acc: 0.630 ;iou_acc: 0.720 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.404 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.375 ;acc: 0.695 ;iou_acc: 0.820 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.527 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.408 ;Test accuracy 0.693 ;IOU accuracy: 0.786 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.880 ;acc: 0.875 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 1.043 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.887 ;acc: 0.885 ;iou: 0.890 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 1.017 ;acc: 0.875 ;iou: 0.885 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.884 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.782 ;acc: 0.915 ;iou: 0.920 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.896 ;Train accuracy: 0.891 ;IOU accuracy: 0.924 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.372 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.545 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.652 ;acc: 0.645 ;iou_acc: 0.710 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.472 ;acc: 0.700 ;iou_acc: 0.755 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.386 ;acc: 0.690 ;iou_acc: 0.815 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.561 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.448 ;Test accuracy 0.688 ;IOU accuracy: 0.782 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.761 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.922 ;acc: 0.905 ;iou: 0.950 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.908 ;acc: 0.870 ;iou: 0.930 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.935 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.764 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.787 ;acc: 0.890 ;iou: 0.945 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.871 ;Train accuracy: 0.895 ;IOU accuracy: 0.928 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.533 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.487 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.601 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.510 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.389 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.435 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.435 ;Test accuracy 0.690 ;IOU accuracy: 0.785 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.930 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.724 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.822 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.947 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.870 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.920 ;acc: 0.870 ;iou: 0.920 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.861 ;Train accuracy: 0.897 ;IOU accuracy: 0.928 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.426 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.478 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.697 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.498 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.409 ;acc: 0.665 ;iou_acc: 0.825 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.487 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.465 ;Test accuracy 0.690 ;IOU accuracy: 0.784 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.804 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.805 ;acc: 0.915 ;iou: 0.920 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.855 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.771 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.873 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.772 ;acc: 0.910 ;iou: 0.955 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.848 ;Train accuracy: 0.901 ;IOU accuracy: 0.931 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.388 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.489 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.530 ;acc: 0.645 ;iou_acc: 0.730 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.488 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.403 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.536 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.445 ;Test accuracy 0.693 ;IOU accuracy: 0.787 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.706 ;acc: 0.945 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.630 ;acc: 0.900 ;iou: 0.950 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.723 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.860 ;acc: 0.935 ;iou: 0.940 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.806 ;acc: 0.865 ;iou: 0.960 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.863 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.825 ;Train accuracy: 0.904 ;IOU accuracy: 0.934 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.466 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.499 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.552 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.540 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.413 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.531 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.452 ;Test accuracy 0.692 ;IOU accuracy: 0.785 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.703 ;acc: 0.955 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.808 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.898 ;acc: 0.900 ;iou: 0.910 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.975 ;acc: 0.900 ;iou: 0.910 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.663 ;acc: 0.905 ;iou: 0.915 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.880 ;acc: 0.885 ;iou: 0.945 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.813 ;Train accuracy: 0.906 ;IOU accuracy: 0.934 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.437 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.498 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.634 ;acc: 0.640 ;iou_acc: 0.710 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.431 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.461 ;acc: 0.680 ;iou_acc: 0.810 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.569 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.481 ;Test accuracy 0.690 ;IOU accuracy: 0.783 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.920 ;acc: 0.905 ;iou: 0.920 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.739 ;acc: 0.920 ;iou: 0.915 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.688 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.845 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.764 ;acc: 0.900 ;iou: 0.925 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.710 ;acc: 0.905 ;iou: 0.960 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.801 ;Train accuracy: 0.909 ;IOU accuracy: 0.936 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.531 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.566 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.612 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.587 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.514 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.498 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.495 ;Test accuracy 0.689 ;IOU accuracy: 0.782 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.691 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.735 ;acc: 0.925 ;iou: 0.935 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.727 ;acc: 0.935 ;iou: 0.945 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.771 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.807 ;acc: 0.870 ;iou: 0.935 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.869 ;acc: 0.895 ;iou: 0.945 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.793 ;Train accuracy: 0.911 ;IOU accuracy: 0.936 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.506 ;acc: 0.650 ;iou_acc: 0.740 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.558 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.608 ;acc: 0.655 ;iou_acc: 0.720 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.533 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.340 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.470 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.509 ;Test accuracy 0.689 ;IOU accuracy: 0.784 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.711 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.601 ;acc: 0.960 ;iou: 0.950 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.756 ;acc: 0.895 ;iou: 0.915 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.677 ;acc: 0.925 ;iou: 0.920 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.890 ;acc: 0.920 ;iou: 0.915 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.853 ;acc: 0.915 ;iou: 0.925 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.774 ;Train accuracy: 0.916 ;IOU accuracy: 0.941 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.543 ;acc: 0.650 ;iou_acc: 0.735 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.600 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.643 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.515 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.528 ;acc: 0.665 ;iou_acc: 0.800 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.532 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.499 ;Test accuracy 0.690 ;IOU accuracy: 0.784 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.865 ;acc: 0.925 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.812 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.698 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.708 ;acc: 0.955 ;iou: 0.940 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.676 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.811 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.766 ;Train accuracy: 0.916 ;IOU accuracy: 0.941 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.542 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.512 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.561 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.487 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.458 ;acc: 0.695 ;iou_acc: 0.840 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.543 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.482 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.696 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.672 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.583 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.654 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.773 ;acc: 0.890 ;iou: 0.960 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.884 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.747 ;Train accuracy: 0.918 ;IOU accuracy: 0.943 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.498 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.537 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.579 ;acc: 0.650 ;iou_acc: 0.735 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.584 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.431 ;acc: 0.665 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.605 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.502 ;Test accuracy 0.691 ;IOU accuracy: 0.785 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.656 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.678 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.822 ;acc: 0.885 ;iou: 0.935 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.837 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.732 ;acc: 0.935 ;iou: 0.975 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.693 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.741 ;Train accuracy: 0.921 ;IOU accuracy: 0.944 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.512 ;acc: 0.685 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.517 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.733 ;acc: 0.645 ;iou_acc: 0.730 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.622 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.440 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.537 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.524 ;Test accuracy 0.691 ;IOU accuracy: 0.784 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.849 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.776 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.751 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.755 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.816 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.659 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.731 ;Train accuracy: 0.921 ;IOU accuracy: 0.944 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.574 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.596 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.796 ;acc: 0.615 ;iou_acc: 0.700 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.614 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.428 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.583 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.528 ;Test accuracy 0.690 ;IOU accuracy: 0.783 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.481 ;acc: 0.945 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.806 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.757 ;acc: 0.915 ;iou: 0.960 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.603 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.677 ;acc: 0.910 ;iou: 0.920 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.729 ;acc: 0.905 ;iou: 0.965 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.721 ;Train accuracy: 0.923 ;IOU accuracy: 0.946 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.610 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.591 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.678 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.590 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.527 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.651 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.554 ;Test accuracy 0.690 ;IOU accuracy: 0.784 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.598 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.644 ;acc: 0.960 ;iou: 0.950 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.618 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.824 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.714 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.822 ;acc: 0.900 ;iou: 0.950 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.710 ;Train accuracy: 0.925 ;IOU accuracy: 0.948 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.632 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.624 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.726 ;acc: 0.645 ;iou_acc: 0.730 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.499 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.545 ;acc: 0.680 ;iou_acc: 0.815 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.698 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.552 ;Test accuracy 0.691 ;IOU accuracy: 0.784 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.762 ;acc: 0.910 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.492 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.683 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.727 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.529 ;acc: 0.940 ;iou: 0.975 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.813 ;acc: 0.915 ;iou: 0.925 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.700 ;Train accuracy: 0.927 ;IOU accuracy: 0.948 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.563 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.581 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.783 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.537 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.524 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.632 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.577 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.674 ;acc: 0.925 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.598 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.593 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.639 ;acc: 0.925 ;iou: 0.965 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.675 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.677 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.684 ;Train accuracy: 0.931 ;IOU accuracy: 0.951 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.518 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.587 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.752 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.561 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.435 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.718 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.584 ;Test accuracy 0.691 ;IOU accuracy: 0.785 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.630 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.688 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.652 ;acc: 0.945 ;iou: 0.950 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.700 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.817 ;acc: 0.885 ;iou: 0.920 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.658 ;acc: 0.945 ;iou: 0.935 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.674 ;Train accuracy: 0.930 ;IOU accuracy: 0.951 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.571 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.593 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.703 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.516 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.527 ;acc: 0.670 ;iou_acc: 0.800 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.695 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.573 ;Test accuracy 0.694 ;IOU accuracy: 0.786 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.685 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.723 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.900 ;acc: 0.935 ;iou: 0.935 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.646 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.653 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.783 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.663 ;Train accuracy: 0.933 ;IOU accuracy: 0.953 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.696 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.613 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.683 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.590 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.490 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.734 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.577 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.585 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.652 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.659 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.690 ;acc: 0.935 ;iou: 0.940 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.605 ;acc: 0.930 ;iou: 0.940 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.628 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.655 ;Train accuracy: 0.935 ;IOU accuracy: 0.954 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.615 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.652 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.793 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.674 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.650 ;acc: 0.670 ;iou_acc: 0.820 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.708 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.633 ;Test accuracy 0.689 ;IOU accuracy: 0.782 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.733 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.807 ;acc: 0.900 ;iou: 0.925 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.557 ;acc: 0.920 ;iou: 0.970 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.620 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.596 ;acc: 0.960 ;iou: 0.945 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.675 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.652 ;Train accuracy: 0.936 ;IOU accuracy: 0.955 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.663 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.630 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.770 ;acc: 0.645 ;iou_acc: 0.730 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.763 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.517 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.707 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.631 ;Test accuracy 0.692 ;IOU accuracy: 0.784 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.522 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.479 ;acc: 0.935 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.539 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.694 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.778 ;acc: 0.930 ;iou: 0.930 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.593 ;acc: 0.925 ;iou: 0.965 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.636 ;Train accuracy: 0.937 ;IOU accuracy: 0.955 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.647 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.671 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.769 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.582 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.524 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.658 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.596 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 1.0\n",
      "dropout_out 0.5\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_1.0,0.5_hidden:50\n",
      "num_hidden: 50\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.899 ;acc: 0.240 ;iou: 0.355 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.664 ;acc: 0.245 ;iou: 0.335 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.678 ;acc: 0.305 ;iou: 0.420 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.724 ;acc: 0.285 ;iou: 0.390 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.547 ;acc: 0.325 ;iou: 0.465 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.546 ;acc: 0.400 ;iou: 0.490 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 2.639 ;Train accuracy: 0.310 ;IOU accuracy: 0.411 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.465 ;acc: 0.320 ;iou_acc: 0.415 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.515 ;acc: 0.355 ;iou_acc: 0.420 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.583 ;acc: 0.265 ;iou_acc: 0.360 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.537 ;acc: 0.305 ;iou_acc: 0.420 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.489 ;acc: 0.330 ;iou_acc: 0.405 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.497 ;acc: 0.320 ;iou_acc: 0.455 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 2.502 ;Test accuracy 0.327 ;IOU accuracy: 0.435 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.460 ;acc: 0.415 ;iou: 0.490 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.361 ;acc: 0.450 ;iou: 0.570 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.489 ;acc: 0.410 ;iou: 0.500 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.218 ;acc: 0.500 ;iou: 0.585 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.342 ;acc: 0.435 ;iou: 0.525 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.236 ;acc: 0.480 ;iou: 0.555 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 2.341 ;Train accuracy: 0.445 ;IOU accuracy: 0.540 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.248 ;acc: 0.390 ;iou_acc: 0.500 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 2.280 ;acc: 0.440 ;iou_acc: 0.510 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.390 ;acc: 0.350 ;iou_acc: 0.410 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.266 ;acc: 0.425 ;iou_acc: 0.505 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.309 ;acc: 0.365 ;iou_acc: 0.475 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.245 ;acc: 0.470 ;iou_acc: 0.550 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 2.250 ;Test accuracy 0.412 ;IOU accuracy: 0.519 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.145 ;acc: 0.485 ;iou: 0.575 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.420 ;acc: 0.425 ;iou: 0.535 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.069 ;acc: 0.580 ;iou: 0.660 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.158 ;acc: 0.495 ;iou: 0.595 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.106 ;acc: 0.505 ;iou: 0.620 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.132 ;acc: 0.520 ;iou: 0.615 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 2.140 ;Train accuracy: 0.528 ;IOU accuracy: 0.620 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.147 ;acc: 0.440 ;iou_acc: 0.555 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.123 ;acc: 0.475 ;iou_acc: 0.545 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.221 ;acc: 0.460 ;iou_acc: 0.535 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.127 ;acc: 0.460 ;iou_acc: 0.560 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.185 ;acc: 0.430 ;iou_acc: 0.520 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.067 ;acc: 0.495 ;iou_acc: 0.610 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 2.095 ;Test accuracy 0.465 ;IOU accuracy: 0.567 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.978 ;acc: 0.615 ;iou: 0.685 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.923 ;acc: 0.615 ;iou: 0.680 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.992 ;acc: 0.585 ;iou: 0.695 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 2.134 ;acc: 0.520 ;iou: 0.630 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.911 ;acc: 0.605 ;iou: 0.680 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.871 ;acc: 0.630 ;iou: 0.685 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.968 ;Train accuracy: 0.598 ;IOU accuracy: 0.679 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.984 ;acc: 0.485 ;iou_acc: 0.610 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.958 ;acc: 0.480 ;iou_acc: 0.550 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.116 ;acc: 0.465 ;iou_acc: 0.540 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.977 ;acc: 0.505 ;iou_acc: 0.585 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.035 ;acc: 0.490 ;iou_acc: 0.595 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.947 ;acc: 0.520 ;iou_acc: 0.625 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.975 ;Test accuracy 0.501 ;IOU accuracy: 0.601 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.932 ;acc: 0.590 ;iou: 0.675 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.685 ;acc: 0.680 ;iou: 0.760 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.803 ;acc: 0.660 ;iou: 0.725 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.701 ;acc: 0.685 ;iou: 0.735 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.716 ;acc: 0.720 ;iou: 0.765 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.782 ;acc: 0.660 ;iou: 0.730 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.835 ;Train accuracy: 0.647 ;IOU accuracy: 0.721 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.904 ;acc: 0.505 ;iou_acc: 0.600 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.910 ;acc: 0.510 ;iou_acc: 0.600 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.063 ;acc: 0.470 ;iou_acc: 0.540 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.880 ;acc: 0.525 ;iou_acc: 0.615 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.993 ;acc: 0.475 ;iou_acc: 0.610 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.871 ;acc: 0.555 ;iou_acc: 0.660 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.878 ;Test accuracy 0.527 ;IOU accuracy: 0.627 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.647 ;acc: 0.730 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.852 ;acc: 0.660 ;iou: 0.755 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.683 ;acc: 0.695 ;iou: 0.730 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.909 ;acc: 0.620 ;iou: 0.720 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.809 ;acc: 0.685 ;iou: 0.780 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.712 ;acc: 0.645 ;iou: 0.715 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.727 ;Train accuracy: 0.690 ;IOU accuracy: 0.758 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.851 ;acc: 0.530 ;iou_acc: 0.620 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.804 ;acc: 0.540 ;iou_acc: 0.605 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.034 ;acc: 0.485 ;iou_acc: 0.560 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.840 ;acc: 0.555 ;iou_acc: 0.640 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.945 ;acc: 0.530 ;iou_acc: 0.605 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.829 ;acc: 0.580 ;iou_acc: 0.695 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.817 ;Test accuracy 0.551 ;IOU accuracy: 0.650 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.518 ;acc: 0.755 ;iou: 0.820 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.801 ;acc: 0.715 ;iou: 0.785 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.737 ;acc: 0.695 ;iou: 0.755 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.642 ;acc: 0.735 ;iou: 0.795 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.662 ;acc: 0.770 ;iou: 0.805 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.658 ;acc: 0.755 ;iou: 0.835 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.612 ;Train accuracy: 0.741 ;IOU accuracy: 0.804 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.820 ;acc: 0.555 ;iou_acc: 0.655 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.628 ;acc: 0.625 ;iou_acc: 0.695 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.992 ;acc: 0.485 ;iou_acc: 0.570 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.691 ;acc: 0.615 ;iou_acc: 0.730 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.749 ;acc: 0.580 ;iou_acc: 0.675 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.736 ;acc: 0.600 ;iou_acc: 0.695 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.713 ;Test accuracy 0.589 ;IOU accuracy: 0.692 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.397 ;acc: 0.815 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.338 ;acc: 0.830 ;iou: 0.885 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.581 ;acc: 0.765 ;iou: 0.835 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.491 ;acc: 0.800 ;iou: 0.870 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.440 ;acc: 0.780 ;iou: 0.840 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.499 ;acc: 0.740 ;iou: 0.850 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.474 ;Train accuracy: 0.794 ;IOU accuracy: 0.851 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.747 ;acc: 0.565 ;iou_acc: 0.670 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.535 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.865 ;acc: 0.495 ;iou_acc: 0.575 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.553 ;acc: 0.630 ;iou_acc: 0.715 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.669 ;acc: 0.610 ;iou_acc: 0.725 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.611 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.623 ;Test accuracy 0.616 ;IOU accuracy: 0.718 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.540 ;acc: 0.780 ;iou: 0.840 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.442 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.257 ;acc: 0.815 ;iou: 0.870 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.246 ;acc: 0.850 ;iou: 0.880 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.336 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.208 ;acc: 0.865 ;iou: 0.895 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.353 ;Train accuracy: 0.826 ;IOU accuracy: 0.878 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.674 ;acc: 0.625 ;iou_acc: 0.715 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.517 ;acc: 0.625 ;iou_acc: 0.715 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.841 ;acc: 0.560 ;iou_acc: 0.645 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.484 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.565 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.611 ;acc: 0.640 ;iou_acc: 0.770 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.575 ;Test accuracy 0.634 ;IOU accuracy: 0.735 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.003 ;acc: 0.880 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.048 ;acc: 0.900 ;iou: 0.920 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.257 ;acc: 0.875 ;iou: 0.930 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.342 ;acc: 0.835 ;iou: 0.875 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.455 ;acc: 0.820 ;iou: 0.885 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.289 ;acc: 0.870 ;iou: 0.890 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.258 ;Train accuracy: 0.850 ;IOU accuracy: 0.896 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.636 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.435 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.767 ;acc: 0.535 ;iou_acc: 0.615 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.446 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.584 ;acc: 0.610 ;iou_acc: 0.720 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.555 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.511 ;Test accuracy 0.648 ;IOU accuracy: 0.749 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.199 ;acc: 0.850 ;iou: 0.885 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.225 ;acc: 0.855 ;iou: 0.905 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.323 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.328 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.185 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.257 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.185 ;Train accuracy: 0.868 ;IOU accuracy: 0.910 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.560 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.431 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.697 ;acc: 0.590 ;iou_acc: 0.660 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.425 ;acc: 0.675 ;iou_acc: 0.805 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.475 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.550 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.463 ;Test accuracy 0.663 ;IOU accuracy: 0.764 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 0.970 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.401 ;acc: 0.845 ;iou: 0.890 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.138 ;acc: 0.860 ;iou: 0.880 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.249 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.261 ;acc: 0.855 ;iou: 0.905 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.193 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.119 ;Train accuracy: 0.882 ;IOU accuracy: 0.920 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.606 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.448 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.712 ;acc: 0.605 ;iou_acc: 0.690 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.490 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.523 ;acc: 0.625 ;iou_acc: 0.740 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.478 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.474 ;Test accuracy 0.664 ;IOU accuracy: 0.763 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.118 ;acc: 0.865 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 0.990 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.112 ;acc: 0.865 ;iou: 0.885 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.268 ;acc: 0.850 ;iou: 0.895 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.262 ;acc: 0.860 ;iou: 0.910 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 1.182 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.062 ;Train accuracy: 0.893 ;IOU accuracy: 0.929 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.573 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.464 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.718 ;acc: 0.570 ;iou_acc: 0.645 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.533 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.525 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.554 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.467 ;Test accuracy 0.668 ;IOU accuracy: 0.767 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.062 ;acc: 0.890 ;iou: 0.910 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.125 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.123 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 0.993 ;acc: 0.905 ;iou: 0.925 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.088 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 1.160 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.013 ;Train accuracy: 0.903 ;IOU accuracy: 0.935 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.521 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.294 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.618 ;acc: 0.595 ;iou_acc: 0.680 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.455 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.468 ;acc: 0.630 ;iou_acc: 0.745 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.608 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.438 ;Test accuracy 0.678 ;IOU accuracy: 0.776 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.881 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 0.880 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.927 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 0.924 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 0.880 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.007 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.968 ;Train accuracy: 0.914 ;IOU accuracy: 0.942 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.548 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.408 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.640 ;acc: 0.620 ;iou_acc: 0.685 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.403 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.503 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.536 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.427 ;Test accuracy 0.682 ;IOU accuracy: 0.778 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.770 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.821 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.874 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 1.076 ;acc: 0.885 ;iou: 0.935 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 0.891 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.894 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.928 ;Train accuracy: 0.921 ;IOU accuracy: 0.948 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.508 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.520 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.556 ;acc: 0.640 ;iou_acc: 0.700 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.444 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.412 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.440 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.435 ;Test accuracy 0.685 ;IOU accuracy: 0.780 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.786 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 1.096 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.757 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.968 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.845 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.996 ;acc: 0.895 ;iou: 0.920 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.886 ;Train accuracy: 0.929 ;IOU accuracy: 0.953 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.534 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.426 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.683 ;acc: 0.610 ;iou_acc: 0.670 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.569 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.623 ;acc: 0.605 ;iou_acc: 0.745 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.530 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.467 ;Test accuracy 0.681 ;IOU accuracy: 0.777 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.827 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.947 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.873 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.758 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.955 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.952 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.851 ;Train accuracy: 0.934 ;IOU accuracy: 0.956 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.484 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.387 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.634 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.441 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.403 ;acc: 0.645 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.521 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.445 ;Test accuracy 0.689 ;IOU accuracy: 0.783 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.655 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.836 ;acc: 0.950 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.764 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.845 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.812 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.737 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.817 ;Train accuracy: 0.939 ;IOU accuracy: 0.960 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.535 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.439 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.598 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.461 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.533 ;acc: 0.645 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.635 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.448 ;Test accuracy 0.691 ;IOU accuracy: 0.786 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.631 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.872 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.861 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.843 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.701 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.790 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:40\n",
      "\n",
      "*Training B: False ;B Train loss: 0.786 ;Train accuracy: 0.945 ;IOU accuracy: 0.964 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.550 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.449 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.667 ;acc: 0.630 ;iou_acc: 0.695 ;time: 0:01:02\n",
      "batch: 150 ;B loss: 1.535 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.604 ;acc: 0.615 ;iou_acc: 0.760 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.590 ;acc: 0.655 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.475 ;Test accuracy 0.688 ;IOU accuracy: 0.782 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.682 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.626 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.652 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.783 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.615 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.777 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:38\n",
      "\n",
      "*Training B: False ;B Train loss: 0.753 ;Train accuracy: 0.950 ;IOU accuracy: 0.967 ;Time: 0:00:46 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.621 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:00:47\n",
      "batch: 50 ;B loss: 1.498 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:00:54\n",
      "batch: 100 ;B loss: 1.651 ;acc: 0.655 ;iou_acc: 0.705 ;time: 0:01:01\n",
      "batch: 150 ;B loss: 1.556 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:09\n",
      "batch: 200 ;B loss: 1.660 ;acc: 0.635 ;iou_acc: 0.785 ;time: 0:01:16\n",
      "batch: 250 ;B loss: 1.583 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 1.471 ;Test accuracy 0.694 ;IOU accuracy: 0.790 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.780 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.704 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.723 ;acc: 0.950 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.769 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.818 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.928 ;acc: 0.935 ;iou: 0.940 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.730 ;Train accuracy: 0.954 ;IOU accuracy: 0.970 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.454 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.452 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.628 ;acc: 0.650 ;iou_acc: 0.710 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.497 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.659 ;acc: 0.630 ;iou_acc: 0.780 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.616 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.506 ;Test accuracy 0.691 ;IOU accuracy: 0.786 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.511 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.672 ;acc: 0.950 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.746 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.773 ;acc: 0.945 ;iou: 0.970 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.822 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.703 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.698 ;Train accuracy: 0.958 ;IOU accuracy: 0.972 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.430 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.561 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.698 ;acc: 0.660 ;iou_acc: 0.715 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.550 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.492 ;acc: 0.650 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.553 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.506 ;Test accuracy 0.694 ;IOU accuracy: 0.789 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.595 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.642 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.685 ;acc: 0.945 ;iou: 0.970 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.571 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.700 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.724 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.672 ;Train accuracy: 0.962 ;IOU accuracy: 0.975 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.399 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.529 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.667 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.510 ;acc: 0.685 ;iou_acc: 0.810 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.555 ;acc: 0.645 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.653 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.504 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.476 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.663 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.667 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.646 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.700 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.558 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.642 ;Train accuracy: 0.965 ;IOU accuracy: 0.978 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.528 ;acc: 0.715 ;iou_acc: 0.775 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.544 ;acc: 0.725 ;iou_acc: 0.790 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.723 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.655 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.657 ;acc: 0.640 ;iou_acc: 0.785 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.708 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.616 ;Test accuracy 0.687 ;IOU accuracy: 0.781 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.557 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.544 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.443 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.767 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.607 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.686 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.623 ;Train accuracy: 0.969 ;IOU accuracy: 0.980 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.565 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.533 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.815 ;acc: 0.645 ;iou_acc: 0.710 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.482 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.620 ;acc: 0.645 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.598 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.511 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.471 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.624 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.501 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.669 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.554 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.650 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.597 ;Train accuracy: 0.970 ;IOU accuracy: 0.980 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.579 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.716 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.773 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.711 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.747 ;acc: 0.680 ;iou_acc: 0.815 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.702 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.609 ;Test accuracy 0.690 ;IOU accuracy: 0.784 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.487 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.539 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.583 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.621 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.623 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.567 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.576 ;Train accuracy: 0.973 ;IOU accuracy: 0.983 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.568 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.666 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.751 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.655 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.556 ;acc: 0.660 ;iou_acc: 0.795 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.658 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.580 ;Test accuracy 0.695 ;IOU accuracy: 0.790 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.544 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.499 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.497 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.509 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.494 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.632 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.551 ;Train accuracy: 0.976 ;IOU accuracy: 0.984 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.561 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.662 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.724 ;acc: 0.695 ;iou_acc: 0.755 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.586 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.680 ;acc: 0.655 ;iou_acc: 0.800 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.742 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.598 ;Test accuracy 0.695 ;IOU accuracy: 0.789 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.442 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.436 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.569 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.696 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.422 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.642 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.532 ;Train accuracy: 0.978 ;IOU accuracy: 0.985 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.571 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.715 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.732 ;acc: 0.665 ;iou_acc: 0.720 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.580 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.833 ;acc: 0.635 ;iou_acc: 0.765 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.731 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.629 ;Test accuracy 0.697 ;IOU accuracy: 0.790 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.387 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.353 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.501 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.397 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.602 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.527 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.513 ;Train accuracy: 0.979 ;IOU accuracy: 0.986 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.638 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.702 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.861 ;acc: 0.655 ;iou_acc: 0.705 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.636 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.734 ;acc: 0.645 ;iou_acc: 0.780 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.724 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.647 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.527 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.387 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.413 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.574 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.404 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.540 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.490 ;Train accuracy: 0.981 ;IOU accuracy: 0.987 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.654 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.759 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.806 ;acc: 0.670 ;iou_acc: 0.730 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.807 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.795 ;acc: 0.640 ;iou_acc: 0.790 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.857 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.697 ;Test accuracy 0.693 ;IOU accuracy: 0.788 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.493 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.445 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.548 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.506 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.534 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.363 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.468 ;Train accuracy: 0.983 ;IOU accuracy: 0.989 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.708 ;acc: 0.705 ;iou_acc: 0.770 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.815 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.983 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.622 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.727 ;acc: 0.645 ;iou_acc: 0.790 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.876 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.679 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.328 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.396 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.368 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.460 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.421 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.451 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.451 ;Train accuracy: 0.984 ;IOU accuracy: 0.990 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.704 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.849 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.832 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.663 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.728 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.812 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.725 ;Test accuracy 0.693 ;IOU accuracy: 0.787 ;Time: 0:01:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.388 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.387 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.431 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.314 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.380 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.485 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.433 ;Train accuracy: 0.986 ;IOU accuracy: 0.991 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.656 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.707 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.002 ;acc: 0.655 ;iou_acc: 0.715 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.785 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.807 ;acc: 0.640 ;iou_acc: 0.775 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.831 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.756 ;Test accuracy 0.695 ;IOU accuracy: 0.789 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.407 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.391 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.400 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.458 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.553 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.517 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.416 ;Train accuracy: 0.986 ;IOU accuracy: 0.991 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.663 ;acc: 0.735 ;iou_acc: 0.790 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.912 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.907 ;acc: 0.670 ;iou_acc: 0.725 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.722 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.853 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.919 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.760 ;Test accuracy 0.696 ;IOU accuracy: 0.790 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.255 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.411 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.481 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.428 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.341 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.581 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.405 ;Train accuracy: 0.988 ;IOU accuracy: 0.992 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.672 ;acc: 0.730 ;iou_acc: 0.785 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.950 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.917 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.767 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.850 ;acc: 0.670 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.924 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:33\n",
      "\n",
      "*BTrain: True ;Test loss: 1.805 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.382 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.292 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.471 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.370 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.329 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.483 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.383 ;Train accuracy: 0.989 ;IOU accuracy: 0.993 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 2.000 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.952 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.853 ;acc: 0.705 ;iou_acc: 0.745 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.054 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.980 ;acc: 0.650 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.851 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.867 ;Test accuracy 0.689 ;IOU accuracy: 0.784 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.435 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.311 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.302 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.401 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.267 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.560 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.376 ;Train accuracy: 0.989 ;IOU accuracy: 0.993 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.797 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.928 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.913 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.906 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.885 ;acc: 0.670 ;iou_acc: 0.815 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.897 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.839 ;Test accuracy 0.695 ;IOU accuracy: 0.788 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.256 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.258 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.273 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.359 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.288 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.418 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.348 ;Train accuracy: 0.991 ;IOU accuracy: 0.994 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.672 ;acc: 0.735 ;iou_acc: 0.800 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.010 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.996 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.805 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.790 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.169 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 1.860 ;Test accuracy 0.695 ;IOU accuracy: 0.789 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.304 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.203 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.298 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.399 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.294 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.287 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.340 ;Train accuracy: 0.991 ;IOU accuracy: 0.994 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.664 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.049 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.097 ;acc: 0.635 ;iou_acc: 0.710 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.876 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 2.090 ;acc: 0.655 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.204 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.915 ;Test accuracy 0.690 ;IOU accuracy: 0.784 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.372 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.301 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.368 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.324 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.307 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.324 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.327 ;Train accuracy: 0.993 ;IOU accuracy: 0.995 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.852 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.006 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.008 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.910 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.080 ;acc: 0.650 ;iou_acc: 0.785 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.994 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.884 ;Test accuracy 0.696 ;IOU accuracy: 0.789 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.199 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.223 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:07\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.259 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.269 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.370 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.287 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.322 ;Train accuracy: 0.992 ;IOU accuracy: 0.995 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.786 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.003 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.130 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.974 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 2.107 ;acc: 0.640 ;iou_acc: 0.785 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.987 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.930 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.306 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.297 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.185 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.271 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.310 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.295 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.307 ;Train accuracy: 0.993 ;IOU accuracy: 0.996 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.852 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.135 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.249 ;acc: 0.645 ;iou_acc: 0.720 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.121 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 2.048 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.204 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.998 ;Test accuracy 0.691 ;IOU accuracy: 0.786 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.229 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.251 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.291 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.342 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.351 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.338 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.299 ;Train accuracy: 0.994 ;IOU accuracy: 0.996 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.780 ;acc: 0.700 ;iou_acc: 0.760 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.944 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.113 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.923 ;acc: 0.735 ;iou_acc: 0.800 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 2.036 ;acc: 0.685 ;iou_acc: 0.810 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.920 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.925 ;Test accuracy 0.697 ;IOU accuracy: 0.790 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.228 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.329 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.185 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.221 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.281 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.273 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.279 ;Train accuracy: 0.995 ;IOU accuracy: 0.996 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.770 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.156 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 2.104 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.068 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.054 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.053 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.985 ;Test accuracy 0.695 ;IOU accuracy: 0.789 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.158 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.205 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.247 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.333 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.388 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.274 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.275 ;Train accuracy: 0.994 ;IOU accuracy: 0.996 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.851 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.977 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.207 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 2.111 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.039 ;acc: 0.670 ;iou_acc: 0.800 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 2.108 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.003 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.319 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.167 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.234 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.227 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.237 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.297 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.259 ;Train accuracy: 0.995 ;IOU accuracy: 0.997 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.845 ;acc: 0.695 ;iou_acc: 0.745 ;time: 0:00:48\n",
      "batch: 50 ;B loss: 2.156 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.990 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 2.061 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 2.142 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 2.187 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.046 ;Test accuracy 0.694 ;IOU accuracy: 0.789 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.273 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.219 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:07\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.324 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.310 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.208 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.304 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:40\n",
      "\n",
      "*Training B: True ;B Train loss: 0.259 ;Train accuracy: 0.995 ;IOU accuracy: 0.997 ;Time: 0:00:47 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.925 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:00:48\n",
      "batch: 50 ;B loss: 2.120 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:00:55\n",
      "batch: 100 ;B loss: 2.028 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:01\n",
      "batch: 150 ;B loss: 2.132 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:09\n",
      "batch: 200 ;B loss: 2.128 ;acc: 0.685 ;iou_acc: 0.810 ;time: 0:01:16\n",
      "batch: 250 ;B loss: 2.146 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:23\n",
      "\n",
      "*BTrain: True ;Test loss: 2.029 ;Test accuracy 0.693 ;IOU accuracy: 0.787 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.226 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.239 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.220 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.345 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.221 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.267 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.236 ;Train accuracy: 0.996 ;IOU accuracy: 0.998 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.815 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 2.088 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.090 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.180 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 2.238 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 2.089 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 2.056 ;Test accuracy 0.696 ;IOU accuracy: 0.791 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 0.5\n",
      "dropout_out 0.5\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_0.5,0.5_hidden:50\n",
      "num_hidden: 50\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.674 ;acc: 0.385 ;iou: 0.430 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.649 ;acc: 0.315 ;iou: 0.410 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.711 ;acc: 0.280 ;iou: 0.350 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.681 ;acc: 0.285 ;iou: 0.420 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.552 ;acc: 0.415 ;iou: 0.520 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.555 ;acc: 0.360 ;iou: 0.405 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 2.621 ;Train accuracy: 0.311 ;IOU accuracy: 0.415 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.440 ;acc: 0.300 ;iou_acc: 0.365 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.495 ;acc: 0.310 ;iou_acc: 0.405 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.578 ;acc: 0.290 ;iou_acc: 0.410 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.483 ;acc: 0.325 ;iou_acc: 0.420 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 2.454 ;acc: 0.360 ;iou_acc: 0.455 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.474 ;acc: 0.385 ;iou_acc: 0.510 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 2.457 ;Test accuracy 0.334 ;IOU accuracy: 0.441 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.348 ;acc: 0.420 ;iou: 0.530 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.495 ;acc: 0.400 ;iou: 0.510 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.423 ;acc: 0.345 ;iou: 0.465 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.310 ;acc: 0.455 ;iou: 0.525 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.477 ;acc: 0.370 ;iou: 0.495 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.193 ;acc: 0.490 ;iou: 0.625 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 2.365 ;Train accuracy: 0.421 ;IOU accuracy: 0.521 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.288 ;acc: 0.355 ;iou_acc: 0.440 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.328 ;acc: 0.390 ;iou_acc: 0.465 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.385 ;acc: 0.405 ;iou_acc: 0.510 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.277 ;acc: 0.385 ;iou_acc: 0.495 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.266 ;acc: 0.430 ;iou_acc: 0.525 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.270 ;acc: 0.445 ;iou_acc: 0.545 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 2.265 ;Test accuracy 0.408 ;IOU accuracy: 0.513 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.328 ;acc: 0.485 ;iou: 0.560 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.195 ;acc: 0.505 ;iou: 0.545 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.239 ;acc: 0.500 ;iou: 0.590 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.060 ;acc: 0.580 ;iou: 0.675 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.133 ;acc: 0.510 ;iou: 0.610 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.086 ;acc: 0.505 ;iou: 0.590 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 2.189 ;Train accuracy: 0.502 ;IOU accuracy: 0.591 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.175 ;acc: 0.455 ;iou_acc: 0.555 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 2.157 ;acc: 0.460 ;iou_acc: 0.535 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.253 ;acc: 0.445 ;iou_acc: 0.525 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 2.162 ;acc: 0.425 ;iou_acc: 0.540 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 2.147 ;acc: 0.425 ;iou_acc: 0.585 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.137 ;acc: 0.480 ;iou_acc: 0.585 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 2.113 ;Test accuracy 0.458 ;IOU accuracy: 0.562 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.234 ;acc: 0.520 ;iou: 0.585 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.063 ;acc: 0.575 ;iou: 0.665 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.977 ;acc: 0.575 ;iou: 0.630 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 2.033 ;acc: 0.570 ;iou: 0.655 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 2.031 ;acc: 0.535 ;iou: 0.665 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.916 ;acc: 0.535 ;iou: 0.620 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 2.048 ;Train accuracy: 0.546 ;IOU accuracy: 0.639 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 2.087 ;acc: 0.465 ;iou_acc: 0.550 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 2.123 ;acc: 0.455 ;iou_acc: 0.540 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.154 ;acc: 0.450 ;iou_acc: 0.555 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.104 ;acc: 0.480 ;iou_acc: 0.600 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 2.123 ;acc: 0.435 ;iou_acc: 0.545 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.009 ;acc: 0.500 ;iou_acc: 0.625 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 2.016 ;Test accuracy 0.488 ;IOU accuracy: 0.590 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.856 ;acc: 0.615 ;iou: 0.665 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.804 ;acc: 0.640 ;iou: 0.705 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.922 ;acc: 0.550 ;iou: 0.690 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.990 ;acc: 0.575 ;iou: 0.705 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.997 ;acc: 0.545 ;iou: 0.690 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.885 ;acc: 0.595 ;iou: 0.695 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.942 ;Train accuracy: 0.584 ;IOU accuracy: 0.667 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.923 ;acc: 0.500 ;iou_acc: 0.580 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.953 ;acc: 0.510 ;iou_acc: 0.610 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.061 ;acc: 0.460 ;iou_acc: 0.550 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.995 ;acc: 0.450 ;iou_acc: 0.555 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.958 ;acc: 0.545 ;iou_acc: 0.640 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.955 ;acc: 0.495 ;iou_acc: 0.615 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.924 ;Test accuracy 0.515 ;IOU accuracy: 0.614 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.841 ;acc: 0.600 ;iou: 0.665 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.854 ;acc: 0.615 ;iou: 0.690 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.817 ;acc: 0.630 ;iou: 0.700 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.969 ;acc: 0.575 ;iou: 0.655 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.800 ;acc: 0.605 ;iou: 0.735 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.763 ;acc: 0.655 ;iou: 0.740 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.860 ;Train accuracy: 0.615 ;IOU accuracy: 0.692 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.923 ;acc: 0.515 ;iou_acc: 0.585 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.933 ;acc: 0.485 ;iou_acc: 0.555 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.015 ;acc: 0.535 ;iou_acc: 0.615 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.972 ;acc: 0.460 ;iou_acc: 0.575 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.887 ;acc: 0.535 ;iou_acc: 0.645 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.917 ;acc: 0.535 ;iou_acc: 0.650 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.877 ;Test accuracy 0.529 ;IOU accuracy: 0.626 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.688 ;acc: 0.640 ;iou: 0.685 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.816 ;acc: 0.630 ;iou: 0.680 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.832 ;acc: 0.625 ;iou: 0.740 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.887 ;acc: 0.625 ;iou: 0.705 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.736 ;acc: 0.665 ;iou: 0.740 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.777 ;acc: 0.675 ;iou: 0.775 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.784 ;Train accuracy: 0.640 ;IOU accuracy: 0.714 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.802 ;acc: 0.545 ;iou_acc: 0.650 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.861 ;acc: 0.515 ;iou_acc: 0.615 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.924 ;acc: 0.545 ;iou_acc: 0.620 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.916 ;acc: 0.520 ;iou_acc: 0.625 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.814 ;acc: 0.535 ;iou_acc: 0.630 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.812 ;acc: 0.580 ;iou_acc: 0.685 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.815 ;Test accuracy 0.546 ;IOU accuracy: 0.643 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.713 ;acc: 0.690 ;iou: 0.700 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.671 ;acc: 0.640 ;iou: 0.730 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.918 ;acc: 0.635 ;iou: 0.615 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.701 ;acc: 0.665 ;iou: 0.700 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.788 ;acc: 0.685 ;iou: 0.790 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.517 ;acc: 0.755 ;iou: 0.800 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.715 ;Train accuracy: 0.669 ;IOU accuracy: 0.741 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.752 ;acc: 0.575 ;iou_acc: 0.655 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.751 ;acc: 0.550 ;iou_acc: 0.650 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.992 ;acc: 0.475 ;iou_acc: 0.570 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.837 ;acc: 0.525 ;iou_acc: 0.645 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.761 ;acc: 0.605 ;iou_acc: 0.685 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.819 ;acc: 0.595 ;iou_acc: 0.705 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.775 ;Test accuracy 0.563 ;IOU accuracy: 0.660 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.667 ;acc: 0.755 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.723 ;acc: 0.675 ;iou: 0.765 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.657 ;acc: 0.710 ;iou: 0.745 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.702 ;acc: 0.710 ;iou: 0.775 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.660 ;acc: 0.710 ;iou: 0.785 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.618 ;acc: 0.725 ;iou: 0.805 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.632 ;Train accuracy: 0.706 ;IOU accuracy: 0.772 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.727 ;acc: 0.595 ;iou_acc: 0.685 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.690 ;acc: 0.585 ;iou_acc: 0.645 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.921 ;acc: 0.515 ;iou_acc: 0.600 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.821 ;acc: 0.530 ;iou_acc: 0.650 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.707 ;acc: 0.595 ;iou_acc: 0.700 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.735 ;acc: 0.595 ;iou_acc: 0.710 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.710 ;Test accuracy 0.586 ;IOU accuracy: 0.687 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.537 ;acc: 0.720 ;iou: 0.830 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.669 ;acc: 0.720 ;iou: 0.800 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.535 ;acc: 0.725 ;iou: 0.850 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.263 ;acc: 0.810 ;iou: 0.835 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.551 ;acc: 0.730 ;iou: 0.810 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.535 ;acc: 0.745 ;iou: 0.855 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.533 ;Train accuracy: 0.743 ;IOU accuracy: 0.807 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.688 ;acc: 0.595 ;iou_acc: 0.680 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.578 ;acc: 0.615 ;iou_acc: 0.720 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.743 ;acc: 0.570 ;iou_acc: 0.660 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.666 ;acc: 0.615 ;iou_acc: 0.750 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.572 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.667 ;acc: 0.605 ;iou_acc: 0.715 ;time: 0:01:33\n",
      "\n",
      "*BTrain: True ;Test loss: 1.591 ;Test accuracy 0.623 ;IOU accuracy: 0.724 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.457 ;acc: 0.730 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.444 ;acc: 0.750 ;iou: 0.835 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.493 ;acc: 0.770 ;iou: 0.815 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.553 ;acc: 0.680 ;iou: 0.765 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.555 ;acc: 0.745 ;iou: 0.800 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.280 ;acc: 0.770 ;iou: 0.840 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.450 ;Train accuracy: 0.764 ;IOU accuracy: 0.829 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.675 ;acc: 0.605 ;iou_acc: 0.680 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.552 ;acc: 0.630 ;iou_acc: 0.725 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.845 ;acc: 0.590 ;iou_acc: 0.655 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.617 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.582 ;acc: 0.635 ;iou_acc: 0.760 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.645 ;acc: 0.620 ;iou_acc: 0.735 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.561 ;Test accuracy 0.634 ;IOU accuracy: 0.737 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.168 ;acc: 0.875 ;iou: 0.895 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.247 ;acc: 0.830 ;iou: 0.860 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.235 ;acc: 0.795 ;iou: 0.885 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.505 ;acc: 0.770 ;iou: 0.820 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.516 ;acc: 0.775 ;iou: 0.850 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.395 ;acc: 0.760 ;iou: 0.850 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.373 ;Train accuracy: 0.786 ;IOU accuracy: 0.847 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.547 ;acc: 0.625 ;iou_acc: 0.720 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.513 ;acc: 0.630 ;iou_acc: 0.740 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.753 ;acc: 0.580 ;iou_acc: 0.660 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.600 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.525 ;acc: 0.630 ;iou_acc: 0.745 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.577 ;acc: 0.635 ;iou_acc: 0.745 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.495 ;Test accuracy 0.651 ;IOU accuracy: 0.750 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.264 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 1.422 ;acc: 0.760 ;iou: 0.870 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.079 ;acc: 0.815 ;iou: 0.890 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.365 ;acc: 0.790 ;iou: 0.850 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.538 ;acc: 0.765 ;iou: 0.775 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 1.370 ;acc: 0.800 ;iou: 0.820 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 1.319 ;Train accuracy: 0.796 ;IOU accuracy: 0.856 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.597 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.470 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.724 ;acc: 0.580 ;iou_acc: 0.660 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.505 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.500 ;acc: 0.610 ;iou_acc: 0.735 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.579 ;acc: 0.645 ;iou_acc: 0.755 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.461 ;Test accuracy 0.662 ;IOU accuracy: 0.759 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.206 ;acc: 0.845 ;iou: 0.895 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.255 ;acc: 0.865 ;iou: 0.880 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.420 ;acc: 0.790 ;iou: 0.835 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 1.186 ;acc: 0.810 ;iou: 0.865 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.319 ;acc: 0.775 ;iou: 0.855 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 1.385 ;acc: 0.775 ;iou: 0.805 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.270 ;Train accuracy: 0.811 ;IOU accuracy: 0.867 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.524 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.449 ;acc: 0.645 ;iou_acc: 0.740 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.737 ;acc: 0.610 ;iou_acc: 0.700 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.543 ;acc: 0.640 ;iou_acc: 0.740 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.504 ;acc: 0.610 ;iou_acc: 0.740 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.568 ;acc: 0.640 ;iou_acc: 0.755 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.456 ;Test accuracy 0.665 ;IOU accuracy: 0.762 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 1.150 ;acc: 0.850 ;iou: 0.860 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.297 ;acc: 0.800 ;iou: 0.865 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 1.287 ;acc: 0.815 ;iou: 0.855 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 1.444 ;acc: 0.730 ;iou: 0.840 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.394 ;acc: 0.790 ;iou: 0.865 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.036 ;acc: 0.860 ;iou: 0.910 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.231 ;Train accuracy: 0.815 ;IOU accuracy: 0.870 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.531 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.509 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.671 ;acc: 0.600 ;iou_acc: 0.680 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.520 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.467 ;acc: 0.640 ;iou_acc: 0.780 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.560 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.433 ;Test accuracy 0.672 ;IOU accuracy: 0.769 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 1.031 ;acc: 0.855 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 1.278 ;acc: 0.840 ;iou: 0.880 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 1.405 ;acc: 0.800 ;iou: 0.860 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 1.145 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.130 ;acc: 0.830 ;iou: 0.895 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 1.177 ;acc: 0.805 ;iou: 0.855 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 1.188 ;Train accuracy: 0.829 ;IOU accuracy: 0.880 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.508 ;acc: 0.640 ;iou_acc: 0.720 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.395 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.616 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.478 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.465 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.504 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.408 ;Test accuracy 0.676 ;IOU accuracy: 0.770 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 1.079 ;acc: 0.875 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 1.189 ;acc: 0.820 ;iou: 0.870 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 1.188 ;acc: 0.815 ;iou: 0.875 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 1.051 ;acc: 0.820 ;iou: 0.880 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 1.375 ;acc: 0.810 ;iou: 0.905 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 1.132 ;acc: 0.875 ;iou: 0.880 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 1.153 ;Train accuracy: 0.835 ;IOU accuracy: 0.885 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.471 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.376 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.593 ;acc: 0.635 ;iou_acc: 0.705 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.465 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.384 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.452 ;acc: 0.640 ;iou_acc: 0.770 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.394 ;Test accuracy 0.682 ;IOU accuracy: 0.776 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 1.015 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 1.037 ;acc: 0.860 ;iou: 0.915 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 1.136 ;acc: 0.805 ;iou: 0.900 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 1.073 ;acc: 0.845 ;iou: 0.905 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 1.096 ;acc: 0.825 ;iou: 0.885 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 1.026 ;acc: 0.850 ;iou: 0.925 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.125 ;Train accuracy: 0.841 ;IOU accuracy: 0.888 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.491 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.318 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.641 ;acc: 0.605 ;iou_acc: 0.670 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.425 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.359 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.502 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.394 ;Test accuracy 0.682 ;IOU accuracy: 0.778 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.845 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 1.202 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 1.240 ;acc: 0.800 ;iou: 0.915 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 1.212 ;acc: 0.825 ;iou: 0.880 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 1.303 ;acc: 0.810 ;iou: 0.845 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 1.041 ;acc: 0.885 ;iou: 0.935 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.099 ;Train accuracy: 0.846 ;IOU accuracy: 0.895 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.486 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.365 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.654 ;acc: 0.630 ;iou_acc: 0.695 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.406 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.386 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.531 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.391 ;Test accuracy 0.686 ;IOU accuracy: 0.780 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.869 ;acc: 0.875 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 1.098 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 1.083 ;acc: 0.895 ;iou: 0.905 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 1.095 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 1.148 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 1.238 ;acc: 0.810 ;iou: 0.845 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.077 ;Train accuracy: 0.854 ;IOU accuracy: 0.897 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.544 ;acc: 0.695 ;iou_acc: 0.755 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.406 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.673 ;acc: 0.640 ;iou_acc: 0.725 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.396 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.370 ;acc: 0.660 ;iou_acc: 0.790 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.474 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.399 ;Test accuracy 0.688 ;IOU accuracy: 0.781 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 1.018 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 1.023 ;acc: 0.870 ;iou: 0.870 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 1.284 ;acc: 0.800 ;iou: 0.870 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 1.165 ;acc: 0.865 ;iou: 0.870 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 1.093 ;acc: 0.855 ;iou: 0.885 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 1.036 ;acc: 0.860 ;iou: 0.880 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.046 ;Train accuracy: 0.857 ;IOU accuracy: 0.899 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.523 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.396 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.657 ;acc: 0.625 ;iou_acc: 0.710 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.427 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.448 ;acc: 0.670 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.513 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.403 ;Test accuracy 0.685 ;IOU accuracy: 0.779 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 1.124 ;acc: 0.865 ;iou: 0.890 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.930 ;acc: 0.870 ;iou: 0.915 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 1.104 ;acc: 0.890 ;iou: 0.875 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.997 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.988 ;acc: 0.870 ;iou: 0.910 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 1.113 ;acc: 0.860 ;iou: 0.885 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.023 ;Train accuracy: 0.863 ;IOU accuracy: 0.904 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.497 ;acc: 0.705 ;iou_acc: 0.770 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.382 ;acc: 0.655 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.550 ;acc: 0.670 ;iou_acc: 0.730 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.497 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.401 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.557 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.394 ;Test accuracy 0.689 ;IOU accuracy: 0.782 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.970 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 1.057 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 1.017 ;acc: 0.860 ;iou: 0.915 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 1.043 ;acc: 0.885 ;iou: 0.945 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.756 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.941 ;acc: 0.875 ;iou: 0.940 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.000 ;Train accuracy: 0.868 ;IOU accuracy: 0.907 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.547 ;acc: 0.685 ;iou_acc: 0.740 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.425 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.630 ;acc: 0.615 ;iou_acc: 0.700 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.456 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.420 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.526 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.405 ;Test accuracy 0.690 ;IOU accuracy: 0.783 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 1.040 ;acc: 0.835 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 1.061 ;acc: 0.845 ;iou: 0.885 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 1.033 ;acc: 0.815 ;iou: 0.865 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.949 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.928 ;acc: 0.870 ;iou: 0.925 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.989 ;acc: 0.885 ;iou: 0.905 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.974 ;Train accuracy: 0.872 ;IOU accuracy: 0.911 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.514 ;acc: 0.655 ;iou_acc: 0.720 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.454 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.537 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.540 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.327 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.510 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.391 ;Test accuracy 0.692 ;IOU accuracy: 0.784 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.984 ;acc: 0.860 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 1.093 ;acc: 0.855 ;iou: 0.935 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.976 ;acc: 0.860 ;iou: 0.940 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.904 ;acc: 0.855 ;iou: 0.915 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.884 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.873 ;acc: 0.905 ;iou: 0.915 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.965 ;Train accuracy: 0.876 ;IOU accuracy: 0.913 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.443 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.332 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.626 ;acc: 0.630 ;iou_acc: 0.705 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.527 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.402 ;acc: 0.680 ;iou_acc: 0.820 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.462 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.379 ;Test accuracy 0.695 ;IOU accuracy: 0.787 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.932 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.750 ;acc: 0.925 ;iou: 0.930 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.780 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.864 ;acc: 0.870 ;iou: 0.920 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.987 ;acc: 0.870 ;iou: 0.935 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.907 ;acc: 0.880 ;iou: 0.955 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.946 ;Train accuracy: 0.878 ;IOU accuracy: 0.914 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.464 ;acc: 0.710 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.303 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.610 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.447 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.387 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.531 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.385 ;Test accuracy 0.698 ;IOU accuracy: 0.789 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.872 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.866 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.873 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.814 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 1.034 ;acc: 0.855 ;iou: 0.910 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 1.098 ;acc: 0.830 ;iou: 0.900 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.925 ;Train accuracy: 0.883 ;IOU accuracy: 0.919 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.459 ;acc: 0.695 ;iou_acc: 0.755 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.429 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.556 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.468 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.426 ;acc: 0.660 ;iou_acc: 0.810 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.608 ;acc: 0.635 ;iou_acc: 0.755 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.416 ;Test accuracy 0.695 ;IOU accuracy: 0.788 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.879 ;acc: 0.850 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.831 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.983 ;acc: 0.910 ;iou: 0.925 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.813 ;acc: 0.865 ;iou: 0.945 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.925 ;acc: 0.890 ;iou: 0.890 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.895 ;iou: 0.910 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.910 ;Train accuracy: 0.886 ;IOU accuracy: 0.921 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.456 ;acc: 0.725 ;iou_acc: 0.785 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.417 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.629 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.513 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.369 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.559 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.420 ;Test accuracy 0.694 ;IOU accuracy: 0.785 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.829 ;acc: 0.920 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.778 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.722 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.883 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 1.004 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.913 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.896 ;Train accuracy: 0.890 ;IOU accuracy: 0.924 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.506 ;acc: 0.710 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.380 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.606 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.516 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.432 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.569 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.415 ;Test accuracy 0.698 ;IOU accuracy: 0.789 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.796 ;acc: 0.905 ;iou: 0.915 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.771 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.762 ;acc: 0.895 ;iou: 0.955 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.960 ;acc: 0.875 ;iou: 0.930 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 1.126 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 1.114 ;acc: 0.860 ;iou: 0.890 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.876 ;Train accuracy: 0.893 ;IOU accuracy: 0.925 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.558 ;acc: 0.695 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.471 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.688 ;acc: 0.645 ;iou_acc: 0.720 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.598 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.508 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.612 ;acc: 0.635 ;iou_acc: 0.760 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.461 ;Test accuracy 0.688 ;IOU accuracy: 0.782 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 1.040 ;acc: 0.880 ;iou: 0.895 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.791 ;acc: 0.900 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.965 ;acc: 0.895 ;iou: 0.905 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.667 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.872 ;acc: 0.830 ;iou: 0.950 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.973 ;acc: 0.850 ;iou: 0.915 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.860 ;Train accuracy: 0.895 ;IOU accuracy: 0.928 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.493 ;acc: 0.685 ;iou_acc: 0.745 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.471 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.672 ;acc: 0.635 ;iou_acc: 0.720 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.557 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.359 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.624 ;acc: 0.630 ;iou_acc: 0.750 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.429 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.994 ;acc: 0.875 ;iou: 0.880 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.972 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.846 ;acc: 0.850 ;iou: 0.895 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.917 ;acc: 0.910 ;iou: 0.915 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.749 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.908 ;acc: 0.925 ;iou: 0.930 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.850 ;Train accuracy: 0.898 ;IOU accuracy: 0.929 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.483 ;acc: 0.705 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.405 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.534 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.579 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.444 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.589 ;acc: 0.640 ;iou_acc: 0.785 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.422 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.801 ;acc: 0.880 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.692 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.784 ;acc: 0.890 ;iou: 0.950 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.855 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.823 ;acc: 0.920 ;iou: 0.925 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.802 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.831 ;Train accuracy: 0.901 ;IOU accuracy: 0.932 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.448 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.378 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.632 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.512 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.424 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.545 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.442 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.791 ;acc: 0.895 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.838 ;acc: 0.880 ;iou: 0.940 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.751 ;acc: 0.920 ;iou: 0.925 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.858 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.828 ;acc: 0.875 ;iou: 0.940 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.701 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.820 ;Train accuracy: 0.904 ;IOU accuracy: 0.933 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.633 ;acc: 0.670 ;iou_acc: 0.730 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.363 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.594 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.648 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.458 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.588 ;acc: 0.635 ;iou_acc: 0.755 ;time: 0:01:33\n",
      "\n",
      "*BTrain: True ;Test loss: 1.440 ;Test accuracy 0.698 ;IOU accuracy: 0.789 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.837 ;acc: 0.855 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.828 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.815 ;acc: 0.910 ;iou: 0.915 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.690 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.806 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.837 ;acc: 0.880 ;iou: 0.895 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.812 ;Train accuracy: 0.906 ;IOU accuracy: 0.935 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.503 ;acc: 0.705 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.405 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.671 ;acc: 0.655 ;iou_acc: 0.715 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.502 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.412 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.603 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.446 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.826 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.807 ;acc: 0.940 ;iou: 0.930 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.755 ;acc: 0.940 ;iou: 0.940 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.775 ;acc: 0.920 ;iou: 0.920 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.926 ;acc: 0.930 ;iou: 0.935 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.786 ;acc: 0.935 ;iou: 0.935 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.794 ;Train accuracy: 0.909 ;IOU accuracy: 0.935 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.516 ;acc: 0.695 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.439 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.647 ;acc: 0.655 ;iou_acc: 0.720 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.602 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.491 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.569 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.465 ;Test accuracy 0.696 ;IOU accuracy: 0.788 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.708 ;acc: 0.935 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.682 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.838 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.868 ;acc: 0.905 ;iou: 0.950 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.819 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.777 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.779 ;Train accuracy: 0.912 ;IOU accuracy: 0.939 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.575 ;acc: 0.725 ;iou_acc: 0.780 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.407 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.652 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.594 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.433 ;acc: 0.690 ;iou_acc: 0.825 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.638 ;acc: 0.630 ;iou_acc: 0.750 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.460 ;Test accuracy 0.696 ;IOU accuracy: 0.787 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.639 ;acc: 0.945 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.762 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.733 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.822 ;acc: 0.885 ;iou: 0.945 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.629 ;acc: 0.900 ;iou: 0.965 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.786 ;acc: 0.890 ;iou: 0.910 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.761 ;Train accuracy: 0.913 ;IOU accuracy: 0.939 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.580 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.481 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.729 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.572 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.490 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.604 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.480 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.750 ;acc: 0.945 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.874 ;acc: 0.905 ;iou: 0.930 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.794 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.755 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.861 ;acc: 0.915 ;iou: 0.930 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.631 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.749 ;Train accuracy: 0.917 ;IOU accuracy: 0.943 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.581 ;acc: 0.685 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.471 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.660 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.641 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.484 ;acc: 0.695 ;iou_acc: 0.820 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.549 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.478 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.606 ;acc: 0.900 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.630 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.675 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.731 ;acc: 0.925 ;iou: 0.920 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.901 ;acc: 0.900 ;iou: 0.915 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.896 ;acc: 0.910 ;iou: 0.920 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.737 ;Train accuracy: 0.919 ;IOU accuracy: 0.943 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.582 ;acc: 0.690 ;iou_acc: 0.745 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.431 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.672 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.539 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.500 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.585 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:27\n",
      "\n",
      "*BTrain: True ;Test loss: 1.463 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.812 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.688 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.768 ;acc: 0.930 ;iou: 0.925 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.555 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.850 ;acc: 0.925 ;iou: 0.905 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.783 ;acc: 0.930 ;iou: 0.940 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.732 ;Train accuracy: 0.921 ;IOU accuracy: 0.944 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.668 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.457 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.684 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.583 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.474 ;acc: 0.665 ;iou_acc: 0.810 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.614 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.508 ;Test accuracy 0.695 ;IOU accuracy: 0.787 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.684 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.561 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.864 ;acc: 0.900 ;iou: 0.925 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.764 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.619 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.873 ;acc: 0.900 ;iou: 0.950 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.716 ;Train accuracy: 0.922 ;IOU accuracy: 0.946 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.521 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.476 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.755 ;acc: 0.645 ;iou_acc: 0.705 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.640 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.552 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.727 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.538 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.631 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.593 ;acc: 0.940 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.703 ;acc: 0.955 ;iou: 0.955 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.809 ;acc: 0.865 ;iou: 0.905 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.757 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.969 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.710 ;Train accuracy: 0.924 ;IOU accuracy: 0.947 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.691 ;acc: 0.685 ;iou_acc: 0.735 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.480 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.760 ;acc: 0.655 ;iou_acc: 0.720 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.670 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.493 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.682 ;acc: 0.640 ;iou_acc: 0.750 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.521 ;Test accuracy 0.695 ;IOU accuracy: 0.787 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.570 ;acc: 0.915 ;iou: 0.965 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.642 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.570 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.805 ;acc: 0.890 ;iou: 0.920 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.753 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.670 ;acc: 0.915 ;iou: 0.925 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.693 ;Train accuracy: 0.928 ;IOU accuracy: 0.949 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.681 ;acc: 0.690 ;iou_acc: 0.740 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.567 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.660 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.609 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.516 ;acc: 0.655 ;iou_acc: 0.800 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.659 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.538 ;Test accuracy 0.697 ;IOU accuracy: 0.788 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.727 ;acc: 0.930 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.630 ;acc: 0.920 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.707 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.653 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.658 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.774 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.688 ;Train accuracy: 0.930 ;IOU accuracy: 0.951 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.522 ;acc: 0.715 ;iou_acc: 0.775 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.567 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.837 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.672 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.523 ;acc: 0.710 ;iou_acc: 0.830 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.640 ;acc: 0.670 ;iou_acc: 0.800 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.581 ;Test accuracy 0.695 ;IOU accuracy: 0.788 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.617 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.705 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.606 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.661 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.568 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.718 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.676 ;Train accuracy: 0.931 ;IOU accuracy: 0.951 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.671 ;acc: 0.705 ;iou_acc: 0.760 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.470 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.868 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.671 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.509 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.669 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.564 ;Test accuracy 0.698 ;IOU accuracy: 0.789 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.843 ;acc: 0.920 ;iou: 0.915 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.493 ;acc: 0.965 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.630 ;acc: 0.945 ;iou: 0.950 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.679 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.721 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.901 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.660 ;Train accuracy: 0.932 ;IOU accuracy: 0.953 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.621 ;acc: 0.705 ;iou_acc: 0.760 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.530 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.716 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.620 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.525 ;acc: 0.675 ;iou_acc: 0.810 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.656 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.559 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.521 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.680 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.654 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.702 ;acc: 0.925 ;iou: 0.970 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.727 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.715 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.658 ;Train accuracy: 0.933 ;IOU accuracy: 0.954 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.593 ;acc: 0.705 ;iou_acc: 0.765 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.583 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.794 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.625 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.663 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.820 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.570 ;Test accuracy 0.696 ;IOU accuracy: 0.789 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.597 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.495 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.646 ;acc: 0.945 ;iou: 0.970 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.769 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.729 ;acc: 0.915 ;iou: 0.920 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.596 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.647 ;Train accuracy: 0.936 ;IOU accuracy: 0.956 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.576 ;acc: 0.700 ;iou_acc: 0.750 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.444 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.712 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.595 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.647 ;acc: 0.645 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.681 ;acc: 0.655 ;iou_acc: 0.780 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.567 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.580 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.642 ;acc: 0.935 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.501 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.515 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.587 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.592 ;acc: 0.945 ;iou: 0.945 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.631 ;Train accuracy: 0.936 ;IOU accuracy: 0.956 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.680 ;acc: 0.695 ;iou_acc: 0.745 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.621 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.901 ;acc: 0.620 ;iou_acc: 0.690 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.661 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.586 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.774 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.646 ;Test accuracy 0.690 ;IOU accuracy: 0.782 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 0.5\n",
      "dropout_out 1.0\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_0.5,1.0_hidden:100\n",
      "num_hidden: 100\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.920 ;acc: 0.360 ;iou: 0.435 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.685 ;acc: 0.255 ;iou: 0.375 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.712 ;acc: 0.335 ;iou: 0.435 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.632 ;acc: 0.355 ;iou: 0.470 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.462 ;acc: 0.420 ;iou: 0.520 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.555 ;acc: 0.370 ;iou: 0.425 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 2.609 ;Train accuracy: 0.340 ;IOU accuracy: 0.439 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.439 ;acc: 0.345 ;iou_acc: 0.420 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 2.451 ;acc: 0.330 ;iou_acc: 0.460 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 2.554 ;acc: 0.305 ;iou_acc: 0.400 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.466 ;acc: 0.365 ;iou_acc: 0.435 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 2.438 ;acc: 0.330 ;iou_acc: 0.415 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.485 ;acc: 0.320 ;iou_acc: 0.475 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 2.432 ;Test accuracy 0.342 ;IOU accuracy: 0.449 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.348 ;acc: 0.415 ;iou: 0.515 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.366 ;acc: 0.425 ;iou: 0.480 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.284 ;acc: 0.465 ;iou: 0.555 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.156 ;acc: 0.535 ;iou: 0.570 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.159 ;acc: 0.475 ;iou: 0.605 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.269 ;acc: 0.495 ;iou: 0.565 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 2.333 ;Train accuracy: 0.449 ;IOU accuracy: 0.543 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.281 ;acc: 0.400 ;iou_acc: 0.490 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 2.288 ;acc: 0.420 ;iou_acc: 0.520 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.432 ;acc: 0.370 ;iou_acc: 0.465 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 2.268 ;acc: 0.420 ;iou_acc: 0.490 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 2.278 ;acc: 0.405 ;iou_acc: 0.520 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 2.298 ;acc: 0.405 ;iou_acc: 0.510 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 2.232 ;Test accuracy 0.419 ;IOU accuracy: 0.527 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.090 ;acc: 0.515 ;iou: 0.555 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.169 ;acc: 0.530 ;iou: 0.625 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.157 ;acc: 0.545 ;iou: 0.605 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.122 ;acc: 0.545 ;iou: 0.590 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.059 ;acc: 0.565 ;iou: 0.630 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 1.964 ;acc: 0.595 ;iou: 0.710 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 2.144 ;Train accuracy: 0.532 ;IOU accuracy: 0.618 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.085 ;acc: 0.475 ;iou_acc: 0.575 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.053 ;acc: 0.485 ;iou_acc: 0.600 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 2.216 ;acc: 0.440 ;iou_acc: 0.535 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.083 ;acc: 0.470 ;iou_acc: 0.550 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 2.120 ;acc: 0.435 ;iou_acc: 0.570 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.133 ;acc: 0.465 ;iou_acc: 0.575 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 2.066 ;Test accuracy 0.473 ;IOU accuracy: 0.576 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.126 ;acc: 0.535 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.078 ;acc: 0.555 ;iou: 0.715 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 2.022 ;acc: 0.575 ;iou: 0.655 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.940 ;acc: 0.595 ;iou: 0.650 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.861 ;acc: 0.580 ;iou: 0.700 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 2.066 ;acc: 0.550 ;iou: 0.640 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 1.978 ;Train accuracy: 0.585 ;IOU accuracy: 0.665 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 2.011 ;acc: 0.490 ;iou_acc: 0.575 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.952 ;acc: 0.530 ;iou_acc: 0.620 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.090 ;acc: 0.460 ;iou_acc: 0.565 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.970 ;acc: 0.530 ;iou_acc: 0.590 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.991 ;acc: 0.480 ;iou_acc: 0.595 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.999 ;acc: 0.510 ;iou_acc: 0.620 ;time: 0:01:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.941 ;Test accuracy 0.514 ;IOU accuracy: 0.614 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.891 ;acc: 0.620 ;iou: 0.730 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.962 ;acc: 0.595 ;iou: 0.650 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.923 ;acc: 0.585 ;iou: 0.700 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.767 ;acc: 0.645 ;iou: 0.715 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.891 ;acc: 0.590 ;iou: 0.695 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.868 ;acc: 0.615 ;iou: 0.665 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.865 ;Train accuracy: 0.625 ;IOU accuracy: 0.700 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.949 ;acc: 0.515 ;iou_acc: 0.625 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.914 ;acc: 0.525 ;iou_acc: 0.610 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.037 ;acc: 0.490 ;iou_acc: 0.610 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.002 ;acc: 0.520 ;iou_acc: 0.590 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 2.019 ;acc: 0.480 ;iou_acc: 0.600 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.961 ;acc: 0.505 ;iou_acc: 0.625 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.880 ;Test accuracy 0.530 ;IOU accuracy: 0.631 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.828 ;acc: 0.655 ;iou: 0.715 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.751 ;acc: 0.635 ;iou: 0.720 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.772 ;acc: 0.675 ;iou: 0.725 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.758 ;acc: 0.635 ;iou: 0.700 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.692 ;acc: 0.605 ;iou: 0.700 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.697 ;acc: 0.670 ;iou: 0.740 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.764 ;Train accuracy: 0.661 ;IOU accuracy: 0.729 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.836 ;acc: 0.520 ;iou_acc: 0.605 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.873 ;acc: 0.555 ;iou_acc: 0.650 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.964 ;acc: 0.545 ;iou_acc: 0.660 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.827 ;acc: 0.575 ;iou_acc: 0.665 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.949 ;acc: 0.495 ;iou_acc: 0.625 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.914 ;acc: 0.515 ;iou_acc: 0.630 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.813 ;Test accuracy 0.552 ;IOU accuracy: 0.650 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.682 ;acc: 0.705 ;iou: 0.775 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.648 ;acc: 0.705 ;iou: 0.755 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.573 ;acc: 0.750 ;iou: 0.780 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.776 ;acc: 0.710 ;iou: 0.720 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.679 ;acc: 0.730 ;iou: 0.765 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.568 ;acc: 0.665 ;iou: 0.795 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 1.664 ;Train accuracy: 0.701 ;IOU accuracy: 0.768 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.883 ;acc: 0.500 ;iou_acc: 0.615 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.728 ;acc: 0.570 ;iou_acc: 0.660 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.826 ;acc: 0.540 ;iou_acc: 0.645 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.722 ;acc: 0.595 ;iou_acc: 0.710 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.757 ;acc: 0.595 ;iou_acc: 0.675 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.793 ;acc: 0.595 ;iou_acc: 0.710 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.710 ;Test accuracy 0.587 ;IOU accuracy: 0.684 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.433 ;acc: 0.755 ;iou: 0.800 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.513 ;acc: 0.765 ;iou: 0.850 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.583 ;acc: 0.730 ;iou: 0.820 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.468 ;acc: 0.775 ;iou: 0.840 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.530 ;acc: 0.765 ;iou: 0.775 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.656 ;acc: 0.700 ;iou: 0.770 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 1.543 ;Train accuracy: 0.747 ;IOU accuracy: 0.809 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.740 ;acc: 0.565 ;iou_acc: 0.690 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.607 ;acc: 0.625 ;iou_acc: 0.725 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.754 ;acc: 0.580 ;iou_acc: 0.705 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.635 ;acc: 0.620 ;iou_acc: 0.710 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.753 ;acc: 0.570 ;iou_acc: 0.670 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.681 ;acc: 0.605 ;iou_acc: 0.700 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.618 ;Test accuracy 0.615 ;IOU accuracy: 0.716 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.487 ;acc: 0.775 ;iou: 0.775 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.605 ;acc: 0.740 ;iou: 0.810 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.504 ;acc: 0.800 ;iou: 0.825 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.452 ;acc: 0.755 ;iou: 0.815 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.576 ;acc: 0.745 ;iou: 0.835 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.627 ;acc: 0.730 ;iou: 0.830 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.438 ;Train accuracy: 0.780 ;IOU accuracy: 0.840 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.633 ;acc: 0.580 ;iou_acc: 0.700 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.472 ;acc: 0.620 ;iou_acc: 0.730 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.721 ;acc: 0.585 ;iou_acc: 0.680 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.564 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.607 ;acc: 0.590 ;iou_acc: 0.705 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.626 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.535 ;Test accuracy 0.640 ;IOU accuracy: 0.739 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.264 ;acc: 0.830 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.449 ;acc: 0.815 ;iou: 0.840 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.232 ;acc: 0.820 ;iou: 0.880 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.315 ;acc: 0.835 ;iou: 0.860 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.355 ;acc: 0.790 ;iou: 0.855 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.149 ;acc: 0.800 ;iou: 0.895 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.339 ;Train accuracy: 0.806 ;IOU accuracy: 0.858 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.586 ;acc: 0.590 ;iou_acc: 0.685 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.468 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.709 ;acc: 0.570 ;iou_acc: 0.670 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.518 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.635 ;acc: 0.610 ;iou_acc: 0.705 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.574 ;acc: 0.645 ;iou_acc: 0.740 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 1.495 ;Test accuracy 0.650 ;IOU accuracy: 0.749 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.144 ;acc: 0.850 ;iou: 0.885 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.312 ;acc: 0.795 ;iou: 0.835 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.436 ;acc: 0.795 ;iou: 0.840 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.396 ;acc: 0.800 ;iou: 0.840 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.156 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.470 ;acc: 0.775 ;iou: 0.835 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.273 ;Train accuracy: 0.820 ;IOU accuracy: 0.872 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.600 ;acc: 0.590 ;iou_acc: 0.695 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.435 ;acc: 0.640 ;iou_acc: 0.750 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.662 ;acc: 0.575 ;iou_acc: 0.685 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.471 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.557 ;acc: 0.625 ;iou_acc: 0.720 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.577 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.466 ;Test accuracy 0.659 ;IOU accuracy: 0.755 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.363 ;acc: 0.805 ;iou: 0.830 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.232 ;acc: 0.855 ;iou: 0.890 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.214 ;acc: 0.835 ;iou: 0.880 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.253 ;acc: 0.800 ;iou: 0.885 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.374 ;acc: 0.855 ;iou: 0.885 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.443 ;acc: 0.800 ;iou: 0.835 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.206 ;Train accuracy: 0.837 ;IOU accuracy: 0.883 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.632 ;acc: 0.610 ;iou_acc: 0.710 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.441 ;acc: 0.645 ;iou_acc: 0.755 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.615 ;acc: 0.610 ;iou_acc: 0.705 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.427 ;acc: 0.645 ;iou_acc: 0.755 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.521 ;acc: 0.640 ;iou_acc: 0.745 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.574 ;acc: 0.660 ;iou_acc: 0.795 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.436 ;Test accuracy 0.667 ;IOU accuracy: 0.763 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.214 ;acc: 0.845 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 1.152 ;acc: 0.850 ;iou: 0.880 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.236 ;acc: 0.835 ;iou: 0.900 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.207 ;acc: 0.830 ;iou: 0.900 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.260 ;acc: 0.830 ;iou: 0.895 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 1.273 ;acc: 0.850 ;iou: 0.890 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 1.156 ;Train accuracy: 0.849 ;IOU accuracy: 0.893 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.625 ;acc: 0.590 ;iou_acc: 0.700 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.388 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.591 ;acc: 0.605 ;iou_acc: 0.715 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.487 ;acc: 0.630 ;iou_acc: 0.725 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.538 ;acc: 0.640 ;iou_acc: 0.745 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.488 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.439 ;Test accuracy 0.670 ;IOU accuracy: 0.768 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.269 ;acc: 0.840 ;iou: 0.880 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.259 ;acc: 0.810 ;iou: 0.890 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.038 ;acc: 0.870 ;iou: 0.895 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 1.067 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.054 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 1.125 ;acc: 0.875 ;iou: 0.875 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.114 ;Train accuracy: 0.857 ;IOU accuracy: 0.900 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.590 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.382 ;acc: 0.635 ;iou_acc: 0.735 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.480 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.395 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.505 ;acc: 0.625 ;iou_acc: 0.745 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.468 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.414 ;Test accuracy 0.677 ;IOU accuracy: 0.771 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.861 ;acc: 0.905 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.061 ;acc: 0.860 ;iou: 0.900 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 1.015 ;acc: 0.860 ;iou: 0.925 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 0.945 ;acc: 0.880 ;iou: 0.930 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.092 ;acc: 0.820 ;iou: 0.875 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.004 ;acc: 0.860 ;iou: 0.910 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 1.072 ;Train accuracy: 0.868 ;IOU accuracy: 0.908 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.561 ;acc: 0.615 ;iou_acc: 0.710 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.437 ;acc: 0.630 ;iou_acc: 0.745 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.596 ;acc: 0.645 ;iou_acc: 0.740 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.353 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.506 ;acc: 0.640 ;iou_acc: 0.740 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.410 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.414 ;Test accuracy 0.679 ;IOU accuracy: 0.773 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.822 ;acc: 0.890 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.968 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.885 ;iou: 0.935 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 1.094 ;acc: 0.895 ;iou: 0.910 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.014 ;acc: 0.860 ;iou: 0.900 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 1.041 ;acc: 0.865 ;iou: 0.905 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 1.029 ;Train accuracy: 0.877 ;IOU accuracy: 0.913 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.538 ;acc: 0.625 ;iou_acc: 0.730 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.329 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.606 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.405 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.472 ;acc: 0.660 ;iou_acc: 0.785 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.525 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.405 ;Test accuracy 0.683 ;IOU accuracy: 0.778 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.799 ;acc: 0.930 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.918 ;acc: 0.910 ;iou: 0.920 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.872 ;acc: 0.920 ;iou: 0.960 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 1.029 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 1.268 ;acc: 0.850 ;iou: 0.885 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.932 ;acc: 0.890 ;iou: 0.955 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.991 ;Train accuracy: 0.885 ;IOU accuracy: 0.919 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.573 ;acc: 0.605 ;iou_acc: 0.700 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.429 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.519 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.426 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.459 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.542 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.409 ;Test accuracy 0.684 ;IOU accuracy: 0.777 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.923 ;acc: 0.895 ;iou: 0.920 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.971 ;acc: 0.895 ;iou: 0.905 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 1.001 ;acc: 0.885 ;iou: 0.905 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.950 ;acc: 0.915 ;iou: 0.960 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 1.050 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.972 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.964 ;Train accuracy: 0.890 ;IOU accuracy: 0.923 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.554 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.362 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.508 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.367 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.452 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.488 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.418 ;Test accuracy 0.688 ;IOU accuracy: 0.780 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.968 ;acc: 0.890 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.927 ;acc: 0.885 ;iou: 0.905 ;time: 0:00:07\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.929 ;acc: 0.900 ;iou: 0.950 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.908 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 1.017 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.984 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.933 ;Train accuracy: 0.898 ;IOU accuracy: 0.929 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.578 ;acc: 0.625 ;iou_acc: 0.705 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.436 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.503 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.375 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.463 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.492 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:01:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.398 ;Test accuracy 0.691 ;IOU accuracy: 0.783 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.719 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.819 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.834 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.881 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.789 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 1.019 ;acc: 0.895 ;iou: 0.945 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.904 ;Train accuracy: 0.902 ;IOU accuracy: 0.933 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.577 ;acc: 0.610 ;iou_acc: 0.720 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.409 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.585 ;acc: 0.625 ;iou_acc: 0.710 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.383 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.399 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.474 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.406 ;Test accuracy 0.693 ;IOU accuracy: 0.784 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.803 ;acc: 0.905 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.972 ;acc: 0.900 ;iou: 0.915 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 1.011 ;acc: 0.900 ;iou: 0.925 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.871 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.711 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.883 ;acc: 0.890 ;iou: 0.910 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.875 ;Train accuracy: 0.909 ;IOU accuracy: 0.937 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.635 ;acc: 0.645 ;iou_acc: 0.730 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.474 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.614 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.439 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.559 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.506 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.443 ;Test accuracy 0.690 ;IOU accuracy: 0.782 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.891 ;acc: 0.900 ;iou: 0.920 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.987 ;acc: 0.870 ;iou: 0.900 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 1.013 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.919 ;acc: 0.905 ;iou: 0.920 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.871 ;acc: 0.905 ;iou: 0.920 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.651 ;acc: 0.945 ;iou: 0.940 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.852 ;Train accuracy: 0.913 ;IOU accuracy: 0.938 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.557 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.444 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.486 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.392 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.460 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.503 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.408 ;Test accuracy 0.698 ;IOU accuracy: 0.788 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.751 ;acc: 0.910 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.829 ;acc: 0.925 ;iou: 0.915 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.814 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.966 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.769 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.867 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.827 ;Train accuracy: 0.917 ;IOU accuracy: 0.941 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.510 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.398 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.626 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.404 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.457 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.478 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.420 ;Test accuracy 0.696 ;IOU accuracy: 0.789 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.716 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.843 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.858 ;acc: 0.920 ;iou: 0.965 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.733 ;acc: 0.920 ;iou: 0.930 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.695 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.804 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.801 ;Train accuracy: 0.923 ;IOU accuracy: 0.945 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.503 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.454 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.568 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.403 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.340 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.513 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.422 ;Test accuracy 0.697 ;IOU accuracy: 0.788 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.715 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.684 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.803 ;acc: 0.920 ;iou: 0.930 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.867 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.813 ;acc: 0.945 ;iou: 0.935 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.801 ;acc: 0.930 ;iou: 0.920 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.778 ;Train accuracy: 0.925 ;IOU accuracy: 0.947 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.537 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.518 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.536 ;acc: 0.685 ;iou_acc: 0.740 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.450 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.498 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.517 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.467 ;Test accuracy 0.697 ;IOU accuracy: 0.787 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.595 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.662 ;acc: 0.960 ;iou: 0.955 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.802 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.872 ;acc: 0.895 ;iou: 0.955 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.715 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.905 ;acc: 0.910 ;iou: 0.955 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.758 ;Train accuracy: 0.929 ;IOU accuracy: 0.951 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.662 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.646 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.486 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.494 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.455 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.632 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.466 ;Test accuracy 0.696 ;IOU accuracy: 0.786 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.790 ;acc: 0.935 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.671 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.718 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.780 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.965 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.783 ;acc: 0.940 ;iou: 0.930 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.734 ;Train accuracy: 0.933 ;IOU accuracy: 0.954 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.620 ;acc: 0.635 ;iou_acc: 0.725 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.561 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.595 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.540 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.377 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.601 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.462 ;Test accuracy 0.699 ;IOU accuracy: 0.789 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.603 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.796 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.819 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.591 ;acc: 0.950 ;iou: 0.960 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.996 ;acc: 0.905 ;iou: 0.885 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.850 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:42\n",
      "\n",
      "*Training B: True ;B Train loss: 0.722 ;Train accuracy: 0.937 ;IOU accuracy: 0.955 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.582 ;acc: 0.625 ;iou_acc: 0.705 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.526 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.614 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.510 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.383 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.633 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:24\n",
      "\n",
      "*BTrain: True ;Test loss: 1.470 ;Test accuracy 0.700 ;IOU accuracy: 0.790 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.519 ;acc: 0.945 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.722 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.719 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.628 ;acc: 0.960 ;iou: 0.960 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.843 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.704 ;acc: 0.920 ;iou: 0.980 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.705 ;Train accuracy: 0.938 ;IOU accuracy: 0.957 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.583 ;acc: 0.625 ;iou_acc: 0.690 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.477 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.650 ;acc: 0.635 ;iou_acc: 0.725 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.475 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.508 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.665 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.461 ;Test accuracy 0.701 ;IOU accuracy: 0.791 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.566 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.557 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.754 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.715 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.523 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.542 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.678 ;Train accuracy: 0.941 ;IOU accuracy: 0.959 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.563 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.459 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.668 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.508 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.525 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.648 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.477 ;Test accuracy 0.700 ;IOU accuracy: 0.791 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.688 ;acc: 0.940 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.750 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.722 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.744 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.659 ;acc: 0.930 ;iou: 0.935 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.840 ;acc: 0.940 ;iou: 0.975 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.660 ;Train accuracy: 0.946 ;IOU accuracy: 0.961 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.518 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.556 ;acc: 0.655 ;iou_acc: 0.780 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.676 ;acc: 0.685 ;iou_acc: 0.745 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.554 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.513 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.736 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 1.526 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.553 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.648 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.650 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.735 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.812 ;acc: 0.895 ;iou: 0.965 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.758 ;acc: 0.925 ;iou: 0.935 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.638 ;Train accuracy: 0.947 ;IOU accuracy: 0.963 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.678 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.594 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.667 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.543 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.569 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.684 ;acc: 0.695 ;iou_acc: 0.820 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.557 ;Test accuracy 0.697 ;IOU accuracy: 0.792 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.595 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.528 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.433 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.674 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.839 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.824 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.637 ;Train accuracy: 0.949 ;IOU accuracy: 0.964 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.494 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.578 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.659 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.683 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.468 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.666 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.506 ;Test accuracy 0.702 ;IOU accuracy: 0.792 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.541 ;acc: 0.935 ;iou: 0.925 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.532 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.482 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.601 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.548 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.663 ;acc: 0.935 ;iou: 0.945 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.610 ;Train accuracy: 0.951 ;IOU accuracy: 0.966 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.608 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.732 ;acc: 0.640 ;iou_acc: 0.750 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.686 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.564 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.640 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.774 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.577 ;Test accuracy 0.696 ;IOU accuracy: 0.787 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.578 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.605 ;acc: 0.975 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.678 ;acc: 0.955 ;iou: 0.985 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.715 ;acc: 0.960 ;iou: 0.955 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.507 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.589 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.594 ;Train accuracy: 0.955 ;IOU accuracy: 0.967 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.721 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.531 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.761 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.800 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.593 ;acc: 0.695 ;iou_acc: 0.815 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.861 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.590 ;Test accuracy 0.701 ;IOU accuracy: 0.791 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.455 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.653 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.632 ;acc: 0.940 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.717 ;acc: 0.910 ;iou: 0.955 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.533 ;acc: 0.950 ;iou: 0.985 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.629 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.585 ;Train accuracy: 0.957 ;IOU accuracy: 0.969 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.588 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.576 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.705 ;acc: 0.685 ;iou_acc: 0.740 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.664 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.552 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.770 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.600 ;Test accuracy 0.696 ;IOU accuracy: 0.786 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.457 ;acc: 0.975 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.548 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.793 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.552 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.653 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.659 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.565 ;Train accuracy: 0.957 ;IOU accuracy: 0.970 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.603 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.677 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.795 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.704 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.608 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.815 ;acc: 0.695 ;iou_acc: 0.815 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.591 ;Test accuracy 0.700 ;IOU accuracy: 0.791 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.553 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.530 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:07\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.752 ;acc: 0.960 ;iou: 0.955 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.530 ;acc: 0.960 ;iou: 0.955 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.809 ;acc: 0.945 ;iou: 0.970 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.448 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.551 ;Train accuracy: 0.959 ;IOU accuracy: 0.971 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.695 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.619 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.771 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.682 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.728 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.858 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.635 ;Test accuracy 0.695 ;IOU accuracy: 0.786 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.554 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.546 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.389 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.511 ;acc: 0.980 ;iou: 0.965 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.546 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.576 ;acc: 0.980 ;iou: 0.970 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.539 ;Train accuracy: 0.962 ;IOU accuracy: 0.973 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.742 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.608 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.744 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.730 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.645 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.842 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.626 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.306 ;acc: 0.980 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.474 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.344 ;acc: 0.985 ;iou: 0.970 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.502 ;acc: 0.960 ;iou: 0.960 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.721 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.505 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.523 ;Train accuracy: 0.962 ;IOU accuracy: 0.973 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.630 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.567 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.695 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.823 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.615 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.846 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.622 ;Test accuracy 0.703 ;IOU accuracy: 0.794 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.530 ;acc: 0.985 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.487 ;acc: 0.980 ;iou: 0.970 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.429 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.343 ;acc: 0.975 ;iou: 0.955 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.484 ;acc: 0.935 ;iou: 0.975 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.619 ;acc: 0.965 ;iou: 0.960 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.513 ;Train accuracy: 0.965 ;IOU accuracy: 0.974 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.582 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.631 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.834 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.748 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.668 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 2.012 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.653 ;Test accuracy 0.698 ;IOU accuracy: 0.788 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.296 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.325 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.538 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.514 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.586 ;acc: 0.945 ;iou: 0.950 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.464 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.503 ;Train accuracy: 0.965 ;IOU accuracy: 0.976 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.701 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.744 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.727 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.807 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.729 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.758 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.641 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.359 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.495 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.442 ;acc: 0.985 ;iou: 0.980 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.495 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.458 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.357 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.490 ;Train accuracy: 0.967 ;IOU accuracy: 0.976 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.856 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.859 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.893 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.681 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.780 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.847 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:33\n",
      "\n",
      "*BTrain: True ;Test loss: 1.691 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.575 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.401 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.483 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.404 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.287 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.461 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.485 ;Train accuracy: 0.968 ;IOU accuracy: 0.977 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.682 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.672 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.830 ;acc: 0.645 ;iou_acc: 0.720 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.775 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.732 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.918 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.698 ;Test accuracy 0.700 ;IOU accuracy: 0.791 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.409 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.415 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.482 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.541 ;acc: 0.960 ;iou: 0.960 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.451 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.433 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.470 ;Train accuracy: 0.969 ;IOU accuracy: 0.978 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.760 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.698 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.878 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.749 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.724 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.900 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.725 ;Test accuracy 0.700 ;IOU accuracy: 0.793 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.393 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.561 ;acc: 0.955 ;iou: 0.945 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.371 ;acc: 0.975 ;iou: 0.965 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.513 ;acc: 0.960 ;iou: 0.950 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.542 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.459 ;acc: 0.950 ;iou: 0.980 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.456 ;Train accuracy: 0.970 ;IOU accuracy: 0.979 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.589 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.729 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.944 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.662 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.716 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.940 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.704 ;Test accuracy 0.703 ;IOU accuracy: 0.794 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.309 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.383 ;acc: 0.975 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.281 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.439 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.632 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.381 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.444 ;Train accuracy: 0.972 ;IOU accuracy: 0.980 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.827 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.856 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.888 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.782 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.669 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.871 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.747 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.297 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.335 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.454 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.561 ;acc: 0.980 ;iou: 0.970 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.555 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.420 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.435 ;Train accuracy: 0.972 ;IOU accuracy: 0.980 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.697 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.747 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.903 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.858 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.783 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.943 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.771 ;Test accuracy 0.700 ;IOU accuracy: 0.790 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.426 ;acc: 1.000 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.411 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.435 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.536 ;acc: 0.960 ;iou: 0.990 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.415 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.549 ;acc: 0.945 ;iou: 0.980 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.427 ;Train accuracy: 0.974 ;IOU accuracy: 0.981 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.740 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.694 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.852 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.877 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.717 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.937 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.732 ;Test accuracy 0.704 ;IOU accuracy: 0.794 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.269 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.471 ;acc: 0.970 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.513 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.550 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.425 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.316 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.420 ;Train accuracy: 0.974 ;IOU accuracy: 0.982 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.588 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.745 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.869 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.787 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.802 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.850 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.770 ;Test accuracy 0.704 ;IOU accuracy: 0.794 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 1.0\n",
      "dropout_out 0.5\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_1.0,0.5_hidden:100\n",
      "num_hidden: 100\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.855 ;acc: 0.375 ;iou: 0.475 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.705 ;acc: 0.295 ;iou: 0.410 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.613 ;acc: 0.300 ;iou: 0.395 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.602 ;acc: 0.330 ;iou: 0.420 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.613 ;acc: 0.385 ;iou: 0.460 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.537 ;acc: 0.395 ;iou: 0.470 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 2.624 ;Train accuracy: 0.345 ;IOU accuracy: 0.444 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.451 ;acc: 0.335 ;iou_acc: 0.425 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.541 ;acc: 0.280 ;iou_acc: 0.360 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.616 ;acc: 0.235 ;iou_acc: 0.310 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.509 ;acc: 0.330 ;iou_acc: 0.410 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 2.462 ;acc: 0.350 ;iou_acc: 0.455 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 2.493 ;acc: 0.355 ;iou_acc: 0.490 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 2.442 ;Test accuracy 0.339 ;IOU accuracy: 0.450 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.465 ;acc: 0.475 ;iou: 0.585 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.564 ;acc: 0.435 ;iou: 0.495 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.334 ;acc: 0.435 ;iou: 0.485 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.191 ;acc: 0.515 ;iou: 0.635 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.303 ;acc: 0.475 ;iou: 0.565 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.216 ;acc: 0.530 ;iou: 0.645 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 2.289 ;Train accuracy: 0.494 ;IOU accuracy: 0.584 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.196 ;acc: 0.440 ;iou_acc: 0.550 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.226 ;acc: 0.475 ;iou_acc: 0.545 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.359 ;acc: 0.385 ;iou_acc: 0.485 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.224 ;acc: 0.435 ;iou_acc: 0.565 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.218 ;acc: 0.420 ;iou_acc: 0.555 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.209 ;acc: 0.455 ;iou_acc: 0.580 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 2.182 ;Test accuracy 0.440 ;IOU accuracy: 0.549 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.114 ;acc: 0.570 ;iou: 0.660 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.004 ;acc: 0.640 ;iou: 0.690 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 1.929 ;acc: 0.610 ;iou: 0.670 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 1.986 ;acc: 0.580 ;iou: 0.660 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 1.962 ;acc: 0.635 ;iou: 0.700 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.069 ;acc: 0.555 ;iou: 0.640 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 2.039 ;Train accuracy: 0.585 ;IOU accuracy: 0.667 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.078 ;acc: 0.500 ;iou_acc: 0.595 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 2.049 ;acc: 0.480 ;iou_acc: 0.560 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.154 ;acc: 0.435 ;iou_acc: 0.530 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 2.067 ;acc: 0.495 ;iou_acc: 0.615 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 2.088 ;acc: 0.490 ;iou_acc: 0.640 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 2.014 ;acc: 0.530 ;iou_acc: 0.665 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.999 ;Test accuracy 0.494 ;IOU accuracy: 0.598 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.661 ;acc: 0.680 ;iou: 0.735 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.836 ;acc: 0.680 ;iou: 0.740 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.928 ;acc: 0.650 ;iou: 0.760 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.847 ;acc: 0.690 ;iou: 0.740 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 2.028 ;acc: 0.615 ;iou: 0.700 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.984 ;acc: 0.615 ;iou: 0.700 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 1.862 ;Train accuracy: 0.646 ;IOU accuracy: 0.719 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.940 ;acc: 0.480 ;iou_acc: 0.595 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.963 ;acc: 0.545 ;iou_acc: 0.615 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 2.119 ;acc: 0.450 ;iou_acc: 0.525 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.940 ;acc: 0.510 ;iou_acc: 0.610 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.955 ;acc: 0.515 ;iou_acc: 0.640 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.899 ;acc: 0.525 ;iou_acc: 0.660 ;time: 0:01:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.882 ;Test accuracy 0.531 ;IOU accuracy: 0.629 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.666 ;acc: 0.700 ;iou: 0.770 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.828 ;acc: 0.620 ;iou: 0.680 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.612 ;acc: 0.730 ;iou: 0.765 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.838 ;acc: 0.710 ;iou: 0.770 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.602 ;acc: 0.700 ;iou: 0.760 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.716 ;acc: 0.695 ;iou: 0.760 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.725 ;Train accuracy: 0.699 ;IOU accuracy: 0.765 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.873 ;acc: 0.505 ;iou_acc: 0.620 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.861 ;acc: 0.560 ;iou_acc: 0.645 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.032 ;acc: 0.485 ;iou_acc: 0.560 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.887 ;acc: 0.550 ;iou_acc: 0.625 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.831 ;acc: 0.510 ;iou_acc: 0.635 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.815 ;acc: 0.575 ;iou_acc: 0.695 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.799 ;Test accuracy 0.559 ;IOU accuracy: 0.655 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.731 ;acc: 0.695 ;iou: 0.755 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.661 ;acc: 0.755 ;iou: 0.815 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.483 ;acc: 0.780 ;iou: 0.820 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.600 ;acc: 0.720 ;iou: 0.790 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.361 ;acc: 0.795 ;iou: 0.835 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.440 ;acc: 0.785 ;iou: 0.850 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.594 ;Train accuracy: 0.756 ;IOU accuracy: 0.814 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.756 ;acc: 0.555 ;iou_acc: 0.685 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.677 ;acc: 0.620 ;iou_acc: 0.695 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.949 ;acc: 0.515 ;iou_acc: 0.605 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.777 ;acc: 0.585 ;iou_acc: 0.665 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.707 ;acc: 0.580 ;iou_acc: 0.685 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.723 ;acc: 0.590 ;iou_acc: 0.705 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.693 ;Test accuracy 0.596 ;IOU accuracy: 0.693 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.438 ;acc: 0.820 ;iou: 0.885 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.440 ;acc: 0.815 ;iou: 0.860 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.481 ;acc: 0.805 ;iou: 0.850 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.467 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.446 ;acc: 0.800 ;iou: 0.835 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.464 ;acc: 0.820 ;iou: 0.870 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.444 ;Train accuracy: 0.811 ;IOU accuracy: 0.863 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.620 ;acc: 0.575 ;iou_acc: 0.695 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.603 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.822 ;acc: 0.595 ;iou_acc: 0.660 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.710 ;acc: 0.605 ;iou_acc: 0.700 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.624 ;acc: 0.625 ;iou_acc: 0.720 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.591 ;acc: 0.625 ;iou_acc: 0.745 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.582 ;Test accuracy 0.628 ;IOU accuracy: 0.727 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.293 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.286 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.295 ;acc: 0.850 ;iou: 0.880 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.308 ;acc: 0.810 ;iou: 0.865 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.431 ;acc: 0.805 ;iou: 0.840 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.396 ;acc: 0.825 ;iou: 0.880 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.307 ;Train accuracy: 0.847 ;IOU accuracy: 0.891 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.643 ;acc: 0.600 ;iou_acc: 0.735 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.634 ;acc: 0.610 ;iou_acc: 0.740 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.739 ;acc: 0.605 ;iou_acc: 0.690 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.581 ;acc: 0.640 ;iou_acc: 0.750 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.619 ;acc: 0.595 ;iou_acc: 0.725 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.571 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.527 ;Test accuracy 0.645 ;IOU accuracy: 0.743 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.248 ;acc: 0.855 ;iou: 0.895 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 0.981 ;acc: 0.905 ;iou: 0.925 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.209 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.129 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.248 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.310 ;acc: 0.870 ;iou: 0.910 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.205 ;Train accuracy: 0.875 ;IOU accuracy: 0.912 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.589 ;acc: 0.585 ;iou_acc: 0.710 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.621 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.745 ;acc: 0.620 ;iou_acc: 0.700 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.548 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.536 ;acc: 0.630 ;iou_acc: 0.740 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.564 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.506 ;Test accuracy 0.654 ;IOU accuracy: 0.752 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.035 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.247 ;acc: 0.850 ;iou: 0.875 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.078 ;acc: 0.895 ;iou: 0.920 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.136 ;acc: 0.900 ;iou: 0.925 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.149 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.234 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 1.121 ;Train accuracy: 0.893 ;IOU accuracy: 0.926 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.567 ;acc: 0.615 ;iou_acc: 0.725 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.461 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.750 ;acc: 0.620 ;iou_acc: 0.700 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.596 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.467 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.625 ;acc: 0.640 ;iou_acc: 0.760 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.477 ;Test accuracy 0.663 ;IOU accuracy: 0.761 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.239 ;acc: 0.860 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 0.950 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 0.943 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 0.914 ;acc: 0.920 ;iou: 0.930 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.077 ;acc: 0.905 ;iou: 0.955 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.011 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.051 ;Train accuracy: 0.907 ;IOU accuracy: 0.936 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.527 ;acc: 0.610 ;iou_acc: 0.730 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.527 ;acc: 0.645 ;iou_acc: 0.770 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.766 ;acc: 0.620 ;iou_acc: 0.685 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.584 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.544 ;acc: 0.610 ;iou_acc: 0.745 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.578 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.469 ;Test accuracy 0.669 ;IOU accuracy: 0.766 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.061 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 0.897 ;acc: 0.925 ;iou: 0.935 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.224 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 0.987 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.247 ;acc: 0.905 ;iou: 0.955 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 0.893 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.988 ;Train accuracy: 0.921 ;IOU accuracy: 0.945 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.551 ;acc: 0.615 ;iou_acc: 0.735 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.510 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.730 ;acc: 0.600 ;iou_acc: 0.705 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.513 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.486 ;acc: 0.635 ;iou_acc: 0.765 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.570 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.456 ;Test accuracy 0.676 ;IOU accuracy: 0.771 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 0.982 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 0.796 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 0.822 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 0.904 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.011 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 0.998 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.927 ;Train accuracy: 0.931 ;IOU accuracy: 0.954 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.504 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.542 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.657 ;acc: 0.615 ;iou_acc: 0.705 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.551 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.514 ;acc: 0.610 ;iou_acc: 0.710 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.634 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.468 ;Test accuracy 0.675 ;IOU accuracy: 0.770 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 0.825 ;acc: 0.960 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 0.819 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 0.920 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 1.053 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 0.998 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 0.804 ;acc: 0.965 ;iou: 0.990 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.880 ;Train accuracy: 0.940 ;IOU accuracy: 0.959 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.496 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.487 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.643 ;acc: 0.645 ;iou_acc: 0.730 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.512 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.567 ;acc: 0.630 ;iou_acc: 0.755 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.615 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.445 ;Test accuracy 0.685 ;IOU accuracy: 0.779 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.639 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 0.806 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.828 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 0.831 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 0.786 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.014 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.828 ;Train accuracy: 0.948 ;IOU accuracy: 0.965 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.386 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.541 ;acc: 0.675 ;iou_acc: 0.810 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.649 ;acc: 0.635 ;iou_acc: 0.725 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.660 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.642 ;acc: 0.640 ;iou_acc: 0.755 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.673 ;acc: 0.630 ;iou_acc: 0.745 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.465 ;Test accuracy 0.684 ;IOU accuracy: 0.778 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.863 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.848 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.943 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 0.996 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 0.698 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.876 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.780 ;Train accuracy: 0.955 ;IOU accuracy: 0.971 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.562 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.466 ;acc: 0.675 ;iou_acc: 0.810 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.760 ;acc: 0.640 ;iou_acc: 0.700 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.543 ;acc: 0.695 ;iou_acc: 0.755 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.481 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.597 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.482 ;Test accuracy 0.687 ;IOU accuracy: 0.780 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.633 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.608 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.764 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.850 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.809 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.872 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.743 ;Train accuracy: 0.959 ;IOU accuracy: 0.973 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.457 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.480 ;acc: 0.685 ;iou_acc: 0.820 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.757 ;acc: 0.590 ;iou_acc: 0.680 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.624 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.531 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.768 ;acc: 0.625 ;iou_acc: 0.750 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.477 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.685 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.603 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.627 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.695 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.605 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.630 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.699 ;Train accuracy: 0.966 ;IOU accuracy: 0.977 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.497 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.581 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.816 ;acc: 0.620 ;iou_acc: 0.705 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.679 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.625 ;acc: 0.635 ;iou_acc: 0.760 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.659 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.532 ;Test accuracy 0.685 ;IOU accuracy: 0.777 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.613 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.731 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.654 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.614 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.605 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.662 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.655 ;Train accuracy: 0.971 ;IOU accuracy: 0.981 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.572 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.530 ;acc: 0.695 ;iou_acc: 0.815 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.866 ;acc: 0.650 ;iou_acc: 0.710 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.708 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.692 ;acc: 0.635 ;iou_acc: 0.760 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.765 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 1.512 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.619 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.616 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.668 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.591 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.525 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.568 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.627 ;Train accuracy: 0.974 ;IOU accuracy: 0.983 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.607 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.559 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.702 ;acc: 0.640 ;iou_acc: 0.705 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.592 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.682 ;acc: 0.630 ;iou_acc: 0.750 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.736 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.522 ;Test accuracy 0.694 ;IOU accuracy: 0.786 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.646 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.669 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.511 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.690 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.665 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.610 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.578 ;Train accuracy: 0.979 ;IOU accuracy: 0.987 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.620 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.645 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.705 ;acc: 0.640 ;iou_acc: 0.700 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.704 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.629 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.867 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.550 ;Test accuracy 0.695 ;IOU accuracy: 0.786 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.594 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.530 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.514 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.568 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.739 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.693 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.555 ;Train accuracy: 0.981 ;IOU accuracy: 0.988 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.651 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.584 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.866 ;acc: 0.635 ;iou_acc: 0.720 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.756 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.726 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.845 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:33\n",
      "\n",
      "*BTrain: True ;Test loss: 1.579 ;Test accuracy 0.695 ;IOU accuracy: 0.788 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.425 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.366 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.598 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.472 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.538 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.477 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.527 ;Train accuracy: 0.983 ;IOU accuracy: 0.989 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.663 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.695 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.877 ;acc: 0.655 ;iou_acc: 0.710 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.774 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.756 ;acc: 0.635 ;iou_acc: 0.750 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.836 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.599 ;Test accuracy 0.697 ;IOU accuracy: 0.789 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.373 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.462 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.402 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.482 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.519 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.452 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.489 ;Train accuracy: 0.986 ;IOU accuracy: 0.991 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.790 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.646 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.797 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.786 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.695 ;acc: 0.645 ;iou_acc: 0.740 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.857 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.638 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.396 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.431 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.637 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.425 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.448 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.532 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.462 ;Train accuracy: 0.988 ;IOU accuracy: 0.992 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.733 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.518 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.916 ;acc: 0.635 ;iou_acc: 0.705 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.815 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.786 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.875 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.676 ;Test accuracy 0.697 ;IOU accuracy: 0.789 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.368 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.441 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.418 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.502 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.559 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.547 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.436 ;Train accuracy: 0.989 ;IOU accuracy: 0.993 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.609 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.566 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.942 ;acc: 0.620 ;iou_acc: 0.685 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.776 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.791 ;acc: 0.635 ;iou_acc: 0.745 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.068 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.647 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.310 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.361 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.341 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.390 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.404 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.408 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.405 ;Train accuracy: 0.991 ;IOU accuracy: 0.995 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.583 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.604 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.946 ;acc: 0.625 ;iou_acc: 0.695 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.811 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.856 ;acc: 0.625 ;iou_acc: 0.740 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.008 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.678 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.301 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.339 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.397 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.364 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.437 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.413 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.385 ;Train accuracy: 0.992 ;IOU accuracy: 0.995 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.743 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.786 ;acc: 0.680 ;iou_acc: 0.805 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.982 ;acc: 0.655 ;iou_acc: 0.715 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.813 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.865 ;acc: 0.660 ;iou_acc: 0.785 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.997 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.768 ;Test accuracy 0.696 ;IOU accuracy: 0.790 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.301 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.346 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.326 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.334 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.256 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.391 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.366 ;Train accuracy: 0.993 ;IOU accuracy: 0.996 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.854 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.791 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.995 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.961 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.871 ;acc: 0.645 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.898 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.775 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.307 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.249 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.264 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.397 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.330 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.475 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.331 ;Train accuracy: 0.995 ;IOU accuracy: 0.997 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.996 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 2.005 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.988 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.989 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.904 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.214 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.828 ;Test accuracy 0.697 ;IOU accuracy: 0.790 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.279 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.397 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.275 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.408 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.345 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.318 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.309 ;Train accuracy: 0.995 ;IOU accuracy: 0.997 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.878 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.830 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.011 ;acc: 0.640 ;iou_acc: 0.710 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.971 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.963 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.112 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:33\n",
      "\n",
      "*BTrain: True ;Test loss: 1.809 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.254 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.301 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.266 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.486 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.278 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.263 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.311 ;Train accuracy: 0.994 ;IOU accuracy: 0.996 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.951 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.895 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.119 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 2.063 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.978 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 2.051 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.867 ;Test accuracy 0.695 ;IOU accuracy: 0.787 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.322 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.370 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.299 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.391 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.252 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.262 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.285 ;Train accuracy: 0.996 ;IOU accuracy: 0.998 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 2.054 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.762 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.982 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.036 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.023 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.162 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.882 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.282 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.266 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.311 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.388 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.267 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.316 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.256 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.804 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.940 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.166 ;acc: 0.665 ;iou_acc: 0.720 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.875 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 2.016 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.262 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.886 ;Test accuracy 0.700 ;IOU accuracy: 0.793 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.233 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.267 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.184 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.230 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.115 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.267 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.233 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 2.120 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 2.181 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.239 ;acc: 0.625 ;iou_acc: 0.710 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 2.161 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 2.055 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 2.395 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.981 ;Test accuracy 0.695 ;IOU accuracy: 0.788 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.295 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.107 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.149 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.223 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.234 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.328 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.223 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.850 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.066 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.335 ;acc: 0.655 ;iou_acc: 0.720 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.126 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 2.205 ;acc: 0.640 ;iou_acc: 0.760 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.338 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.970 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.214 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.251 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.178 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.189 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.200 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.210 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.216 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 2.091 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.968 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.246 ;acc: 0.640 ;iou_acc: 0.705 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.188 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 2.088 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.437 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:33\n",
      "\n",
      "*BTrain: True ;Test loss: 1.996 ;Test accuracy 0.697 ;IOU accuracy: 0.790 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.121 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.164 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.170 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.136 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.269 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.254 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.189 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.981 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.979 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.139 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.211 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 2.112 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.423 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 2.045 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.115 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.150 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.140 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.273 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.129 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.141 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.180 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.958 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.974 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.322 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.232 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 2.091 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.351 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 2.077 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.115 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.134 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.141 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.145 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.140 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.188 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.170 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.961 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.178 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.242 ;acc: 0.640 ;iou_acc: 0.725 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.288 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 2.342 ;acc: 0.625 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.341 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 2.089 ;Test accuracy 0.695 ;IOU accuracy: 0.789 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.152 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.071 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.179 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.140 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.135 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.254 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.153 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 2.122 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.190 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.262 ;acc: 0.635 ;iou_acc: 0.705 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.461 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.154 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.561 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 2.137 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.146 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.133 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.166 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.135 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.251 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.136 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.146 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 2.050 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.075 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 2.405 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 2.334 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 2.371 ;acc: 0.640 ;iou_acc: 0.765 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 2.461 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 2.167 ;Test accuracy 0.697 ;IOU accuracy: 0.790 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.082 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.123 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.069 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.104 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.236 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.133 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.142 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 2.193 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.055 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.335 ;acc: 0.645 ;iou_acc: 0.715 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.617 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 2.214 ;acc: 0.630 ;iou_acc: 0.770 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.602 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 2.187 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.102 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.163 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.124 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.136 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.079 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.112 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.129 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.958 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.006 ;acc: 0.700 ;iou_acc: 0.825 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.370 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.460 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 2.230 ;acc: 0.650 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.497 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 2.149 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.127 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.065 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.108 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.165 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.130 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.099 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.121 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 2.154 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 2.119 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.517 ;acc: 0.620 ;iou_acc: 0.685 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.497 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.305 ;acc: 0.620 ;iou_acc: 0.765 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.479 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 2.232 ;Test accuracy 0.696 ;IOU accuracy: 0.790 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.068 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.064 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.073 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.085 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.159 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.124 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.113 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 2.031 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.024 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.542 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.554 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 2.419 ;acc: 0.630 ;iou_acc: 0.775 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.640 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 2.211 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.080 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.091 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.053 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.076 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.093 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.093 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.102 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 2.183 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.087 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.619 ;acc: 0.605 ;iou_acc: 0.665 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.497 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 2.327 ;acc: 0.635 ;iou_acc: 0.755 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.593 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 2.244 ;Test accuracy 0.700 ;IOU accuracy: 0.793 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.049 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.062 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.097 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.085 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.064 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.139 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.093 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 2.239 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.199 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.468 ;acc: 0.640 ;iou_acc: 0.705 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.634 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.349 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.675 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 2.267 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.151 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.134 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.097 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.065 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.091 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.228 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.083 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 2.185 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.289 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.536 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.655 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.391 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.652 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 2.304 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.040 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.105 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.038 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.059 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.087 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.060 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.102 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 2.108 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 2.165 ;acc: 0.710 ;iou_acc: 0.830 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.650 ;acc: 0.665 ;iou_acc: 0.710 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 2.536 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 2.291 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 2.517 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 2.294 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 0.5\n",
      "dropout_out 0.5\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_0.5,0.5_hidden:100\n",
      "num_hidden: 100\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.906 ;acc: 0.310 ;iou: 0.385 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.744 ;acc: 0.280 ;iou: 0.375 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.732 ;acc: 0.300 ;iou: 0.375 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.716 ;acc: 0.290 ;iou: 0.415 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.728 ;acc: 0.310 ;iou: 0.390 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.574 ;acc: 0.345 ;iou: 0.500 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 2.663 ;Train accuracy: 0.311 ;IOU accuracy: 0.412 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.566 ;acc: 0.305 ;iou_acc: 0.385 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.597 ;acc: 0.255 ;iou_acc: 0.370 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.614 ;acc: 0.280 ;iou_acc: 0.370 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.565 ;acc: 0.265 ;iou_acc: 0.385 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 2.557 ;acc: 0.275 ;iou_acc: 0.380 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.550 ;acc: 0.310 ;iou_acc: 0.430 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 2.528 ;Test accuracy 0.316 ;IOU accuracy: 0.425 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.593 ;acc: 0.360 ;iou: 0.480 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.581 ;acc: 0.400 ;iou: 0.490 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.516 ;acc: 0.380 ;iou: 0.475 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.346 ;acc: 0.410 ;iou: 0.510 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.407 ;acc: 0.405 ;iou: 0.495 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.390 ;acc: 0.460 ;iou: 0.575 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 2.376 ;Train accuracy: 0.435 ;IOU accuracy: 0.531 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.238 ;acc: 0.400 ;iou_acc: 0.485 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 2.326 ;acc: 0.415 ;iou_acc: 0.495 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.403 ;acc: 0.430 ;iou_acc: 0.520 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.279 ;acc: 0.420 ;iou_acc: 0.505 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.288 ;acc: 0.400 ;iou_acc: 0.495 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.288 ;acc: 0.440 ;iou_acc: 0.555 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 2.247 ;Test accuracy 0.416 ;IOU accuracy: 0.523 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.215 ;acc: 0.500 ;iou: 0.610 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.096 ;acc: 0.530 ;iou: 0.610 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.124 ;acc: 0.565 ;iou: 0.625 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.081 ;acc: 0.525 ;iou: 0.630 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.184 ;acc: 0.525 ;iou: 0.615 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.105 ;acc: 0.510 ;iou: 0.625 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 2.157 ;Train accuracy: 0.521 ;IOU accuracy: 0.611 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.073 ;acc: 0.475 ;iou_acc: 0.565 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.108 ;acc: 0.480 ;iou_acc: 0.570 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.226 ;acc: 0.490 ;iou_acc: 0.545 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.146 ;acc: 0.465 ;iou_acc: 0.570 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 2.167 ;acc: 0.405 ;iou_acc: 0.530 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.089 ;acc: 0.500 ;iou_acc: 0.605 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 2.065 ;Test accuracy 0.477 ;IOU accuracy: 0.579 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.100 ;acc: 0.550 ;iou: 0.620 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.148 ;acc: 0.540 ;iou: 0.605 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.998 ;acc: 0.545 ;iou: 0.635 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.976 ;acc: 0.570 ;iou: 0.615 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 2.155 ;acc: 0.535 ;iou: 0.625 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.851 ;acc: 0.635 ;iou: 0.730 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 1.996 ;Train accuracy: 0.577 ;IOU accuracy: 0.658 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.952 ;acc: 0.520 ;iou_acc: 0.575 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.002 ;acc: 0.495 ;iou_acc: 0.570 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.159 ;acc: 0.455 ;iou_acc: 0.550 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.027 ;acc: 0.490 ;iou_acc: 0.595 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.043 ;acc: 0.460 ;iou_acc: 0.575 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.022 ;acc: 0.525 ;iou_acc: 0.605 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.963 ;Test accuracy 0.507 ;IOU accuracy: 0.607 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.802 ;acc: 0.610 ;iou: 0.640 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.842 ;acc: 0.640 ;iou: 0.740 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.902 ;acc: 0.590 ;iou: 0.680 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.727 ;acc: 0.625 ;iou: 0.705 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.976 ;acc: 0.600 ;iou: 0.675 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.946 ;acc: 0.525 ;iou: 0.625 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.880 ;Train accuracy: 0.617 ;IOU accuracy: 0.695 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.832 ;acc: 0.560 ;iou_acc: 0.625 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.856 ;acc: 0.525 ;iou_acc: 0.620 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 2.001 ;acc: 0.510 ;iou_acc: 0.585 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.918 ;acc: 0.550 ;iou_acc: 0.640 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.963 ;acc: 0.465 ;iou_acc: 0.595 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.951 ;acc: 0.550 ;iou_acc: 0.675 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.879 ;Test accuracy 0.529 ;IOU accuracy: 0.629 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.823 ;acc: 0.620 ;iou: 0.710 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.825 ;acc: 0.665 ;iou: 0.735 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.791 ;acc: 0.650 ;iou: 0.760 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.735 ;acc: 0.675 ;iou: 0.730 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.738 ;acc: 0.665 ;iou: 0.760 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.815 ;acc: 0.635 ;iou: 0.730 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.780 ;Train accuracy: 0.658 ;IOU accuracy: 0.732 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.806 ;acc: 0.565 ;iou_acc: 0.635 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.816 ;acc: 0.525 ;iou_acc: 0.615 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.946 ;acc: 0.505 ;iou_acc: 0.590 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.840 ;acc: 0.555 ;iou_acc: 0.645 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.871 ;acc: 0.495 ;iou_acc: 0.605 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.919 ;acc: 0.545 ;iou_acc: 0.660 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.809 ;Test accuracy 0.552 ;IOU accuracy: 0.651 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.768 ;acc: 0.670 ;iou: 0.775 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.606 ;acc: 0.680 ;iou: 0.795 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.651 ;acc: 0.715 ;iou: 0.800 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.628 ;acc: 0.675 ;iou: 0.800 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.532 ;acc: 0.735 ;iou: 0.825 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.711 ;acc: 0.685 ;iou: 0.770 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 1.659 ;Train accuracy: 0.711 ;IOU accuracy: 0.781 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.699 ;acc: 0.610 ;iou_acc: 0.690 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.632 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.840 ;acc: 0.550 ;iou_acc: 0.625 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.729 ;acc: 0.590 ;iou_acc: 0.670 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.780 ;acc: 0.530 ;iou_acc: 0.640 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.802 ;acc: 0.580 ;iou_acc: 0.695 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.693 ;Test accuracy 0.593 ;IOU accuracy: 0.694 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.573 ;acc: 0.725 ;iou: 0.760 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.458 ;acc: 0.785 ;iou: 0.835 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.444 ;acc: 0.760 ;iou: 0.800 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.483 ;acc: 0.710 ;iou: 0.805 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.622 ;acc: 0.725 ;iou: 0.805 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.639 ;acc: 0.710 ;iou: 0.805 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.529 ;Train accuracy: 0.758 ;IOU accuracy: 0.823 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.671 ;acc: 0.585 ;iou_acc: 0.670 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.516 ;acc: 0.620 ;iou_acc: 0.715 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.757 ;acc: 0.595 ;iou_acc: 0.660 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.605 ;acc: 0.630 ;iou_acc: 0.715 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.634 ;acc: 0.600 ;iou_acc: 0.730 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.709 ;acc: 0.615 ;iou_acc: 0.730 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.596 ;Test accuracy 0.621 ;IOU accuracy: 0.723 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.309 ;acc: 0.820 ;iou: 0.875 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.413 ;acc: 0.850 ;iou: 0.870 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.478 ;acc: 0.790 ;iou: 0.845 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.689 ;acc: 0.735 ;iou: 0.785 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.383 ;acc: 0.810 ;iou: 0.840 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.393 ;acc: 0.810 ;iou: 0.835 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.415 ;Train accuracy: 0.791 ;IOU accuracy: 0.846 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.473 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.418 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.762 ;acc: 0.585 ;iou_acc: 0.660 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.545 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.565 ;acc: 0.610 ;iou_acc: 0.750 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.663 ;acc: 0.620 ;iou_acc: 0.725 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.557 ;Test accuracy 0.636 ;IOU accuracy: 0.736 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.317 ;acc: 0.840 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.251 ;acc: 0.820 ;iou: 0.850 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.598 ;acc: 0.770 ;iou: 0.820 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.263 ;acc: 0.840 ;iou: 0.880 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.305 ;acc: 0.840 ;iou: 0.855 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.319 ;acc: 0.785 ;iou: 0.840 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.333 ;Train accuracy: 0.810 ;IOU accuracy: 0.863 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.528 ;acc: 0.645 ;iou_acc: 0.720 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.435 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.674 ;acc: 0.605 ;iou_acc: 0.680 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.388 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.552 ;acc: 0.630 ;iou_acc: 0.740 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.661 ;acc: 0.615 ;iou_acc: 0.735 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.506 ;Test accuracy 0.649 ;IOU accuracy: 0.749 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.263 ;acc: 0.785 ;iou: 0.850 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.347 ;acc: 0.850 ;iou: 0.880 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.197 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.286 ;acc: 0.765 ;iou: 0.845 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.388 ;acc: 0.815 ;iou: 0.865 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.245 ;acc: 0.835 ;iou: 0.890 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.271 ;Train accuracy: 0.827 ;IOU accuracy: 0.873 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.528 ;acc: 0.645 ;iou_acc: 0.715 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.453 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.636 ;acc: 0.605 ;iou_acc: 0.660 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.434 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.551 ;acc: 0.630 ;iou_acc: 0.750 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.559 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.477 ;Test accuracy 0.655 ;IOU accuracy: 0.755 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.311 ;acc: 0.815 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.210 ;acc: 0.840 ;iou: 0.860 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.071 ;acc: 0.885 ;iou: 0.935 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.063 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.248 ;acc: 0.865 ;iou: 0.915 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.264 ;acc: 0.800 ;iou: 0.865 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.210 ;Train accuracy: 0.839 ;IOU accuracy: 0.883 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.464 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.379 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.615 ;acc: 0.625 ;iou_acc: 0.675 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.419 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.442 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.565 ;acc: 0.650 ;iou_acc: 0.790 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.444 ;Test accuracy 0.664 ;IOU accuracy: 0.763 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.127 ;acc: 0.855 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 1.109 ;acc: 0.890 ;iou: 0.885 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.030 ;acc: 0.905 ;iou: 0.915 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.355 ;acc: 0.800 ;iou: 0.900 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.247 ;acc: 0.860 ;iou: 0.910 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 0.938 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 1.163 ;Train accuracy: 0.850 ;IOU accuracy: 0.894 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.468 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.367 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.614 ;acc: 0.620 ;iou_acc: 0.690 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.450 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.443 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.570 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:01:33\n",
      "\n",
      "*BTrain: True ;Test loss: 1.430 ;Test accuracy 0.671 ;IOU accuracy: 0.767 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.035 ;acc: 0.865 ;iou: 0.930 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.018 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.157 ;acc: 0.830 ;iou: 0.920 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 0.931 ;acc: 0.860 ;iou: 0.935 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.277 ;acc: 0.850 ;iou: 0.845 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 0.948 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.113 ;Train accuracy: 0.861 ;IOU accuracy: 0.900 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.445 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.338 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.612 ;acc: 0.625 ;iou_acc: 0.695 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.447 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.426 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.564 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.442 ;Test accuracy 0.671 ;IOU accuracy: 0.767 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 1.020 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.074 ;acc: 0.835 ;iou: 0.905 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.956 ;acc: 0.920 ;iou: 0.925 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 1.124 ;acc: 0.860 ;iou: 0.900 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.179 ;acc: 0.870 ;iou: 0.895 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.010 ;acc: 0.875 ;iou: 0.900 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 1.077 ;Train accuracy: 0.867 ;IOU accuracy: 0.907 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.481 ;acc: 0.610 ;iou_acc: 0.695 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.341 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.529 ;acc: 0.640 ;iou_acc: 0.700 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.392 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.387 ;acc: 0.655 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.583 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.429 ;Test accuracy 0.675 ;IOU accuracy: 0.771 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.998 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.947 ;acc: 0.890 ;iou: 0.900 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 1.037 ;acc: 0.870 ;iou: 0.910 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 1.144 ;acc: 0.850 ;iou: 0.890 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 0.887 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 1.018 ;acc: 0.890 ;iou: 0.920 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 1.034 ;Train accuracy: 0.877 ;IOU accuracy: 0.912 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.457 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.346 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.581 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.482 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.399 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.550 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.415 ;Test accuracy 0.682 ;IOU accuracy: 0.777 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.826 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 1.098 ;acc: 0.885 ;iou: 0.945 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 1.072 ;acc: 0.860 ;iou: 0.935 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 1.061 ;acc: 0.880 ;iou: 0.935 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 1.145 ;acc: 0.870 ;iou: 0.895 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.970 ;acc: 0.890 ;iou: 0.910 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.002 ;Train accuracy: 0.884 ;IOU accuracy: 0.919 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.467 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.451 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.622 ;acc: 0.630 ;iou_acc: 0.685 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.444 ;acc: 0.705 ;iou_acc: 0.770 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.415 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.577 ;acc: 0.640 ;iou_acc: 0.760 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.422 ;Test accuracy 0.680 ;IOU accuracy: 0.775 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.793 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 1.051 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.950 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.902 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 1.050 ;acc: 0.845 ;iou: 0.895 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 1.001 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.975 ;Train accuracy: 0.889 ;IOU accuracy: 0.923 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.409 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.340 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.540 ;acc: 0.645 ;iou_acc: 0.715 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.418 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.399 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.555 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.400 ;Test accuracy 0.689 ;IOU accuracy: 0.783 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.768 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.933 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 1.117 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.968 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 1.038 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 1.007 ;acc: 0.910 ;iou: 0.910 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 0.939 ;Train accuracy: 0.898 ;IOU accuracy: 0.928 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.502 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.537 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.531 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.522 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.453 ;acc: 0.660 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.656 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.441 ;Test accuracy 0.685 ;IOU accuracy: 0.779 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.863 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.766 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.925 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.870 ;acc: 0.930 ;iou: 0.930 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.898 ;acc: 0.905 ;iou: 0.950 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.932 ;acc: 0.885 ;iou: 0.920 ;time: 0:00:40\n",
      "\n",
      "*Training B: False ;B Train loss: 0.908 ;Train accuracy: 0.903 ;IOU accuracy: 0.932 ;Time: 0:00:48 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.560 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.490 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:00:55\n",
      "batch: 100 ;B loss: 1.556 ;acc: 0.645 ;iou_acc: 0.715 ;time: 0:01:02\n",
      "batch: 150 ;B loss: 1.432 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:08\n",
      "batch: 200 ;B loss: 1.333 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:15\n",
      "batch: 250 ;B loss: 1.631 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "\n",
      "*BTrain: False ;Test loss: 1.434 ;Test accuracy 0.689 ;IOU accuracy: 0.783 ;Time: 0:01:27\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.688 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.820 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.743 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.955 ;acc: 0.915 ;iou: 0.930 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.978 ;acc: 0.905 ;iou: 0.910 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.927 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:39\n",
      "\n",
      "*Training B: False ;B Train loss: 0.881 ;Train accuracy: 0.911 ;IOU accuracy: 0.937 ;Time: 0:00:46 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.433 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:00:47\n",
      "batch: 50 ;B loss: 1.404 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:00:54\n",
      "batch: 100 ;B loss: 1.652 ;acc: 0.645 ;iou_acc: 0.715 ;time: 0:01:01\n",
      "batch: 150 ;B loss: 1.557 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:07\n",
      "batch: 200 ;B loss: 1.501 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:14\n",
      "batch: 250 ;B loss: 1.579 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:20\n",
      "\n",
      "*BTrain: False ;Test loss: 1.443 ;Test accuracy 0.688 ;IOU accuracy: 0.782 ;Time: 0:01:26\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.612 ;acc: 0.925 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.654 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:07\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.741 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.981 ;acc: 0.920 ;iou: 0.965 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.968 ;acc: 0.905 ;iou: 0.915 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.861 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:39\n",
      "\n",
      "*Training B: True ;B Train loss: 0.855 ;Train accuracy: 0.914 ;IOU accuracy: 0.940 ;Time: 0:00:47 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.489 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:00:47\n",
      "batch: 50 ;B loss: 1.455 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:00:54\n",
      "batch: 100 ;B loss: 1.607 ;acc: 0.655 ;iou_acc: 0.705 ;time: 0:01:00\n",
      "batch: 150 ;B loss: 1.440 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:07\n",
      "batch: 200 ;B loss: 1.320 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 250 ;B loss: 1.718 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:21\n",
      "\n",
      "*BTrain: True ;Test loss: 1.450 ;Test accuracy 0.692 ;IOU accuracy: 0.786 ;Time: 0:01:28\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.766 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.866 ;acc: 0.920 ;iou: 0.905 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.734 ;acc: 0.910 ;iou: 0.965 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 1.020 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.893 ;acc: 0.895 ;iou: 0.955 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.926 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.826 ;Train accuracy: 0.920 ;IOU accuracy: 0.943 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.407 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.500 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.518 ;acc: 0.660 ;iou_acc: 0.715 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.573 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.472 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.644 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.458 ;Test accuracy 0.690 ;IOU accuracy: 0.785 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.834 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.880 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.725 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.811 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.904 ;acc: 0.910 ;iou: 0.910 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.940 ;acc: 0.920 ;iou: 0.920 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.805 ;Train accuracy: 0.924 ;IOU accuracy: 0.946 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.458 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.541 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.604 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.522 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.446 ;acc: 0.650 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.589 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.436 ;Test accuracy 0.694 ;IOU accuracy: 0.788 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.652 ;acc: 0.925 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.709 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.761 ;acc: 0.940 ;iou: 0.930 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.750 ;acc: 0.925 ;iou: 0.930 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.857 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.664 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.789 ;Train accuracy: 0.925 ;IOU accuracy: 0.949 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.574 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.545 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.682 ;acc: 0.620 ;iou_acc: 0.690 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.453 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.385 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.722 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.477 ;Test accuracy 0.690 ;IOU accuracy: 0.783 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.694 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.740 ;acc: 0.935 ;iou: 0.925 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.731 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 1.008 ;acc: 0.925 ;iou: 0.915 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.793 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.777 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.761 ;Train accuracy: 0.930 ;IOU accuracy: 0.951 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.431 ;acc: 0.735 ;iou_acc: 0.790 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.522 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.511 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.519 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.579 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.673 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.477 ;Test accuracy 0.695 ;IOU accuracy: 0.789 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.691 ;acc: 0.955 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.731 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.694 ;acc: 0.940 ;iou: 0.935 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.829 ;acc: 0.930 ;iou: 0.925 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.645 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.764 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 0.740 ;Train accuracy: 0.934 ;IOU accuracy: 0.953 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.431 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.455 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.610 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.530 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.565 ;acc: 0.660 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.665 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.492 ;Test accuracy 0.692 ;IOU accuracy: 0.786 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.684 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.733 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.651 ;acc: 0.950 ;iou: 0.960 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.552 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.909 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.692 ;acc: 0.950 ;iou: 0.940 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.717 ;Train accuracy: 0.938 ;IOU accuracy: 0.956 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.367 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.605 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.530 ;acc: 0.655 ;iou_acc: 0.715 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.549 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.602 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.741 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.485 ;Test accuracy 0.695 ;IOU accuracy: 0.788 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.453 ;acc: 0.965 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.751 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.681 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.641 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.710 ;acc: 0.910 ;iou: 0.955 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.708 ;acc: 0.945 ;iou: 0.950 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.702 ;Train accuracy: 0.941 ;IOU accuracy: 0.959 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.502 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.555 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.613 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.591 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.616 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.741 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.501 ;Test accuracy 0.697 ;IOU accuracy: 0.789 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.831 ;acc: 0.975 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.560 ;acc: 0.970 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.664 ;acc: 0.950 ;iou: 0.940 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.657 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.659 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.602 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.681 ;Train accuracy: 0.942 ;IOU accuracy: 0.960 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.517 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.607 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.598 ;acc: 0.650 ;iou_acc: 0.710 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.581 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.572 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.813 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.510 ;Test accuracy 0.695 ;IOU accuracy: 0.790 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.682 ;acc: 0.955 ;iou: 0.950 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.603 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.656 ;acc: 0.950 ;iou: 0.960 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.541 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.590 ;acc: 0.955 ;iou: 0.940 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.751 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.662 ;Train accuracy: 0.946 ;IOU accuracy: 0.962 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.553 ;acc: 0.690 ;iou_acc: 0.740 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.655 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.558 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.609 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.587 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.766 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.529 ;Test accuracy 0.697 ;IOU accuracy: 0.790 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.582 ;acc: 0.960 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.617 ;acc: 0.930 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.581 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.537 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.581 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.737 ;acc: 0.895 ;iou: 0.920 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.637 ;Train accuracy: 0.948 ;IOU accuracy: 0.965 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.394 ;acc: 0.720 ;iou_acc: 0.780 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.575 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.653 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.525 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.547 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.713 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.518 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.664 ;acc: 0.970 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.571 ;acc: 0.945 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.662 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.628 ;acc: 0.965 ;iou: 0.960 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.625 ;acc: 0.960 ;iou: 0.960 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.561 ;acc: 0.980 ;iou: 0.970 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.631 ;Train accuracy: 0.951 ;IOU accuracy: 0.967 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.564 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.681 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.646 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.685 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.580 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.759 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.556 ;Test accuracy 0.693 ;IOU accuracy: 0.787 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.578 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.540 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.576 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.680 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.769 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.702 ;acc: 0.940 ;iou: 0.980 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.613 ;Train accuracy: 0.952 ;IOU accuracy: 0.967 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.655 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.753 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.673 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.580 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.722 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.768 ;acc: 0.695 ;iou_acc: 0.820 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.594 ;Test accuracy 0.694 ;IOU accuracy: 0.789 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.464 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.436 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.591 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.496 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.621 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.544 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.595 ;Train accuracy: 0.954 ;IOU accuracy: 0.969 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.527 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.723 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.666 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.628 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.621 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.783 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.597 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.474 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.609 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.503 ;acc: 0.975 ;iou: 0.965 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.482 ;acc: 0.935 ;iou: 0.970 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.555 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.781 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.583 ;Train accuracy: 0.955 ;IOU accuracy: 0.970 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.608 ;acc: 0.715 ;iou_acc: 0.775 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.734 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.680 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.769 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.620 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.876 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.593 ;Test accuracy 0.696 ;IOU accuracy: 0.790 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.450 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.532 ;acc: 0.985 ;iou: 0.965 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.618 ;acc: 0.950 ;iou: 0.960 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.710 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.547 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.355 ;acc: 0.980 ;iou: 0.960 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.566 ;Train accuracy: 0.958 ;IOU accuracy: 0.971 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.602 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.705 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.661 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.736 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.803 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.892 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 1.635 ;Test accuracy 0.696 ;IOU accuracy: 0.790 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.363 ;acc: 0.995 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.435 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.574 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.411 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.604 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.507 ;acc: 0.955 ;iou: 0.985 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.550 ;Train accuracy: 0.960 ;IOU accuracy: 0.972 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.567 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.720 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.675 ;acc: 0.670 ;iou_acc: 0.725 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.614 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.526 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.809 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.596 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.482 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.642 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.645 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.564 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.671 ;acc: 0.950 ;iou: 0.945 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.514 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.535 ;Train accuracy: 0.962 ;IOU accuracy: 0.973 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.595 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.764 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.808 ;acc: 0.680 ;iou_acc: 0.735 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.749 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.804 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.867 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.659 ;Test accuracy 0.695 ;IOU accuracy: 0.789 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.532 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.547 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.511 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.549 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.467 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.601 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.525 ;Train accuracy: 0.964 ;IOU accuracy: 0.975 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.673 ;acc: 0.685 ;iou_acc: 0.735 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.905 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.722 ;acc: 0.680 ;iou_acc: 0.730 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.829 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.893 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.942 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.681 ;Test accuracy 0.696 ;IOU accuracy: 0.788 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.426 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.446 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.549 ;acc: 0.985 ;iou: 0.965 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.638 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.639 ;acc: 0.955 ;iou: 0.955 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.498 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.510 ;Train accuracy: 0.965 ;IOU accuracy: 0.976 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.625 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.796 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.771 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.653 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.760 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.927 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.647 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.439 ;acc: 0.985 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.492 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.490 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.473 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.420 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.559 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.502 ;Train accuracy: 0.967 ;IOU accuracy: 0.976 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.738 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.834 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.614 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.770 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.644 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.971 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.670 ;Test accuracy 0.700 ;IOU accuracy: 0.793 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.407 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.540 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.448 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.420 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.422 ;acc: 0.990 ;iou: 0.980 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.408 ;acc: 0.985 ;iou: 0.970 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.487 ;Train accuracy: 0.967 ;IOU accuracy: 0.978 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.596 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.895 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.853 ;acc: 0.650 ;iou_acc: 0.710 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.755 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.816 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.783 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:31\n",
      "\n",
      "*BTrain: True ;Test loss: 1.677 ;Test accuracy 0.699 ;IOU accuracy: 0.790 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.440 ;acc: 0.975 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.453 ;acc: 0.980 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.412 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.261 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.628 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.483 ;acc: 0.965 ;iou: 0.955 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.473 ;Train accuracy: 0.970 ;IOU accuracy: 0.977 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.669 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.919 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.766 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.751 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.724 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.999 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.706 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.489 ;acc: 0.980 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.484 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.463 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.449 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.463 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.480 ;acc: 0.995 ;iou: 0.980 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.462 ;Train accuracy: 0.970 ;IOU accuracy: 0.978 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.661 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.826 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.612 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.769 ;acc: 0.730 ;iou_acc: 0.810 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.744 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.921 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.707 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.431 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.502 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.352 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.398 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.478 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.653 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.450 ;Train accuracy: 0.970 ;IOU accuracy: 0.980 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.687 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.874 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.901 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.811 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.782 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.917 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.744 ;Test accuracy 0.697 ;IOU accuracy: 0.789 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.605 ;acc: 0.970 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.409 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.438 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.426 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.406 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.626 ;acc: 0.950 ;iou: 0.985 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.445 ;Train accuracy: 0.973 ;IOU accuracy: 0.980 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.597 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.860 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.858 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.846 ;acc: 0.705 ;iou_acc: 0.815 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.900 ;acc: 0.670 ;iou_acc: 0.800 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 2.024 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.745 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.296 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.439 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.393 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.253 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.406 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.446 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.434 ;Train accuracy: 0.973 ;IOU accuracy: 0.981 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.655 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.058 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.819 ;acc: 0.700 ;iou_acc: 0.750 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.884 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.769 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 2.028 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.772 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.405 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.440 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.473 ;acc: 0.995 ;iou: 0.980 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.321 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.493 ;acc: 0.965 ;iou: 0.955 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.362 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.421 ;Train accuracy: 0.974 ;IOU accuracy: 0.982 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.853 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.866 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.744 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.787 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.849 ;acc: 0.660 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 2.065 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.822 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.374 ;acc: 0.985 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.407 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.407 ;acc: 0.985 ;iou: 0.980 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.461 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.576 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.551 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.416 ;Train accuracy: 0.974 ;IOU accuracy: 0.982 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.560 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.990 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.963 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.992 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.948 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.997 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.812 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 0.5\n",
      "dropout_out 1.0\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_0.5,1.0_hidden:150\n",
      "num_hidden: 150\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 3.145 ;acc: 0.430 ;iou: 0.490 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.737 ;acc: 0.320 ;iou: 0.455 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.641 ;acc: 0.345 ;iou: 0.400 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.602 ;acc: 0.375 ;iou: 0.460 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.606 ;acc: 0.350 ;iou: 0.460 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.479 ;acc: 0.365 ;iou: 0.480 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 2.619 ;Train accuracy: 0.348 ;IOU accuracy: 0.447 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.411 ;acc: 0.350 ;iou_acc: 0.465 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 2.541 ;acc: 0.325 ;iou_acc: 0.400 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.571 ;acc: 0.280 ;iou_acc: 0.350 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 2.476 ;acc: 0.325 ;iou_acc: 0.425 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 2.435 ;acc: 0.390 ;iou_acc: 0.485 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 2.436 ;acc: 0.365 ;iou_acc: 0.490 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 2.425 ;Test accuracy 0.342 ;IOU accuracy: 0.452 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.484 ;acc: 0.445 ;iou: 0.530 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.373 ;acc: 0.460 ;iou: 0.540 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.376 ;acc: 0.470 ;iou: 0.540 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.277 ;acc: 0.500 ;iou: 0.550 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.397 ;acc: 0.445 ;iou: 0.550 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.326 ;acc: 0.480 ;iou: 0.575 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 2.326 ;Train accuracy: 0.463 ;IOU accuracy: 0.555 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.211 ;acc: 0.440 ;iou_acc: 0.570 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 2.306 ;acc: 0.375 ;iou_acc: 0.470 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 2.393 ;acc: 0.365 ;iou_acc: 0.430 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 2.259 ;acc: 0.450 ;iou_acc: 0.560 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 2.234 ;acc: 0.430 ;iou_acc: 0.545 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 2.229 ;acc: 0.485 ;iou_acc: 0.600 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 2.219 ;Test accuracy 0.425 ;IOU accuracy: 0.533 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.172 ;acc: 0.520 ;iou: 0.635 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.183 ;acc: 0.510 ;iou: 0.615 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.220 ;acc: 0.570 ;iou: 0.660 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.008 ;acc: 0.600 ;iou: 0.680 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.299 ;acc: 0.510 ;iou: 0.575 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.090 ;acc: 0.555 ;iou: 0.635 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 2.125 ;Train accuracy: 0.549 ;IOU accuracy: 0.634 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.101 ;acc: 0.505 ;iou_acc: 0.585 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.164 ;acc: 0.470 ;iou_acc: 0.545 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 2.212 ;acc: 0.435 ;iou_acc: 0.510 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 2.051 ;acc: 0.510 ;iou_acc: 0.610 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 2.125 ;acc: 0.430 ;iou_acc: 0.545 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 2.074 ;acc: 0.505 ;iou_acc: 0.605 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 2.045 ;Test accuracy 0.484 ;IOU accuracy: 0.587 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.932 ;acc: 0.565 ;iou: 0.735 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.109 ;acc: 0.565 ;iou: 0.630 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.883 ;acc: 0.640 ;iou: 0.685 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 2.069 ;acc: 0.575 ;iou: 0.655 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.830 ;acc: 0.635 ;iou: 0.720 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.773 ;acc: 0.695 ;iou: 0.735 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 1.951 ;Train accuracy: 0.608 ;IOU accuracy: 0.690 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.949 ;acc: 0.530 ;iou_acc: 0.620 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.999 ;acc: 0.470 ;iou_acc: 0.535 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.091 ;acc: 0.495 ;iou_acc: 0.575 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.925 ;acc: 0.550 ;iou_acc: 0.650 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.971 ;acc: 0.530 ;iou_acc: 0.620 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.938 ;acc: 0.560 ;iou_acc: 0.660 ;time: 0:01:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.917 ;Test accuracy 0.525 ;IOU accuracy: 0.626 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.842 ;acc: 0.675 ;iou: 0.715 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.823 ;acc: 0.645 ;iou: 0.715 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.761 ;acc: 0.690 ;iou: 0.730 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.908 ;acc: 0.690 ;iou: 0.730 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.691 ;acc: 0.725 ;iou: 0.770 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.678 ;acc: 0.705 ;iou: 0.765 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.794 ;Train accuracy: 0.674 ;IOU accuracy: 0.748 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.890 ;acc: 0.505 ;iou_acc: 0.665 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.871 ;acc: 0.550 ;iou_acc: 0.645 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.947 ;acc: 0.505 ;iou_acc: 0.590 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.861 ;acc: 0.580 ;iou_acc: 0.695 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.792 ;acc: 0.545 ;iou_acc: 0.655 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.845 ;acc: 0.555 ;iou_acc: 0.675 ;time: 0:01:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.789 ;Test accuracy 0.569 ;IOU accuracy: 0.672 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.792 ;acc: 0.650 ;iou: 0.775 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.646 ;acc: 0.720 ;iou: 0.805 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.518 ;acc: 0.780 ;iou: 0.840 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.710 ;acc: 0.745 ;iou: 0.845 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.608 ;acc: 0.740 ;iou: 0.800 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.500 ;acc: 0.775 ;iou: 0.865 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.629 ;Train accuracy: 0.729 ;IOU accuracy: 0.799 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.731 ;acc: 0.565 ;iou_acc: 0.670 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.667 ;acc: 0.600 ;iou_acc: 0.700 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.871 ;acc: 0.550 ;iou_acc: 0.625 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 1.663 ;acc: 0.615 ;iou_acc: 0.705 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.683 ;acc: 0.585 ;iou_acc: 0.690 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 1.700 ;acc: 0.595 ;iou_acc: 0.680 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.641 ;Test accuracy 0.613 ;IOU accuracy: 0.714 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.422 ;acc: 0.765 ;iou: 0.805 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.481 ;acc: 0.795 ;iou: 0.850 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.448 ;acc: 0.800 ;iou: 0.845 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.476 ;acc: 0.770 ;iou: 0.785 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.383 ;acc: 0.790 ;iou: 0.855 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.693 ;acc: 0.730 ;iou: 0.815 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 1.486 ;Train accuracy: 0.772 ;IOU accuracy: 0.835 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.725 ;acc: 0.595 ;iou_acc: 0.700 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.557 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.834 ;acc: 0.560 ;iou_acc: 0.665 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.620 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.663 ;acc: 0.620 ;iou_acc: 0.720 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.698 ;acc: 0.600 ;iou_acc: 0.690 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.589 ;Test accuracy 0.627 ;IOU accuracy: 0.728 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.371 ;acc: 0.810 ;iou: 0.880 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.457 ;acc: 0.755 ;iou: 0.825 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.371 ;acc: 0.825 ;iou: 0.855 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.523 ;acc: 0.835 ;iou: 0.845 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.252 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.527 ;acc: 0.760 ;iou: 0.800 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.387 ;Train accuracy: 0.798 ;IOU accuracy: 0.854 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.625 ;acc: 0.615 ;iou_acc: 0.710 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.569 ;acc: 0.630 ;iou_acc: 0.730 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.794 ;acc: 0.565 ;iou_acc: 0.650 ;time: 0:01:03\n",
      "batch: 150 ;B loss: 1.578 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.631 ;acc: 0.640 ;iou_acc: 0.740 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.671 ;acc: 0.595 ;iou_acc: 0.710 ;time: 0:01:24\n",
      "\n",
      "*BTrain: False ;Test loss: 1.528 ;Test accuracy 0.643 ;IOU accuracy: 0.739 ;Time: 0:01:30\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.273 ;acc: 0.810 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.216 ;acc: 0.800 ;iou: 0.835 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.254 ;acc: 0.805 ;iou: 0.880 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.366 ;acc: 0.775 ;iou: 0.855 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.340 ;acc: 0.810 ;iou: 0.895 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.309 ;acc: 0.825 ;iou: 0.915 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.298 ;Train accuracy: 0.818 ;IOU accuracy: 0.869 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.567 ;acc: 0.645 ;iou_acc: 0.740 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.504 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.693 ;acc: 0.600 ;iou_acc: 0.685 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.521 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:10\n",
      "batch: 200 ;B loss: 1.635 ;acc: 0.595 ;iou_acc: 0.725 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.601 ;acc: 0.630 ;iou_acc: 0.750 ;time: 0:01:23\n",
      "\n",
      "*BTrain: False ;Test loss: 1.487 ;Test accuracy 0.654 ;IOU accuracy: 0.752 ;Time: 0:01:29\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.163 ;acc: 0.830 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.256 ;acc: 0.820 ;iou: 0.850 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.440 ;acc: 0.825 ;iou: 0.850 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.172 ;acc: 0.840 ;iou: 0.910 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.317 ;acc: 0.820 ;iou: 0.865 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.364 ;acc: 0.790 ;iou: 0.855 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 1.236 ;Train accuracy: 0.836 ;IOU accuracy: 0.882 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.573 ;acc: 0.605 ;iou_acc: 0.730 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.481 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.725 ;acc: 0.605 ;iou_acc: 0.700 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.511 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.607 ;acc: 0.605 ;iou_acc: 0.715 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.630 ;acc: 0.605 ;iou_acc: 0.735 ;time: 0:01:29\n",
      "\n",
      "*BTrain: True ;Test loss: 1.473 ;Test accuracy 0.662 ;IOU accuracy: 0.758 ;Time: 0:01:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.110 ;acc: 0.880 ;iou: 0.895 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.341 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.225 ;acc: 0.830 ;iou: 0.870 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.267 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.239 ;acc: 0.865 ;iou: 0.900 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.233 ;acc: 0.830 ;iou: 0.885 ;time: 0:00:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.171 ;Train accuracy: 0.849 ;IOU accuracy: 0.893 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.523 ;acc: 0.630 ;iou_acc: 0.730 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.442 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.642 ;acc: 0.615 ;iou_acc: 0.700 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.419 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.498 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.572 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.439 ;Test accuracy 0.669 ;IOU accuracy: 0.766 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.086 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.044 ;acc: 0.870 ;iou: 0.900 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.252 ;acc: 0.850 ;iou: 0.880 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.086 ;acc: 0.870 ;iou: 0.880 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.180 ;acc: 0.875 ;iou: 0.890 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.368 ;acc: 0.810 ;iou: 0.870 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.119 ;Train accuracy: 0.862 ;IOU accuracy: 0.903 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.450 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.356 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.682 ;acc: 0.605 ;iou_acc: 0.700 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.465 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.480 ;acc: 0.625 ;iou_acc: 0.745 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.518 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:01:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.411 ;Test accuracy 0.679 ;IOU accuracy: 0.773 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.002 ;acc: 0.870 ;iou: 0.895 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 1.017 ;acc: 0.915 ;iou: 0.925 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 0.840 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.271 ;acc: 0.835 ;iou: 0.885 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.076 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 0.991 ;acc: 0.880 ;iou: 0.905 ;time: 0:00:41\n",
      "\n",
      "*Training B: True ;B Train loss: 1.072 ;Train accuracy: 0.874 ;IOU accuracy: 0.911 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.524 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.443 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:00:56\n",
      "batch: 100 ;B loss: 1.619 ;acc: 0.625 ;iou_acc: 0.700 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.459 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:11\n",
      "batch: 200 ;B loss: 1.514 ;acc: 0.620 ;iou_acc: 0.740 ;time: 0:01:17\n",
      "batch: 250 ;B loss: 1.610 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.420 ;Test accuracy 0.680 ;IOU accuracy: 0.775 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.045 ;acc: 0.890 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 0.978 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 0.946 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 0.965 ;acc: 0.895 ;iou: 0.920 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.101 ;acc: 0.865 ;iou: 0.935 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 1.018 ;acc: 0.900 ;iou: 0.895 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 1.027 ;Train accuracy: 0.884 ;IOU accuracy: 0.918 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.481 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:00:50\n",
      "batch: 50 ;B loss: 1.405 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.529 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.420 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.486 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.497 ;acc: 0.635 ;iou_acc: 0.740 ;time: 0:01:25\n",
      "\n",
      "*BTrain: False ;Test loss: 1.413 ;Test accuracy 0.682 ;IOU accuracy: 0.777 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.802 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.003 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.960 ;acc: 0.870 ;iou: 0.920 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 0.976 ;acc: 0.880 ;iou: 0.900 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 0.968 ;acc: 0.895 ;iou: 0.905 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.182 ;acc: 0.845 ;iou: 0.885 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.983 ;Train accuracy: 0.892 ;IOU accuracy: 0.924 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.450 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.371 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.604 ;acc: 0.630 ;iou_acc: 0.715 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.437 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.554 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.583 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.406 ;Test accuracy 0.685 ;IOU accuracy: 0.778 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.879 ;acc: 0.905 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.947 ;acc: 0.925 ;iou: 0.930 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 0.963 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 0.819 ;acc: 0.915 ;iou: 0.975 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.943 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.951 ;Train accuracy: 0.899 ;IOU accuracy: 0.930 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.472 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.346 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.527 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.469 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.604 ;acc: 0.640 ;iou_acc: 0.770 ;time: 0:01:18\n",
      "batch: 250 ;B loss: 1.508 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.412 ;Test accuracy 0.689 ;IOU accuracy: 0.781 ;Time: 0:01:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.789 ;acc: 0.915 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.983 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.932 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.931 ;acc: 0.910 ;iou: 0.915 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 1.053 ;acc: 0.910 ;iou: 0.960 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.913 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.909 ;Train accuracy: 0.908 ;IOU accuracy: 0.936 ;Time: 0:00:49 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.548 ;acc: 0.635 ;iou_acc: 0.745 ;time: 0:00:49\n",
      "batch: 50 ;B loss: 1.402 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 100 ;B loss: 1.676 ;acc: 0.630 ;iou_acc: 0.710 ;time: 0:01:05\n",
      "batch: 150 ;B loss: 1.462 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.497 ;acc: 0.660 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.503 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.402 ;Test accuracy 0.692 ;IOU accuracy: 0.785 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.757 ;acc: 0.920 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.893 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.825 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.753 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 1.045 ;acc: 0.900 ;iou: 0.895 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.760 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.874 ;Train accuracy: 0.916 ;IOU accuracy: 0.940 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.569 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.329 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.626 ;acc: 0.620 ;iou_acc: 0.725 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.406 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:13\n",
      "batch: 200 ;B loss: 1.509 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:20\n",
      "batch: 250 ;B loss: 1.501 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:27\n",
      "\n",
      "*BTrain: False ;Test loss: 1.407 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.834 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.972 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.776 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.810 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.757 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.799 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:44\n",
      "\n",
      "*Training B: True ;B Train loss: 0.842 ;Train accuracy: 0.922 ;IOU accuracy: 0.946 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.657 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 1.403 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.608 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.465 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.568 ;acc: 0.650 ;iou_acc: 0.780 ;time: 0:01:21\n",
      "batch: 250 ;B loss: 1.616 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.425 ;Test accuracy 0.697 ;IOU accuracy: 0.788 ;Time: 0:01:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.652 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.807 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.802 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.793 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.717 ;acc: 0.950 ;iou: 0.950 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.955 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.813 ;Train accuracy: 0.927 ;IOU accuracy: 0.949 ;Time: 0:00:51 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.589 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.376 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.620 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:04\n",
      "batch: 150 ;B loss: 1.479 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:12\n",
      "batch: 200 ;B loss: 1.548 ;acc: 0.640 ;iou_acc: 0.765 ;time: 0:01:19\n",
      "batch: 250 ;B loss: 1.500 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:26\n",
      "\n",
      "*BTrain: False ;Test loss: 1.420 ;Test accuracy 0.698 ;IOU accuracy: 0.788 ;Time: 0:01:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.727 ;acc: 0.965 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.864 ;acc: 0.905 ;iou: 0.925 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.683 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.633 ;acc: 0.960 ;iou: 0.990 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.741 ;acc: 0.920 ;iou: 0.930 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.855 ;acc: 0.935 ;iou: 0.940 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.781 ;Train accuracy: 0.932 ;IOU accuracy: 0.952 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.593 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.431 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.673 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.463 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.546 ;acc: 0.635 ;iou_acc: 0.750 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.622 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.445 ;Test accuracy 0.698 ;IOU accuracy: 0.789 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.627 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.710 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.773 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.818 ;acc: 0.930 ;iou: 0.975 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.714 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.642 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.756 ;Train accuracy: 0.938 ;IOU accuracy: 0.957 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.562 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.392 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.681 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.433 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.531 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.608 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.421 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.619 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.731 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.864 ;acc: 0.945 ;iou: 0.945 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.762 ;acc: 0.975 ;iou: 0.960 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.634 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.648 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.727 ;Train accuracy: 0.940 ;IOU accuracy: 0.959 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.550 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.334 ;acc: 0.750 ;iou_acc: 0.825 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.669 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 1.574 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "batch: 200 ;B loss: 1.588 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:32\n",
      "batch: 250 ;B loss: 1.613 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:41\n",
      "\n",
      "*BTrain: False ;Test loss: 1.449 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.602 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.539 ;acc: 0.950 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.891 ;acc: 0.950 ;iou: 0.950 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.830 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.704 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.848 ;acc: 0.950 ;iou: 0.945 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.707 ;Train accuracy: 0.947 ;IOU accuracy: 0.962 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.695 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.390 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.738 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.466 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.465 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.640 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.443 ;Test accuracy 0.701 ;IOU accuracy: 0.791 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.639 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.678 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.696 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.759 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.647 ;acc: 0.970 ;iou: 0.965 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.738 ;acc: 0.950 ;iou: 0.950 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.673 ;Train accuracy: 0.950 ;IOU accuracy: 0.965 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.614 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.484 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.706 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.504 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.572 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.591 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:46\n",
      "\n",
      "*BTrain: True ;Test loss: 1.481 ;Test accuracy 0.702 ;IOU accuracy: 0.792 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.629 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.571 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.726 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.801 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.619 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.597 ;acc: 0.950 ;iou: 0.940 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.658 ;Train accuracy: 0.952 ;IOU accuracy: 0.966 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.642 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.480 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.804 ;acc: 0.635 ;iou_acc: 0.735 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 1.537 ;acc: 0.735 ;iou_acc: 0.820 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.779 ;acc: 0.640 ;iou_acc: 0.755 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.701 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:45\n",
      "\n",
      "*BTrain: False ;Test loss: 1.516 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.531 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.619 ;acc: 0.955 ;iou: 0.985 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.531 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.611 ;acc: 0.945 ;iou: 0.985 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.468 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.636 ;acc: 0.945 ;iou: 0.940 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.636 ;Train accuracy: 0.955 ;IOU accuracy: 0.969 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.620 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.417 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.654 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.512 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.596 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.565 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.475 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.466 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.466 ;acc: 0.935 ;iou: 0.980 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.488 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.606 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.623 ;acc: 0.980 ;iou: 0.965 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.650 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 0.607 ;Train accuracy: 0.958 ;IOU accuracy: 0.970 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.781 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.530 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.881 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.581 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.752 ;acc: 0.620 ;iou_acc: 0.780 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.751 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:46\n",
      "\n",
      "*BTrain: True ;Test loss: 1.568 ;Test accuracy 0.696 ;IOU accuracy: 0.787 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.574 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.570 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.685 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.748 ;acc: 0.955 ;iou: 0.945 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.665 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.740 ;acc: 0.945 ;iou: 0.970 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.591 ;Train accuracy: 0.961 ;IOU accuracy: 0.972 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.760 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.457 ;acc: 0.740 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.722 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.472 ;acc: 0.725 ;iou_acc: 0.835 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.613 ;acc: 0.640 ;iou_acc: 0.770 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.705 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.552 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.604 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.580 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.437 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.510 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.730 ;acc: 0.915 ;iou: 0.975 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.559 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.568 ;Train accuracy: 0.962 ;IOU accuracy: 0.975 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.796 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.458 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.776 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.627 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.513 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.703 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.560 ;Test accuracy 0.702 ;IOU accuracy: 0.793 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.547 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.604 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.541 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.721 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.522 ;acc: 0.965 ;iou: 0.990 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.422 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.548 ;Train accuracy: 0.965 ;IOU accuracy: 0.976 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.725 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.524 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.569 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.598 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.587 ;acc: 0.660 ;iou_acc: 0.785 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.710 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 1.570 ;Test accuracy 0.703 ;IOU accuracy: 0.794 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.468 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.501 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.666 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.476 ;acc: 0.945 ;iou: 0.980 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.464 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.662 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.533 ;Train accuracy: 0.968 ;IOU accuracy: 0.977 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.651 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.486 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.827 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.775 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.776 ;acc: 0.650 ;iou_acc: 0.780 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.750 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.603 ;Test accuracy 0.702 ;IOU accuracy: 0.792 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.534 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.476 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.489 ;acc: 0.985 ;iou: 0.980 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.519 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.564 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.487 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.514 ;Train accuracy: 0.970 ;IOU accuracy: 0.979 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.804 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.519 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.746 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.616 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.728 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.783 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.590 ;Test accuracy 0.705 ;IOU accuracy: 0.794 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.472 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.409 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.525 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.468 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.408 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.459 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.491 ;Train accuracy: 0.971 ;IOU accuracy: 0.980 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.749 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.512 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.867 ;acc: 0.635 ;iou_acc: 0.720 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.677 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.675 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.796 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:46\n",
      "\n",
      "*BTrain: True ;Test loss: 1.600 ;Test accuracy 0.704 ;IOU accuracy: 0.794 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.401 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.414 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.396 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.408 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.577 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.539 ;acc: 0.970 ;iou: 0.965 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.484 ;Train accuracy: 0.972 ;IOU accuracy: 0.980 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.796 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.573 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.880 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.718 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.729 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.867 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.618 ;Test accuracy 0.704 ;IOU accuracy: 0.794 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.407 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.471 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.377 ;acc: 0.975 ;iou: 0.970 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.401 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.557 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.552 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.471 ;Train accuracy: 0.973 ;IOU accuracy: 0.981 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.755 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.550 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.883 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.786 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.669 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.784 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.632 ;Test accuracy 0.706 ;IOU accuracy: 0.796 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.389 ;acc: 0.985 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.504 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.262 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.436 ;acc: 0.960 ;iou: 0.995 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.591 ;acc: 0.980 ;iou: 0.965 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.592 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 0.453 ;Train accuracy: 0.975 ;IOU accuracy: 0.983 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.845 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.548 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.923 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.809 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.773 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.865 ;acc: 0.705 ;iou_acc: 0.815 ;time: 0:01:47\n",
      "\n",
      "*BTrain: True ;Test loss: 1.690 ;Test accuracy 0.704 ;IOU accuracy: 0.794 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.364 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.349 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.449 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.406 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.304 ;acc: 0.990 ;iou: 0.975 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.679 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.434 ;Train accuracy: 0.976 ;IOU accuracy: 0.984 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.849 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.547 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.878 ;acc: 0.670 ;iou_acc: 0.730 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.865 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.793 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.797 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.673 ;Test accuracy 0.707 ;IOU accuracy: 0.796 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.379 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.356 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.544 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.565 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.520 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.495 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.427 ;Train accuracy: 0.979 ;IOU accuracy: 0.984 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.738 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.389 ;acc: 0.735 ;iou_acc: 0.825 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.801 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.733 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.710 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.859 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.664 ;Test accuracy 0.705 ;IOU accuracy: 0.796 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.337 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.370 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.290 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.364 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.347 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.481 ;acc: 0.990 ;iou: 0.970 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 0.411 ;Train accuracy: 0.978 ;IOU accuracy: 0.985 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.917 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.559 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.959 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.925 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.909 ;acc: 0.630 ;iou_acc: 0.765 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.811 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:46\n",
      "\n",
      "*BTrain: True ;Test loss: 1.707 ;Test accuracy 0.705 ;IOU accuracy: 0.796 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.462 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.355 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.359 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.474 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.411 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.389 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.400 ;Train accuracy: 0.980 ;IOU accuracy: 0.986 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.823 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.554 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.908 ;acc: 0.660 ;iou_acc: 0.720 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.759 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.829 ;acc: 0.660 ;iou_acc: 0.785 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.846 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:45\n",
      "\n",
      "*BTrain: False ;Test loss: 1.725 ;Test accuracy 0.705 ;IOU accuracy: 0.795 ;Time: 0:01:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.263 ;acc: 0.960 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.297 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.368 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.349 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.418 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.404 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.383 ;Train accuracy: 0.981 ;IOU accuracy: 0.986 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.912 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.632 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.944 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.824 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.907 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.768 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.726 ;Test accuracy 0.706 ;IOU accuracy: 0.795 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.340 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.300 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.325 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.527 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.411 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.365 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.377 ;Train accuracy: 0.981 ;IOU accuracy: 0.986 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.731 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.572 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.971 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 1.968 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.853 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.862 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:46\n",
      "\n",
      "*BTrain: True ;Test loss: 1.734 ;Test accuracy 0.705 ;IOU accuracy: 0.796 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.336 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.192 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.397 ;acc: 0.995 ;iou: 0.985 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.328 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.386 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.343 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.371 ;Train accuracy: 0.982 ;IOU accuracy: 0.987 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.891 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.708 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.909 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.837 ;acc: 0.680 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.837 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 2.005 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.763 ;Test accuracy 0.706 ;IOU accuracy: 0.795 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.278 ;acc: 0.995 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.332 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.358 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.432 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.382 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.342 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.352 ;Train accuracy: 0.983 ;IOU accuracy: 0.988 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 2.080 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.746 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.997 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 2.009 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.794 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.953 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.843 ;Test accuracy 0.706 ;IOU accuracy: 0.796 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.378 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.365 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.303 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.340 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.413 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.296 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.340 ;Train accuracy: 0.983 ;IOU accuracy: 0.988 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.986 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.608 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 2.063 ;acc: 0.645 ;iou_acc: 0.730 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 1.952 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.921 ;acc: 0.650 ;iou_acc: 0.780 ;time: 0:01:36\n",
      "batch: 250 ;B loss: 2.040 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:45\n",
      "\n",
      "*BTrain: True ;Test loss: 1.780 ;Test accuracy 0.706 ;IOU accuracy: 0.795 ;Time: 0:01:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.233 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.404 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.270 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.278 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.282 ;acc: 0.965 ;iou: 0.995 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.394 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.329 ;Train accuracy: 0.984 ;IOU accuracy: 0.989 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.949 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.814 ;acc: 0.725 ;iou_acc: 0.780 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.965 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 2.001 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.968 ;acc: 0.645 ;iou_acc: 0.775 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.986 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.846 ;Test accuracy 0.705 ;IOU accuracy: 0.795 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.249 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.307 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.219 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.460 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.394 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.479 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.319 ;Train accuracy: 0.985 ;IOU accuracy: 0.989 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.953 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.675 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 2.045 ;acc: 0.655 ;iou_acc: 0.720 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 2.044 ;acc: 0.675 ;iou_acc: 0.805 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.813 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 2.024 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.868 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.299 ;acc: 0.980 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.357 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.335 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.350 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.302 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.252 ;acc: 0.995 ;iou: 0.985 ;time: 0:00:51\n",
      "\n",
      "*Training B: True ;B Train loss: 0.307 ;Train accuracy: 0.986 ;IOU accuracy: 0.990 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.971 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.618 ;acc: 0.755 ;iou_acc: 0.845 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 1.971 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 1.898 ;acc: 0.680 ;iou_acc: 0.810 ;time: 0:01:27\n",
      "batch: 200 ;B loss: 1.923 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:36\n",
      "batch: 250 ;B loss: 1.939 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:45\n",
      "\n",
      "*BTrain: True ;Test loss: 1.850 ;Test accuracy 0.707 ;IOU accuracy: 0.797 ;Time: 0:01:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.299 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.350 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.185 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.271 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.245 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.314 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.305 ;Train accuracy: 0.986 ;IOU accuracy: 0.991 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.906 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.669 ;acc: 0.725 ;iou_acc: 0.835 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 2.113 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 2.073 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.952 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 2.148 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.878 ;Test accuracy 0.704 ;IOU accuracy: 0.794 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 1.0\n",
      "dropout_out 0.5\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_1.0,0.5_hidden:150\n",
      "num_hidden: 150\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 3.036 ;acc: 0.405 ;iou: 0.490 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.769 ;acc: 0.275 ;iou: 0.385 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.621 ;acc: 0.370 ;iou: 0.455 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.586 ;acc: 0.350 ;iou: 0.460 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.513 ;acc: 0.440 ;iou: 0.540 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.405 ;acc: 0.415 ;iou: 0.510 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 2.593 ;Train accuracy: 0.375 ;IOU accuracy: 0.472 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.369 ;acc: 0.370 ;iou_acc: 0.455 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 2.538 ;acc: 0.340 ;iou_acc: 0.435 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 2.534 ;acc: 0.265 ;iou_acc: 0.380 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 2.414 ;acc: 0.355 ;iou_acc: 0.470 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 2.369 ;acc: 0.370 ;iou_acc: 0.480 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.414 ;acc: 0.380 ;iou_acc: 0.495 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 2.389 ;Test accuracy 0.361 ;IOU accuracy: 0.476 ;Time: 0:01:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.318 ;acc: 0.500 ;iou: 0.600 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.370 ;acc: 0.455 ;iou: 0.575 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.171 ;acc: 0.545 ;iou: 0.620 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.136 ;acc: 0.540 ;iou: 0.635 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.224 ;acc: 0.495 ;iou: 0.570 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.171 ;acc: 0.550 ;iou: 0.625 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 2.224 ;Train accuracy: 0.529 ;IOU accuracy: 0.619 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.119 ;acc: 0.420 ;iou_acc: 0.520 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 2.215 ;acc: 0.465 ;iou_acc: 0.560 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 2.271 ;acc: 0.440 ;iou_acc: 0.510 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 2.198 ;acc: 0.420 ;iou_acc: 0.495 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 2.154 ;acc: 0.420 ;iou_acc: 0.580 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.104 ;acc: 0.465 ;iou_acc: 0.565 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 2.108 ;Test accuracy 0.464 ;IOU accuracy: 0.571 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.061 ;acc: 0.595 ;iou: 0.710 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.006 ;acc: 0.620 ;iou: 0.685 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 1.987 ;acc: 0.640 ;iou: 0.715 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 1.770 ;acc: 0.700 ;iou: 0.750 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.135 ;acc: 0.540 ;iou: 0.630 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 1.949 ;acc: 0.645 ;iou: 0.715 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.968 ;Train accuracy: 0.621 ;IOU accuracy: 0.699 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 1.970 ;acc: 0.495 ;iou_acc: 0.590 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 2.059 ;acc: 0.470 ;iou_acc: 0.545 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 2.129 ;acc: 0.455 ;iou_acc: 0.530 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 2.019 ;acc: 0.510 ;iou_acc: 0.610 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 2.021 ;acc: 0.475 ;iou_acc: 0.595 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.976 ;acc: 0.490 ;iou_acc: 0.620 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.945 ;Test accuracy 0.512 ;IOU accuracy: 0.615 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.937 ;acc: 0.635 ;iou: 0.730 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.798 ;acc: 0.665 ;iou: 0.725 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.728 ;acc: 0.715 ;iou: 0.775 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.739 ;acc: 0.730 ;iou: 0.785 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.784 ;acc: 0.700 ;iou: 0.750 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.758 ;acc: 0.690 ;iou: 0.750 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.798 ;Train accuracy: 0.685 ;IOU accuracy: 0.752 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.869 ;acc: 0.510 ;iou_acc: 0.630 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.950 ;acc: 0.465 ;iou_acc: 0.560 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.960 ;acc: 0.510 ;iou_acc: 0.565 ;time: 0:01:23\n",
      "batch: 150 ;B loss: 1.881 ;acc: 0.545 ;iou_acc: 0.655 ;time: 0:01:32\n",
      "batch: 200 ;B loss: 1.876 ;acc: 0.515 ;iou_acc: 0.625 ;time: 0:01:41\n",
      "batch: 250 ;B loss: 1.865 ;acc: 0.550 ;iou_acc: 0.685 ;time: 0:01:50\n",
      "\n",
      "*BTrain: True ;Test loss: 1.840 ;Test accuracy 0.548 ;IOU accuracy: 0.646 ;Time: 0:01:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.602 ;acc: 0.725 ;iou: 0.810 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.569 ;acc: 0.775 ;iou: 0.820 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.490 ;acc: 0.765 ;iou: 0.810 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.552 ;acc: 0.780 ;iou: 0.855 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.607 ;acc: 0.770 ;iou: 0.830 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.718 ;acc: 0.740 ;iou: 0.810 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 1.641 ;Train accuracy: 0.747 ;IOU accuracy: 0.807 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.765 ;acc: 0.585 ;iou_acc: 0.675 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.739 ;acc: 0.580 ;iou_acc: 0.685 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.930 ;acc: 0.525 ;iou_acc: 0.600 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.792 ;acc: 0.565 ;iou_acc: 0.660 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.801 ;acc: 0.555 ;iou_acc: 0.690 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.805 ;acc: 0.575 ;iou_acc: 0.675 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.719 ;Test accuracy 0.587 ;IOU accuracy: 0.690 ;Time: 0:01:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.283 ;acc: 0.840 ;iou: 0.885 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.671 ;acc: 0.755 ;iou: 0.815 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.490 ;acc: 0.805 ;iou: 0.855 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.392 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.501 ;acc: 0.830 ;iou: 0.890 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.256 ;acc: 0.860 ;iou: 0.885 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 1.473 ;Train accuracy: 0.812 ;IOU accuracy: 0.864 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.682 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.601 ;acc: 0.630 ;iou_acc: 0.715 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.862 ;acc: 0.555 ;iou_acc: 0.640 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.695 ;acc: 0.620 ;iou_acc: 0.715 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.652 ;acc: 0.590 ;iou_acc: 0.725 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.634 ;acc: 0.585 ;iou_acc: 0.690 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.638 ;Test accuracy 0.615 ;IOU accuracy: 0.717 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.311 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.198 ;acc: 0.850 ;iou: 0.890 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.316 ;acc: 0.860 ;iou: 0.905 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.243 ;acc: 0.845 ;iou: 0.880 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.284 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.389 ;acc: 0.845 ;iou: 0.890 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.320 ;Train accuracy: 0.854 ;IOU accuracy: 0.896 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.540 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.535 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.806 ;acc: 0.550 ;iou_acc: 0.620 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.508 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.629 ;acc: 0.605 ;iou_acc: 0.740 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.509 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 1.534 ;Test accuracy 0.643 ;IOU accuracy: 0.742 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.042 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.272 ;acc: 0.855 ;iou: 0.905 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.146 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.360 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.149 ;acc: 0.875 ;iou: 0.890 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.024 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.211 ;Train accuracy: 0.880 ;IOU accuracy: 0.916 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.581 ;acc: 0.630 ;iou_acc: 0.730 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.477 ;acc: 0.655 ;iou_acc: 0.795 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.713 ;acc: 0.560 ;iou_acc: 0.635 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.505 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.533 ;acc: 0.655 ;iou_acc: 0.785 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.481 ;acc: 0.640 ;iou_acc: 0.745 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.490 ;Test accuracy 0.657 ;IOU accuracy: 0.755 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.068 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.155 ;acc: 0.905 ;iou: 0.925 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.091 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.265 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.148 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.085 ;acc: 0.895 ;iou: 0.915 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 1.120 ;Train accuracy: 0.899 ;IOU accuracy: 0.930 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.479 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.386 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.623 ;acc: 0.640 ;iou_acc: 0.690 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.497 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.532 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.499 ;acc: 0.620 ;iou_acc: 0.735 ;time: 0:01:50\n",
      "\n",
      "*BTrain: False ;Test loss: 1.444 ;Test accuracy 0.669 ;IOU accuracy: 0.765 ;Time: 0:01:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.137 ;acc: 0.895 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 0.937 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 0.926 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.030 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 0.862 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 0.940 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.037 ;Train accuracy: 0.917 ;IOU accuracy: 0.942 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.500 ;acc: 0.640 ;iou_acc: 0.720 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.432 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.629 ;acc: 0.640 ;iou_acc: 0.695 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.534 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.567 ;acc: 0.625 ;iou_acc: 0.735 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.536 ;acc: 0.640 ;iou_acc: 0.760 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.443 ;Test accuracy 0.673 ;IOU accuracy: 0.769 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 0.952 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 0.949 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.007 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 0.946 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.188 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.974 ;Train accuracy: 0.927 ;IOU accuracy: 0.949 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.470 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.417 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.640 ;acc: 0.630 ;iou_acc: 0.715 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.530 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.583 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.516 ;acc: 0.635 ;iou_acc: 0.750 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.459 ;Test accuracy 0.677 ;IOU accuracy: 0.772 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 0.792 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 0.712 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 0.978 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 0.927 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 0.862 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.028 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.912 ;Train accuracy: 0.938 ;IOU accuracy: 0.958 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.383 ;acc: 0.670 ;iou_acc: 0.730 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.417 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.617 ;acc: 0.635 ;iou_acc: 0.710 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.482 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.523 ;acc: 0.660 ;iou_acc: 0.800 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.538 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.427 ;Test accuracy 0.685 ;IOU accuracy: 0.779 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 0.726 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 0.965 ;acc: 0.910 ;iou: 0.925 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 0.885 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 0.852 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 0.992 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 0.753 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 0.848 ;Train accuracy: 0.947 ;IOU accuracy: 0.965 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.358 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.462 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.499 ;acc: 0.680 ;iou_acc: 0.735 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.552 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.516 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.551 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.434 ;Test accuracy 0.689 ;IOU accuracy: 0.783 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 0.612 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 0.769 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 0.785 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 0.741 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 0.898 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 0.957 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.798 ;Train accuracy: 0.956 ;IOU accuracy: 0.971 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.456 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.436 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.550 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:23\n",
      "batch: 150 ;B loss: 1.598 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:32\n",
      "batch: 200 ;B loss: 1.619 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:41\n",
      "batch: 250 ;B loss: 1.689 ;acc: 0.630 ;iou_acc: 0.755 ;time: 0:01:50\n",
      "\n",
      "*BTrain: False ;Test loss: 1.472 ;Test accuracy 0.690 ;IOU accuracy: 0.784 ;Time: 0:01:59\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.583 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 0.704 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.522 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 0.678 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.008 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 0.810 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.745 ;Train accuracy: 0.963 ;IOU accuracy: 0.974 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.422 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.658 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.652 ;acc: 0.645 ;iou_acc: 0.720 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.579 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.650 ;acc: 0.660 ;iou_acc: 0.795 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.762 ;acc: 0.630 ;iou_acc: 0.745 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.508 ;Test accuracy 0.686 ;IOU accuracy: 0.781 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.520 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.790 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.681 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 0.780 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 0.757 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.636 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.693 ;Train accuracy: 0.969 ;IOU accuracy: 0.980 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.348 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.479 ;acc: 0.695 ;iou_acc: 0.815 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.665 ;acc: 0.640 ;iou_acc: 0.720 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.671 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.577 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.745 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.491 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.630 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.585 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.543 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.687 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.924 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.658 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.649 ;Train accuracy: 0.974 ;IOU accuracy: 0.982 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.439 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.436 ;acc: 0.740 ;iou_acc: 0.835 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.625 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.590 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.584 ;acc: 0.695 ;iou_acc: 0.825 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.767 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.506 ;Test accuracy 0.697 ;IOU accuracy: 0.789 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.597 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.524 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.583 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.562 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.591 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.562 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.608 ;Train accuracy: 0.977 ;IOU accuracy: 0.985 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.381 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.456 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.651 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.638 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.580 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.689 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.506 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.611 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.428 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.628 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.557 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.533 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.506 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.562 ;Train accuracy: 0.982 ;IOU accuracy: 0.988 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.469 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.469 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.622 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.632 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.609 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.760 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.535 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.447 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.420 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.573 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.538 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.646 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.425 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.526 ;Train accuracy: 0.985 ;IOU accuracy: 0.990 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.545 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.570 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.697 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.773 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.669 ;acc: 0.695 ;iou_acc: 0.820 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.843 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:50\n",
      "\n",
      "*BTrain: False ;Test loss: 1.601 ;Test accuracy 0.696 ;IOU accuracy: 0.788 ;Time: 0:01:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.545 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.431 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.498 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.517 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.690 ;acc: 0.950 ;iou: 0.960 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.530 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.491 ;Train accuracy: 0.988 ;IOU accuracy: 0.992 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.440 ;acc: 0.730 ;iou_acc: 0.810 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.527 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.713 ;acc: 0.670 ;iou_acc: 0.730 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.706 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.654 ;acc: 0.685 ;iou_acc: 0.825 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.952 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.587 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.409 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.476 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.502 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.414 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.437 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.497 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.450 ;Train accuracy: 0.989 ;IOU accuracy: 0.993 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.632 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.564 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.797 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.821 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.711 ;acc: 0.670 ;iou_acc: 0.820 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.886 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.635 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.315 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.468 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.581 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.358 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.620 ;acc: 0.965 ;iou: 0.990 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.395 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.422 ;Train accuracy: 0.991 ;IOU accuracy: 0.994 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.600 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.691 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.888 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.771 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.653 ;acc: 0.665 ;iou_acc: 0.805 ;time: 0:01:41\n",
      "batch: 250 ;B loss: 1.914 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:50\n",
      "\n",
      "*BTrain: False ;Test loss: 1.669 ;Test accuracy 0.700 ;IOU accuracy: 0.791 ;Time: 0:01:59\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.440 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.255 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.446 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.581 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.501 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.364 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.394 ;Train accuracy: 0.993 ;IOU accuracy: 0.995 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.512 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.639 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.959 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.891 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.639 ;acc: 0.700 ;iou_acc: 0.820 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.939 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.696 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.433 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.272 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.380 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.303 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.287 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.373 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 0.359 ;Train accuracy: 0.994 ;IOU accuracy: 0.996 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.594 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.708 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.974 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.822 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.759 ;acc: 0.680 ;iou_acc: 0.815 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.025 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.708 ;Test accuracy 0.703 ;IOU accuracy: 0.794 ;Time: 0:01:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.233 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.203 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.329 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.387 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.288 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.472 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.332 ;Train accuracy: 0.995 ;IOU accuracy: 0.997 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.743 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.762 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.933 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 1.975 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.873 ;acc: 0.675 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.138 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.766 ;Test accuracy 0.701 ;IOU accuracy: 0.794 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.312 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.228 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:07\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.313 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.336 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.310 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.356 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.311 ;Train accuracy: 0.996 ;IOU accuracy: 0.997 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.642 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.852 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:00:58\n",
      "batch: 100 ;B loss: 1.915 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.976 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.643 ;acc: 0.695 ;iou_acc: 0.835 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 2.090 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.793 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.257 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.325 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.237 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.288 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.452 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.285 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: True ;B Train loss: 0.274 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.571 ;acc: 0.760 ;iou_acc: 0.805 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.924 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.042 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.043 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.961 ;acc: 0.665 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.327 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 1.869 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.219 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.133 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.372 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.264 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.209 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.247 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.257 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.638 ;acc: 0.730 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.957 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.130 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.147 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.890 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.333 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.908 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.221 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.290 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.244 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.204 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.277 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.342 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.241 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.704 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.952 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.068 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.207 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 2.036 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.281 ;acc: 0.650 ;iou_acc: 0.775 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.911 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.243 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.198 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.256 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.199 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.163 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.228 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:49\n",
      "\n",
      "*Training B: True ;B Train loss: 0.227 ;Train accuracy: 0.998 ;IOU accuracy: 0.998 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.620 ;acc: 0.745 ;iou_acc: 0.820 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.117 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.976 ;acc: 0.690 ;iou_acc: 0.745 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 2.058 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.905 ;acc: 0.685 ;iou_acc: 0.835 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.283 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:39\n",
      "\n",
      "*BTrain: True ;Test loss: 1.895 ;Test accuracy 0.702 ;IOU accuracy: 0.794 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.208 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.152 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.126 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.282 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.246 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.179 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.195 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.685 ;acc: 0.750 ;iou_acc: 0.830 ;time: 0:00:52\n",
      "batch: 50 ;B loss: 2.097 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 1.998 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:01:07\n",
      "batch: 150 ;B loss: 2.253 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.962 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.235 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.932 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.110 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.108 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.303 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.257 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.270 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.224 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:44\n",
      "\n",
      "*Training B: False ;B Train loss: 0.179 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.792 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.216 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 2.140 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 2.124 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.014 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.463 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.991 ;Test accuracy 0.701 ;IOU accuracy: 0.794 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.153 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.160 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.203 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.109 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.144 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.130 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.161 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.752 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.207 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.195 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.337 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 1.928 ;acc: 0.670 ;iou_acc: 0.810 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.351 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.992 ;Test accuracy 0.703 ;IOU accuracy: 0.796 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.073 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.189 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.107 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.098 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.167 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.106 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.139 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.779 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 2.309 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.975 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.242 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.989 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.358 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 2.017 ;Test accuracy 0.702 ;IOU accuracy: 0.795 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.142 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.138 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.147 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.153 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.153 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.126 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.816 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.192 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.151 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.492 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.113 ;acc: 0.685 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.650 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 2.090 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.118 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.099 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.160 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.086 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.192 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.118 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.801 ;acc: 0.740 ;iou_acc: 0.815 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 2.199 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 2.041 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 2.417 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 2.139 ;acc: 0.670 ;iou_acc: 0.815 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.453 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:38\n",
      "\n",
      "*BTrain: True ;Test loss: 2.065 ;Test accuracy 0.705 ;IOU accuracy: 0.796 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.071 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.065 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.090 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.157 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.071 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.110 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.862 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 2.197 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 2.438 ;acc: 0.690 ;iou_acc: 0.750 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 2.663 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 2.073 ;acc: 0.710 ;iou_acc: 0.835 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.709 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 2.202 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.144 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.064 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.067 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.061 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.150 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.090 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.104 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.804 ;acc: 0.760 ;iou_acc: 0.820 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.340 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.347 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.429 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.144 ;acc: 0.710 ;iou_acc: 0.830 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.664 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 2.203 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.079 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.089 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.066 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.100 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.046 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.083 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.093 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.890 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.344 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.287 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.519 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.360 ;acc: 0.670 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.670 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 2.175 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.094 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.101 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.065 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.055 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.104 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.151 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.084 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 2.006 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 2.692 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.489 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.470 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.255 ;acc: 0.675 ;iou_acc: 0.805 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.778 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 2.280 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.075 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.044 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.072 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.078 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.148 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.081 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.849 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 2.341 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.444 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 2.452 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 2.238 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.760 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 2.240 ;Test accuracy 0.704 ;IOU accuracy: 0.795 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.057 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.044 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.048 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.038 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.084 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.095 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.070 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.779 ;acc: 0.735 ;iou_acc: 0.810 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 2.554 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.398 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.543 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 2.132 ;acc: 0.680 ;iou_acc: 0.815 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.856 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:39\n",
      "\n",
      "*BTrain: True ;Test loss: 2.250 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.102 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.062 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.070 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.049 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.060 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.043 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.064 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.910 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.578 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.410 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.610 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.249 ;acc: 0.680 ;iou_acc: 0.815 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.830 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 2.277 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.026 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.043 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.033 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.138 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.053 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.096 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.063 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.901 ;acc: 0.745 ;iou_acc: 0.815 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.646 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.319 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.691 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.365 ;acc: 0.680 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.860 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 2.329 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.022 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.033 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.048 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.108 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.218 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.055 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.061 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 2.012 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.632 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.481 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.655 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.298 ;acc: 0.685 ;iou_acc: 0.830 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.998 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 2.335 ;Test accuracy 0.699 ;IOU accuracy: 0.792 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.042 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.040 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.051 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.025 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.033 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.046 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.051 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 2.013 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.473 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.392 ;acc: 0.690 ;iou_acc: 0.740 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.813 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.408 ;acc: 0.695 ;iou_acc: 0.825 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.834 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 2.347 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.031 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.057 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.081 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.024 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.021 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.045 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.046 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.949 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.516 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.423 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.820 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.362 ;acc: 0.670 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.886 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 2.366 ;Test accuracy 0.703 ;IOU accuracy: 0.794 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.029 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.027 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.025 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.042 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.107 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.108 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: True ;B Train loss: 0.044 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 2.040 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 2.536 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.465 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.654 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.434 ;acc: 0.670 ;iou_acc: 0.820 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 3.133 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 2.388 ;Test accuracy 0.702 ;IOU accuracy: 0.795 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.016 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.030 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.075 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.029 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.045 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.019 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.042 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.905 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 2.616 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 2.422 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 2.873 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:23\n",
      "batch: 200 ;B loss: 2.489 ;acc: 0.690 ;iou_acc: 0.840 ;time: 0:01:31\n",
      "batch: 250 ;B loss: 3.013 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:39\n",
      "\n",
      "*BTrain: False ;Test loss: 2.393 ;Test accuracy 0.704 ;IOU accuracy: 0.795 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 0.5\n",
      "dropout_out 0.5\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_0.5,0.5_hidden:150\n",
      "num_hidden: 150\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 3.116 ;acc: 0.410 ;iou: 0.495 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.764 ;acc: 0.305 ;iou: 0.430 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.700 ;acc: 0.365 ;iou: 0.435 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.546 ;acc: 0.360 ;iou: 0.475 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.513 ;acc: 0.390 ;iou: 0.495 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.514 ;acc: 0.355 ;iou: 0.450 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 2.610 ;Train accuracy: 0.354 ;IOU accuracy: 0.454 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.420 ;acc: 0.350 ;iou_acc: 0.445 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.497 ;acc: 0.320 ;iou_acc: 0.440 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.506 ;acc: 0.350 ;iou_acc: 0.430 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.439 ;acc: 0.365 ;iou_acc: 0.470 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.459 ;acc: 0.360 ;iou_acc: 0.455 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.445 ;acc: 0.360 ;iou_acc: 0.480 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 2.422 ;Test accuracy 0.349 ;IOU accuracy: 0.455 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.416 ;acc: 0.425 ;iou: 0.520 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.368 ;acc: 0.445 ;iou: 0.550 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.480 ;acc: 0.400 ;iou: 0.530 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.272 ;acc: 0.470 ;iou: 0.585 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.320 ;acc: 0.465 ;iou: 0.525 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.158 ;acc: 0.515 ;iou: 0.580 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 2.316 ;Train accuracy: 0.468 ;IOU accuracy: 0.561 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.243 ;acc: 0.385 ;iou_acc: 0.485 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.222 ;acc: 0.435 ;iou_acc: 0.505 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.328 ;acc: 0.420 ;iou_acc: 0.510 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.264 ;acc: 0.435 ;iou_acc: 0.560 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.232 ;acc: 0.385 ;iou_acc: 0.505 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.203 ;acc: 0.465 ;iou_acc: 0.595 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 2.194 ;Test accuracy 0.437 ;IOU accuracy: 0.544 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.177 ;acc: 0.510 ;iou: 0.565 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.184 ;acc: 0.540 ;iou: 0.620 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.032 ;acc: 0.520 ;iou: 0.615 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.163 ;acc: 0.530 ;iou: 0.635 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.046 ;acc: 0.555 ;iou: 0.650 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.063 ;acc: 0.565 ;iou: 0.635 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 2.095 ;Train accuracy: 0.554 ;IOU accuracy: 0.641 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.103 ;acc: 0.460 ;iou_acc: 0.585 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.073 ;acc: 0.485 ;iou_acc: 0.555 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 2.176 ;acc: 0.470 ;iou_acc: 0.530 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 2.166 ;acc: 0.440 ;iou_acc: 0.570 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 2.127 ;acc: 0.445 ;iou_acc: 0.565 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.033 ;acc: 0.525 ;iou_acc: 0.640 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 2.034 ;Test accuracy 0.485 ;IOU accuracy: 0.590 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.956 ;acc: 0.595 ;iou: 0.630 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.859 ;acc: 0.635 ;iou: 0.730 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.876 ;acc: 0.615 ;iou: 0.670 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.938 ;acc: 0.600 ;iou: 0.670 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.856 ;acc: 0.615 ;iou: 0.700 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.964 ;acc: 0.610 ;iou: 0.675 ;time: 0:00:49\n",
      "\n",
      "*Training B: True ;B Train loss: 1.930 ;Train accuracy: 0.610 ;IOU accuracy: 0.689 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.986 ;acc: 0.480 ;iou_acc: 0.590 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.916 ;acc: 0.560 ;iou_acc: 0.635 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 2.096 ;acc: 0.465 ;iou_acc: 0.555 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.994 ;acc: 0.500 ;iou_acc: 0.610 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.965 ;acc: 0.515 ;iou_acc: 0.625 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.962 ;acc: 0.545 ;iou_acc: 0.655 ;time: 0:01:39\n",
      "\n",
      "*BTrain: True ;Test loss: 1.901 ;Test accuracy 0.527 ;IOU accuracy: 0.628 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.837 ;acc: 0.630 ;iou: 0.745 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.760 ;acc: 0.655 ;iou: 0.760 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.740 ;acc: 0.650 ;iou: 0.685 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.704 ;acc: 0.695 ;iou: 0.705 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.742 ;acc: 0.680 ;iou: 0.755 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.863 ;acc: 0.610 ;iou: 0.705 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 1.793 ;Train accuracy: 0.661 ;IOU accuracy: 0.739 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.780 ;acc: 0.575 ;iou_acc: 0.650 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.732 ;acc: 0.595 ;iou_acc: 0.690 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.970 ;acc: 0.480 ;iou_acc: 0.560 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 1.895 ;acc: 0.520 ;iou_acc: 0.665 ;time: 0:01:23\n",
      "batch: 200 ;B loss: 1.848 ;acc: 0.520 ;iou_acc: 0.635 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.829 ;acc: 0.585 ;iou_acc: 0.670 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.785 ;Test accuracy 0.564 ;IOU accuracy: 0.663 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.693 ;acc: 0.695 ;iou: 0.750 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.541 ;acc: 0.740 ;iou: 0.825 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.636 ;acc: 0.745 ;iou: 0.770 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.550 ;acc: 0.760 ;iou: 0.815 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.656 ;acc: 0.760 ;iou: 0.810 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.551 ;acc: 0.795 ;iou: 0.845 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.638 ;Train accuracy: 0.728 ;IOU accuracy: 0.793 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.677 ;acc: 0.625 ;iou_acc: 0.720 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.580 ;acc: 0.620 ;iou_acc: 0.715 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.887 ;acc: 0.535 ;iou_acc: 0.625 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.689 ;acc: 0.585 ;iou_acc: 0.735 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.677 ;acc: 0.590 ;iou_acc: 0.700 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.737 ;acc: 0.615 ;iou_acc: 0.715 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.653 ;Test accuracy 0.606 ;IOU accuracy: 0.707 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.370 ;acc: 0.765 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.468 ;acc: 0.770 ;iou: 0.835 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.220 ;acc: 0.785 ;iou: 0.850 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.705 ;acc: 0.700 ;iou: 0.820 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.542 ;acc: 0.805 ;iou: 0.850 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.317 ;acc: 0.775 ;iou: 0.850 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.501 ;Train accuracy: 0.768 ;IOU accuracy: 0.830 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.659 ;acc: 0.615 ;iou_acc: 0.715 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.531 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.800 ;acc: 0.600 ;iou_acc: 0.680 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.705 ;acc: 0.555 ;iou_acc: 0.700 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.662 ;acc: 0.575 ;iou_acc: 0.720 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.651 ;acc: 0.620 ;iou_acc: 0.740 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.584 ;Test accuracy 0.626 ;IOU accuracy: 0.727 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.241 ;acc: 0.830 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.568 ;acc: 0.780 ;iou: 0.840 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.349 ;acc: 0.775 ;iou: 0.810 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.456 ;acc: 0.860 ;iou: 0.845 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.445 ;acc: 0.780 ;iou: 0.865 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.814 ;acc: 0.700 ;iou: 0.790 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 1.395 ;Train accuracy: 0.795 ;IOU accuracy: 0.852 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.588 ;acc: 0.595 ;iou_acc: 0.725 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.441 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.762 ;acc: 0.570 ;iou_acc: 0.675 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.621 ;acc: 0.600 ;iou_acc: 0.715 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.575 ;acc: 0.615 ;iou_acc: 0.725 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.580 ;acc: 0.630 ;iou_acc: 0.755 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.520 ;Test accuracy 0.642 ;IOU accuracy: 0.740 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.142 ;acc: 0.835 ;iou: 0.895 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.364 ;acc: 0.890 ;iou: 0.910 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.422 ;acc: 0.760 ;iou: 0.830 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.400 ;acc: 0.840 ;iou: 0.875 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.364 ;acc: 0.810 ;iou: 0.875 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.245 ;acc: 0.770 ;iou: 0.845 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.317 ;Train accuracy: 0.816 ;IOU accuracy: 0.866 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.527 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.467 ;acc: 0.635 ;iou_acc: 0.750 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.694 ;acc: 0.605 ;iou_acc: 0.700 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.621 ;acc: 0.600 ;iou_acc: 0.695 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.566 ;acc: 0.620 ;iou_acc: 0.750 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.592 ;acc: 0.640 ;iou_acc: 0.760 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.497 ;Test accuracy 0.650 ;IOU accuracy: 0.747 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.087 ;acc: 0.865 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.263 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.402 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.215 ;acc: 0.860 ;iou: 0.855 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.277 ;acc: 0.800 ;iou: 0.885 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.325 ;acc: 0.840 ;iou: 0.855 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.251 ;Train accuracy: 0.832 ;IOU accuracy: 0.879 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.567 ;acc: 0.630 ;iou_acc: 0.725 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.370 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.706 ;acc: 0.600 ;iou_acc: 0.690 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.583 ;acc: 0.605 ;iou_acc: 0.705 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.494 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.597 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.474 ;Test accuracy 0.659 ;IOU accuracy: 0.756 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.200 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.136 ;acc: 0.875 ;iou: 0.910 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.141 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.173 ;acc: 0.840 ;iou: 0.890 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.202 ;acc: 0.810 ;iou: 0.880 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.239 ;acc: 0.825 ;iou: 0.865 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.189 ;Train accuracy: 0.845 ;IOU accuracy: 0.890 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.479 ;acc: 0.640 ;iou_acc: 0.740 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.419 ;acc: 0.640 ;iou_acc: 0.755 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.739 ;acc: 0.595 ;iou_acc: 0.685 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.498 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.604 ;acc: 0.630 ;iou_acc: 0.760 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.506 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.475 ;Test accuracy 0.663 ;IOU accuracy: 0.758 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.098 ;acc: 0.880 ;iou: 0.895 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.038 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.169 ;acc: 0.890 ;iou: 0.945 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 0.962 ;acc: 0.875 ;iou: 0.945 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.293 ;acc: 0.830 ;iou: 0.870 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.219 ;acc: 0.820 ;iou: 0.890 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 1.132 ;Train accuracy: 0.861 ;IOU accuracy: 0.900 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.502 ;acc: 0.640 ;iou_acc: 0.745 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.333 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.751 ;acc: 0.585 ;iou_acc: 0.655 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.558 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.524 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.589 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.455 ;Test accuracy 0.665 ;IOU accuracy: 0.760 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.245 ;acc: 0.835 ;iou: 0.835 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 0.915 ;acc: 0.915 ;iou: 0.915 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.058 ;acc: 0.855 ;iou: 0.920 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.220 ;acc: 0.875 ;iou: 0.890 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.015 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 1.130 ;acc: 0.885 ;iou: 0.905 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.090 ;Train accuracy: 0.872 ;IOU accuracy: 0.908 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.420 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.365 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.716 ;acc: 0.600 ;iou_acc: 0.685 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.506 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.578 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.582 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.451 ;Test accuracy 0.670 ;IOU accuracy: 0.766 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 0.811 ;acc: 0.880 ;iou: 0.930 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.021 ;acc: 0.900 ;iou: 0.920 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 0.871 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 0.980 ;acc: 0.865 ;iou: 0.895 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.023 ;acc: 0.875 ;iou: 0.910 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 1.031 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.041 ;Train accuracy: 0.882 ;IOU accuracy: 0.916 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.534 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.374 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.654 ;acc: 0.615 ;iou_acc: 0.700 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.504 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.567 ;acc: 0.635 ;iou_acc: 0.780 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.580 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.461 ;Test accuracy 0.675 ;IOU accuracy: 0.769 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.902 ;acc: 0.915 ;iou: 0.915 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.110 ;acc: 0.865 ;iou: 0.930 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.998 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 1.010 ;acc: 0.870 ;iou: 0.915 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.067 ;acc: 0.880 ;iou: 0.900 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.054 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.997 ;Train accuracy: 0.890 ;IOU accuracy: 0.924 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.376 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.407 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.753 ;acc: 0.615 ;iou_acc: 0.685 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.479 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.633 ;acc: 0.615 ;iou_acc: 0.730 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.529 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.446 ;Test accuracy 0.678 ;IOU accuracy: 0.772 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 1.107 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.736 ;acc: 0.900 ;iou: 0.945 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.899 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 0.992 ;acc: 0.885 ;iou: 0.940 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.087 ;acc: 0.885 ;iou: 0.905 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.989 ;acc: 0.890 ;iou: 0.920 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.961 ;Train accuracy: 0.898 ;IOU accuracy: 0.928 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.477 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.408 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.655 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.479 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.549 ;acc: 0.630 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.449 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "\n",
      "*BTrain: True ;Test loss: 1.438 ;Test accuracy 0.684 ;IOU accuracy: 0.776 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.919 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.724 ;acc: 0.935 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 1.063 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.879 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.881 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.841 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.930 ;Train accuracy: 0.908 ;IOU accuracy: 0.936 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.490 ;acc: 0.655 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.471 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.671 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.517 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.629 ;acc: 0.645 ;iou_acc: 0.770 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.494 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.458 ;Test accuracy 0.682 ;IOU accuracy: 0.776 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.698 ;acc: 0.935 ;iou: 0.970 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.684 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.869 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.694 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.990 ;acc: 0.900 ;iou: 0.925 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.801 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.884 ;Train accuracy: 0.915 ;IOU accuracy: 0.939 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.569 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.462 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.673 ;acc: 0.640 ;iou_acc: 0.720 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 1.486 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:23\n",
      "batch: 200 ;B loss: 1.654 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:31\n",
      "batch: 250 ;B loss: 1.623 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:39\n",
      "\n",
      "*BTrain: False ;Test loss: 1.466 ;Test accuracy 0.682 ;IOU accuracy: 0.775 ;Time: 0:01:47\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.746 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.760 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.881 ;acc: 0.930 ;iou: 0.975 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.834 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.952 ;acc: 0.910 ;iou: 0.920 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.816 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.854 ;Train accuracy: 0.920 ;IOU accuracy: 0.945 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.476 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.460 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.668 ;acc: 0.645 ;iou_acc: 0.700 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.522 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.618 ;acc: 0.645 ;iou_acc: 0.780 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.570 ;acc: 0.645 ;iou_acc: 0.755 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.450 ;Test accuracy 0.687 ;IOU accuracy: 0.780 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.794 ;acc: 0.950 ;iou: 0.950 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.773 ;acc: 0.930 ;iou: 0.935 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.924 ;acc: 0.880 ;iou: 0.935 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.837 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.770 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.828 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.823 ;Train accuracy: 0.927 ;IOU accuracy: 0.948 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.439 ;acc: 0.680 ;iou_acc: 0.725 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.526 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.598 ;acc: 0.620 ;iou_acc: 0.705 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.470 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.594 ;acc: 0.645 ;iou_acc: 0.755 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.612 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.465 ;Test accuracy 0.688 ;IOU accuracy: 0.779 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.723 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.879 ;acc: 0.935 ;iou: 0.940 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.798 ;acc: 0.950 ;iou: 0.935 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.862 ;acc: 0.930 ;iou: 0.940 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.752 ;acc: 0.935 ;iou: 0.945 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.753 ;acc: 0.945 ;iou: 0.970 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.791 ;Train accuracy: 0.932 ;IOU accuracy: 0.952 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.495 ;acc: 0.700 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.521 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.669 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.429 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.697 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.645 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.471 ;Test accuracy 0.691 ;IOU accuracy: 0.782 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.627 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.851 ;acc: 0.910 ;iou: 0.920 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.682 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.733 ;acc: 0.945 ;iou: 0.945 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.743 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.819 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.768 ;Train accuracy: 0.936 ;IOU accuracy: 0.955 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.425 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.515 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.715 ;acc: 0.650 ;iou_acc: 0.740 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.526 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.557 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.700 ;acc: 0.640 ;iou_acc: 0.760 ;time: 0:01:38\n",
      "\n",
      "*BTrain: True ;Test loss: 1.484 ;Test accuracy 0.691 ;IOU accuracy: 0.782 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.595 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.583 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.784 ;acc: 0.945 ;iou: 0.945 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.765 ;acc: 0.950 ;iou: 0.980 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.680 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.891 ;acc: 0.925 ;iou: 0.925 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.744 ;Train accuracy: 0.939 ;IOU accuracy: 0.959 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.630 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.547 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.791 ;acc: 0.635 ;iou_acc: 0.705 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.567 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.698 ;acc: 0.650 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.654 ;acc: 0.655 ;iou_acc: 0.765 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.514 ;Test accuracy 0.691 ;IOU accuracy: 0.782 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.736 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.698 ;acc: 0.950 ;iou: 0.960 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.736 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.641 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.816 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.687 ;acc: 0.900 ;iou: 0.975 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.716 ;Train accuracy: 0.944 ;IOU accuracy: 0.961 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.569 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.601 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.717 ;acc: 0.635 ;iou_acc: 0.725 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.604 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.654 ;acc: 0.660 ;iou_acc: 0.785 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.677 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.517 ;Test accuracy 0.690 ;IOU accuracy: 0.782 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.629 ;acc: 0.960 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.628 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.731 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.700 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.729 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.674 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.688 ;Train accuracy: 0.949 ;IOU accuracy: 0.963 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.459 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.547 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.789 ;acc: 0.635 ;iou_acc: 0.710 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.520 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.637 ;acc: 0.650 ;iou_acc: 0.780 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.767 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.520 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.610 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.588 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.467 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.652 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.696 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.613 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.671 ;Train accuracy: 0.952 ;IOU accuracy: 0.965 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.516 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.602 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.796 ;acc: 0.590 ;iou_acc: 0.675 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.562 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.731 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.692 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.532 ;Test accuracy 0.694 ;IOU accuracy: 0.785 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.467 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.625 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.741 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.604 ;acc: 0.965 ;iou: 0.955 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.587 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.600 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.644 ;Train accuracy: 0.955 ;IOU accuracy: 0.969 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.553 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.588 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.851 ;acc: 0.625 ;iou_acc: 0.690 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.646 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.656 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.778 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.587 ;Test accuracy 0.692 ;IOU accuracy: 0.784 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.750 ;acc: 0.970 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.681 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.658 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.615 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.609 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.601 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.622 ;Train accuracy: 0.958 ;IOU accuracy: 0.970 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.574 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.659 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.809 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.558 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.735 ;acc: 0.650 ;iou_acc: 0.795 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.822 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:38\n",
      "\n",
      "*BTrain: True ;Test loss: 1.566 ;Test accuracy 0.692 ;IOU accuracy: 0.785 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.669 ;acc: 0.950 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.764 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.570 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.608 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.670 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.556 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.602 ;Train accuracy: 0.960 ;IOU accuracy: 0.973 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.553 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.688 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.765 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.652 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.815 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.828 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.589 ;Test accuracy 0.694 ;IOU accuracy: 0.785 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.410 ;acc: 0.990 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.541 ;acc: 0.955 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.484 ;acc: 0.995 ;iou: 0.985 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.777 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.537 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.536 ;acc: 0.955 ;iou: 0.955 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.578 ;Train accuracy: 0.963 ;IOU accuracy: 0.974 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.499 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.661 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.890 ;acc: 0.640 ;iou_acc: 0.725 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.555 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.782 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.772 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.635 ;Test accuracy 0.692 ;IOU accuracy: 0.784 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.688 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.403 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.519 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.574 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.537 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.664 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.559 ;Train accuracy: 0.965 ;IOU accuracy: 0.976 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.507 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.740 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.934 ;acc: 0.640 ;iou_acc: 0.710 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.625 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.752 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.773 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.616 ;Test accuracy 0.697 ;IOU accuracy: 0.789 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.418 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.568 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.745 ;acc: 0.955 ;iou: 0.960 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.538 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.603 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.615 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.540 ;Train accuracy: 0.967 ;IOU accuracy: 0.977 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.615 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.667 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.040 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.727 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.771 ;acc: 0.670 ;iou_acc: 0.805 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.752 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.640 ;Test accuracy 0.697 ;IOU accuracy: 0.787 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.522 ;acc: 0.980 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.410 ;acc: 0.995 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.450 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.485 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.496 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.631 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.527 ;Train accuracy: 0.969 ;IOU accuracy: 0.979 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.581 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.737 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.793 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.680 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.854 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.790 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.617 ;Test accuracy 0.700 ;IOU accuracy: 0.790 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.317 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.562 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.381 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.480 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.563 ;acc: 0.980 ;iou: 0.960 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.543 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.505 ;Train accuracy: 0.971 ;IOU accuracy: 0.978 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.621 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.620 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.962 ;acc: 0.635 ;iou_acc: 0.710 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.776 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.844 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.719 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.670 ;Test accuracy 0.697 ;IOU accuracy: 0.789 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.511 ;acc: 0.970 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.624 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.409 ;acc: 0.990 ;iou: 0.975 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.367 ;acc: 0.965 ;iou: 0.995 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.472 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.419 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.484 ;Train accuracy: 0.971 ;IOU accuracy: 0.981 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.601 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.835 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.846 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.717 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:23\n",
      "batch: 200 ;B loss: 1.900 ;acc: 0.650 ;iou_acc: 0.775 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.912 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.693 ;Test accuracy 0.697 ;IOU accuracy: 0.788 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.359 ;acc: 0.995 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.382 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.357 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.522 ;acc: 0.990 ;iou: 0.975 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.477 ;acc: 0.980 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.394 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.467 ;Train accuracy: 0.974 ;IOU accuracy: 0.982 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.634 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.626 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.922 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.676 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.936 ;acc: 0.635 ;iou_acc: 0.770 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.948 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.689 ;Test accuracy 0.699 ;IOU accuracy: 0.790 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.429 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.466 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.471 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.552 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.428 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.505 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.457 ;Train accuracy: 0.975 ;IOU accuracy: 0.982 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.658 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.566 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.042 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.668 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.784 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.023 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.684 ;Test accuracy 0.700 ;IOU accuracy: 0.791 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.359 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.479 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.461 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.569 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.340 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.369 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.443 ;Train accuracy: 0.977 ;IOU accuracy: 0.983 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.686 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.634 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 2.067 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.840 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.871 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.036 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.753 ;Test accuracy 0.698 ;IOU accuracy: 0.789 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.389 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.545 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.368 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.369 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.465 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.470 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.427 ;Train accuracy: 0.978 ;IOU accuracy: 0.984 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.628 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.763 ;acc: 0.705 ;iou_acc: 0.815 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.937 ;acc: 0.635 ;iou_acc: 0.710 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.869 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.947 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.891 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.729 ;Test accuracy 0.699 ;IOU accuracy: 0.790 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.426 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.376 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.294 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.531 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.506 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.395 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.420 ;Train accuracy: 0.979 ;IOU accuracy: 0.986 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.723 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.712 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.000 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.847 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.008 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.958 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.788 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.328 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.303 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.287 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.581 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.338 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.452 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.406 ;Train accuracy: 0.980 ;IOU accuracy: 0.985 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.818 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.981 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.088 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.743 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.997 ;acc: 0.660 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.017 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.809 ;Test accuracy 0.698 ;IOU accuracy: 0.790 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.284 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.347 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.426 ;acc: 0.990 ;iou: 0.975 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.416 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.402 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.270 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.398 ;Train accuracy: 0.979 ;IOU accuracy: 0.986 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.698 ;acc: 0.700 ;iou_acc: 0.760 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.738 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.952 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.744 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.940 ;acc: 0.655 ;iou_acc: 0.780 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.920 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.755 ;Test accuracy 0.700 ;IOU accuracy: 0.790 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.343 ;acc: 0.980 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.497 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.299 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.590 ;acc: 0.960 ;iou: 0.950 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.286 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.407 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.376 ;Train accuracy: 0.981 ;IOU accuracy: 0.987 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.786 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.925 ;acc: 0.735 ;iou_acc: 0.820 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.152 ;acc: 0.625 ;iou_acc: 0.700 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.784 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 2.105 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.982 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:38\n",
      "\n",
      "*BTrain: True ;Test loss: 1.851 ;Test accuracy 0.696 ;IOU accuracy: 0.787 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.297 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.352 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.448 ;acc: 0.990 ;iou: 0.980 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.312 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.366 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.364 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.369 ;Train accuracy: 0.983 ;IOU accuracy: 0.988 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.845 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.993 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.155 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.919 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.085 ;acc: 0.650 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.092 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.868 ;Test accuracy 0.696 ;IOU accuracy: 0.787 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.360 ;acc: 0.985 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.303 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.230 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.355 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.581 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.397 ;acc: 1.000 ;iou: 0.995 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.362 ;Train accuracy: 0.982 ;IOU accuracy: 0.987 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.717 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.852 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.976 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.959 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 2.065 ;acc: 0.655 ;iou_acc: 0.765 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.973 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.830 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.339 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.304 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.307 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.324 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.320 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.277 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.342 ;Train accuracy: 0.984 ;IOU accuracy: 0.989 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.749 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.897 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.057 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.865 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.095 ;acc: 0.655 ;iou_acc: 0.765 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.959 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.871 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.275 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.323 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.377 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.362 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.301 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.467 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.343 ;Train accuracy: 0.984 ;IOU accuracy: 0.989 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.849 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.737 ;acc: 0.725 ;iou_acc: 0.820 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.171 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.037 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.048 ;acc: 0.640 ;iou_acc: 0.760 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.939 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.878 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.435 ;acc: 0.985 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.291 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.336 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.347 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.393 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.273 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.329 ;Train accuracy: 0.986 ;IOU accuracy: 0.989 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.806 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.991 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 2.216 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 2.082 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 2.092 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.150 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.906 ;Test accuracy 0.698 ;IOU accuracy: 0.789 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.210 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.218 ;acc: 0.980 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.505 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.327 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.260 ;acc: 0.990 ;iou: 0.970 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.278 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.315 ;Train accuracy: 0.985 ;IOU accuracy: 0.990 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.794 ;acc: 0.730 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.949 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.213 ;acc: 0.645 ;iou_acc: 0.730 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.979 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.198 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.095 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:38\n",
      "\n",
      "*BTrain: True ;Test loss: 1.891 ;Test accuracy 0.703 ;IOU accuracy: 0.792 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.195 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.169 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.329 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.275 ;acc: 0.995 ;iou: 0.985 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.495 ;acc: 0.985 ;iou: 0.980 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.368 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.304 ;Train accuracy: 0.986 ;IOU accuracy: 0.990 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.945 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.949 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.333 ;acc: 0.650 ;iou_acc: 0.740 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.946 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.118 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.131 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.950 ;Test accuracy 0.698 ;IOU accuracy: 0.788 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 0.5\n",
      "dropout_out 1.0\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_0.5,1.0_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.956 ;acc: 0.385 ;iou: 0.470 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.732 ;acc: 0.375 ;iou: 0.440 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.734 ;acc: 0.295 ;iou: 0.410 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.623 ;acc: 0.355 ;iou: 0.440 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.464 ;acc: 0.425 ;iou: 0.485 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.451 ;acc: 0.460 ;iou: 0.520 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 2.592 ;Train accuracy: 0.379 ;IOU accuracy: 0.473 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.345 ;acc: 0.380 ;iou_acc: 0.465 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.442 ;acc: 0.315 ;iou_acc: 0.405 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.521 ;acc: 0.290 ;iou_acc: 0.380 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.469 ;acc: 0.355 ;iou_acc: 0.460 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.386 ;acc: 0.400 ;iou_acc: 0.500 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.426 ;acc: 0.345 ;iou_acc: 0.465 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 2.394 ;Test accuracy 0.355 ;IOU accuracy: 0.464 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.352 ;acc: 0.540 ;iou: 0.635 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.453 ;acc: 0.460 ;iou: 0.535 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.283 ;acc: 0.450 ;iou: 0.555 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.318 ;acc: 0.505 ;iou: 0.590 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.148 ;acc: 0.545 ;iou: 0.640 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.161 ;acc: 0.545 ;iou: 0.670 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 2.269 ;Train accuracy: 0.502 ;IOU accuracy: 0.591 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.154 ;acc: 0.495 ;iou_acc: 0.560 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.145 ;acc: 0.465 ;iou_acc: 0.585 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.297 ;acc: 0.410 ;iou_acc: 0.525 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.200 ;acc: 0.455 ;iou_acc: 0.565 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.185 ;acc: 0.420 ;iou_acc: 0.545 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.184 ;acc: 0.430 ;iou_acc: 0.560 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 2.140 ;Test accuracy 0.451 ;IOU accuracy: 0.557 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.133 ;acc: 0.570 ;iou: 0.615 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.163 ;acc: 0.550 ;iou: 0.640 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.002 ;acc: 0.605 ;iou: 0.650 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.011 ;acc: 0.645 ;iou: 0.680 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.002 ;acc: 0.565 ;iou: 0.680 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 1.944 ;acc: 0.615 ;iou: 0.705 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 2.049 ;Train accuracy: 0.579 ;IOU accuracy: 0.663 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.008 ;acc: 0.510 ;iou_acc: 0.575 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.999 ;acc: 0.525 ;iou_acc: 0.640 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.132 ;acc: 0.445 ;iou_acc: 0.550 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.041 ;acc: 0.475 ;iou_acc: 0.575 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.028 ;acc: 0.480 ;iou_acc: 0.585 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.042 ;acc: 0.520 ;iou_acc: 0.610 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.983 ;Test accuracy 0.500 ;IOU accuracy: 0.603 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.938 ;acc: 0.650 ;iou: 0.705 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.916 ;acc: 0.605 ;iou: 0.665 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.948 ;acc: 0.600 ;iou: 0.720 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.965 ;acc: 0.595 ;iou: 0.695 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.994 ;acc: 0.585 ;iou: 0.680 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.796 ;acc: 0.635 ;iou: 0.710 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.893 ;Train accuracy: 0.632 ;IOU accuracy: 0.707 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.915 ;acc: 0.530 ;iou_acc: 0.605 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.928 ;acc: 0.485 ;iou_acc: 0.600 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.040 ;acc: 0.505 ;iou_acc: 0.580 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.920 ;acc: 0.545 ;iou_acc: 0.670 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.906 ;acc: 0.520 ;iou_acc: 0.625 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.929 ;acc: 0.530 ;iou_acc: 0.660 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.884 ;Test accuracy 0.530 ;IOU accuracy: 0.629 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.810 ;acc: 0.710 ;iou: 0.720 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.873 ;acc: 0.635 ;iou: 0.735 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.625 ;acc: 0.665 ;iou: 0.760 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.706 ;acc: 0.720 ;iou: 0.780 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.857 ;acc: 0.670 ;iou: 0.735 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.696 ;acc: 0.745 ;iou: 0.820 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.755 ;Train accuracy: 0.686 ;IOU accuracy: 0.753 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.757 ;acc: 0.615 ;iou_acc: 0.680 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.738 ;acc: 0.575 ;iou_acc: 0.670 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.936 ;acc: 0.505 ;iou_acc: 0.590 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.792 ;acc: 0.570 ;iou_acc: 0.675 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.791 ;acc: 0.535 ;iou_acc: 0.655 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.833 ;acc: 0.600 ;iou_acc: 0.705 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.764 ;Test accuracy 0.571 ;IOU accuracy: 0.672 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.606 ;acc: 0.705 ;iou: 0.770 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.716 ;acc: 0.745 ;iou: 0.825 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.493 ;acc: 0.795 ;iou: 0.855 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.684 ;acc: 0.685 ;iou: 0.785 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.586 ;acc: 0.780 ;iou: 0.835 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.779 ;acc: 0.710 ;iou: 0.790 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.602 ;Train accuracy: 0.745 ;IOU accuracy: 0.810 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.654 ;acc: 0.580 ;iou_acc: 0.655 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.593 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.861 ;acc: 0.545 ;iou_acc: 0.620 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.701 ;acc: 0.615 ;iou_acc: 0.725 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.676 ;acc: 0.600 ;iou_acc: 0.720 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.681 ;acc: 0.610 ;iou_acc: 0.710 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.633 ;Test accuracy 0.613 ;IOU accuracy: 0.715 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.206 ;acc: 0.820 ;iou: 0.875 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.324 ;acc: 0.825 ;iou: 0.840 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.507 ;acc: 0.820 ;iou: 0.860 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.420 ;acc: 0.795 ;iou: 0.860 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.564 ;acc: 0.755 ;iou: 0.810 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.419 ;acc: 0.820 ;iou: 0.850 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.455 ;Train accuracy: 0.789 ;IOU accuracy: 0.845 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.651 ;acc: 0.610 ;iou_acc: 0.705 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.510 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.814 ;acc: 0.570 ;iou_acc: 0.655 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.607 ;acc: 0.625 ;iou_acc: 0.740 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.640 ;acc: 0.635 ;iou_acc: 0.755 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.635 ;acc: 0.615 ;iou_acc: 0.730 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.561 ;Test accuracy 0.633 ;IOU accuracy: 0.733 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.263 ;acc: 0.860 ;iou: 0.915 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.333 ;acc: 0.840 ;iou: 0.885 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.412 ;acc: 0.785 ;iou: 0.860 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.354 ;acc: 0.790 ;iou: 0.865 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.282 ;acc: 0.855 ;iou: 0.890 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.455 ;acc: 0.770 ;iou: 0.825 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 1.353 ;Train accuracy: 0.818 ;IOU accuracy: 0.866 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.591 ;acc: 0.625 ;iou_acc: 0.730 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.439 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.772 ;acc: 0.585 ;iou_acc: 0.695 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.530 ;acc: 0.640 ;iou_acc: 0.725 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.548 ;acc: 0.645 ;iou_acc: 0.770 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.569 ;acc: 0.630 ;iou_acc: 0.730 ;time: 0:01:42\n",
      "\n",
      "*BTrain: False ;Test loss: 1.506 ;Test accuracy 0.649 ;IOU accuracy: 0.748 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.314 ;acc: 0.805 ;iou: 0.860 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.333 ;acc: 0.845 ;iou: 0.870 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.087 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.362 ;acc: 0.815 ;iou: 0.835 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 0.993 ;acc: 0.855 ;iou: 0.910 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.421 ;acc: 0.815 ;iou: 0.870 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 1.262 ;Train accuracy: 0.838 ;IOU accuracy: 0.883 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.472 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.381 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.691 ;acc: 0.605 ;iou_acc: 0.695 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.442 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:24\n",
      "batch: 200 ;B loss: 1.571 ;acc: 0.625 ;iou_acc: 0.735 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.591 ;acc: 0.620 ;iou_acc: 0.730 ;time: 0:01:41\n",
      "\n",
      "*BTrain: False ;Test loss: 1.466 ;Test accuracy 0.659 ;IOU accuracy: 0.757 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.243 ;acc: 0.865 ;iou: 0.875 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.158 ;acc: 0.870 ;iou: 0.870 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.059 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.376 ;acc: 0.830 ;iou: 0.895 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.258 ;acc: 0.865 ;iou: 0.875 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.298 ;acc: 0.820 ;iou: 0.860 ;time: 0:00:50\n",
      "\n",
      "*Training B: True ;B Train loss: 1.193 ;Train accuracy: 0.852 ;IOU accuracy: 0.893 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.539 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.379 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.710 ;acc: 0.595 ;iou_acc: 0.670 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.412 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.418 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.479 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:43\n",
      "\n",
      "*BTrain: True ;Test loss: 1.430 ;Test accuracy 0.670 ;IOU accuracy: 0.767 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 0.945 ;acc: 0.875 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 0.967 ;acc: 0.885 ;iou: 0.905 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.238 ;acc: 0.840 ;iou: 0.910 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.122 ;acc: 0.870 ;iou: 0.870 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.161 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.033 ;acc: 0.915 ;iou: 0.910 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 1.129 ;Train accuracy: 0.867 ;IOU accuracy: 0.906 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.549 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.454 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.712 ;acc: 0.605 ;iou_acc: 0.695 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.458 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.500 ;acc: 0.650 ;iou_acc: 0.780 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.459 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.426 ;Test accuracy 0.675 ;IOU accuracy: 0.770 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.054 ;acc: 0.885 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.082 ;acc: 0.850 ;iou: 0.910 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.075 ;acc: 0.905 ;iou: 0.905 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.162 ;acc: 0.855 ;iou: 0.880 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.128 ;acc: 0.850 ;iou: 0.885 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.313 ;acc: 0.800 ;iou: 0.895 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 1.071 ;Train accuracy: 0.881 ;IOU accuracy: 0.915 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.486 ;acc: 0.640 ;iou_acc: 0.730 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.451 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.721 ;acc: 0.620 ;iou_acc: 0.695 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.377 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.479 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.522 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.434 ;Test accuracy 0.677 ;IOU accuracy: 0.772 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.293 ;acc: 0.875 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 0.995 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.139 ;acc: 0.880 ;iou: 0.880 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 0.973 ;acc: 0.900 ;iou: 0.920 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.053 ;acc: 0.875 ;iou: 0.905 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 0.951 ;acc: 0.870 ;iou: 0.940 ;time: 0:00:50\n",
      "\n",
      "*Training B: True ;B Train loss: 1.018 ;Train accuracy: 0.892 ;IOU accuracy: 0.923 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.513 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.359 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.654 ;acc: 0.610 ;iou_acc: 0.690 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.396 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.458 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.449 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:44\n",
      "\n",
      "*BTrain: True ;Test loss: 1.418 ;Test accuracy 0.682 ;IOU accuracy: 0.776 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.054 ;acc: 0.900 ;iou: 0.925 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.085 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.058 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 0.906 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 0.986 ;acc: 0.895 ;iou: 0.905 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 0.983 ;acc: 0.880 ;iou: 0.935 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.973 ;Train accuracy: 0.899 ;IOU accuracy: 0.929 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.438 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.378 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.666 ;acc: 0.615 ;iou_acc: 0.700 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.384 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.418 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.552 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:42\n",
      "\n",
      "*BTrain: False ;Test loss: 1.423 ;Test accuracy 0.686 ;IOU accuracy: 0.779 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.824 ;acc: 0.910 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.009 ;acc: 0.895 ;iou: 0.900 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.846 ;acc: 0.905 ;iou: 0.955 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 0.912 ;acc: 0.920 ;iou: 0.930 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.183 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.015 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.931 ;Train accuracy: 0.907 ;IOU accuracy: 0.935 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.441 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.368 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.729 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.392 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.397 ;acc: 0.670 ;iou_acc: 0.800 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.513 ;acc: 0.640 ;iou_acc: 0.730 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.402 ;Test accuracy 0.690 ;IOU accuracy: 0.783 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.743 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 1.059 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.801 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 1.046 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.024 ;acc: 0.850 ;iou: 0.910 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.748 ;acc: 0.940 ;iou: 0.940 ;time: 0:00:50\n",
      "\n",
      "*Training B: True ;B Train loss: 0.890 ;Train accuracy: 0.918 ;IOU accuracy: 0.941 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.491 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.405 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.787 ;acc: 0.595 ;iou_acc: 0.675 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.503 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "batch: 200 ;B loss: 1.451 ;acc: 0.680 ;iou_acc: 0.805 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.518 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:41\n",
      "\n",
      "*BTrain: True ;Test loss: 1.415 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.725 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.832 ;acc: 0.915 ;iou: 0.960 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.861 ;acc: 0.925 ;iou: 0.935 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.931 ;acc: 0.940 ;iou: 0.940 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.858 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.828 ;acc: 0.935 ;iou: 0.940 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 0.855 ;Train accuracy: 0.926 ;IOU accuracy: 0.946 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.427 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.351 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.678 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.386 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.454 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.508 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:40\n",
      "\n",
      "*BTrain: False ;Test loss: 1.405 ;Test accuracy 0.696 ;IOU accuracy: 0.787 ;Time: 0:01:48\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.826 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.857 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.700 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.781 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.801 ;acc: 0.930 ;iou: 0.935 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.827 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:41\n",
      "\n",
      "*Training B: False ;B Train loss: 0.816 ;Train accuracy: 0.930 ;IOU accuracy: 0.951 ;Time: 0:00:50 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.472 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:00:51\n",
      "batch: 50 ;B loss: 1.454 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:00:59\n",
      "batch: 100 ;B loss: 1.720 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:06\n",
      "batch: 150 ;B loss: 1.438 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:14\n",
      "batch: 200 ;B loss: 1.462 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.591 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.438 ;Test accuracy 0.692 ;IOU accuracy: 0.786 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.883 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.677 ;acc: 0.935 ;iou: 0.970 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.779 ;acc: 0.945 ;iou: 0.980 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.716 ;acc: 0.945 ;iou: 0.970 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.696 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.889 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:50\n",
      "\n",
      "*Training B: True ;B Train loss: 0.780 ;Train accuracy: 0.937 ;IOU accuracy: 0.955 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.587 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.573 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.719 ;acc: 0.615 ;iou_acc: 0.705 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.597 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.508 ;acc: 0.695 ;iou_acc: 0.825 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.506 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:43\n",
      "\n",
      "*BTrain: True ;Test loss: 1.478 ;Test accuracy 0.692 ;IOU accuracy: 0.784 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.783 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.760 ;acc: 0.940 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.860 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.578 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.658 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.878 ;acc: 0.925 ;iou: 0.930 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 0.746 ;Train accuracy: 0.940 ;IOU accuracy: 0.958 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.498 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.475 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.713 ;acc: 0.635 ;iou_acc: 0.710 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.493 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.556 ;acc: 0.665 ;iou_acc: 0.810 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.524 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.438 ;Test accuracy 0.699 ;IOU accuracy: 0.790 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.672 ;acc: 0.945 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.590 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.672 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.779 ;acc: 0.955 ;iou: 0.955 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.751 ;acc: 0.960 ;iou: 0.955 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.694 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.720 ;Train accuracy: 0.947 ;IOU accuracy: 0.961 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.494 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.563 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.783 ;acc: 0.645 ;iou_acc: 0.715 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 1.515 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:01:24\n",
      "batch: 200 ;B loss: 1.496 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.624 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:41\n",
      "\n",
      "*BTrain: False ;Test loss: 1.448 ;Test accuracy 0.700 ;IOU accuracy: 0.792 ;Time: 0:01:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.643 ;acc: 0.965 ;iou: 0.945 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.787 ;acc: 0.950 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.754 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.829 ;acc: 0.950 ;iou: 0.980 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.755 ;acc: 0.930 ;iou: 0.980 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.698 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:51\n",
      "\n",
      "*Training B: True ;B Train loss: 0.692 ;Train accuracy: 0.949 ;IOU accuracy: 0.965 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.499 ;acc: 0.705 ;iou_acc: 0.770 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.627 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.700 ;acc: 0.645 ;iou_acc: 0.740 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.552 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.517 ;acc: 0.645 ;iou_acc: 0.780 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.643 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:44\n",
      "\n",
      "*BTrain: True ;Test loss: 1.457 ;Test accuracy 0.701 ;IOU accuracy: 0.794 ;Time: 0:01:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.564 ;acc: 0.975 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.645 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.586 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.676 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.647 ;acc: 0.930 ;iou: 0.940 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.702 ;acc: 0.950 ;iou: 0.985 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.662 ;Train accuracy: 0.954 ;IOU accuracy: 0.968 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.538 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.475 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.722 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.394 ;acc: 0.750 ;iou_acc: 0.860 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.468 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.607 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:42\n",
      "\n",
      "*BTrain: False ;Test loss: 1.472 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.578 ;acc: 0.970 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.585 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.775 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.474 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.549 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.732 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.636 ;Train accuracy: 0.957 ;IOU accuracy: 0.970 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.559 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.486 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.818 ;acc: 0.625 ;iou_acc: 0.700 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 1.563 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:24\n",
      "batch: 200 ;B loss: 1.607 ;acc: 0.650 ;iou_acc: 0.790 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.678 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:42\n",
      "\n",
      "*BTrain: False ;Test loss: 1.510 ;Test accuracy 0.697 ;IOU accuracy: 0.788 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.577 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.493 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.622 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.475 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.534 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.545 ;acc: 0.970 ;iou: 0.955 ;time: 0:00:49\n",
      "\n",
      "*Training B: True ;B Train loss: 0.608 ;Train accuracy: 0.960 ;IOU accuracy: 0.972 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.555 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.606 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.782 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.654 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:24\n",
      "batch: 200 ;B loss: 1.638 ;acc: 0.660 ;iou_acc: 0.785 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.664 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:41\n",
      "\n",
      "*BTrain: True ;Test loss: 1.532 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.619 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.614 ;acc: 0.985 ;iou: 0.970 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.506 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.566 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.672 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.519 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 0.584 ;Train accuracy: 0.963 ;IOU accuracy: 0.974 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.553 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.598 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.775 ;acc: 0.630 ;iou_acc: 0.715 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.526 ;acc: 0.735 ;iou_acc: 0.825 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.631 ;acc: 0.670 ;iou_acc: 0.800 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.814 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.545 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.489 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.488 ;acc: 0.985 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.497 ;acc: 0.970 ;iou: 0.955 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.647 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.660 ;acc: 0.965 ;iou: 0.955 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.564 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.563 ;Train accuracy: 0.967 ;IOU accuracy: 0.977 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.604 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.481 ;acc: 0.725 ;iou_acc: 0.840 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.779 ;acc: 0.635 ;iou_acc: 0.705 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.562 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.470 ;acc: 0.690 ;iou_acc: 0.815 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.708 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:42\n",
      "\n",
      "*BTrain: False ;Test loss: 1.517 ;Test accuracy 0.706 ;IOU accuracy: 0.797 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.455 ;acc: 0.990 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.474 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.488 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.553 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.631 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.573 ;acc: 0.975 ;iou: 0.970 ;time: 0:00:50\n",
      "\n",
      "*Training B: True ;B Train loss: 0.540 ;Train accuracy: 0.969 ;IOU accuracy: 0.979 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.532 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.553 ;acc: 0.715 ;iou_acc: 0.820 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.705 ;acc: 0.635 ;iou_acc: 0.710 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.609 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.451 ;acc: 0.675 ;iou_acc: 0.815 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.732 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:43\n",
      "\n",
      "*BTrain: True ;Test loss: 1.560 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.375 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.495 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.563 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.393 ;acc: 0.965 ;iou: 0.990 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.452 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.554 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.512 ;Train accuracy: 0.972 ;IOU accuracy: 0.980 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.643 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.490 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.885 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.623 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:24\n",
      "batch: 200 ;B loss: 1.605 ;acc: 0.675 ;iou_acc: 0.810 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.885 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:41\n",
      "\n",
      "*BTrain: False ;Test loss: 1.579 ;Test accuracy 0.705 ;IOU accuracy: 0.797 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.558 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.510 ;acc: 0.990 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.406 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.496 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.610 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.555 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.499 ;Train accuracy: 0.973 ;IOU accuracy: 0.981 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.953 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.662 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.907 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.679 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.552 ;acc: 0.680 ;iou_acc: 0.835 ;time: 0:01:31\n",
      "batch: 250 ;B loss: 1.939 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:39\n",
      "\n",
      "*BTrain: False ;Test loss: 1.662 ;Test accuracy 0.700 ;IOU accuracy: 0.790 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.462 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.434 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.396 ;acc: 0.970 ;iou: 0.960 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.562 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.376 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.490 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.474 ;Train accuracy: 0.975 ;IOU accuracy: 0.982 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.558 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.535 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.880 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.671 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.521 ;acc: 0.690 ;iou_acc: 0.825 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.830 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:33\n",
      "\n",
      "*BTrain: True ;Test loss: 1.610 ;Test accuracy 0.703 ;IOU accuracy: 0.794 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.438 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.431 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.446 ;acc: 1.000 ;iou: 0.985 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.432 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.684 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.466 ;acc: 0.970 ;iou: 0.970 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.455 ;Train accuracy: 0.977 ;IOU accuracy: 0.984 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.641 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.563 ;acc: 0.725 ;iou_acc: 0.820 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.976 ;acc: 0.625 ;iou_acc: 0.720 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.818 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.586 ;acc: 0.670 ;iou_acc: 0.805 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.811 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.648 ;Test accuracy 0.705 ;IOU accuracy: 0.795 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.388 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.434 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.469 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.412 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.372 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.422 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.442 ;Train accuracy: 0.978 ;IOU accuracy: 0.985 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.661 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.653 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.972 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.749 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.686 ;acc: 0.690 ;iou_acc: 0.820 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.927 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.650 ;Test accuracy 0.707 ;IOU accuracy: 0.798 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.369 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.316 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.405 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.335 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.351 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.397 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.425 ;Train accuracy: 0.980 ;IOU accuracy: 0.985 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.654 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.705 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.001 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.873 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.499 ;acc: 0.670 ;iou_acc: 0.820 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.842 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.665 ;Test accuracy 0.704 ;IOU accuracy: 0.795 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.383 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.343 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.312 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.376 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.410 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.527 ;acc: 0.995 ;iou: 0.975 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.403 ;Train accuracy: 0.982 ;IOU accuracy: 0.987 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.760 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.526 ;acc: 0.715 ;iou_acc: 0.820 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 2.077 ;acc: 0.650 ;iou_acc: 0.715 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.609 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.610 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 1.836 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:01:32\n",
      "\n",
      "*BTrain: False ;Test loss: 1.685 ;Test accuracy 0.706 ;IOU accuracy: 0.796 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.336 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.415 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.308 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.337 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.428 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.439 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.387 ;Train accuracy: 0.982 ;IOU accuracy: 0.987 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.763 ;acc: 0.715 ;iou_acc: 0.770 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.636 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.928 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.759 ;acc: 0.725 ;iou_acc: 0.820 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.556 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 1.908 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.731 ;Test accuracy 0.706 ;IOU accuracy: 0.795 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.238 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.303 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.459 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.428 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.375 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.389 ;acc: 0.995 ;iou: 0.985 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.374 ;Train accuracy: 0.983 ;IOU accuracy: 0.988 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.918 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.731 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.012 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.775 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.786 ;acc: 0.675 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.967 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.734 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.258 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.437 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.425 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.304 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.384 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.335 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.361 ;Train accuracy: 0.984 ;IOU accuracy: 0.989 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.856 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.660 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.126 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.759 ;acc: 0.740 ;iou_acc: 0.835 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.693 ;acc: 0.660 ;iou_acc: 0.800 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.134 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.759 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.317 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.442 ;acc: 0.995 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.540 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.344 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.362 ;acc: 0.990 ;iou: 0.980 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.308 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.350 ;Train accuracy: 0.985 ;IOU accuracy: 0.989 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.666 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.624 ;acc: 0.710 ;iou_acc: 0.825 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.135 ;acc: 0.640 ;iou_acc: 0.720 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.843 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.723 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.012 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.753 ;Test accuracy 0.706 ;IOU accuracy: 0.796 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.356 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.451 ;acc: 0.980 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.338 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.465 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.384 ;acc: 0.990 ;iou: 0.975 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.351 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.332 ;Train accuracy: 0.985 ;IOU accuracy: 0.990 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.552 ;acc: 0.735 ;iou_acc: 0.800 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.679 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.163 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.758 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.653 ;acc: 0.700 ;iou_acc: 0.825 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.977 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.746 ;Test accuracy 0.707 ;IOU accuracy: 0.799 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.295 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.339 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.390 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.419 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.306 ;acc: 0.985 ;iou: 0.980 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.461 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.322 ;Train accuracy: 0.986 ;IOU accuracy: 0.990 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.790 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.810 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.215 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 1.848 ;acc: 0.745 ;iou_acc: 0.825 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.626 ;acc: 0.700 ;iou_acc: 0.820 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.150 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.833 ;Test accuracy 0.705 ;IOU accuracy: 0.795 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.286 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.327 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.302 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.354 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.450 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.282 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.313 ;Train accuracy: 0.987 ;IOU accuracy: 0.991 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.813 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.673 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.170 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.929 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.750 ;acc: 0.695 ;iou_acc: 0.825 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.089 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.824 ;Test accuracy 0.705 ;IOU accuracy: 0.797 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.251 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.229 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.299 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.273 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.308 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.385 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.293 ;Train accuracy: 0.988 ;IOU accuracy: 0.991 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.987 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.834 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.226 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.857 ;acc: 0.745 ;iou_acc: 0.840 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 1.703 ;acc: 0.680 ;iou_acc: 0.815 ;time: 0:01:24\n",
      "batch: 250 ;B loss: 2.169 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.842 ;Test accuracy 0.707 ;IOU accuracy: 0.797 ;Time: 0:01:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.170 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.236 ;acc: 1.000 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.292 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.223 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.172 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.239 ;acc: 0.980 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.292 ;Train accuracy: 0.988 ;IOU accuracy: 0.992 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.886 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.806 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.236 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.087 ;acc: 0.670 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.609 ;acc: 0.685 ;iou_acc: 0.815 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.240 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.842 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.331 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.254 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.222 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.238 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.209 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.247 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.269 ;Train accuracy: 0.989 ;IOU accuracy: 0.993 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.964 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.914 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.396 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.038 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.848 ;acc: 0.700 ;iou_acc: 0.835 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.281 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.907 ;Test accuracy 0.704 ;IOU accuracy: 0.795 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.305 ;acc: 1.000 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.300 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.360 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.279 ;acc: 0.980 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.428 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.435 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.270 ;Train accuracy: 0.989 ;IOU accuracy: 0.992 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.811 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.882 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.334 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.962 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.793 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.174 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.876 ;Test accuracy 0.706 ;IOU accuracy: 0.796 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.253 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.220 ;acc: 0.975 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.208 ;acc: 0.990 ;iou: 0.980 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.304 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.236 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.167 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.257 ;Train accuracy: 0.990 ;IOU accuracy: 0.993 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.829 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.779 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.379 ;acc: 0.650 ;iou_acc: 0.735 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.997 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.747 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.261 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.884 ;Test accuracy 0.709 ;IOU accuracy: 0.798 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.218 ;acc: 0.980 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.216 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.234 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.288 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.499 ;acc: 0.980 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.352 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.251 ;Train accuracy: 0.990 ;IOU accuracy: 0.993 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.889 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.783 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.349 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.028 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.869 ;acc: 0.700 ;iou_acc: 0.820 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.127 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.907 ;Test accuracy 0.709 ;IOU accuracy: 0.798 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.209 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.140 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.270 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.232 ;acc: 1.000 ;iou: 0.995 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.197 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.274 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.245 ;Train accuracy: 0.990 ;IOU accuracy: 0.993 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 2.021 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.795 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.330 ;acc: 0.670 ;iou_acc: 0.725 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.119 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.777 ;acc: 0.685 ;iou_acc: 0.830 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.216 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.968 ;Test accuracy 0.707 ;IOU accuracy: 0.797 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.233 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.138 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.319 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.211 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.167 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.270 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.233 ;Train accuracy: 0.991 ;IOU accuracy: 0.993 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.977 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.984 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.542 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.085 ;acc: 0.705 ;iou_acc: 0.815 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.828 ;acc: 0.690 ;iou_acc: 0.825 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.269 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.966 ;Test accuracy 0.708 ;IOU accuracy: 0.797 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 1.0\n",
      "dropout_out 0.5\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.986 ;acc: 0.425 ;iou: 0.520 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.683 ;acc: 0.375 ;iou: 0.500 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.702 ;acc: 0.370 ;iou: 0.475 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.633 ;acc: 0.345 ;iou: 0.435 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.451 ;acc: 0.430 ;iou: 0.530 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.377 ;acc: 0.440 ;iou: 0.545 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 2.568 ;Train accuracy: 0.406 ;IOU accuracy: 0.498 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.375 ;acc: 0.335 ;iou_acc: 0.435 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 2.429 ;acc: 0.415 ;iou_acc: 0.510 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.493 ;acc: 0.295 ;iou_acc: 0.415 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.385 ;acc: 0.345 ;iou_acc: 0.450 ;time: 0:01:16\n",
      "batch: 200 ;B loss: 2.435 ;acc: 0.375 ;iou_acc: 0.490 ;time: 0:01:23\n",
      "batch: 250 ;B loss: 2.402 ;acc: 0.350 ;iou_acc: 0.470 ;time: 0:01:30\n",
      "\n",
      "*BTrain: True ;Test loss: 2.362 ;Test accuracy 0.375 ;IOU accuracy: 0.484 ;Time: 0:01:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.287 ;acc: 0.560 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.337 ;acc: 0.535 ;iou: 0.635 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.246 ;acc: 0.530 ;iou: 0.610 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.054 ;acc: 0.575 ;iou: 0.690 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.073 ;acc: 0.575 ;iou: 0.680 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.133 ;acc: 0.570 ;iou: 0.655 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 2.177 ;Train accuracy: 0.558 ;IOU accuracy: 0.642 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.159 ;acc: 0.465 ;iou_acc: 0.555 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.215 ;acc: 0.420 ;iou_acc: 0.495 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.208 ;acc: 0.475 ;iou_acc: 0.570 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.134 ;acc: 0.385 ;iou_acc: 0.480 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 2.225 ;acc: 0.380 ;iou_acc: 0.555 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.131 ;acc: 0.470 ;iou_acc: 0.575 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 2.095 ;Test accuracy 0.469 ;IOU accuracy: 0.574 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 1.922 ;acc: 0.660 ;iou: 0.725 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 1.999 ;acc: 0.615 ;iou: 0.700 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 1.893 ;acc: 0.645 ;iou: 0.715 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 1.817 ;acc: 0.675 ;iou: 0.730 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 1.864 ;acc: 0.680 ;iou: 0.730 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 1.875 ;acc: 0.660 ;iou: 0.755 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 1.924 ;Train accuracy: 0.648 ;IOU accuracy: 0.722 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 1.965 ;acc: 0.535 ;iou_acc: 0.615 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.000 ;acc: 0.505 ;iou_acc: 0.600 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.071 ;acc: 0.475 ;iou_acc: 0.545 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.995 ;acc: 0.485 ;iou_acc: 0.580 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.035 ;acc: 0.465 ;iou_acc: 0.590 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.966 ;acc: 0.535 ;iou_acc: 0.650 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.919 ;Test accuracy 0.523 ;IOU accuracy: 0.623 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.719 ;acc: 0.700 ;iou: 0.775 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 1.698 ;acc: 0.690 ;iou: 0.765 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 1.663 ;acc: 0.700 ;iou: 0.770 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.796 ;acc: 0.690 ;iou: 0.750 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.675 ;acc: 0.730 ;iou: 0.780 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.696 ;acc: 0.725 ;iou: 0.780 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 1.739 ;Train accuracy: 0.718 ;IOU accuracy: 0.783 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.865 ;acc: 0.565 ;iou_acc: 0.670 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.846 ;acc: 0.565 ;iou_acc: 0.645 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.902 ;acc: 0.525 ;iou_acc: 0.605 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.850 ;acc: 0.565 ;iou_acc: 0.645 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.842 ;acc: 0.515 ;iou_acc: 0.650 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.791 ;acc: 0.570 ;iou_acc: 0.675 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.771 ;Test accuracy 0.571 ;IOU accuracy: 0.671 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.426 ;acc: 0.845 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.532 ;acc: 0.835 ;iou: 0.870 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.586 ;acc: 0.770 ;iou: 0.835 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.457 ;acc: 0.810 ;iou: 0.845 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.588 ;acc: 0.770 ;iou: 0.820 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.473 ;acc: 0.815 ;iou: 0.870 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 1.540 ;Train accuracy: 0.795 ;IOU accuracy: 0.851 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.729 ;acc: 0.580 ;iou_acc: 0.675 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 1.603 ;acc: 0.635 ;iou_acc: 0.725 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.753 ;acc: 0.570 ;iou_acc: 0.630 ;time: 0:01:08\n",
      "batch: 150 ;B loss: 1.733 ;acc: 0.585 ;iou_acc: 0.695 ;time: 0:01:15\n",
      "batch: 200 ;B loss: 1.643 ;acc: 0.615 ;iou_acc: 0.770 ;time: 0:01:22\n",
      "batch: 250 ;B loss: 1.709 ;acc: 0.610 ;iou_acc: 0.720 ;time: 0:01:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.669 ;Test accuracy 0.606 ;IOU accuracy: 0.706 ;Time: 0:01:38\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.431 ;acc: 0.790 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.519 ;acc: 0.800 ;iou: 0.855 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.329 ;acc: 0.830 ;iou: 0.905 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.423 ;acc: 0.855 ;iou: 0.880 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.330 ;acc: 0.865 ;iou: 0.890 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.503 ;acc: 0.785 ;iou: 0.860 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.369 ;Train accuracy: 0.844 ;IOU accuracy: 0.889 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.657 ;acc: 0.610 ;iou_acc: 0.730 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.524 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.632 ;acc: 0.600 ;iou_acc: 0.680 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.524 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.545 ;acc: 0.635 ;iou_acc: 0.755 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.608 ;acc: 0.625 ;iou_acc: 0.770 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.539 ;Test accuracy 0.642 ;IOU accuracy: 0.741 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.299 ;acc: 0.850 ;iou: 0.890 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.375 ;acc: 0.855 ;iou: 0.915 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.313 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.373 ;acc: 0.840 ;iou: 0.905 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.331 ;acc: 0.870 ;iou: 0.900 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.445 ;acc: 0.795 ;iou: 0.850 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.237 ;Train accuracy: 0.873 ;IOU accuracy: 0.912 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.551 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.435 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.605 ;acc: 0.635 ;iou_acc: 0.700 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.516 ;acc: 0.645 ;iou_acc: 0.715 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.529 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.494 ;acc: 0.655 ;iou_acc: 0.765 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.497 ;Test accuracy 0.658 ;IOU accuracy: 0.757 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 0.975 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.039 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.123 ;acc: 0.905 ;iou: 0.930 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.175 ;acc: 0.895 ;iou: 0.960 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.131 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.208 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 1.137 ;Train accuracy: 0.897 ;IOU accuracy: 0.928 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.479 ;acc: 0.630 ;iou_acc: 0.725 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.417 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.574 ;acc: 0.625 ;iou_acc: 0.685 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.514 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.518 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.489 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.462 ;Test accuracy 0.666 ;IOU accuracy: 0.761 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.089 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 0.942 ;acc: 0.930 ;iou: 0.940 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 0.979 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 0.983 ;acc: 0.945 ;iou: 0.945 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 0.936 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 0.985 ;acc: 0.940 ;iou: 0.975 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.049 ;Train accuracy: 0.916 ;IOU accuracy: 0.942 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.488 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.457 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:01:01\n",
      "batch: 100 ;B loss: 1.588 ;acc: 0.645 ;iou_acc: 0.705 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.529 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.463 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.537 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.436 ;Test accuracy 0.675 ;IOU accuracy: 0.770 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.071 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 0.934 ;acc: 0.935 ;iou: 0.945 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 0.962 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.024 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 0.957 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 0.803 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.975 ;Train accuracy: 0.929 ;IOU accuracy: 0.952 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.518 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.473 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.578 ;acc: 0.635 ;iou_acc: 0.700 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.456 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.447 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.566 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.452 ;Test accuracy 0.676 ;IOU accuracy: 0.770 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 0.917 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.053 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 0.868 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 0.984 ;acc: 0.925 ;iou: 0.935 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 0.947 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 0.817 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.901 ;Train accuracy: 0.942 ;IOU accuracy: 0.961 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.493 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.394 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.576 ;acc: 0.645 ;iou_acc: 0.705 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.482 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.478 ;acc: 0.645 ;iou_acc: 0.770 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.647 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.466 ;Test accuracy 0.682 ;IOU accuracy: 0.776 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.024 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 0.834 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 0.841 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 0.931 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 0.852 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 0.877 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.836 ;Train accuracy: 0.952 ;IOU accuracy: 0.968 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.550 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.522 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.444 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.521 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.543 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.590 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.440 ;Test accuracy 0.689 ;IOU accuracy: 0.782 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 0.694 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 0.760 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 0.857 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 0.699 ;acc: 0.950 ;iou: 0.960 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 0.733 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 0.651 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:49\n",
      "\n",
      "*Training B: True ;B Train loss: 0.776 ;Train accuracy: 0.962 ;IOU accuracy: 0.974 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.442 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.429 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.511 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 1.375 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:24\n",
      "batch: 200 ;B loss: 1.420 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:32\n",
      "batch: 250 ;B loss: 1.680 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:41\n",
      "\n",
      "*BTrain: True ;Test loss: 1.451 ;Test accuracy 0.692 ;IOU accuracy: 0.785 ;Time: 0:01:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 0.576 ;acc: 0.980 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 0.686 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 0.741 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 0.813 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 0.525 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 0.909 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.719 ;Train accuracy: 0.968 ;IOU accuracy: 0.979 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.505 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.467 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.522 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.473 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.482 ;acc: 0.660 ;iou_acc: 0.785 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.721 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:44\n",
      "\n",
      "*BTrain: False ;Test loss: 1.466 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.652 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 0.663 ;acc: 0.960 ;iou: 0.960 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.526 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 0.655 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 0.637 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 0.627 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 0.662 ;Train accuracy: 0.975 ;IOU accuracy: 0.984 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.549 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.442 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.567 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.669 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.541 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.784 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.529 ;Test accuracy 0.688 ;IOU accuracy: 0.781 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.484 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.639 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.551 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 0.496 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 0.677 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.719 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:50\n",
      "\n",
      "*Training B: True ;B Train loss: 0.618 ;Train accuracy: 0.979 ;IOU accuracy: 0.986 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.585 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.546 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.560 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.440 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.547 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.821 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:42\n",
      "\n",
      "*BTrain: True ;Test loss: 1.513 ;Test accuracy 0.695 ;IOU accuracy: 0.787 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.445 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.391 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.436 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.531 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.692 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.567 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 0.561 ;Train accuracy: 0.983 ;IOU accuracy: 0.989 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.557 ;acc: 0.695 ;iou_acc: 0.815 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.536 ;acc: 0.695 ;iou_acc: 0.810 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.584 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.493 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.532 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.741 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.532 ;Test accuracy 0.697 ;IOU accuracy: 0.790 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.471 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.371 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.648 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.566 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.493 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.544 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.524 ;Train accuracy: 0.986 ;IOU accuracy: 0.991 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.841 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.606 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.642 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.553 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.579 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.938 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.611 ;Test accuracy 0.694 ;IOU accuracy: 0.785 ;Time: 0:01:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.410 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.446 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.459 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.487 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.528 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.538 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:49\n",
      "\n",
      "*Training B: True ;B Train loss: 0.477 ;Train accuracy: 0.990 ;IOU accuracy: 0.994 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.706 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.567 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.648 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.489 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.591 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.841 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:42\n",
      "\n",
      "*BTrain: True ;Test loss: 1.600 ;Test accuracy 0.697 ;IOU accuracy: 0.790 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.332 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.320 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.325 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.444 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.418 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.465 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 0.442 ;Train accuracy: 0.992 ;IOU accuracy: 0.994 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.524 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.599 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.658 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.617 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.815 ;acc: 0.650 ;iou_acc: 0.775 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 2.006 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.643 ;Test accuracy 0.697 ;IOU accuracy: 0.790 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.399 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.268 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.322 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.319 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.369 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.419 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 0.405 ;Train accuracy: 0.993 ;IOU accuracy: 0.995 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.742 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.568 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.626 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.594 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:24\n",
      "batch: 200 ;B loss: 1.697 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 2.052 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:42\n",
      "\n",
      "*BTrain: False ;Test loss: 1.667 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.372 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.306 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.411 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.268 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.472 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.457 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:50\n",
      "\n",
      "*Training B: True ;B Train loss: 0.369 ;Train accuracy: 0.995 ;IOU accuracy: 0.996 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.660 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.598 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.542 ;acc: 0.725 ;iou_acc: 0.780 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.582 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.616 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 2.046 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:42\n",
      "\n",
      "*BTrain: True ;Test loss: 1.644 ;Test accuracy 0.705 ;IOU accuracy: 0.796 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.241 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.263 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.272 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.262 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.404 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.261 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 0.333 ;Train accuracy: 0.996 ;IOU accuracy: 0.997 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.888 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.575 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.726 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.579 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.872 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.217 ;acc: 0.645 ;iou_acc: 0.770 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.740 ;Test accuracy 0.698 ;IOU accuracy: 0.792 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.245 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.285 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.244 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.198 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.293 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.376 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.300 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.832 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.699 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.912 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.852 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.990 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.384 ;acc: 0.645 ;iou_acc: 0.755 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.826 ;Test accuracy 0.696 ;IOU accuracy: 0.790 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.173 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.276 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.239 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.250 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.336 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.329 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.275 ;Train accuracy: 0.997 ;IOU accuracy: 0.998 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.747 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.709 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.739 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.770 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.043 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.166 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.799 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.177 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.154 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.234 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.233 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.345 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.266 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.246 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.784 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.841 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.823 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.673 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.054 ;acc: 0.630 ;iou_acc: 0.760 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.322 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.864 ;Test accuracy 0.697 ;IOU accuracy: 0.791 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.248 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.181 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.220 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.190 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.285 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.288 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.227 ;Train accuracy: 0.998 ;IOU accuracy: 0.999 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.842 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.645 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.863 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.797 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.924 ;acc: 0.685 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.301 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.867 ;Test accuracy 0.704 ;IOU accuracy: 0.797 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.165 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.177 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.216 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.148 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.272 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.162 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.205 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.842 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.750 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.014 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.683 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.939 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.395 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.925 ;Test accuracy 0.698 ;IOU accuracy: 0.791 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.258 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.150 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.198 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.187 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.179 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.155 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.183 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.901 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.647 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.949 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.768 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.982 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.603 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.953 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.161 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.139 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.213 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.138 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.202 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.122 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.161 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.785 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.693 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.850 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.729 ;acc: 0.740 ;iou_acc: 0.805 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.054 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.394 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.961 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.093 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.086 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.134 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.088 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.212 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.187 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:49\n",
      "\n",
      "*Training B: True ;B Train loss: 0.151 ;Train accuracy: 0.999 ;IOU accuracy: 0.999 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.875 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.747 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 2.059 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 1.729 ;acc: 0.735 ;iou_acc: 0.810 ;time: 0:01:23\n",
      "batch: 200 ;B loss: 2.185 ;acc: 0.655 ;iou_acc: 0.785 ;time: 0:01:31\n",
      "batch: 250 ;B loss: 2.476 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:39\n",
      "\n",
      "*BTrain: True ;Test loss: 2.018 ;Test accuracy 0.700 ;IOU accuracy: 0.793 ;Time: 0:01:47\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.185 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.106 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.173 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.176 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.112 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.167 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.128 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 2.027 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.746 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.968 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.934 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.143 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.510 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 2.034 ;Test accuracy 0.701 ;IOU accuracy: 0.794 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.192 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.185 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.118 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.078 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.181 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.161 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.117 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.834 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.887 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.061 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.845 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.245 ;acc: 0.680 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.587 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 2.055 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.129 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.139 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.069 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.209 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.121 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.129 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.102 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.853 ;acc: 0.720 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.791 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.051 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.936 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.340 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.806 ;acc: 0.640 ;iou_acc: 0.765 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 2.104 ;Test accuracy 0.702 ;IOU accuracy: 0.795 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.074 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.085 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.085 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.101 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.140 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.075 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 0.088 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 2.085 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.691 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.282 ;acc: 0.705 ;iou_acc: 0.760 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.891 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.225 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.588 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 2.171 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.076 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.060 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.054 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.053 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.068 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.073 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.084 ;Train accuracy: 0.999 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 2.035 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.910 ;acc: 0.740 ;iou_acc: 0.815 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.248 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.965 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.331 ;acc: 0.680 ;iou_acc: 0.800 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.729 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 2.168 ;Test accuracy 0.700 ;IOU accuracy: 0.794 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.060 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.145 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.059 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.068 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.079 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.207 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.071 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 2.172 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.895 ;acc: 0.725 ;iou_acc: 0.820 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.258 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.886 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.416 ;acc: 0.660 ;iou_acc: 0.780 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.712 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 2.203 ;Test accuracy 0.702 ;IOU accuracy: 0.794 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.079 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.028 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.029 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.052 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.062 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.086 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.068 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 2.066 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.818 ;acc: 0.750 ;iou_acc: 0.830 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.337 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.996 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.528 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.812 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 2.226 ;Test accuracy 0.703 ;IOU accuracy: 0.796 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.047 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.045 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.055 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.105 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.060 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.178 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.063 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 2.127 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.018 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.335 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.974 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.374 ;acc: 0.695 ;iou_acc: 0.815 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.797 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 2.211 ;Test accuracy 0.702 ;IOU accuracy: 0.795 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.037 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.032 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.027 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.048 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.061 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.041 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.059 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 2.136 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.888 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.256 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.967 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.521 ;acc: 0.675 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.728 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 2.244 ;Test accuracy 0.702 ;IOU accuracy: 0.795 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.030 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.044 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.048 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.038 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.090 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.069 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.054 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 2.257 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.970 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.306 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.114 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.579 ;acc: 0.660 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 2.878 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 2.290 ;Test accuracy 0.699 ;IOU accuracy: 0.793 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.034 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.096 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.036 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.048 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.027 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.064 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.050 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 2.184 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.879 ;acc: 0.755 ;iou_acc: 0.820 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.344 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.991 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.529 ;acc: 0.665 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.907 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 2.272 ;Test accuracy 0.703 ;IOU accuracy: 0.796 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.017 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.083 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.069 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.056 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.071 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.040 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.047 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 2.201 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.977 ;acc: 0.745 ;iou_acc: 0.825 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.356 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.075 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.500 ;acc: 0.680 ;iou_acc: 0.810 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.877 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 2.269 ;Test accuracy 0.705 ;IOU accuracy: 0.798 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.036 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.034 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.029 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.058 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.040 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.035 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.040 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 2.367 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 2.200 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.363 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 2.127 ;acc: 0.730 ;iou_acc: 0.810 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.603 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.885 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 2.327 ;Test accuracy 0.702 ;IOU accuracy: 0.796 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.017 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.025 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.019 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.079 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.028 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.024 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:43\n",
      "\n",
      "*Training B: False ;B Train loss: 0.038 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:52 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 2.250 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:00:53\n",
      "batch: 50 ;B loss: 2.066 ;acc: 0.735 ;iou_acc: 0.825 ;time: 0:01:00\n",
      "batch: 100 ;B loss: 2.332 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 2.014 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 2.585 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 2.884 ;acc: 0.660 ;iou_acc: 0.790 ;time: 0:01:33\n",
      "\n",
      "*BTrain: False ;Test loss: 2.344 ;Test accuracy 0.701 ;IOU accuracy: 0.794 ;Time: 0:01:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.026 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.031 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.016 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.024 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.042 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.017 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.034 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 2.294 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.142 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.308 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.137 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.630 ;acc: 0.665 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 3.021 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 2.373 ;Test accuracy 0.701 ;IOU accuracy: 0.795 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.017 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.017 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.022 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.031 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.035 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.014 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.035 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 2.308 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.100 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.378 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.193 ;acc: 0.740 ;iou_acc: 0.830 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.653 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.909 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 2.383 ;Test accuracy 0.703 ;IOU accuracy: 0.796 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.022 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.017 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.029 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.051 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.024 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.018 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 0.033 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 2.317 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 2.075 ;acc: 0.730 ;iou_acc: 0.825 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 2.345 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 2.152 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 2.668 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 2.938 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 2.379 ;Test accuracy 0.703 ;IOU accuracy: 0.796 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.020 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.014 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.015 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.017 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.010 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.070 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.028 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 2.305 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.102 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.393 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.142 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.595 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.954 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 2.379 ;Test accuracy 0.704 ;IOU accuracy: 0.797 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.012 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.011 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.010 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.010 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.056 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.033 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.030 ;Train accuracy: 1.000 ;IOU accuracy: 1.000 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 2.222 ;acc: 0.725 ;iou_acc: 0.790 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 2.084 ;acc: 0.730 ;iou_acc: 0.810 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.591 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 2.233 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 2.537 ;acc: 0.685 ;iou_acc: 0.810 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 3.010 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 2.402 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 0.5\n",
      "dropout_out 0.5\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/drop_0.5,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 3.011 ;acc: 0.360 ;iou: 0.390 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.826 ;acc: 0.220 ;iou: 0.345 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.653 ;acc: 0.350 ;iou: 0.465 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.615 ;acc: 0.400 ;iou: 0.515 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.497 ;acc: 0.425 ;iou: 0.510 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.371 ;acc: 0.445 ;iou: 0.500 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 2.595 ;Train accuracy: 0.374 ;IOU accuracy: 0.471 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.380 ;acc: 0.335 ;iou_acc: 0.440 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 2.463 ;acc: 0.345 ;iou_acc: 0.425 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 2.510 ;acc: 0.325 ;iou_acc: 0.445 ;time: 0:01:10\n",
      "batch: 150 ;B loss: 2.395 ;acc: 0.390 ;iou_acc: 0.485 ;time: 0:01:18\n",
      "batch: 200 ;B loss: 2.353 ;acc: 0.395 ;iou_acc: 0.495 ;time: 0:01:26\n",
      "batch: 250 ;B loss: 2.430 ;acc: 0.355 ;iou_acc: 0.515 ;time: 0:01:34\n",
      "\n",
      "*BTrain: True ;Test loss: 2.383 ;Test accuracy 0.362 ;IOU accuracy: 0.472 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.348 ;acc: 0.440 ;iou: 0.525 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.124 ;acc: 0.490 ;iou: 0.595 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.288 ;acc: 0.520 ;iou: 0.575 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.234 ;acc: 0.445 ;iou: 0.585 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.346 ;acc: 0.480 ;iou: 0.535 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.273 ;acc: 0.495 ;iou: 0.575 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 2.253 ;Train accuracy: 0.501 ;IOU accuracy: 0.592 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.188 ;acc: 0.415 ;iou_acc: 0.520 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.165 ;acc: 0.460 ;iou_acc: 0.545 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.278 ;acc: 0.445 ;iou_acc: 0.545 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.204 ;acc: 0.445 ;iou_acc: 0.535 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.234 ;acc: 0.430 ;iou_acc: 0.560 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 2.234 ;acc: 0.425 ;iou_acc: 0.555 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 2.143 ;Test accuracy 0.450 ;IOU accuracy: 0.556 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 1.971 ;acc: 0.590 ;iou: 0.675 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 1.988 ;acc: 0.605 ;iou: 0.650 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.045 ;acc: 0.590 ;iou: 0.685 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.035 ;acc: 0.575 ;iou: 0.650 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 1.939 ;acc: 0.555 ;iou: 0.680 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.102 ;acc: 0.555 ;iou: 0.600 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 2.045 ;Train accuracy: 0.574 ;IOU accuracy: 0.657 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.021 ;acc: 0.500 ;iou_acc: 0.590 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 2.072 ;acc: 0.505 ;iou_acc: 0.580 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 2.133 ;acc: 0.510 ;iou_acc: 0.570 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 2.046 ;acc: 0.465 ;iou_acc: 0.530 ;time: 0:01:23\n",
      "batch: 200 ;B loss: 2.036 ;acc: 0.490 ;iou_acc: 0.610 ;time: 0:01:31\n",
      "batch: 250 ;B loss: 2.065 ;acc: 0.485 ;iou_acc: 0.615 ;time: 0:01:39\n",
      "\n",
      "*BTrain: False ;Test loss: 1.992 ;Test accuracy 0.499 ;IOU accuracy: 0.599 ;Time: 0:01:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 1.855 ;acc: 0.665 ;iou: 0.710 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.004 ;acc: 0.640 ;iou: 0.700 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 2.017 ;acc: 0.630 ;iou: 0.670 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 1.878 ;acc: 0.575 ;iou: 0.720 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.815 ;acc: 0.670 ;iou: 0.735 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 1.889 ;acc: 0.565 ;iou: 0.690 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.894 ;Train accuracy: 0.626 ;IOU accuracy: 0.703 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 1.904 ;acc: 0.525 ;iou_acc: 0.600 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.908 ;acc: 0.545 ;iou_acc: 0.620 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 2.032 ;acc: 0.500 ;iou_acc: 0.590 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.951 ;acc: 0.525 ;iou_acc: 0.610 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.958 ;acc: 0.520 ;iou_acc: 0.620 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.955 ;acc: 0.555 ;iou_acc: 0.665 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.882 ;Test accuracy 0.530 ;IOU accuracy: 0.628 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.698 ;acc: 0.710 ;iou: 0.750 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.680 ;acc: 0.720 ;iou: 0.765 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.718 ;acc: 0.690 ;iou: 0.760 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.646 ;acc: 0.690 ;iou: 0.770 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.714 ;acc: 0.650 ;iou: 0.725 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.707 ;acc: 0.685 ;iou: 0.770 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.771 ;Train accuracy: 0.673 ;IOU accuracy: 0.742 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.750 ;acc: 0.580 ;iou_acc: 0.655 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.907 ;acc: 0.505 ;iou_acc: 0.590 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.958 ;acc: 0.505 ;iou_acc: 0.590 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.886 ;acc: 0.560 ;iou_acc: 0.675 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.891 ;acc: 0.530 ;iou_acc: 0.645 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.909 ;acc: 0.510 ;iou_acc: 0.655 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.820 ;Test accuracy 0.550 ;IOU accuracy: 0.649 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.655 ;acc: 0.750 ;iou: 0.765 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.656 ;acc: 0.735 ;iou: 0.795 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.705 ;acc: 0.680 ;iou: 0.715 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.567 ;acc: 0.780 ;iou: 0.805 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.580 ;acc: 0.780 ;iou: 0.810 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.626 ;acc: 0.765 ;iou: 0.790 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 1.635 ;Train accuracy: 0.730 ;IOU accuracy: 0.794 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.684 ;acc: 0.610 ;iou_acc: 0.700 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.723 ;acc: 0.605 ;iou_acc: 0.710 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.800 ;acc: 0.570 ;iou_acc: 0.645 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.718 ;acc: 0.610 ;iou_acc: 0.715 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.776 ;acc: 0.575 ;iou_acc: 0.665 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.781 ;acc: 0.615 ;iou_acc: 0.735 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.684 ;Test accuracy 0.596 ;IOU accuracy: 0.697 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.609 ;acc: 0.755 ;iou: 0.810 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.448 ;acc: 0.800 ;iou: 0.865 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.580 ;acc: 0.750 ;iou: 0.815 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.606 ;acc: 0.775 ;iou: 0.820 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.656 ;acc: 0.745 ;iou: 0.815 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.494 ;acc: 0.775 ;iou: 0.870 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.478 ;Train accuracy: 0.784 ;IOU accuracy: 0.841 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.598 ;acc: 0.615 ;iou_acc: 0.715 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.535 ;acc: 0.630 ;iou_acc: 0.725 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.727 ;acc: 0.595 ;iou_acc: 0.685 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.594 ;acc: 0.635 ;iou_acc: 0.740 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.601 ;acc: 0.615 ;iou_acc: 0.735 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.690 ;acc: 0.605 ;iou_acc: 0.740 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.581 ;Test accuracy 0.626 ;IOU accuracy: 0.726 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.428 ;acc: 0.795 ;iou: 0.840 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.446 ;acc: 0.785 ;iou: 0.860 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.192 ;acc: 0.850 ;iou: 0.880 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.554 ;acc: 0.725 ;iou: 0.840 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.273 ;acc: 0.835 ;iou: 0.815 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.251 ;acc: 0.825 ;iou: 0.910 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.363 ;Train accuracy: 0.812 ;IOU accuracy: 0.865 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.677 ;acc: 0.605 ;iou_acc: 0.725 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.502 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.669 ;acc: 0.600 ;iou_acc: 0.700 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.588 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.524 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.622 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.537 ;Test accuracy 0.639 ;IOU accuracy: 0.740 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.321 ;acc: 0.825 ;iou: 0.855 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.374 ;acc: 0.810 ;iou: 0.870 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.414 ;acc: 0.800 ;iou: 0.890 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.178 ;acc: 0.845 ;iou: 0.890 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.312 ;acc: 0.865 ;iou: 0.905 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.516 ;acc: 0.775 ;iou: 0.850 ;time: 0:00:46\n",
      "\n",
      "*Training B: False ;B Train loss: 1.277 ;Train accuracy: 0.832 ;IOU accuracy: 0.879 ;Time: 0:00:54 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.614 ;acc: 0.625 ;iou_acc: 0.725 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.447 ;acc: 0.650 ;iou_acc: 0.760 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.601 ;acc: 0.620 ;iou_acc: 0.710 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.478 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.506 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.534 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:01:35\n",
      "\n",
      "*BTrain: False ;Test loss: 1.476 ;Test accuracy 0.657 ;IOU accuracy: 0.753 ;Time: 0:01:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.150 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.205 ;acc: 0.830 ;iou: 0.885 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.283 ;acc: 0.825 ;iou: 0.860 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.114 ;acc: 0.860 ;iou: 0.860 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.167 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.253 ;acc: 0.805 ;iou: 0.845 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 1.201 ;Train accuracy: 0.848 ;IOU accuracy: 0.892 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.578 ;acc: 0.585 ;iou_acc: 0.695 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.394 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.658 ;acc: 0.615 ;iou_acc: 0.705 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.377 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.475 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.539 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.455 ;Test accuracy 0.661 ;IOU accuracy: 0.756 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.150 ;acc: 0.835 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.050 ;acc: 0.835 ;iou: 0.895 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.180 ;acc: 0.840 ;iou: 0.910 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.101 ;acc: 0.875 ;iou: 0.910 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.233 ;acc: 0.855 ;iou: 0.885 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.160 ;acc: 0.870 ;iou: 0.865 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 1.140 ;Train accuracy: 0.862 ;IOU accuracy: 0.901 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.533 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.347 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.634 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.411 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.389 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.512 ;acc: 0.630 ;iou_acc: 0.740 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.432 ;Test accuracy 0.673 ;IOU accuracy: 0.767 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.107 ;acc: 0.845 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.023 ;acc: 0.880 ;iou: 0.940 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.190 ;acc: 0.865 ;iou: 0.890 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.256 ;acc: 0.845 ;iou: 0.930 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 0.832 ;acc: 0.905 ;iou: 0.925 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 0.984 ;acc: 0.895 ;iou: 0.915 ;time: 0:00:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.086 ;Train accuracy: 0.875 ;IOU accuracy: 0.911 ;Time: 0:00:53 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.621 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:00:54\n",
      "batch: 50 ;B loss: 1.328 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:02\n",
      "batch: 100 ;B loss: 1.560 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:09\n",
      "batch: 150 ;B loss: 1.389 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:17\n",
      "batch: 200 ;B loss: 1.547 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:25\n",
      "batch: 250 ;B loss: 1.566 ;acc: 0.610 ;iou_acc: 0.735 ;time: 0:01:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.435 ;Test accuracy 0.674 ;IOU accuracy: 0.770 ;Time: 0:01:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 0.973 ;acc: 0.915 ;iou: 0.925 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 1.063 ;acc: 0.875 ;iou: 0.910 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.166 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.134 ;acc: 0.860 ;iou: 0.905 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.054 ;acc: 0.895 ;iou: 0.910 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 1.327 ;acc: 0.820 ;iou: 0.860 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 1.031 ;Train accuracy: 0.886 ;IOU accuracy: 0.920 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.511 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.335 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.730 ;acc: 0.635 ;iou_acc: 0.725 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.407 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.425 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.614 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.442 ;Test accuracy 0.679 ;IOU accuracy: 0.772 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.026 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 0.933 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.086 ;acc: 0.885 ;iou: 0.890 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 1.098 ;acc: 0.890 ;iou: 0.895 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.041 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 0.988 ;acc: 0.870 ;iou: 0.910 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.988 ;Train accuracy: 0.896 ;IOU accuracy: 0.927 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.493 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.386 ;acc: 0.650 ;iou_acc: 0.785 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.658 ;acc: 0.615 ;iou_acc: 0.705 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.340 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.404 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.580 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.426 ;Test accuracy 0.684 ;IOU accuracy: 0.777 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 0.853 ;acc: 0.910 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 0.838 ;acc: 0.900 ;iou: 0.950 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 0.927 ;acc: 0.920 ;iou: 0.920 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 1.092 ;acc: 0.885 ;iou: 0.895 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.117 ;acc: 0.930 ;iou: 0.940 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.000 ;acc: 0.915 ;iou: 0.930 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.947 ;Train accuracy: 0.904 ;IOU accuracy: 0.933 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.490 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.396 ;acc: 0.665 ;iou_acc: 0.800 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.556 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.367 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.490 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.512 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.390 ;Test accuracy 0.690 ;IOU accuracy: 0.783 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 0.869 ;acc: 0.905 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 0.995 ;acc: 0.905 ;iou: 0.950 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 0.970 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 0.875 ;acc: 0.925 ;iou: 0.920 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.056 ;acc: 0.885 ;iou: 0.930 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 0.933 ;acc: 0.920 ;iou: 0.920 ;time: 0:00:46\n",
      "\n",
      "*Training B: True ;B Train loss: 0.899 ;Train accuracy: 0.912 ;IOU accuracy: 0.938 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.573 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:00:55\n",
      "batch: 50 ;B loss: 1.356 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:03\n",
      "batch: 100 ;B loss: 1.644 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:01:11\n",
      "batch: 150 ;B loss: 1.410 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:19\n",
      "batch: 200 ;B loss: 1.486 ;acc: 0.655 ;iou_acc: 0.785 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.620 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.435 ;Test accuracy 0.688 ;IOU accuracy: 0.781 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 0.773 ;acc: 0.935 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 0.817 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 0.905 ;acc: 0.905 ;iou: 0.930 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 0.869 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 0.774 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 0.857 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.869 ;Train accuracy: 0.919 ;IOU accuracy: 0.943 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.502 ;acc: 0.695 ;iou_acc: 0.755 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.401 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.511 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.415 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.383 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.617 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.400 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 0.722 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 0.888 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 0.850 ;acc: 0.900 ;iou: 0.940 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 0.935 ;acc: 0.930 ;iou: 0.905 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 0.749 ;acc: 0.940 ;iou: 0.930 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 0.960 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.833 ;Train accuracy: 0.927 ;IOU accuracy: 0.948 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.519 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.310 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.585 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.455 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.462 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.482 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.432 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 0.778 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 0.697 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 0.762 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 0.951 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 0.791 ;acc: 0.910 ;iou: 0.960 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 0.650 ;acc: 0.935 ;iou: 0.940 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.797 ;Train accuracy: 0.931 ;IOU accuracy: 0.952 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.455 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.359 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.534 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.399 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.455 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 1.541 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "\n",
      "*BTrain: True ;Test loss: 1.428 ;Test accuracy 0.694 ;IOU accuracy: 0.787 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 0.743 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 0.820 ;acc: 0.910 ;iou: 0.910 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 0.910 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 0.794 ;acc: 0.925 ;iou: 0.925 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 0.692 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 0.873 ;acc: 0.905 ;iou: 0.930 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.766 ;Train accuracy: 0.937 ;IOU accuracy: 0.957 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.563 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.312 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.573 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.390 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.417 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.600 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.434 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 0.774 ;acc: 0.925 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 0.578 ;acc: 0.945 ;iou: 0.940 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 0.778 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 0.785 ;acc: 0.960 ;iou: 0.960 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 0.675 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 0.804 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.737 ;Train accuracy: 0.942 ;IOU accuracy: 0.960 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.537 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.406 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.507 ;acc: 0.705 ;iou_acc: 0.760 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.449 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.564 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.640 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.455 ;Test accuracy 0.696 ;IOU accuracy: 0.788 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 0.553 ;acc: 0.950 ;iou: 0.985 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 0.678 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 0.682 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 0.894 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 0.762 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 0.693 ;acc: 0.925 ;iou: 0.970 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.709 ;Train accuracy: 0.947 ;IOU accuracy: 0.962 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.557 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.346 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.554 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.440 ;acc: 0.740 ;iou_acc: 0.825 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.453 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.588 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.457 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 0.736 ;acc: 0.940 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 0.734 ;acc: 0.960 ;iou: 0.965 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 0.759 ;acc: 0.960 ;iou: 0.945 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 0.544 ;acc: 0.965 ;iou: 0.960 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 0.713 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 0.673 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.679 ;Train accuracy: 0.950 ;IOU accuracy: 0.964 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.487 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.402 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.615 ;acc: 0.680 ;iou_acc: 0.730 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.475 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.458 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.664 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.471 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 0.589 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 0.536 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 0.633 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 0.664 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 0.590 ;acc: 0.960 ;iou: 0.990 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 0.722 ;acc: 0.935 ;iou: 0.945 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.653 ;Train accuracy: 0.955 ;IOU accuracy: 0.969 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.706 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.390 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.668 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.525 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.509 ;acc: 0.700 ;iou_acc: 0.820 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.779 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.514 ;Test accuracy 0.698 ;IOU accuracy: 0.789 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 0.516 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 0.628 ;acc: 0.935 ;iou: 0.985 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 0.616 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.592 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 0.798 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 0.713 ;acc: 0.960 ;iou: 0.955 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.625 ;Train accuracy: 0.959 ;IOU accuracy: 0.971 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.669 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.414 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.940 ;acc: 0.655 ;iou_acc: 0.720 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.536 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.639 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.716 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.548 ;Test accuracy 0.694 ;IOU accuracy: 0.786 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 0.615 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.530 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 0.557 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 0.628 ;acc: 0.965 ;iou: 0.970 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 0.616 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 0.650 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.600 ;Train accuracy: 0.962 ;IOU accuracy: 0.973 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.568 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.363 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.663 ;acc: 0.690 ;iou_acc: 0.740 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.524 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.509 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.764 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.514 ;Test accuracy 0.700 ;IOU accuracy: 0.791 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 0.417 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 0.475 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 0.611 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.559 ;acc: 0.945 ;iou: 0.985 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 0.632 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 0.581 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.573 ;Train accuracy: 0.965 ;IOU accuracy: 0.975 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.615 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.467 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.651 ;acc: 0.700 ;iou_acc: 0.740 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.501 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.573 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.663 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.514 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 0.551 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 0.473 ;acc: 0.985 ;iou: 0.980 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.681 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 0.462 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.621 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 0.715 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 0.553 ;Train accuracy: 0.967 ;IOU accuracy: 0.977 ;Time: 0:00:55 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.506 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:00:56\n",
      "batch: 50 ;B loss: 1.578 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:04\n",
      "batch: 100 ;B loss: 1.710 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:12\n",
      "batch: 150 ;B loss: 1.494 ;acc: 0.740 ;iou_acc: 0.825 ;time: 0:01:20\n",
      "batch: 200 ;B loss: 1.547 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:27\n",
      "batch: 250 ;B loss: 1.909 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:35\n",
      "\n",
      "*BTrain: True ;Test loss: 1.560 ;Test accuracy 0.705 ;IOU accuracy: 0.795 ;Time: 0:01:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 0.424 ;acc: 0.980 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 0.595 ;acc: 0.985 ;iou: 0.970 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 0.566 ;acc: 0.960 ;iou: 0.990 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.495 ;acc: 0.960 ;iou: 0.995 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 0.786 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 0.682 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.533 ;Train accuracy: 0.970 ;IOU accuracy: 0.978 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.564 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.465 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.855 ;acc: 0.680 ;iou_acc: 0.730 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.490 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.647 ;acc: 0.680 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.785 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.563 ;Test accuracy 0.705 ;IOU accuracy: 0.796 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.646 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 0.557 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 0.459 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.543 ;acc: 0.985 ;iou: 0.965 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 0.703 ;acc: 0.960 ;iou: 0.955 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 0.664 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:47\n",
      "\n",
      "*Training B: False ;B Train loss: 0.509 ;Train accuracy: 0.972 ;IOU accuracy: 0.980 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.650 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.552 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.755 ;acc: 0.690 ;iou_acc: 0.740 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.488 ;acc: 0.740 ;iou_acc: 0.810 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.597 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 250 ;B loss: 1.753 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.586 ;Test accuracy 0.702 ;IOU accuracy: 0.792 ;Time: 0:01:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.457 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 0.503 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.452 ;acc: 0.950 ;iou: 0.980 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.387 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 0.480 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 0.454 ;acc: 0.940 ;iou: 0.985 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.485 ;Train accuracy: 0.973 ;IOU accuracy: 0.981 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.653 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 1.467 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 1.705 ;acc: 0.665 ;iou_acc: 0.720 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.692 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.613 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.870 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.627 ;Test accuracy 0.702 ;IOU accuracy: 0.793 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.320 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.408 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 0.402 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 0.534 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 0.556 ;acc: 0.980 ;iou: 0.955 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.436 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.470 ;Train accuracy: 0.974 ;IOU accuracy: 0.983 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.697 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.515 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.836 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.562 ;acc: 0.715 ;iou_acc: 0.820 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.592 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.900 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:44\n",
      "\n",
      "*BTrain: False ;Test loss: 1.604 ;Test accuracy 0.706 ;IOU accuracy: 0.796 ;Time: 0:01:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.310 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.380 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.435 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 0.575 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 0.582 ;acc: 0.965 ;iou: 0.965 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.506 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.453 ;Train accuracy: 0.976 ;IOU accuracy: 0.984 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.659 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.569 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.869 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.737 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.647 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.031 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.639 ;Test accuracy 0.704 ;IOU accuracy: 0.796 ;Time: 0:01:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.364 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.494 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.388 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.435 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 0.493 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.400 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.441 ;Train accuracy: 0.978 ;IOU accuracy: 0.984 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.826 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.677 ;acc: 0.650 ;iou_acc: 0.780 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.905 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.602 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.553 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 2.043 ;acc: 0.640 ;iou_acc: 0.765 ;time: 0:01:47\n",
      "\n",
      "*BTrain: True ;Test loss: 1.652 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.369 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.336 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.508 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.341 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.309 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.444 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.418 ;Train accuracy: 0.980 ;IOU accuracy: 0.986 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.856 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.642 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.977 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.583 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.524 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.035 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.697 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.269 ;acc: 0.990 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.395 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.378 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.352 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 0.307 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.428 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.399 ;Train accuracy: 0.981 ;IOU accuracy: 0.986 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.726 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.614 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.771 ;acc: 0.720 ;iou_acc: 0.765 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.686 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.513 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.041 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.671 ;Test accuracy 0.706 ;IOU accuracy: 0.795 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.327 ;acc: 0.965 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.532 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.364 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.385 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.512 ;acc: 0.970 ;iou: 0.995 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 0.329 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.385 ;Train accuracy: 0.982 ;IOU accuracy: 0.988 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.959 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.608 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 2.024 ;acc: 0.660 ;iou_acc: 0.715 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.667 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.587 ;acc: 0.745 ;iou_acc: 0.840 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.000 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.715 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.433 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.330 ;acc: 0.995 ;iou: 0.985 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.362 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 0.304 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.258 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.573 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.370 ;Train accuracy: 0.982 ;IOU accuracy: 0.988 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.933 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.613 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.837 ;acc: 0.695 ;iou_acc: 0.745 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.809 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:32\n",
      "batch: 200 ;B loss: 1.611 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:01:41\n",
      "batch: 250 ;B loss: 1.993 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:50\n",
      "\n",
      "*BTrain: False ;Test loss: 1.704 ;Test accuracy 0.705 ;IOU accuracy: 0.795 ;Time: 0:01:59\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.367 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.439 ;acc: 0.965 ;iou: 0.990 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 0.356 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.295 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.295 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.287 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.361 ;Train accuracy: 0.985 ;IOU accuracy: 0.988 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.998 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.797 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.858 ;acc: 0.710 ;iou_acc: 0.770 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.805 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.671 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.092 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.776 ;Test accuracy 0.703 ;IOU accuracy: 0.795 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.310 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.250 ;acc: 1.000 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.377 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.324 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.265 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.360 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.346 ;Train accuracy: 0.985 ;IOU accuracy: 0.990 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.951 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.738 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.947 ;acc: 0.715 ;iou_acc: 0.770 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.662 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.600 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.049 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.782 ;Test accuracy 0.705 ;IOU accuracy: 0.796 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.277 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.289 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.433 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.438 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.185 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.349 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.340 ;Train accuracy: 0.985 ;IOU accuracy: 0.990 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.877 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.743 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.995 ;acc: 0.705 ;iou_acc: 0.760 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.717 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.662 ;acc: 0.715 ;iou_acc: 0.820 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.229 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.793 ;Test accuracy 0.707 ;IOU accuracy: 0.798 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.301 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.347 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.327 ;acc: 0.985 ;iou: 0.975 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.392 ;acc: 0.990 ;iou: 0.980 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.306 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.354 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.318 ;Train accuracy: 0.986 ;IOU accuracy: 0.990 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 2.004 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.822 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.960 ;acc: 0.695 ;iou_acc: 0.735 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.949 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.873 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.024 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.840 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.354 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.285 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.233 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.334 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.323 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.345 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 0.309 ;Train accuracy: 0.987 ;IOU accuracy: 0.991 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.908 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.684 ;acc: 0.730 ;iou_acc: 0.825 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.904 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.887 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.931 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.267 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 1.870 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.299 ;acc: 0.995 ;iou: 0.985 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.234 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.288 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.191 ;acc: 1.000 ;iou: 0.995 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.277 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.310 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.301 ;Train accuracy: 0.987 ;IOU accuracy: 0.991 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 2.023 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.805 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.921 ;acc: 0.705 ;iou_acc: 0.755 ;time: 0:01:23\n",
      "batch: 150 ;B loss: 1.768 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:32\n",
      "batch: 200 ;B loss: 1.725 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:41\n",
      "batch: 250 ;B loss: 2.193 ;acc: 0.705 ;iou_acc: 0.815 ;time: 0:01:50\n",
      "\n",
      "*BTrain: False ;Test loss: 1.834 ;Test accuracy 0.708 ;IOU accuracy: 0.799 ;Time: 0:01:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.188 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.366 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.207 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.448 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.235 ;acc: 0.995 ;iou: 0.980 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.325 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.291 ;Train accuracy: 0.988 ;IOU accuracy: 0.991 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 2.004 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.713 ;acc: 0.730 ;iou_acc: 0.825 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.963 ;acc: 0.680 ;iou_acc: 0.735 ;time: 0:01:23\n",
      "batch: 150 ;B loss: 1.869 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.855 ;acc: 0.680 ;iou_acc: 0.805 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.115 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.862 ;Test accuracy 0.705 ;IOU accuracy: 0.795 ;Time: 0:01:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.247 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.197 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.231 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.295 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.186 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.371 ;acc: 0.985 ;iou: 0.980 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 0.277 ;Train accuracy: 0.989 ;IOU accuracy: 0.992 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 2.016 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.842 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 2.126 ;acc: 0.680 ;iou_acc: 0.730 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.795 ;acc: 0.710 ;iou_acc: 0.830 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.886 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.174 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.874 ;Test accuracy 0.706 ;IOU accuracy: 0.795 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.225 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.216 ;acc: 1.000 ;iou: 0.995 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.323 ;acc: 1.000 ;iou: 0.975 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.265 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.418 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.314 ;acc: 0.985 ;iou: 0.980 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.268 ;Train accuracy: 0.990 ;IOU accuracy: 0.993 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 2.065 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.940 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 2.102 ;acc: 0.665 ;iou_acc: 0.715 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.811 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.698 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.221 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.876 ;Test accuracy 0.706 ;IOU accuracy: 0.797 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.239 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.258 ;acc: 0.990 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.343 ;acc: 1.000 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.218 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.279 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.285 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.253 ;Train accuracy: 0.990 ;IOU accuracy: 0.993 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.908 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.861 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 2.129 ;acc: 0.680 ;iou_acc: 0.725 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.978 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.839 ;acc: 0.685 ;iou_acc: 0.820 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.237 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.900 ;Test accuracy 0.705 ;IOU accuracy: 0.796 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.220 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.261 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.188 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.151 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.260 ;acc: 0.995 ;iou: 1.000 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.372 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 0.248 ;Train accuracy: 0.990 ;IOU accuracy: 0.992 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 2.205 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.837 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 2.171 ;acc: 0.680 ;iou_acc: 0.735 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 1.951 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.948 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.274 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.935 ;Test accuracy 0.706 ;IOU accuracy: 0.795 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.144 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.244 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.266 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.272 ;acc: 0.990 ;iou: 1.000 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.248 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.197 ;acc: 0.995 ;iou: 0.990 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.244 ;Train accuracy: 0.990 ;IOU accuracy: 0.993 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 2.168 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.958 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 2.080 ;acc: 0.690 ;iou_acc: 0.745 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 2.087 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.931 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.291 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.957 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dropout_in : dropout ratio for the RNN's inputs\n",
    "#dropout_out : dropout ratio for the RNN's outputs\n",
    "\n",
    "dout_bnorm_test_res, dout_bnorm_train_res = [], []\n",
    "drpos_ratio = [[0.5, 1.], [1., 0.5], [.5,.5]]\n",
    "for num_hidden in [50, 100, 150, 200]:\n",
    "    for drops in drpos_ratio:\n",
    "        dropout_in, dropout_out = drops\n",
    "        params_dir = params_dir_tmp+'bnorm_base/drop_'+str(dropout_in)+','+str(dropout_out)+'_hidden:'+str(num_hidden)\n",
    "        tf.reset_default_graph()\n",
    "        m = Model(\n",
    "            batch_size=200, \n",
    "            num_hidden=num_hidden,\n",
    "            embed_size=embed_vecs.shape[1],,\n",
    "            img_dims=trainset[0][0][1][0].shape[1], \n",
    "            bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "            lr=.05,\n",
    "            vocab=vocab, \n",
    "            decay_steps=10000, \n",
    "            decay_rate=0.99, \n",
    "            edit_reward=0.,\n",
    "            rnn_editProb=0.,\n",
    "            coefAlr=1,\n",
    "            bnorm=True)\n",
    "\n",
    "\n",
    "        # start comp\n",
    "        print('dropout_in', dropout_in)\n",
    "        print('dropout_out', dropout_out)\n",
    "        print('params_dir:', params_dir)\n",
    "        print('num_hidden:', m.num_hidden)\n",
    "        print('learning rate:', m.lr)\n",
    "        tst, trn = m.train(trainset, testset,\n",
    "                ephocs_num=50,\n",
    "                start_ephoc=0,\n",
    "                startA=51,\n",
    "                activation_ephoc=51,\n",
    "                muteB=0, \n",
    "                activateAProb=0,\n",
    "                max_activateAProb=0,\n",
    "                editProb=0,\n",
    "                edit_reward=0,\n",
    "                dropout_in=dropout_in,\n",
    "                dropout_out=dropout_out)\n",
    "\n",
    "        dout_bnorm_test_res.append(tst)\n",
    "        dout_bnorm_train_res.append(trn)\n",
    "        print('\\n'+'*'*100)\n",
    "        print('*'*100)\n",
    "        print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Image Dropout\n",
    "\n",
    "<p>Next we use 200 hidden units and we add dropout ratio of 0.5 to the images vectors before the final attention layer<br>\n",
    "We test it for different dropout_in and dropout_out (as in the privious notebook's cell) </p>\n",
    "\n",
    "<p><b> This gives us IOU of 82.1% for dropout_in=0.5 (with dropout_out=0.5/1.)</b><br>\n",
    "We went from 60% IOU to 82.1% just by using regularization. Usually, if a paper writes about the regularization methods at all, it's just writen as a side note, this indicates that for this problam, a good regularization methods is crucial for the research and it need to be taken into account while designing the model and not just as a tuning method or else we might get misleading results.  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout_in 0.5\n",
      "dropout_out 1.0\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/img_drop_0.5,1.0_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.971 ;acc: 0.315 ;iou: 0.400 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.728 ;acc: 0.230 ;iou: 0.330 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.845 ;acc: 0.250 ;iou: 0.330 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.726 ;acc: 0.280 ;iou: 0.400 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.560 ;acc: 0.360 ;iou: 0.440 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.666 ;acc: 0.280 ;iou: 0.370 ;time: 0:00:47\n",
      "\n",
      "*Training B: True ;B Train loss: 2.690 ;Train accuracy: 0.296 ;IOU accuracy: 0.399 ;Time: 0:00:56 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.559 ;acc: 0.290 ;iou_acc: 0.375 ;time: 0:00:57\n",
      "batch: 50 ;B loss: 2.628 ;acc: 0.270 ;iou_acc: 0.390 ;time: 0:01:05\n",
      "batch: 100 ;B loss: 2.642 ;acc: 0.250 ;iou_acc: 0.325 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 2.547 ;acc: 0.330 ;iou_acc: 0.405 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 2.551 ;acc: 0.285 ;iou_acc: 0.375 ;time: 0:01:30\n",
      "batch: 250 ;B loss: 2.506 ;acc: 0.315 ;iou_acc: 0.425 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 2.538 ;Test accuracy 0.311 ;IOU accuracy: 0.425 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.651 ;acc: 0.370 ;iou: 0.470 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.604 ;acc: 0.260 ;iou: 0.400 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.398 ;acc: 0.415 ;iou: 0.515 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.330 ;acc: 0.460 ;iou: 0.545 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.405 ;acc: 0.400 ;iou: 0.500 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.349 ;acc: 0.475 ;iou: 0.595 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 2.441 ;Train accuracy: 0.398 ;IOU accuracy: 0.503 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.348 ;acc: 0.335 ;iou_acc: 0.445 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 2.383 ;acc: 0.385 ;iou_acc: 0.470 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 2.467 ;acc: 0.350 ;iou_acc: 0.445 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 2.369 ;acc: 0.395 ;iou_acc: 0.490 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 2.351 ;acc: 0.365 ;iou_acc: 0.475 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 2.333 ;acc: 0.395 ;iou_acc: 0.540 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.316 ;Test accuracy 0.391 ;IOU accuracy: 0.499 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.428 ;acc: 0.430 ;iou: 0.520 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.256 ;acc: 0.490 ;iou: 0.560 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.346 ;acc: 0.450 ;iou: 0.535 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.408 ;acc: 0.435 ;iou: 0.560 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.235 ;acc: 0.480 ;iou: 0.590 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.231 ;acc: 0.505 ;iou: 0.615 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 2.290 ;Train accuracy: 0.461 ;IOU accuracy: 0.563 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.217 ;acc: 0.395 ;iou_acc: 0.490 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 2.240 ;acc: 0.445 ;iou_acc: 0.510 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 2.315 ;acc: 0.400 ;iou_acc: 0.505 ;time: 0:01:23\n",
      "batch: 150 ;B loss: 2.254 ;acc: 0.450 ;iou_acc: 0.545 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 2.247 ;acc: 0.415 ;iou_acc: 0.565 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 2.177 ;acc: 0.440 ;iou_acc: 0.570 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 2.172 ;Test accuracy 0.443 ;IOU accuracy: 0.549 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.279 ;acc: 0.480 ;iou: 0.550 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.193 ;acc: 0.550 ;iou: 0.655 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 2.191 ;acc: 0.525 ;iou: 0.575 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 2.162 ;acc: 0.505 ;iou: 0.620 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 2.056 ;acc: 0.570 ;iou: 0.620 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 2.108 ;acc: 0.505 ;iou: 0.610 ;time: 0:00:57\n",
      "\n",
      "*Training B: True ;B Train loss: 2.170 ;Train accuracy: 0.507 ;IOU accuracy: 0.603 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 2.104 ;acc: 0.445 ;iou_acc: 0.525 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 2.096 ;acc: 0.490 ;iou_acc: 0.585 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 2.210 ;acc: 0.445 ;iou_acc: 0.530 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 2.176 ;acc: 0.405 ;iou_acc: 0.520 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 2.140 ;acc: 0.430 ;iou_acc: 0.545 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 2.063 ;acc: 0.475 ;iou_acc: 0.600 ;time: 0:01:58\n",
      "\n",
      "*BTrain: True ;Test loss: 2.062 ;Test accuracy 0.479 ;IOU accuracy: 0.582 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.985 ;acc: 0.570 ;iou: 0.670 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 2.097 ;acc: 0.555 ;iou: 0.640 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 2.062 ;acc: 0.530 ;iou: 0.615 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.936 ;acc: 0.615 ;iou: 0.700 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 2.147 ;acc: 0.530 ;iou: 0.630 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 2.065 ;acc: 0.565 ;iou: 0.685 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 2.070 ;Train accuracy: 0.538 ;IOU accuracy: 0.632 ;Time: 0:01:08 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 2.024 ;acc: 0.500 ;iou_acc: 0.560 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.995 ;acc: 0.500 ;iou_acc: 0.580 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 2.129 ;acc: 0.450 ;iou_acc: 0.525 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 2.083 ;acc: 0.430 ;iou_acc: 0.540 ;time: 0:01:39\n",
      "batch: 200 ;B loss: 2.025 ;acc: 0.480 ;iou_acc: 0.595 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 2.004 ;acc: 0.500 ;iou_acc: 0.620 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.985 ;Test accuracy 0.499 ;IOU accuracy: 0.599 ;Time: 0:02:08\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.945 ;acc: 0.610 ;iou: 0.700 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 2.054 ;acc: 0.535 ;iou: 0.660 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 2.010 ;acc: 0.555 ;iou: 0.670 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 2.059 ;acc: 0.560 ;iou: 0.700 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 2.020 ;acc: 0.550 ;iou: 0.665 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.999 ;acc: 0.580 ;iou: 0.700 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.997 ;Train accuracy: 0.561 ;IOU accuracy: 0.653 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.939 ;acc: 0.530 ;iou_acc: 0.615 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.975 ;acc: 0.520 ;iou_acc: 0.605 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 2.037 ;acc: 0.475 ;iou_acc: 0.545 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 2.026 ;acc: 0.485 ;iou_acc: 0.595 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.950 ;acc: 0.545 ;iou_acc: 0.655 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.961 ;acc: 0.510 ;iou_acc: 0.640 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.910 ;Test accuracy 0.522 ;IOU accuracy: 0.620 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.971 ;acc: 0.525 ;iou: 0.620 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.923 ;acc: 0.550 ;iou: 0.660 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.819 ;acc: 0.565 ;iou: 0.670 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.914 ;acc: 0.640 ;iou: 0.710 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 2.029 ;acc: 0.570 ;iou: 0.670 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.755 ;acc: 0.650 ;iou: 0.725 ;time: 0:00:56\n",
      "\n",
      "*Training B: True ;B Train loss: 1.935 ;Train accuracy: 0.584 ;IOU accuracy: 0.673 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.875 ;acc: 0.530 ;iou_acc: 0.625 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.891 ;acc: 0.535 ;iou_acc: 0.625 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.968 ;acc: 0.505 ;iou_acc: 0.570 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.968 ;acc: 0.500 ;iou_acc: 0.625 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.902 ;acc: 0.525 ;iou_acc: 0.630 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.883 ;acc: 0.525 ;iou_acc: 0.645 ;time: 0:01:58\n",
      "\n",
      "*BTrain: True ;Test loss: 1.854 ;Test accuracy 0.538 ;IOU accuracy: 0.632 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.811 ;acc: 0.615 ;iou: 0.700 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.952 ;acc: 0.575 ;iou: 0.645 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.810 ;acc: 0.595 ;iou: 0.680 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.874 ;acc: 0.605 ;iou: 0.665 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.769 ;acc: 0.590 ;iou: 0.685 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.816 ;acc: 0.655 ;iou: 0.730 ;time: 0:00:58\n",
      "\n",
      "*Training B: False ;B Train loss: 1.875 ;Train accuracy: 0.603 ;IOU accuracy: 0.689 ;Time: 0:01:09 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.828 ;acc: 0.525 ;iou_acc: 0.630 ;time: 0:01:10\n",
      "batch: 50 ;B loss: 1.838 ;acc: 0.565 ;iou_acc: 0.645 ;time: 0:01:19\n",
      "batch: 100 ;B loss: 1.934 ;acc: 0.495 ;iou_acc: 0.575 ;time: 0:01:29\n",
      "batch: 150 ;B loss: 1.921 ;acc: 0.515 ;iou_acc: 0.620 ;time: 0:01:40\n",
      "batch: 200 ;B loss: 1.837 ;acc: 0.560 ;iou_acc: 0.650 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 1.852 ;acc: 0.555 ;iou_acc: 0.675 ;time: 0:01:59\n",
      "\n",
      "*BTrain: False ;Test loss: 1.805 ;Test accuracy 0.551 ;IOU accuracy: 0.644 ;Time: 0:02:09\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.763 ;acc: 0.610 ;iou: 0.675 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.711 ;acc: 0.665 ;iou: 0.715 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.702 ;acc: 0.660 ;iou: 0.735 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.885 ;acc: 0.610 ;iou: 0.690 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.909 ;acc: 0.585 ;iou: 0.660 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.751 ;acc: 0.610 ;iou: 0.725 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.825 ;Train accuracy: 0.622 ;IOU accuracy: 0.704 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.802 ;acc: 0.520 ;iou_acc: 0.635 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.816 ;acc: 0.555 ;iou_acc: 0.645 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.844 ;acc: 0.550 ;iou_acc: 0.620 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.892 ;acc: 0.540 ;iou_acc: 0.655 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.788 ;acc: 0.555 ;iou_acc: 0.645 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.807 ;acc: 0.560 ;iou_acc: 0.675 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.770 ;Test accuracy 0.561 ;IOU accuracy: 0.653 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.804 ;acc: 0.615 ;iou: 0.715 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.668 ;acc: 0.605 ;iou: 0.685 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.628 ;acc: 0.705 ;iou: 0.785 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.698 ;acc: 0.705 ;iou: 0.800 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.866 ;acc: 0.640 ;iou: 0.685 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.824 ;acc: 0.655 ;iou: 0.715 ;time: 0:00:56\n",
      "\n",
      "*Training B: True ;B Train loss: 1.783 ;Train accuracy: 0.638 ;IOU accuracy: 0.719 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.750 ;acc: 0.515 ;iou_acc: 0.610 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.759 ;acc: 0.570 ;iou_acc: 0.665 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.857 ;acc: 0.510 ;iou_acc: 0.595 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.829 ;acc: 0.560 ;iou_acc: 0.680 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.768 ;acc: 0.550 ;iou_acc: 0.645 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.756 ;acc: 0.600 ;iou_acc: 0.720 ;time: 0:01:57\n",
      "\n",
      "*BTrain: True ;Test loss: 1.731 ;Test accuracy 0.572 ;IOU accuracy: 0.664 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.725 ;acc: 0.655 ;iou: 0.740 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.686 ;acc: 0.675 ;iou: 0.730 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.760 ;acc: 0.645 ;iou: 0.730 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.809 ;acc: 0.645 ;iou: 0.725 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.734 ;acc: 0.670 ;iou: 0.740 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.917 ;acc: 0.585 ;iou: 0.665 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.747 ;Train accuracy: 0.651 ;IOU accuracy: 0.731 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.750 ;acc: 0.525 ;iou_acc: 0.630 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.735 ;acc: 0.570 ;iou_acc: 0.665 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.792 ;acc: 0.545 ;iou_acc: 0.625 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.795 ;acc: 0.575 ;iou_acc: 0.670 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.772 ;acc: 0.540 ;iou_acc: 0.655 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 1.739 ;acc: 0.565 ;iou_acc: 0.690 ;time: 0:01:59\n",
      "\n",
      "*BTrain: False ;Test loss: 1.699 ;Test accuracy 0.583 ;IOU accuracy: 0.674 ;Time: 0:02:08\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.678 ;acc: 0.700 ;iou: 0.770 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.570 ;acc: 0.710 ;iou: 0.780 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.642 ;acc: 0.675 ;iou: 0.770 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.750 ;acc: 0.615 ;iou: 0.715 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.800 ;acc: 0.615 ;iou: 0.695 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.730 ;acc: 0.665 ;iou: 0.710 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.707 ;Train accuracy: 0.669 ;IOU accuracy: 0.745 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.738 ;acc: 0.540 ;iou_acc: 0.645 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.687 ;acc: 0.575 ;iou_acc: 0.660 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.753 ;acc: 0.555 ;iou_acc: 0.620 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.760 ;acc: 0.590 ;iou_acc: 0.690 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.722 ;acc: 0.565 ;iou_acc: 0.675 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.694 ;acc: 0.615 ;iou_acc: 0.730 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.661 ;Test accuracy 0.596 ;IOU accuracy: 0.687 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.611 ;acc: 0.645 ;iou: 0.725 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 1.727 ;acc: 0.640 ;iou: 0.715 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.786 ;acc: 0.655 ;iou: 0.745 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.534 ;acc: 0.710 ;iou: 0.790 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.686 ;acc: 0.655 ;iou: 0.760 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 1.824 ;acc: 0.650 ;iou: 0.760 ;time: 0:00:58\n",
      "\n",
      "*Training B: True ;B Train loss: 1.659 ;Train accuracy: 0.686 ;IOU accuracy: 0.762 ;Time: 0:01:08 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.687 ;acc: 0.580 ;iou_acc: 0.675 ;time: 0:01:09\n",
      "batch: 50 ;B loss: 1.613 ;acc: 0.610 ;iou_acc: 0.705 ;time: 0:01:19\n",
      "batch: 100 ;B loss: 1.727 ;acc: 0.570 ;iou_acc: 0.645 ;time: 0:01:29\n",
      "batch: 150 ;B loss: 1.728 ;acc: 0.595 ;iou_acc: 0.685 ;time: 0:01:39\n",
      "batch: 200 ;B loss: 1.653 ;acc: 0.610 ;iou_acc: 0.720 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 1.641 ;acc: 0.625 ;iou_acc: 0.745 ;time: 0:01:59\n",
      "\n",
      "*BTrain: True ;Test loss: 1.618 ;Test accuracy 0.611 ;IOU accuracy: 0.702 ;Time: 0:02:08\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.513 ;acc: 0.755 ;iou: 0.820 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.661 ;acc: 0.720 ;iou: 0.775 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.556 ;acc: 0.715 ;iou: 0.795 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 1.479 ;acc: 0.765 ;iou: 0.805 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.655 ;acc: 0.705 ;iou: 0.780 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 1.623 ;acc: 0.670 ;iou: 0.755 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.616 ;Train accuracy: 0.708 ;IOU accuracy: 0.783 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.622 ;acc: 0.610 ;iou_acc: 0.710 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.525 ;acc: 0.640 ;iou_acc: 0.710 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.709 ;acc: 0.595 ;iou_acc: 0.675 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.673 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.581 ;acc: 0.615 ;iou_acc: 0.720 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.604 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.564 ;Test accuracy 0.630 ;IOU accuracy: 0.722 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 1.696 ;acc: 0.700 ;iou: 0.765 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.509 ;acc: 0.760 ;iou: 0.825 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 1.598 ;acc: 0.720 ;iou: 0.790 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 1.429 ;acc: 0.775 ;iou: 0.845 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.617 ;acc: 0.725 ;iou: 0.825 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.691 ;acc: 0.715 ;iou: 0.765 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.560 ;Train accuracy: 0.731 ;IOU accuracy: 0.805 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.547 ;acc: 0.625 ;iou_acc: 0.725 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.482 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.638 ;acc: 0.605 ;iou_acc: 0.685 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.627 ;acc: 0.630 ;iou_acc: 0.750 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.547 ;acc: 0.630 ;iou_acc: 0.745 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.534 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.519 ;Test accuracy 0.643 ;IOU accuracy: 0.736 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 1.612 ;acc: 0.740 ;iou: 0.805 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 1.422 ;acc: 0.795 ;iou: 0.835 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 1.581 ;acc: 0.755 ;iou: 0.810 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 1.480 ;acc: 0.790 ;iou: 0.855 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.479 ;acc: 0.730 ;iou: 0.785 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 1.588 ;acc: 0.745 ;iou: 0.815 ;time: 0:00:58\n",
      "\n",
      "*Training B: True ;B Train loss: 1.519 ;Train accuracy: 0.748 ;IOU accuracy: 0.820 ;Time: 0:01:08 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.561 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:01:09\n",
      "batch: 50 ;B loss: 1.393 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:19\n",
      "batch: 100 ;B loss: 1.606 ;acc: 0.625 ;iou_acc: 0.705 ;time: 0:01:29\n",
      "batch: 150 ;B loss: 1.546 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:39\n",
      "batch: 200 ;B loss: 1.503 ;acc: 0.635 ;iou_acc: 0.775 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 1.522 ;acc: 0.685 ;iou_acc: 0.815 ;time: 0:01:59\n",
      "\n",
      "*BTrain: True ;Test loss: 1.469 ;Test accuracy 0.660 ;IOU accuracy: 0.752 ;Time: 0:02:09\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 1.570 ;acc: 0.720 ;iou: 0.795 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 1.657 ;acc: 0.695 ;iou: 0.790 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 1.693 ;acc: 0.710 ;iou: 0.800 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 1.542 ;acc: 0.750 ;iou: 0.845 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 1.279 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 1.511 ;acc: 0.745 ;iou: 0.825 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.483 ;Train accuracy: 0.761 ;IOU accuracy: 0.831 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.499 ;acc: 0.630 ;iou_acc: 0.730 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.378 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.546 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.505 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.454 ;acc: 0.640 ;iou_acc: 0.775 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.467 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.437 ;Test accuracy 0.666 ;IOU accuracy: 0.758 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 1.376 ;acc: 0.760 ;iou: 0.840 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 1.446 ;acc: 0.795 ;iou: 0.850 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 1.352 ;acc: 0.795 ;iou: 0.825 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 1.356 ;acc: 0.810 ;iou: 0.840 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 1.611 ;acc: 0.765 ;iou: 0.825 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 1.439 ;acc: 0.780 ;iou: 0.835 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.454 ;Train accuracy: 0.770 ;IOU accuracy: 0.839 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.516 ;acc: 0.590 ;iou_acc: 0.730 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.368 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.543 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.487 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.429 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.486 ;acc: 0.655 ;iou_acc: 0.785 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.418 ;Test accuracy 0.672 ;IOU accuracy: 0.764 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 1.258 ;acc: 0.815 ;iou: 0.885 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 1.615 ;acc: 0.750 ;iou: 0.815 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 1.375 ;acc: 0.760 ;iou: 0.855 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 1.371 ;acc: 0.805 ;iou: 0.850 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 1.465 ;acc: 0.785 ;iou: 0.855 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 1.539 ;acc: 0.765 ;iou: 0.795 ;time: 0:00:57\n",
      "\n",
      "*Training B: True ;B Train loss: 1.428 ;Train accuracy: 0.779 ;IOU accuracy: 0.846 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.514 ;acc: 0.605 ;iou_acc: 0.730 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.339 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.489 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.475 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.429 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.495 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:58\n",
      "\n",
      "*BTrain: True ;Test loss: 1.400 ;Test accuracy 0.676 ;IOU accuracy: 0.769 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 1.328 ;acc: 0.865 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 1.502 ;acc: 0.760 ;iou: 0.850 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 1.353 ;acc: 0.795 ;iou: 0.870 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 1.326 ;acc: 0.790 ;iou: 0.875 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 1.274 ;acc: 0.795 ;iou: 0.855 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 1.553 ;acc: 0.780 ;iou: 0.850 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.400 ;Train accuracy: 0.786 ;IOU accuracy: 0.851 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.463 ;acc: 0.635 ;iou_acc: 0.755 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.322 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.516 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.458 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.428 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.423 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.380 ;Test accuracy 0.680 ;IOU accuracy: 0.772 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 1.446 ;acc: 0.775 ;iou: 0.840 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 1.245 ;acc: 0.825 ;iou: 0.905 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 1.524 ;acc: 0.765 ;iou: 0.815 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 1.331 ;acc: 0.790 ;iou: 0.830 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 1.304 ;acc: 0.835 ;iou: 0.905 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 1.431 ;acc: 0.785 ;iou: 0.845 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.370 ;Train accuracy: 0.792 ;IOU accuracy: 0.856 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.467 ;acc: 0.620 ;iou_acc: 0.725 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.297 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.501 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.434 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.391 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.467 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.370 ;Test accuracy 0.683 ;IOU accuracy: 0.773 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 1.464 ;acc: 0.760 ;iou: 0.860 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 1.252 ;acc: 0.815 ;iou: 0.880 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 1.361 ;acc: 0.845 ;iou: 0.890 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 1.263 ;acc: 0.805 ;iou: 0.880 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 1.474 ;acc: 0.785 ;iou: 0.865 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 1.509 ;acc: 0.775 ;iou: 0.850 ;time: 0:00:56\n",
      "\n",
      "*Training B: True ;B Train loss: 1.359 ;Train accuracy: 0.797 ;IOU accuracy: 0.860 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.420 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.268 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.468 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.411 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.364 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.438 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:58\n",
      "\n",
      "*BTrain: True ;Test loss: 1.345 ;Test accuracy 0.689 ;IOU accuracy: 0.778 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 1.353 ;acc: 0.820 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 1.457 ;acc: 0.810 ;iou: 0.870 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 1.536 ;acc: 0.790 ;iou: 0.870 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 1.254 ;acc: 0.810 ;iou: 0.875 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 1.300 ;acc: 0.795 ;iou: 0.850 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 1.276 ;acc: 0.840 ;iou: 0.910 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.330 ;Train accuracy: 0.805 ;IOU accuracy: 0.866 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.393 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.291 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.423 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.413 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.395 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.382 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.334 ;Test accuracy 0.691 ;IOU accuracy: 0.781 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 1.353 ;acc: 0.805 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 1.268 ;acc: 0.815 ;iou: 0.880 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 1.362 ;acc: 0.770 ;iou: 0.830 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 1.347 ;acc: 0.855 ;iou: 0.910 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 1.404 ;acc: 0.835 ;iou: 0.870 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 1.269 ;acc: 0.785 ;iou: 0.845 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.314 ;Train accuracy: 0.809 ;IOU accuracy: 0.869 ;Time: 0:01:08 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.403 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.282 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.414 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.355 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.352 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.405 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.318 ;Test accuracy 0.695 ;IOU accuracy: 0.785 ;Time: 0:02:08\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 1.176 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 1.245 ;acc: 0.855 ;iou: 0.895 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 1.160 ;acc: 0.830 ;iou: 0.890 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 1.209 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 1.189 ;acc: 0.835 ;iou: 0.885 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 1.291 ;acc: 0.795 ;iou: 0.850 ;time: 0:00:56\n",
      "\n",
      "*Training B: True ;B Train loss: 1.294 ;Train accuracy: 0.815 ;IOU accuracy: 0.874 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.404 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.241 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.458 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:01:26\n",
      "batch: 150 ;B loss: 1.363 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:36\n",
      "batch: 200 ;B loss: 1.311 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:46\n",
      "batch: 250 ;B loss: 1.421 ;acc: 0.700 ;iou_acc: 0.820 ;time: 0:01:56\n",
      "\n",
      "*BTrain: True ;Test loss: 1.316 ;Test accuracy 0.698 ;IOU accuracy: 0.786 ;Time: 0:02:05\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 1.298 ;acc: 0.825 ;iou: 0.895 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 1.343 ;acc: 0.810 ;iou: 0.895 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 1.218 ;acc: 0.830 ;iou: 0.905 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 1.292 ;acc: 0.835 ;iou: 0.880 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 1.238 ;acc: 0.825 ;iou: 0.905 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 1.232 ;acc: 0.815 ;iou: 0.885 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.286 ;Train accuracy: 0.819 ;IOU accuracy: 0.878 ;Time: 0:01:08 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.374 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.212 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.406 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.364 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.312 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.391 ;acc: 0.695 ;iou_acc: 0.830 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.301 ;Test accuracy 0.700 ;IOU accuracy: 0.788 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 1.361 ;acc: 0.775 ;iou: 0.865 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 1.079 ;acc: 0.865 ;iou: 0.890 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 1.477 ;acc: 0.780 ;iou: 0.865 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 1.396 ;acc: 0.790 ;iou: 0.855 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 1.142 ;acc: 0.825 ;iou: 0.885 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 1.292 ;acc: 0.830 ;iou: 0.895 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.270 ;Train accuracy: 0.822 ;IOU accuracy: 0.879 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.382 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.222 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.391 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.357 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.291 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.395 ;acc: 0.690 ;iou_acc: 0.820 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.294 ;Test accuracy 0.703 ;IOU accuracy: 0.790 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 1.287 ;acc: 0.840 ;iou: 0.880 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 1.273 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 1.270 ;acc: 0.805 ;iou: 0.860 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 1.422 ;acc: 0.765 ;iou: 0.845 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 1.161 ;acc: 0.815 ;iou: 0.895 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 1.205 ;acc: 0.820 ;iou: 0.885 ;time: 0:00:57\n",
      "\n",
      "*Training B: True ;B Train loss: 1.255 ;Train accuracy: 0.828 ;IOU accuracy: 0.884 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.337 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.243 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.419 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.369 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.298 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.386 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:58\n",
      "\n",
      "*BTrain: True ;Test loss: 1.289 ;Test accuracy 0.704 ;IOU accuracy: 0.791 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 1.364 ;acc: 0.810 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 1.050 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 1.377 ;acc: 0.785 ;iou: 0.870 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 1.247 ;acc: 0.800 ;iou: 0.875 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 1.203 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 1.092 ;acc: 0.860 ;iou: 0.915 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.231 ;Train accuracy: 0.833 ;IOU accuracy: 0.887 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.369 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.196 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.391 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.318 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.251 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.365 ;acc: 0.690 ;iou_acc: 0.815 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.279 ;Test accuracy 0.708 ;IOU accuracy: 0.796 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 1.092 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 1.191 ;acc: 0.825 ;iou: 0.870 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 1.162 ;acc: 0.815 ;iou: 0.860 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 1.314 ;acc: 0.800 ;iou: 0.850 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 1.310 ;acc: 0.785 ;iou: 0.840 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 1.142 ;acc: 0.815 ;iou: 0.895 ;time: 0:00:58\n",
      "\n",
      "*Training B: False ;B Train loss: 1.219 ;Train accuracy: 0.837 ;IOU accuracy: 0.891 ;Time: 0:01:08 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.325 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:09\n",
      "batch: 50 ;B loss: 1.219 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:19\n",
      "batch: 100 ;B loss: 1.303 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.321 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.244 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.353 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.261 ;Test accuracy 0.711 ;IOU accuracy: 0.798 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.971 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 1.101 ;acc: 0.870 ;iou: 0.930 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 1.326 ;acc: 0.795 ;iou: 0.890 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 1.234 ;acc: 0.810 ;iou: 0.855 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 1.221 ;acc: 0.870 ;iou: 0.920 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 1.340 ;acc: 0.830 ;iou: 0.885 ;time: 0:00:57\n",
      "\n",
      "*Training B: True ;B Train loss: 1.206 ;Train accuracy: 0.840 ;IOU accuracy: 0.893 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.388 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.181 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.384 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.355 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.239 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.311 ;acc: 0.720 ;iou_acc: 0.840 ;time: 0:01:57\n",
      "\n",
      "*BTrain: True ;Test loss: 1.266 ;Test accuracy 0.710 ;IOU accuracy: 0.796 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 0.944 ;acc: 0.865 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 1.224 ;acc: 0.875 ;iou: 0.930 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 1.188 ;acc: 0.835 ;iou: 0.890 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 1.129 ;acc: 0.855 ;iou: 0.935 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 1.245 ;acc: 0.805 ;iou: 0.865 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 1.149 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.191 ;Train accuracy: 0.843 ;IOU accuracy: 0.895 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.337 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.201 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.317 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.310 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.256 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.300 ;acc: 0.725 ;iou_acc: 0.845 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.257 ;Test accuracy 0.713 ;IOU accuracy: 0.798 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 1.198 ;acc: 0.850 ;iou: 0.895 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 1.362 ;acc: 0.820 ;iou: 0.895 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 1.222 ;acc: 0.860 ;iou: 0.915 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 1.057 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 1.098 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 1.264 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.183 ;Train accuracy: 0.849 ;IOU accuracy: 0.899 ;Time: 0:01:08 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.312 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:09\n",
      "batch: 50 ;B loss: 1.189 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:19\n",
      "batch: 100 ;B loss: 1.319 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:29\n",
      "batch: 150 ;B loss: 1.328 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:39\n",
      "batch: 200 ;B loss: 1.244 ;acc: 0.700 ;iou_acc: 0.825 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 1.328 ;acc: 0.735 ;iou_acc: 0.855 ;time: 0:01:59\n",
      "\n",
      "*BTrain: False ;Test loss: 1.255 ;Test accuracy 0.714 ;IOU accuracy: 0.800 ;Time: 0:02:08\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 1.166 ;acc: 0.860 ;iou: 0.930 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 1.169 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 1.201 ;acc: 0.835 ;iou: 0.920 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 1.375 ;acc: 0.825 ;iou: 0.870 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 1.181 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 1.304 ;acc: 0.840 ;iou: 0.880 ;time: 0:00:56\n",
      "\n",
      "*Training B: True ;B Train loss: 1.174 ;Train accuracy: 0.851 ;IOU accuracy: 0.901 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.322 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.168 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.298 ;acc: 0.725 ;iou_acc: 0.790 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.350 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.213 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.312 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:01:58\n",
      "\n",
      "*BTrain: True ;Test loss: 1.240 ;Test accuracy 0.718 ;IOU accuracy: 0.803 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 1.000 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 1.021 ;acc: 0.890 ;iou: 0.900 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 1.171 ;acc: 0.835 ;iou: 0.890 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 1.151 ;acc: 0.855 ;iou: 0.905 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 1.171 ;acc: 0.840 ;iou: 0.885 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 1.275 ;acc: 0.840 ;iou: 0.900 ;time: 0:00:58\n",
      "\n",
      "*Training B: False ;B Train loss: 1.163 ;Train accuracy: 0.854 ;IOU accuracy: 0.902 ;Time: 0:01:08 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.330 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:09\n",
      "batch: 50 ;B loss: 1.166 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:19\n",
      "batch: 100 ;B loss: 1.300 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 150 ;B loss: 1.326 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:01:39\n",
      "batch: 200 ;B loss: 1.198 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 1.311 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:59\n",
      "\n",
      "*BTrain: False ;Test loss: 1.243 ;Test accuracy 0.716 ;IOU accuracy: 0.801 ;Time: 0:02:09\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 1.171 ;acc: 0.855 ;iou: 0.880 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 1.074 ;acc: 0.865 ;iou: 0.915 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 1.267 ;acc: 0.840 ;iou: 0.875 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 1.025 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 1.086 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 1.234 ;acc: 0.850 ;iou: 0.890 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.145 ;Train accuracy: 0.858 ;IOU accuracy: 0.906 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.310 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.154 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.292 ;acc: 0.725 ;iou_acc: 0.780 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.340 ;acc: 0.705 ;iou_acc: 0.765 ;time: 0:01:36\n",
      "batch: 200 ;B loss: 1.213 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:01:46\n",
      "batch: 250 ;B loss: 1.297 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.237 ;Test accuracy 0.717 ;IOU accuracy: 0.802 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 1.163 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 1.216 ;acc: 0.825 ;iou: 0.920 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 1.102 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 1.254 ;acc: 0.865 ;iou: 0.905 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 1.149 ;acc: 0.855 ;iou: 0.910 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 1.051 ;acc: 0.855 ;iou: 0.895 ;time: 0:00:56\n",
      "\n",
      "*Training B: True ;B Train loss: 1.136 ;Train accuracy: 0.861 ;IOU accuracy: 0.909 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.341 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.168 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.309 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:01:26\n",
      "batch: 150 ;B loss: 1.344 ;acc: 0.700 ;iou_acc: 0.760 ;time: 0:01:36\n",
      "batch: 200 ;B loss: 1.219 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:46\n",
      "batch: 250 ;B loss: 1.329 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:01:56\n",
      "\n",
      "*BTrain: True ;Test loss: 1.244 ;Test accuracy 0.717 ;IOU accuracy: 0.801 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 1.179 ;acc: 0.845 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 1.117 ;acc: 0.865 ;iou: 0.895 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 1.051 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 1.172 ;acc: 0.855 ;iou: 0.895 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 1.159 ;acc: 0.855 ;iou: 0.885 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 1.143 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.127 ;Train accuracy: 0.863 ;IOU accuracy: 0.910 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.307 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.159 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.280 ;acc: 0.740 ;iou_acc: 0.800 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.298 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.168 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.317 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.229 ;Test accuracy 0.721 ;IOU accuracy: 0.806 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.980 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.974 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 1.145 ;acc: 0.890 ;iou: 0.920 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 0.995 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 1.177 ;acc: 0.900 ;iou: 0.915 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 1.135 ;acc: 0.855 ;iou: 0.915 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.116 ;Train accuracy: 0.866 ;IOU accuracy: 0.912 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.309 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.137 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.266 ;acc: 0.755 ;iou_acc: 0.810 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.353 ;acc: 0.700 ;iou_acc: 0.755 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.231 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.288 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.226 ;Test accuracy 0.720 ;IOU accuracy: 0.806 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 1.085 ;acc: 0.870 ;iou: 0.910 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 1.034 ;acc: 0.870 ;iou: 0.920 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 1.026 ;acc: 0.855 ;iou: 0.915 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 1.046 ;acc: 0.865 ;iou: 0.930 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 1.101 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 1.035 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:58\n",
      "\n",
      "*Training B: True ;B Train loss: 1.107 ;Train accuracy: 0.869 ;IOU accuracy: 0.914 ;Time: 0:01:08 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.317 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:09\n",
      "batch: 50 ;B loss: 1.168 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:19\n",
      "batch: 100 ;B loss: 1.266 ;acc: 0.720 ;iou_acc: 0.780 ;time: 0:01:29\n",
      "batch: 150 ;B loss: 1.321 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:39\n",
      "batch: 200 ;B loss: 1.164 ;acc: 0.740 ;iou_acc: 0.840 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 1.267 ;acc: 0.740 ;iou_acc: 0.830 ;time: 0:01:59\n",
      "\n",
      "*BTrain: True ;Test loss: 1.221 ;Test accuracy 0.722 ;IOU accuracy: 0.807 ;Time: 0:02:08\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.967 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 1.167 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.942 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.963 ;acc: 0.885 ;iou: 0.945 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 1.051 ;acc: 0.870 ;iou: 0.915 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.944 ;acc: 0.890 ;iou: 0.945 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.088 ;Train accuracy: 0.872 ;IOU accuracy: 0.915 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.310 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.173 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.307 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.287 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.196 ;acc: 0.730 ;iou_acc: 0.840 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.301 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.218 ;Test accuracy 0.724 ;IOU accuracy: 0.809 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 1.018 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 1.090 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 1.303 ;acc: 0.845 ;iou: 0.910 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 1.180 ;acc: 0.845 ;iou: 0.900 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 1.136 ;acc: 0.845 ;iou: 0.910 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 1.009 ;acc: 0.900 ;iou: 0.945 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.086 ;Train accuracy: 0.875 ;IOU accuracy: 0.919 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.305 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.174 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.257 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.284 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.174 ;acc: 0.740 ;iou_acc: 0.840 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.300 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:56\n",
      "\n",
      "*BTrain: False ;Test loss: 1.217 ;Test accuracy 0.723 ;IOU accuracy: 0.808 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.971 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.999 ;acc: 0.860 ;iou: 0.910 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.979 ;acc: 0.885 ;iou: 0.940 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 1.182 ;acc: 0.870 ;iou: 0.950 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 1.032 ;acc: 0.885 ;iou: 0.920 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 1.044 ;acc: 0.860 ;iou: 0.940 ;time: 0:00:56\n",
      "\n",
      "*Training B: True ;B Train loss: 1.070 ;Train accuracy: 0.878 ;IOU accuracy: 0.920 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.296 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.110 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.260 ;acc: 0.735 ;iou_acc: 0.800 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.295 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.139 ;acc: 0.750 ;iou_acc: 0.855 ;time: 0:01:46\n",
      "batch: 250 ;B loss: 1.277 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:56\n",
      "\n",
      "*BTrain: True ;Test loss: 1.205 ;Test accuracy 0.728 ;IOU accuracy: 0.812 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.907 ;acc: 0.870 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.969 ;acc: 0.860 ;iou: 0.920 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 1.060 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 1.099 ;acc: 0.815 ;iou: 0.885 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 1.203 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 1.154 ;acc: 0.840 ;iou: 0.905 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.059 ;Train accuracy: 0.879 ;IOU accuracy: 0.922 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.220 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.136 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.272 ;acc: 0.720 ;iou_acc: 0.780 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.256 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.146 ;acc: 0.740 ;iou_acc: 0.830 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.265 ;acc: 0.740 ;iou_acc: 0.835 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.204 ;Test accuracy 0.727 ;IOU accuracy: 0.812 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 1.190 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 1.037 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.974 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.951 ;acc: 0.885 ;iou: 0.935 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 1.121 ;acc: 0.920 ;iou: 0.960 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 1.085 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.057 ;Train accuracy: 0.883 ;IOU accuracy: 0.923 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.253 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.168 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.239 ;acc: 0.740 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.231 ;acc: 0.735 ;iou_acc: 0.800 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.198 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.280 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.210 ;Test accuracy 0.726 ;IOU accuracy: 0.809 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 1.137 ;acc: 0.855 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 1.078 ;acc: 0.855 ;iou: 0.935 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 1.109 ;acc: 0.855 ;iou: 0.930 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 1.007 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.975 ;acc: 0.845 ;iou: 0.900 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 1.044 ;acc: 0.895 ;iou: 0.945 ;time: 0:00:57\n",
      "\n",
      "*Training B: True ;B Train loss: 1.043 ;Train accuracy: 0.883 ;IOU accuracy: 0.925 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.241 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.138 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.275 ;acc: 0.745 ;iou_acc: 0.810 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.225 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.126 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.296 ;acc: 0.725 ;iou_acc: 0.820 ;time: 0:01:57\n",
      "\n",
      "*BTrain: True ;Test loss: 1.195 ;Test accuracy 0.730 ;IOU accuracy: 0.815 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 1.024 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 1.075 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.804 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 1.055 ;acc: 0.880 ;iou: 0.900 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 1.093 ;acc: 0.895 ;iou: 0.910 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.922 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.034 ;Train accuracy: 0.887 ;IOU accuracy: 0.926 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.241 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.158 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:18\n",
      "batch: 100 ;B loss: 1.298 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 150 ;B loss: 1.258 ;acc: 0.730 ;iou_acc: 0.795 ;time: 0:01:38\n",
      "batch: 200 ;B loss: 1.133 ;acc: 0.750 ;iou_acc: 0.850 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 1.288 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.204 ;Test accuracy 0.729 ;IOU accuracy: 0.812 ;Time: 0:02:08\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 1.015 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.954 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 1.019 ;acc: 0.900 ;iou: 0.955 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.952 ;acc: 0.885 ;iou: 0.920 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 1.154 ;acc: 0.860 ;iou: 0.905 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 1.034 ;acc: 0.840 ;iou: 0.885 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.031 ;Train accuracy: 0.889 ;IOU accuracy: 0.928 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.252 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.162 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.210 ;acc: 0.755 ;iou_acc: 0.820 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.257 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.150 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.242 ;acc: 0.740 ;iou_acc: 0.825 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.195 ;Test accuracy 0.731 ;IOU accuracy: 0.815 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.810 ;acc: 0.900 ;iou: 0.955 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 1.017 ;acc: 0.905 ;iou: 0.950 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 1.173 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.958 ;acc: 0.875 ;iou: 0.900 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 1.066 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 1.038 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:57\n",
      "\n",
      "*Training B: True ;B Train loss: 1.018 ;Train accuracy: 0.890 ;IOU accuracy: 0.929 ;Time: 0:01:07 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.226 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:08\n",
      "batch: 50 ;B loss: 1.169 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.230 ;acc: 0.755 ;iou_acc: 0.815 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.279 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.225 ;acc: 0.725 ;iou_acc: 0.845 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.262 ;acc: 0.745 ;iou_acc: 0.830 ;time: 0:01:57\n",
      "\n",
      "*BTrain: True ;Test loss: 1.203 ;Test accuracy 0.730 ;IOU accuracy: 0.813 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.978 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.916 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 1.106 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 1.023 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 1.015 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 1.259 ;acc: 0.870 ;iou: 0.915 ;time: 0:00:58\n",
      "\n",
      "*Training B: False ;B Train loss: 1.011 ;Train accuracy: 0.893 ;IOU accuracy: 0.931 ;Time: 0:01:09 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.250 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:01:09\n",
      "batch: 50 ;B loss: 1.141 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:20\n",
      "batch: 100 ;B loss: 1.234 ;acc: 0.745 ;iou_acc: 0.805 ;time: 0:01:29\n",
      "batch: 150 ;B loss: 1.261 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:01:39\n",
      "batch: 200 ;B loss: 1.139 ;acc: 0.765 ;iou_acc: 0.855 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 1.273 ;acc: 0.745 ;iou_acc: 0.830 ;time: 0:01:59\n",
      "\n",
      "*BTrain: False ;Test loss: 1.196 ;Test accuracy 0.732 ;IOU accuracy: 0.815 ;Time: 0:02:08\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 50 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14851 ;lr: 0.0495 ;B loss: 0.939 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14901 ;lr: 0.0495 ;B loss: 1.112 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14951 ;lr: 0.0495 ;B loss: 0.938 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15001 ;lr: 0.0495 ;B loss: 1.046 ;acc: 0.875 ;iou: 0.905 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15051 ;lr: 0.0495 ;B loss: 0.999 ;acc: 0.870 ;iou: 0.925 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15101 ;lr: 0.0495 ;B loss: 1.104 ;acc: 0.880 ;iou: 0.945 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.002 ;Train accuracy: 0.896 ;IOU accuracy: 0.933 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 50\n",
      "batch: 0 ;B loss: 1.244 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.155 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.259 ;acc: 0.740 ;iou_acc: 0.810 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.266 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.146 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.273 ;acc: 0.750 ;iou_acc: 0.845 ;time: 0:01:45\n",
      "\n",
      "*BTrain: False ;Test loss: 1.200 ;Test accuracy 0.731 ;IOU accuracy: 0.814 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 51 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15148 ;lr: 0.0495 ;B loss: 0.969 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15198 ;lr: 0.0495 ;B loss: 1.008 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15248 ;lr: 0.0495 ;B loss: 0.901 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15298 ;lr: 0.0495 ;B loss: 0.913 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15348 ;lr: 0.0495 ;B loss: 0.957 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15398 ;lr: 0.0495 ;B loss: 1.164 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:49\n",
      "\n",
      "*Training B: True ;B Train loss: 0.995 ;Train accuracy: 0.897 ;IOU accuracy: 0.933 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 51\n",
      "batch: 0 ;B loss: 1.236 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.148 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.252 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:13\n",
      "batch: 150 ;B loss: 1.249 ;acc: 0.745 ;iou_acc: 0.810 ;time: 0:01:21\n",
      "batch: 200 ;B loss: 1.160 ;acc: 0.755 ;iou_acc: 0.840 ;time: 0:01:29\n",
      "batch: 250 ;B loss: 1.249 ;acc: 0.755 ;iou_acc: 0.840 ;time: 0:01:37\n",
      "\n",
      "*BTrain: True ;Test loss: 1.190 ;Test accuracy 0.734 ;IOU accuracy: 0.817 ;Time: 0:01:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 52 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15445 ;lr: 0.0495 ;B loss: 0.925 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15495 ;lr: 0.0495 ;B loss: 0.993 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15545 ;lr: 0.0495 ;B loss: 0.913 ;acc: 0.885 ;iou: 0.935 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15595 ;lr: 0.0495 ;B loss: 0.922 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15645 ;lr: 0.0495 ;B loss: 1.132 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15695 ;lr: 0.0495 ;B loss: 0.921 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:48\n",
      "\n",
      "*Training B: False ;B Train loss: 0.987 ;Train accuracy: 0.900 ;IOU accuracy: 0.936 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 52\n",
      "batch: 0 ;B loss: 1.221 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.188 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:06\n",
      "batch: 100 ;B loss: 1.226 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:14\n",
      "batch: 150 ;B loss: 1.270 ;acc: 0.730 ;iou_acc: 0.795 ;time: 0:01:22\n",
      "batch: 200 ;B loss: 1.150 ;acc: 0.735 ;iou_acc: 0.845 ;time: 0:01:32\n",
      "batch: 250 ;B loss: 1.264 ;acc: 0.745 ;iou_acc: 0.845 ;time: 0:01:41\n",
      "\n",
      "*BTrain: False ;Test loss: 1.192 ;Test accuracy 0.732 ;IOU accuracy: 0.814 ;Time: 0:01:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 53 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15742 ;lr: 0.0495 ;B loss: 0.970 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15792 ;lr: 0.0495 ;B loss: 0.967 ;acc: 0.915 ;iou: 0.960 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15842 ;lr: 0.0495 ;B loss: 1.039 ;acc: 0.895 ;iou: 0.920 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15892 ;lr: 0.0495 ;B loss: 0.804 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15942 ;lr: 0.0495 ;B loss: 1.052 ;acc: 0.890 ;iou: 0.920 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15992 ;lr: 0.0495 ;B loss: 0.806 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.979 ;Train accuracy: 0.902 ;IOU accuracy: 0.937 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 53\n",
      "batch: 0 ;B loss: 1.223 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.187 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.190 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.280 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.139 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.294 ;acc: 0.730 ;iou_acc: 0.840 ;time: 0:01:42\n",
      "\n",
      "*BTrain: False ;Test loss: 1.194 ;Test accuracy 0.733 ;IOU accuracy: 0.815 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 54 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16039 ;lr: 0.0495 ;B loss: 0.803 ;acc: 0.925 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16089 ;lr: 0.0495 ;B loss: 0.998 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16139 ;lr: 0.0495 ;B loss: 1.090 ;acc: 0.870 ;iou: 0.950 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16189 ;lr: 0.0495 ;B loss: 0.988 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16239 ;lr: 0.0495 ;B loss: 0.992 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16289 ;lr: 0.0495 ;B loss: 0.911 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.965 ;Train accuracy: 0.905 ;IOU accuracy: 0.939 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 54\n",
      "batch: 0 ;B loss: 1.164 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.192 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.222 ;acc: 0.710 ;iou_acc: 0.765 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.309 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.155 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.267 ;acc: 0.745 ;iou_acc: 0.855 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 1.194 ;Test accuracy 0.732 ;IOU accuracy: 0.815 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 55 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16336 ;lr: 0.0495 ;B loss: 0.941 ;acc: 0.915 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16386 ;lr: 0.0495 ;B loss: 1.000 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16436 ;lr: 0.0495 ;B loss: 0.894 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16486 ;lr: 0.0495 ;B loss: 0.971 ;acc: 0.905 ;iou: 0.925 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16536 ;lr: 0.0495 ;B loss: 0.955 ;acc: 0.910 ;iou: 0.965 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16586 ;lr: 0.0495 ;B loss: 0.872 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.971 ;Train accuracy: 0.905 ;IOU accuracy: 0.940 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 55\n",
      "batch: 0 ;B loss: 1.202 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.184 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.240 ;acc: 0.735 ;iou_acc: 0.795 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.291 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.190 ;acc: 0.730 ;iou_acc: 0.835 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.296 ;acc: 0.730 ;iou_acc: 0.840 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.198 ;Test accuracy 0.733 ;IOU accuracy: 0.816 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 56 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16633 ;lr: 0.0495 ;B loss: 0.880 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16683 ;lr: 0.0495 ;B loss: 1.026 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16733 ;lr: 0.0495 ;B loss: 0.922 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16783 ;lr: 0.0495 ;B loss: 1.045 ;acc: 0.890 ;iou: 0.945 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16833 ;lr: 0.0495 ;B loss: 1.019 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16883 ;lr: 0.0495 ;B loss: 1.024 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.961 ;Train accuracy: 0.907 ;IOU accuracy: 0.941 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 56\n",
      "batch: 0 ;B loss: 1.217 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.155 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.252 ;acc: 0.725 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.258 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.125 ;acc: 0.760 ;iou_acc: 0.845 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.241 ;acc: 0.760 ;iou_acc: 0.855 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.195 ;Test accuracy 0.734 ;IOU accuracy: 0.816 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 57 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16930 ;lr: 0.0495 ;B loss: 1.077 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16980 ;lr: 0.0495 ;B loss: 0.933 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17030 ;lr: 0.0495 ;B loss: 0.882 ;acc: 0.935 ;iou: 0.970 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17080 ;lr: 0.0495 ;B loss: 0.922 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17130 ;lr: 0.0495 ;B loss: 0.989 ;acc: 0.895 ;iou: 0.915 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17180 ;lr: 0.0495 ;B loss: 0.876 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:49\n",
      "\n",
      "*Training B: True ;B Train loss: 0.948 ;Train accuracy: 0.909 ;IOU accuracy: 0.941 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 57\n",
      "batch: 0 ;B loss: 1.190 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.183 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.255 ;acc: 0.725 ;iou_acc: 0.780 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.311 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.145 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.256 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:42\n",
      "\n",
      "*BTrain: True ;Test loss: 1.183 ;Test accuracy 0.736 ;IOU accuracy: 0.818 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 58 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17227 ;lr: 0.0495 ;B loss: 1.025 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17277 ;lr: 0.0495 ;B loss: 0.920 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17327 ;lr: 0.0495 ;B loss: 1.021 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17377 ;lr: 0.0495 ;B loss: 1.074 ;acc: 0.875 ;iou: 0.930 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17427 ;lr: 0.0495 ;B loss: 0.970 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17477 ;lr: 0.0495 ;B loss: 0.966 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.946 ;Train accuracy: 0.912 ;IOU accuracy: 0.944 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 58\n",
      "batch: 0 ;B loss: 1.211 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.182 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.299 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.327 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.127 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.319 ;acc: 0.730 ;iou_acc: 0.825 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.193 ;Test accuracy 0.733 ;IOU accuracy: 0.816 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 59 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17524 ;lr: 0.0495 ;B loss: 1.097 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17574 ;lr: 0.0495 ;B loss: 0.906 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17624 ;lr: 0.0495 ;B loss: 1.029 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17674 ;lr: 0.0495 ;B loss: 1.058 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17724 ;lr: 0.0495 ;B loss: 1.014 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17774 ;lr: 0.0495 ;B loss: 1.061 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 0.936 ;Train accuracy: 0.913 ;IOU accuracy: 0.945 ;Time: 0:00:58 \n",
      "\n",
      "Testing, ephoc: 59\n",
      "batch: 0 ;B loss: 1.166 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.149 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.309 ;acc: 0.740 ;iou_acc: 0.795 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.296 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:25\n",
      "batch: 200 ;B loss: 1.179 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.304 ;acc: 0.730 ;iou_acc: 0.810 ;time: 0:01:42\n",
      "\n",
      "*BTrain: False ;Test loss: 1.199 ;Test accuracy 0.732 ;IOU accuracy: 0.815 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 60 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17821 ;lr: 0.0495 ;B loss: 0.989 ;acc: 0.895 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17871 ;lr: 0.0495 ;B loss: 0.838 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17921 ;lr: 0.0495 ;B loss: 1.024 ;acc: 0.910 ;iou: 0.955 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17971 ;lr: 0.0495 ;B loss: 0.895 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18021 ;lr: 0.0495 ;B loss: 0.996 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18071 ;lr: 0.0495 ;B loss: 0.943 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:48\n",
      "\n",
      "*Training B: True ;B Train loss: 0.930 ;Train accuracy: 0.915 ;IOU accuracy: 0.947 ;Time: 0:00:57 \n",
      "\n",
      "Testing, ephoc: 60\n",
      "batch: 0 ;B loss: 1.195 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:00:58\n",
      "batch: 50 ;B loss: 1.185 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:07\n",
      "batch: 100 ;B loss: 1.246 ;acc: 0.735 ;iou_acc: 0.800 ;time: 0:01:15\n",
      "batch: 150 ;B loss: 1.245 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:01:24\n",
      "batch: 200 ;B loss: 1.132 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:33\n",
      "batch: 250 ;B loss: 1.258 ;acc: 0.750 ;iou_acc: 0.840 ;time: 0:01:42\n",
      "\n",
      "*BTrain: True ;Test loss: 1.185 ;Test accuracy 0.737 ;IOU accuracy: 0.819 ;Time: 0:01:50\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 61 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18118 ;lr: 0.0495 ;B loss: 0.856 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18168 ;lr: 0.0495 ;B loss: 0.860 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18218 ;lr: 0.0495 ;B loss: 1.167 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18268 ;lr: 0.0495 ;B loss: 1.008 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18318 ;lr: 0.0495 ;B loss: 1.004 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18368 ;lr: 0.0495 ;B loss: 1.107 ;acc: 0.870 ;iou: 0.925 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 0.925 ;Train accuracy: 0.916 ;IOU accuracy: 0.947 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 61\n",
      "batch: 0 ;B loss: 1.201 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.148 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.302 ;acc: 0.710 ;iou_acc: 0.770 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.264 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.118 ;acc: 0.730 ;iou_acc: 0.835 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.267 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.183 ;Test accuracy 0.736 ;IOU accuracy: 0.819 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 62 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18415 ;lr: 0.0495 ;B loss: 1.084 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18465 ;lr: 0.0495 ;B loss: 0.788 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18515 ;lr: 0.0495 ;B loss: 0.939 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18565 ;lr: 0.0495 ;B loss: 0.909 ;acc: 0.920 ;iou: 0.970 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18615 ;lr: 0.0495 ;B loss: 0.965 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18665 ;lr: 0.0495 ;B loss: 0.952 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 0.921 ;Train accuracy: 0.918 ;IOU accuracy: 0.948 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 62\n",
      "batch: 0 ;B loss: 1.215 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.185 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.297 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.243 ;acc: 0.745 ;iou_acc: 0.800 ;time: 0:01:27\n",
      "batch: 200 ;B loss: 1.128 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:01:36\n",
      "batch: 250 ;B loss: 1.253 ;acc: 0.760 ;iou_acc: 0.855 ;time: 0:01:45\n",
      "\n",
      "*BTrain: False ;Test loss: 1.201 ;Test accuracy 0.735 ;IOU accuracy: 0.817 ;Time: 0:01:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 63 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18712 ;lr: 0.0495 ;B loss: 0.790 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18762 ;lr: 0.0495 ;B loss: 1.261 ;acc: 0.855 ;iou: 0.925 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18812 ;lr: 0.0495 ;B loss: 0.796 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18862 ;lr: 0.0495 ;B loss: 0.902 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18912 ;lr: 0.0495 ;B loss: 0.938 ;acc: 0.910 ;iou: 0.960 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18962 ;lr: 0.0495 ;B loss: 1.107 ;acc: 0.860 ;iou: 0.950 ;time: 0:00:49\n",
      "\n",
      "*Training B: True ;B Train loss: 0.915 ;Train accuracy: 0.920 ;IOU accuracy: 0.950 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 63\n",
      "batch: 0 ;B loss: 1.211 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.150 ;acc: 0.745 ;iou_acc: 0.825 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.279 ;acc: 0.720 ;iou_acc: 0.780 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.245 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.096 ;acc: 0.735 ;iou_acc: 0.820 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.258 ;acc: 0.750 ;iou_acc: 0.845 ;time: 0:01:43\n",
      "\n",
      "*BTrain: True ;Test loss: 1.194 ;Test accuracy 0.736 ;IOU accuracy: 0.818 ;Time: 0:01:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 64 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19009 ;lr: 0.0495 ;B loss: 1.090 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19059 ;lr: 0.0495 ;B loss: 0.988 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19109 ;lr: 0.0495 ;B loss: 0.803 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19159 ;lr: 0.0495 ;B loss: 0.972 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19209 ;lr: 0.0495 ;B loss: 0.825 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19259 ;lr: 0.0495 ;B loss: 0.868 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.907 ;Train accuracy: 0.920 ;IOU accuracy: 0.951 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 64\n",
      "batch: 0 ;B loss: 1.184 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.194 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.265 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.243 ;acc: 0.725 ;iou_acc: 0.790 ;time: 0:01:27\n",
      "batch: 200 ;B loss: 1.123 ;acc: 0.730 ;iou_acc: 0.825 ;time: 0:01:36\n",
      "batch: 250 ;B loss: 1.242 ;acc: 0.760 ;iou_acc: 0.845 ;time: 0:01:45\n",
      "\n",
      "*BTrain: False ;Test loss: 1.186 ;Test accuracy 0.738 ;IOU accuracy: 0.819 ;Time: 0:01:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 65 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19306 ;lr: 0.0495 ;B loss: 0.682 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19356 ;lr: 0.0495 ;B loss: 0.918 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19406 ;lr: 0.0495 ;B loss: 0.828 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19456 ;lr: 0.0495 ;B loss: 0.983 ;acc: 0.900 ;iou: 0.950 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19506 ;lr: 0.0495 ;B loss: 0.860 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19556 ;lr: 0.0495 ;B loss: 1.049 ;acc: 0.920 ;iou: 0.965 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.889 ;Train accuracy: 0.922 ;IOU accuracy: 0.951 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 65\n",
      "batch: 0 ;B loss: 1.219 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.159 ;acc: 0.725 ;iou_acc: 0.790 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.279 ;acc: 0.735 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.247 ;acc: 0.740 ;iou_acc: 0.805 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.131 ;acc: 0.730 ;iou_acc: 0.825 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.270 ;acc: 0.735 ;iou_acc: 0.825 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.186 ;Test accuracy 0.737 ;IOU accuracy: 0.819 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 66 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19603 ;lr: 0.0495 ;B loss: 0.801 ;acc: 0.945 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19653 ;lr: 0.0495 ;B loss: 0.942 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19703 ;lr: 0.0495 ;B loss: 0.898 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19753 ;lr: 0.0495 ;B loss: 0.935 ;acc: 0.885 ;iou: 0.920 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19803 ;lr: 0.0495 ;B loss: 0.788 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19853 ;lr: 0.0495 ;B loss: 0.884 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.893 ;Train accuracy: 0.924 ;IOU accuracy: 0.953 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 66\n",
      "batch: 0 ;B loss: 1.187 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.138 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 1.307 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 1.235 ;acc: 0.730 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.124 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.265 ;acc: 0.750 ;iou_acc: 0.830 ;time: 0:01:46\n",
      "\n",
      "*BTrain: True ;Test loss: 1.182 ;Test accuracy 0.740 ;IOU accuracy: 0.821 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 67 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19900 ;lr: 0.0495 ;B loss: 0.939 ;acc: 0.955 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19950 ;lr: 0.0495 ;B loss: 0.890 ;acc: 0.925 ;iou: 0.965 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20000 ;lr: 0.0495 ;B loss: 1.014 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20050 ;lr: 0.0490 ;B loss: 0.783 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20100 ;lr: 0.0490 ;B loss: 0.910 ;acc: 0.920 ;iou: 0.960 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20150 ;lr: 0.0490 ;B loss: 0.892 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.883 ;Train accuracy: 0.926 ;IOU accuracy: 0.954 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 67\n",
      "batch: 0 ;B loss: 1.157 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.190 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.281 ;acc: 0.735 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.270 ;acc: 0.735 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.104 ;acc: 0.765 ;iou_acc: 0.840 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.252 ;acc: 0.770 ;iou_acc: 0.860 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.191 ;Test accuracy 0.739 ;IOU accuracy: 0.819 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 68 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20197 ;lr: 0.0490 ;B loss: 1.025 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20247 ;lr: 0.0490 ;B loss: 0.894 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20297 ;lr: 0.0490 ;B loss: 0.855 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20347 ;lr: 0.0490 ;B loss: 0.926 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20397 ;lr: 0.0490 ;B loss: 0.947 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20447 ;lr: 0.0490 ;B loss: 0.781 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.877 ;Train accuracy: 0.927 ;IOU accuracy: 0.954 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 68\n",
      "batch: 0 ;B loss: 1.138 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.144 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 1.261 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 1.225 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.139 ;acc: 0.735 ;iou_acc: 0.840 ;time: 0:01:36\n",
      "batch: 250 ;B loss: 1.234 ;acc: 0.765 ;iou_acc: 0.840 ;time: 0:01:45\n",
      "\n",
      "*BTrain: False ;Test loss: 1.185 ;Test accuracy 0.739 ;IOU accuracy: 0.820 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 69 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20494 ;lr: 0.0490 ;B loss: 0.774 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20544 ;lr: 0.0490 ;B loss: 0.766 ;acc: 0.915 ;iou: 0.960 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20594 ;lr: 0.0490 ;B loss: 0.917 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20644 ;lr: 0.0490 ;B loss: 0.640 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20694 ;lr: 0.0490 ;B loss: 0.871 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20744 ;lr: 0.0490 ;B loss: 1.053 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.865 ;Train accuracy: 0.930 ;IOU accuracy: 0.957 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 69\n",
      "batch: 0 ;B loss: 1.214 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.109 ;acc: 0.755 ;iou_acc: 0.835 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.235 ;acc: 0.735 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.289 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.119 ;acc: 0.760 ;iou_acc: 0.845 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.273 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:47\n",
      "\n",
      "*BTrain: True ;Test loss: 1.191 ;Test accuracy 0.740 ;IOU accuracy: 0.820 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 1.0\n",
      "dropout_out 0.5\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/img_drop_1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 3.096 ;acc: 0.320 ;iou: 0.430 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.690 ;acc: 0.245 ;iou: 0.330 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.823 ;acc: 0.240 ;iou: 0.340 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.791 ;acc: 0.280 ;iou: 0.375 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.627 ;acc: 0.300 ;iou: 0.410 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.588 ;acc: 0.330 ;iou: 0.450 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 2.695 ;Train accuracy: 0.293 ;IOU accuracy: 0.397 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.546 ;acc: 0.310 ;iou_acc: 0.395 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 2.628 ;acc: 0.275 ;iou_acc: 0.380 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 2.628 ;acc: 0.270 ;iou_acc: 0.385 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 2.593 ;acc: 0.300 ;iou_acc: 0.425 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 2.573 ;acc: 0.310 ;iou_acc: 0.390 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.578 ;acc: 0.305 ;iou_acc: 0.450 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 2.548 ;Test accuracy 0.307 ;IOU accuracy: 0.416 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.593 ;acc: 0.350 ;iou: 0.450 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.491 ;acc: 0.315 ;iou: 0.445 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.509 ;acc: 0.380 ;iou: 0.460 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.463 ;acc: 0.330 ;iou: 0.470 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.326 ;acc: 0.470 ;iou: 0.555 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.365 ;acc: 0.425 ;iou: 0.535 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 2.441 ;Train accuracy: 0.394 ;IOU accuracy: 0.498 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.300 ;acc: 0.395 ;iou_acc: 0.520 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 2.398 ;acc: 0.385 ;iou_acc: 0.485 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 2.447 ;acc: 0.360 ;iou_acc: 0.445 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 2.385 ;acc: 0.390 ;iou_acc: 0.480 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 2.351 ;acc: 0.330 ;iou_acc: 0.450 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.343 ;acc: 0.425 ;iou_acc: 0.555 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 2.322 ;Test accuracy 0.386 ;IOU accuracy: 0.495 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.321 ;acc: 0.450 ;iou: 0.570 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.251 ;acc: 0.430 ;iou: 0.550 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.150 ;acc: 0.475 ;iou: 0.565 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.175 ;acc: 0.450 ;iou: 0.535 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.319 ;acc: 0.415 ;iou: 0.535 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.235 ;acc: 0.480 ;iou: 0.585 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 2.259 ;Train accuracy: 0.470 ;IOU accuracy: 0.571 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.192 ;acc: 0.435 ;iou_acc: 0.550 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 2.235 ;acc: 0.450 ;iou_acc: 0.520 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 2.299 ;acc: 0.415 ;iou_acc: 0.510 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 2.288 ;acc: 0.420 ;iou_acc: 0.545 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 2.237 ;acc: 0.445 ;iou_acc: 0.580 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 2.156 ;acc: 0.465 ;iou_acc: 0.590 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 2.141 ;Test accuracy 0.456 ;IOU accuracy: 0.563 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.173 ;acc: 0.505 ;iou: 0.580 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.164 ;acc: 0.530 ;iou: 0.620 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 2.131 ;acc: 0.495 ;iou: 0.585 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 2.235 ;acc: 0.490 ;iou: 0.600 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 1.795 ;acc: 0.580 ;iou: 0.710 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 2.090 ;acc: 0.545 ;iou: 0.605 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 2.088 ;Train accuracy: 0.533 ;IOU accuracy: 0.627 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 2.002 ;acc: 0.505 ;iou_acc: 0.590 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 2.070 ;acc: 0.490 ;iou_acc: 0.580 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 2.104 ;acc: 0.475 ;iou_acc: 0.560 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 2.072 ;acc: 0.480 ;iou_acc: 0.600 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 2.088 ;acc: 0.450 ;iou_acc: 0.600 ;time: 0:01:42\n",
      "batch: 250 ;B loss: 2.011 ;acc: 0.525 ;iou_acc: 0.605 ;time: 0:01:52\n",
      "\n",
      "*BTrain: True ;Test loss: 1.987 ;Test accuracy 0.501 ;IOU accuracy: 0.602 ;Time: 0:02:01\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 1.904 ;acc: 0.585 ;iou: 0.660 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 1.954 ;acc: 0.590 ;iou: 0.650 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 1.819 ;acc: 0.610 ;iou: 0.710 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.901 ;acc: 0.580 ;iou: 0.660 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 2.097 ;acc: 0.480 ;iou: 0.595 ;time: 0:00:54\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 1.986 ;acc: 0.565 ;iou: 0.680 ;time: 0:01:08\n",
      "\n",
      "*Training B: False ;B Train loss: 1.967 ;Train accuracy: 0.569 ;IOU accuracy: 0.660 ;Time: 0:01:19 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.920 ;acc: 0.550 ;iou_acc: 0.610 ;time: 0:01:19\n",
      "batch: 50 ;B loss: 1.976 ;acc: 0.505 ;iou_acc: 0.590 ;time: 0:01:30\n",
      "batch: 100 ;B loss: 1.994 ;acc: 0.505 ;iou_acc: 0.570 ;time: 0:01:41\n",
      "batch: 150 ;B loss: 1.997 ;acc: 0.515 ;iou_acc: 0.610 ;time: 0:01:52\n",
      "batch: 200 ;B loss: 1.992 ;acc: 0.470 ;iou_acc: 0.605 ;time: 0:02:03\n",
      "batch: 250 ;B loss: 1.923 ;acc: 0.530 ;iou_acc: 0.620 ;time: 0:02:14\n",
      "\n",
      "*BTrain: False ;Test loss: 1.900 ;Test accuracy 0.526 ;IOU accuracy: 0.623 ;Time: 0:02:24\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 1.923 ;acc: 0.595 ;iou: 0.685 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.828 ;acc: 0.600 ;iou: 0.690 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.911 ;acc: 0.620 ;iou: 0.675 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 1.919 ;acc: 0.605 ;iou: 0.690 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.895 ;acc: 0.600 ;iou: 0.690 ;time: 0:00:54\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.889 ;acc: 0.600 ;iou: 0.695 ;time: 0:01:08\n",
      "\n",
      "*Training B: False ;B Train loss: 1.880 ;Train accuracy: 0.600 ;IOU accuracy: 0.684 ;Time: 0:01:22 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.819 ;acc: 0.535 ;iou_acc: 0.610 ;time: 0:01:22\n",
      "batch: 50 ;B loss: 1.930 ;acc: 0.545 ;iou_acc: 0.635 ;time: 0:01:34\n",
      "batch: 100 ;B loss: 1.922 ;acc: 0.550 ;iou_acc: 0.635 ;time: 0:01:46\n",
      "batch: 150 ;B loss: 1.981 ;acc: 0.490 ;iou_acc: 0.580 ;time: 0:01:59\n",
      "batch: 200 ;B loss: 1.927 ;acc: 0.520 ;iou_acc: 0.640 ;time: 0:02:11\n",
      "batch: 250 ;B loss: 1.899 ;acc: 0.550 ;iou_acc: 0.645 ;time: 0:02:23\n",
      "\n",
      "*BTrain: False ;Test loss: 1.842 ;Test accuracy 0.543 ;IOU accuracy: 0.638 ;Time: 0:02:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 1.756 ;acc: 0.640 ;iou: 0.700 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 1.544 ;acc: 0.700 ;iou: 0.795 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.662 ;acc: 0.655 ;iou: 0.730 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.830 ;acc: 0.610 ;iou: 0.695 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.779 ;acc: 0.630 ;iou: 0.690 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 1.743 ;acc: 0.580 ;iou: 0.690 ;time: 0:00:50\n",
      "\n",
      "*Training B: True ;B Train loss: 1.811 ;Train accuracy: 0.621 ;IOU accuracy: 0.703 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.790 ;acc: 0.550 ;iou_acc: 0.620 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.884 ;acc: 0.535 ;iou_acc: 0.620 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.872 ;acc: 0.515 ;iou_acc: 0.590 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.912 ;acc: 0.530 ;iou_acc: 0.625 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.871 ;acc: 0.525 ;iou_acc: 0.630 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.836 ;acc: 0.565 ;iou_acc: 0.665 ;time: 0:01:44\n",
      "\n",
      "*BTrain: True ;Test loss: 1.785 ;Test accuracy 0.559 ;IOU accuracy: 0.653 ;Time: 0:01:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.647 ;acc: 0.670 ;iou: 0.760 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.790 ;acc: 0.620 ;iou: 0.735 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.866 ;acc: 0.640 ;iou: 0.730 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.823 ;acc: 0.630 ;iou: 0.740 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.855 ;acc: 0.595 ;iou: 0.700 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.717 ;acc: 0.635 ;iou: 0.710 ;time: 0:00:49\n",
      "\n",
      "*Training B: False ;B Train loss: 1.750 ;Train accuracy: 0.643 ;IOU accuracy: 0.721 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.759 ;acc: 0.595 ;iou_acc: 0.655 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.819 ;acc: 0.545 ;iou_acc: 0.640 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.834 ;acc: 0.525 ;iou_acc: 0.625 ;time: 0:01:16\n",
      "batch: 150 ;B loss: 1.823 ;acc: 0.560 ;iou_acc: 0.665 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.831 ;acc: 0.555 ;iou_acc: 0.645 ;time: 0:01:34\n",
      "batch: 250 ;B loss: 1.835 ;acc: 0.545 ;iou_acc: 0.635 ;time: 0:01:43\n",
      "\n",
      "*BTrain: False ;Test loss: 1.742 ;Test accuracy 0.571 ;IOU accuracy: 0.663 ;Time: 0:01:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.804 ;acc: 0.610 ;iou: 0.715 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.641 ;acc: 0.700 ;iou: 0.775 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.584 ;acc: 0.725 ;iou: 0.760 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.584 ;acc: 0.680 ;iou: 0.730 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.783 ;acc: 0.665 ;iou: 0.745 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.558 ;acc: 0.660 ;iou: 0.735 ;time: 0:00:50\n",
      "\n",
      "*Training B: False ;B Train loss: 1.697 ;Train accuracy: 0.664 ;IOU accuracy: 0.741 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.724 ;acc: 0.580 ;iou_acc: 0.650 ;time: 0:01:00\n",
      "batch: 50 ;B loss: 1.757 ;acc: 0.555 ;iou_acc: 0.630 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.777 ;acc: 0.550 ;iou_acc: 0.650 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.770 ;acc: 0.590 ;iou_acc: 0.675 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.791 ;acc: 0.565 ;iou_acc: 0.650 ;time: 0:01:36\n",
      "batch: 250 ;B loss: 1.751 ;acc: 0.580 ;iou_acc: 0.675 ;time: 0:01:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.695 ;Test accuracy 0.587 ;IOU accuracy: 0.679 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.520 ;acc: 0.760 ;iou: 0.815 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.761 ;acc: 0.650 ;iou: 0.745 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.672 ;acc: 0.705 ;iou: 0.770 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.754 ;acc: 0.695 ;iou: 0.730 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.640 ;acc: 0.695 ;iou: 0.780 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.554 ;acc: 0.730 ;iou: 0.790 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.644 ;Train accuracy: 0.686 ;IOU accuracy: 0.761 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.659 ;acc: 0.585 ;iou_acc: 0.660 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.721 ;acc: 0.595 ;iou_acc: 0.675 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.711 ;acc: 0.580 ;iou_acc: 0.670 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.739 ;acc: 0.595 ;iou_acc: 0.695 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.762 ;acc: 0.590 ;iou_acc: 0.680 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.683 ;acc: 0.625 ;iou_acc: 0.720 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.653 ;Test accuracy 0.603 ;IOU accuracy: 0.695 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.506 ;acc: 0.755 ;iou: 0.805 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.735 ;acc: 0.695 ;iou: 0.775 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.416 ;acc: 0.780 ;iou: 0.840 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.510 ;acc: 0.715 ;iou: 0.775 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.758 ;acc: 0.685 ;iou: 0.770 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.524 ;acc: 0.725 ;iou: 0.825 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.585 ;Train accuracy: 0.714 ;IOU accuracy: 0.786 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.583 ;acc: 0.610 ;iou_acc: 0.700 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.624 ;acc: 0.630 ;iou_acc: 0.710 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.702 ;acc: 0.580 ;iou_acc: 0.650 ;time: 0:01:26\n",
      "batch: 150 ;B loss: 1.678 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:01:36\n",
      "batch: 200 ;B loss: 1.706 ;acc: 0.590 ;iou_acc: 0.705 ;time: 0:01:46\n",
      "batch: 250 ;B loss: 1.668 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.602 ;Test accuracy 0.620 ;IOU accuracy: 0.713 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.744 ;acc: 0.660 ;iou: 0.785 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.846 ;acc: 0.690 ;iou: 0.790 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.559 ;acc: 0.715 ;iou: 0.795 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.738 ;acc: 0.735 ;iou: 0.800 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.524 ;acc: 0.740 ;iou: 0.830 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.589 ;acc: 0.735 ;iou: 0.785 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.533 ;Train accuracy: 0.739 ;IOU accuracy: 0.810 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.620 ;acc: 0.620 ;iou_acc: 0.725 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.598 ;acc: 0.610 ;iou_acc: 0.700 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.681 ;acc: 0.590 ;iou_acc: 0.695 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.601 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.668 ;acc: 0.585 ;iou_acc: 0.700 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.589 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.553 ;Test accuracy 0.638 ;IOU accuracy: 0.732 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.427 ;acc: 0.745 ;iou: 0.840 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 1.491 ;acc: 0.725 ;iou: 0.845 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.365 ;acc: 0.795 ;iou: 0.845 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.607 ;acc: 0.715 ;iou: 0.785 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.402 ;acc: 0.760 ;iou: 0.830 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 1.482 ;acc: 0.785 ;iou: 0.835 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.471 ;Train accuracy: 0.759 ;IOU accuracy: 0.828 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.527 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.550 ;acc: 0.615 ;iou_acc: 0.705 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.572 ;acc: 0.605 ;iou_acc: 0.690 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.563 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.620 ;acc: 0.615 ;iou_acc: 0.725 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.547 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.505 ;Test accuracy 0.652 ;IOU accuracy: 0.745 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.437 ;acc: 0.795 ;iou: 0.855 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.383 ;acc: 0.800 ;iou: 0.855 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.520 ;acc: 0.790 ;iou: 0.855 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 1.439 ;acc: 0.765 ;iou: 0.830 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.223 ;acc: 0.780 ;iou: 0.855 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 1.371 ;acc: 0.775 ;iou: 0.865 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.427 ;Train accuracy: 0.774 ;IOU accuracy: 0.841 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.485 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.453 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.582 ;acc: 0.625 ;iou_acc: 0.700 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.505 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.526 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.587 ;acc: 0.630 ;iou_acc: 0.735 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.456 ;Test accuracy 0.665 ;IOU accuracy: 0.758 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 1.286 ;acc: 0.805 ;iou: 0.880 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.473 ;acc: 0.785 ;iou: 0.850 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 1.430 ;acc: 0.760 ;iou: 0.845 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 1.495 ;acc: 0.795 ;iou: 0.840 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.346 ;acc: 0.790 ;iou: 0.850 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.567 ;acc: 0.760 ;iou: 0.855 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.381 ;Train accuracy: 0.789 ;IOU accuracy: 0.854 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.496 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.470 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.546 ;acc: 0.625 ;iou_acc: 0.710 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.473 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.513 ;acc: 0.655 ;iou_acc: 0.790 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.536 ;acc: 0.635 ;iou_acc: 0.725 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.425 ;Test accuracy 0.673 ;IOU accuracy: 0.766 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 1.397 ;acc: 0.775 ;iou: 0.845 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 1.350 ;acc: 0.805 ;iou: 0.870 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 1.205 ;acc: 0.805 ;iou: 0.870 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 1.319 ;acc: 0.810 ;iou: 0.860 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.162 ;acc: 0.865 ;iou: 0.925 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 1.302 ;acc: 0.780 ;iou: 0.845 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.347 ;Train accuracy: 0.800 ;IOU accuracy: 0.862 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.447 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.428 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.471 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.449 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.451 ;acc: 0.650 ;iou_acc: 0.785 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.536 ;acc: 0.635 ;iou_acc: 0.730 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.406 ;Test accuracy 0.677 ;IOU accuracy: 0.770 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 1.170 ;acc: 0.850 ;iou: 0.895 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 1.390 ;acc: 0.790 ;iou: 0.875 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 1.225 ;acc: 0.825 ;iou: 0.885 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 1.311 ;acc: 0.815 ;iou: 0.865 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 1.487 ;acc: 0.765 ;iou: 0.845 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 1.330 ;acc: 0.800 ;iou: 0.845 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.320 ;Train accuracy: 0.807 ;IOU accuracy: 0.868 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.391 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.439 ;acc: 0.650 ;iou_acc: 0.740 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.471 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.430 ;acc: 0.720 ;iou_acc: 0.775 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.472 ;acc: 0.655 ;iou_acc: 0.775 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.537 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.388 ;Test accuracy 0.683 ;IOU accuracy: 0.774 ;Time: 0:02:05\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 1.181 ;acc: 0.865 ;iou: 0.885 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 1.239 ;acc: 0.820 ;iou: 0.895 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 1.220 ;acc: 0.830 ;iou: 0.895 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 1.310 ;acc: 0.825 ;iou: 0.895 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 1.265 ;acc: 0.805 ;iou: 0.860 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 1.268 ;acc: 0.820 ;iou: 0.875 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.284 ;Train accuracy: 0.817 ;IOU accuracy: 0.876 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.408 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.381 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.450 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.466 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.463 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.501 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:01:56\n",
      "\n",
      "*BTrain: False ;Test loss: 1.366 ;Test accuracy 0.688 ;IOU accuracy: 0.779 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 1.141 ;acc: 0.870 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 1.352 ;acc: 0.775 ;iou: 0.865 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 1.229 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 1.239 ;acc: 0.850 ;iou: 0.895 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 1.178 ;acc: 0.850 ;iou: 0.895 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 1.195 ;acc: 0.835 ;iou: 0.875 ;time: 0:00:56\n",
      "\n",
      "*Training B: True ;B Train loss: 1.256 ;Train accuracy: 0.826 ;IOU accuracy: 0.882 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.354 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.399 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.434 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:27\n",
      "batch: 150 ;B loss: 1.481 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:37\n",
      "batch: 200 ;B loss: 1.444 ;acc: 0.660 ;iou_acc: 0.785 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 1.561 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:57\n",
      "\n",
      "*BTrain: True ;Test loss: 1.362 ;Test accuracy 0.689 ;IOU accuracy: 0.779 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 1.218 ;acc: 0.840 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 1.213 ;acc: 0.835 ;iou: 0.905 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 1.199 ;acc: 0.840 ;iou: 0.910 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 1.361 ;acc: 0.850 ;iou: 0.875 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 1.134 ;acc: 0.835 ;iou: 0.915 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 1.285 ;acc: 0.810 ;iou: 0.855 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.230 ;Train accuracy: 0.832 ;IOU accuracy: 0.887 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.333 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.335 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.434 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.432 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.378 ;acc: 0.655 ;iou_acc: 0.790 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.532 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.339 ;Test accuracy 0.694 ;IOU accuracy: 0.785 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 1.178 ;acc: 0.860 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 1.344 ;acc: 0.820 ;iou: 0.860 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 1.130 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 1.075 ;acc: 0.870 ;iou: 0.895 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 1.120 ;acc: 0.850 ;iou: 0.870 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 1.387 ;acc: 0.795 ;iou: 0.855 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 1.206 ;Train accuracy: 0.840 ;IOU accuracy: 0.893 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.389 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.310 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.426 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.462 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.382 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.534 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.339 ;Test accuracy 0.693 ;IOU accuracy: 0.783 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 1.282 ;acc: 0.870 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 1.238 ;acc: 0.850 ;iou: 0.875 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 1.059 ;acc: 0.840 ;iou: 0.905 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 1.244 ;acc: 0.850 ;iou: 0.905 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 1.208 ;acc: 0.835 ;iou: 0.900 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 1.239 ;acc: 0.850 ;iou: 0.905 ;time: 0:00:51\n",
      "\n",
      "*Training B: True ;B Train loss: 1.183 ;Train accuracy: 0.845 ;IOU accuracy: 0.897 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.305 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.322 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.399 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.410 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.376 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.508 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 1.322 ;Test accuracy 0.700 ;IOU accuracy: 0.790 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 1.107 ;acc: 0.840 ;iou: 0.875 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 1.191 ;acc: 0.810 ;iou: 0.915 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 1.194 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 1.041 ;acc: 0.860 ;iou: 0.915 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 1.070 ;acc: 0.860 ;iou: 0.910 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 1.098 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.161 ;Train accuracy: 0.853 ;IOU accuracy: 0.902 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.348 ;acc: 0.685 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.309 ;acc: 0.730 ;iou_acc: 0.790 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.420 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.372 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.369 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.476 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.314 ;Test accuracy 0.701 ;IOU accuracy: 0.791 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 1.109 ;acc: 0.850 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 1.092 ;acc: 0.880 ;iou: 0.905 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 1.024 ;acc: 0.875 ;iou: 0.930 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 1.057 ;acc: 0.880 ;iou: 0.945 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 1.300 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 1.189 ;acc: 0.850 ;iou: 0.915 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.142 ;Train accuracy: 0.857 ;IOU accuracy: 0.906 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.326 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.305 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.400 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.380 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.337 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.451 ;acc: 0.650 ;iou_acc: 0.740 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.310 ;Test accuracy 0.703 ;IOU accuracy: 0.792 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 1.040 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 1.219 ;acc: 0.860 ;iou: 0.900 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 1.166 ;acc: 0.865 ;iou: 0.925 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 0.938 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 1.085 ;acc: 0.870 ;iou: 0.925 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 1.105 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.115 ;Train accuracy: 0.864 ;IOU accuracy: 0.910 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.283 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.289 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.407 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.405 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.325 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.528 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.304 ;Test accuracy 0.706 ;IOU accuracy: 0.795 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 1.140 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 0.930 ;acc: 0.865 ;iou: 0.915 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 1.108 ;acc: 0.865 ;iou: 0.915 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 1.029 ;acc: 0.870 ;iou: 0.890 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 1.061 ;acc: 0.850 ;iou: 0.905 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 1.085 ;acc: 0.835 ;iou: 0.900 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.095 ;Train accuracy: 0.869 ;IOU accuracy: 0.915 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.297 ;acc: 0.730 ;iou_acc: 0.835 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.220 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.366 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.395 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.344 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.512 ;acc: 0.650 ;iou_acc: 0.740 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.297 ;Test accuracy 0.707 ;IOU accuracy: 0.796 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 1.114 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 1.050 ;acc: 0.885 ;iou: 0.935 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 1.215 ;acc: 0.850 ;iou: 0.880 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 0.997 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 1.043 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 1.035 ;acc: 0.870 ;iou: 0.920 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 1.077 ;Train accuracy: 0.874 ;IOU accuracy: 0.917 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.284 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.290 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.351 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:23\n",
      "batch: 150 ;B loss: 1.364 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 1.371 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.512 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:01:52\n",
      "\n",
      "*BTrain: False ;Test loss: 1.295 ;Test accuracy 0.709 ;IOU accuracy: 0.796 ;Time: 0:02:01\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 1.354 ;acc: 0.870 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 1.031 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 0.928 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 1.034 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 0.970 ;acc: 0.895 ;iou: 0.960 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 1.067 ;acc: 0.845 ;iou: 0.885 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.061 ;Train accuracy: 0.878 ;IOU accuracy: 0.921 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.284 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.215 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.358 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.382 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.311 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.488 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.294 ;Test accuracy 0.711 ;IOU accuracy: 0.798 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 1.137 ;acc: 0.885 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 1.083 ;acc: 0.835 ;iou: 0.890 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 1.095 ;acc: 0.855 ;iou: 0.925 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 0.970 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 1.007 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 1.229 ;acc: 0.830 ;iou: 0.890 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.048 ;Train accuracy: 0.883 ;IOU accuracy: 0.925 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.252 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.229 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.357 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.403 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.329 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.466 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.286 ;Test accuracy 0.713 ;IOU accuracy: 0.800 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 0.988 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 1.039 ;acc: 0.870 ;iou: 0.915 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 1.055 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 0.961 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 1.000 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 1.014 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.029 ;Train accuracy: 0.888 ;IOU accuracy: 0.927 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.201 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.262 ;acc: 0.735 ;iou_acc: 0.800 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.380 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.352 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.354 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.507 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.286 ;Test accuracy 0.714 ;IOU accuracy: 0.801 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 0.729 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 1.022 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 0.885 ;acc: 0.920 ;iou: 0.945 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 0.892 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 1.013 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 1.025 ;acc: 0.870 ;iou: 0.920 ;time: 0:00:51\n",
      "\n",
      "*Training B: True ;B Train loss: 1.004 ;Train accuracy: 0.892 ;IOU accuracy: 0.931 ;Time: 0:00:59 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.191 ;acc: 0.745 ;iou_acc: 0.825 ;time: 0:00:59\n",
      "batch: 50 ;B loss: 1.206 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:08\n",
      "batch: 100 ;B loss: 1.348 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:17\n",
      "batch: 150 ;B loss: 1.370 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:26\n",
      "batch: 200 ;B loss: 1.304 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:35\n",
      "batch: 250 ;B loss: 1.466 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:01:44\n",
      "\n",
      "*BTrain: True ;Test loss: 1.279 ;Test accuracy 0.716 ;IOU accuracy: 0.801 ;Time: 0:01:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 1.006 ;acc: 0.900 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 0.952 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 1.050 ;acc: 0.905 ;iou: 0.930 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 1.097 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 1.055 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 0.944 ;acc: 0.895 ;iou: 0.945 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.995 ;Train accuracy: 0.897 ;IOU accuracy: 0.934 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.227 ;acc: 0.735 ;iou_acc: 0.810 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.246 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:09\n",
      "batch: 100 ;B loss: 1.353 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:18\n",
      "batch: 150 ;B loss: 1.335 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:27\n",
      "batch: 200 ;B loss: 1.338 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.464 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:45\n",
      "\n",
      "*BTrain: False ;Test loss: 1.284 ;Test accuracy 0.714 ;IOU accuracy: 0.801 ;Time: 0:01:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 0.921 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 0.928 ;acc: 0.905 ;iou: 0.950 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 0.903 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 1.165 ;acc: 0.850 ;iou: 0.910 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 1.034 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 0.960 ;acc: 0.935 ;iou: 0.955 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 0.971 ;Train accuracy: 0.902 ;IOU accuracy: 0.938 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.230 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.222 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.332 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.371 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.335 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.474 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.269 ;Test accuracy 0.718 ;IOU accuracy: 0.803 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 0.897 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.925 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 0.845 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 0.998 ;acc: 0.915 ;iou: 0.960 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 1.030 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 0.893 ;acc: 0.890 ;iou: 0.935 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.961 ;Train accuracy: 0.905 ;IOU accuracy: 0.941 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.242 ;acc: 0.735 ;iou_acc: 0.820 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.201 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.372 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.369 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.320 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.530 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.278 ;Test accuracy 0.720 ;IOU accuracy: 0.805 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 0.776 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 0.828 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 0.868 ;acc: 0.930 ;iou: 0.975 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 0.797 ;acc: 0.945 ;iou: 0.955 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 0.830 ;acc: 0.930 ;iou: 0.975 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 0.903 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 0.945 ;Train accuracy: 0.908 ;IOU accuracy: 0.943 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.260 ;acc: 0.745 ;iou_acc: 0.810 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.220 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.402 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.358 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.349 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.518 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.281 ;Test accuracy 0.718 ;IOU accuracy: 0.803 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 0.846 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 0.911 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 0.881 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 0.734 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 1.032 ;acc: 0.900 ;iou: 0.920 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 0.919 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 0.928 ;Train accuracy: 0.911 ;IOU accuracy: 0.944 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.177 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.251 ;acc: 0.740 ;iou_acc: 0.810 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.376 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.362 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.357 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.547 ;acc: 0.655 ;iou_acc: 0.725 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.276 ;Test accuracy 0.718 ;IOU accuracy: 0.803 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 0.809 ;acc: 0.930 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 0.945 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 0.728 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 0.815 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.932 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 1.083 ;acc: 0.900 ;iou: 0.945 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 0.916 ;Train accuracy: 0.916 ;IOU accuracy: 0.948 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.158 ;acc: 0.750 ;iou_acc: 0.805 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.228 ;acc: 0.750 ;iou_acc: 0.820 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.398 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.384 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.346 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.564 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.287 ;Test accuracy 0.718 ;IOU accuracy: 0.804 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 0.809 ;acc: 0.920 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 0.788 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 0.861 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 1.021 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 0.794 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.919 ;acc: 0.925 ;iou: 0.965 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.894 ;Train accuracy: 0.918 ;IOU accuracy: 0.949 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.214 ;acc: 0.740 ;iou_acc: 0.815 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.219 ;acc: 0.760 ;iou_acc: 0.825 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.330 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.338 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 1.347 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.519 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.279 ;Test accuracy 0.722 ;IOU accuracy: 0.805 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 0.876 ;acc: 0.915 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 0.831 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 1.026 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 1.001 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 0.908 ;acc: 0.890 ;iou: 0.920 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 0.872 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.885 ;Train accuracy: 0.922 ;IOU accuracy: 0.952 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.191 ;acc: 0.745 ;iou_acc: 0.830 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.260 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.391 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:23\n",
      "batch: 150 ;B loss: 1.352 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 1.310 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.550 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:52\n",
      "\n",
      "*BTrain: False ;Test loss: 1.276 ;Test accuracy 0.722 ;IOU accuracy: 0.806 ;Time: 0:02:01\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 0.896 ;acc: 0.860 ;iou: 0.925 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 0.930 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 0.800 ;acc: 0.915 ;iou: 0.945 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 0.789 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 0.952 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 0.903 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 0.872 ;Train accuracy: 0.924 ;IOU accuracy: 0.954 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.156 ;acc: 0.745 ;iou_acc: 0.820 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.251 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.350 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.329 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.354 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.581 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.279 ;Test accuracy 0.723 ;IOU accuracy: 0.807 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 0.885 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 0.788 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 0.769 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 0.846 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 0.891 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 0.861 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.853 ;Train accuracy: 0.929 ;IOU accuracy: 0.957 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.310 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.231 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.351 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.378 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 1.338 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.541 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.291 ;Test accuracy 0.722 ;IOU accuracy: 0.807 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 0.828 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.635 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 0.889 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 0.948 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 0.732 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.956 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 0.847 ;Train accuracy: 0.930 ;IOU accuracy: 0.958 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.230 ;acc: 0.735 ;iou_acc: 0.795 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.220 ;acc: 0.730 ;iou_acc: 0.810 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.370 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.341 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.351 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.527 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.291 ;Test accuracy 0.722 ;IOU accuracy: 0.808 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 0.891 ;acc: 0.940 ;iou: 0.980 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 0.604 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 0.932 ;acc: 0.860 ;iou: 0.905 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 0.632 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 0.971 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 0.808 ;acc: 0.940 ;iou: 0.950 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 0.833 ;Train accuracy: 0.933 ;IOU accuracy: 0.959 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.188 ;acc: 0.755 ;iou_acc: 0.820 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.243 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.288 ;acc: 0.705 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.388 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.282 ;acc: 0.725 ;iou_acc: 0.835 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.542 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.283 ;Test accuracy 0.726 ;IOU accuracy: 0.810 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 0.687 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 0.842 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.829 ;acc: 0.925 ;iou: 0.955 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 0.806 ;acc: 0.930 ;iou: 0.970 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 0.759 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 0.779 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.819 ;Train accuracy: 0.936 ;IOU accuracy: 0.961 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.241 ;acc: 0.735 ;iou_acc: 0.800 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.254 ;acc: 0.760 ;iou_acc: 0.825 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 1.310 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 1.303 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.306 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.578 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.287 ;Test accuracy 0.724 ;IOU accuracy: 0.808 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.813 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 0.759 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.728 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 0.821 ;acc: 0.935 ;iou: 0.945 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 0.941 ;acc: 0.905 ;iou: 0.955 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 0.791 ;acc: 0.925 ;iou: 0.945 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 0.810 ;Train accuracy: 0.939 ;IOU accuracy: 0.963 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.155 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.257 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.370 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.346 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.372 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.578 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.291 ;Test accuracy 0.724 ;IOU accuracy: 0.807 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.787 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.653 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 0.692 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 0.744 ;acc: 0.935 ;iou: 0.950 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 0.855 ;acc: 0.920 ;iou: 0.965 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 0.907 ;acc: 0.905 ;iou: 0.960 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.801 ;Train accuracy: 0.941 ;IOU accuracy: 0.965 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.182 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.294 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.360 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.388 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 1.362 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.601 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.289 ;Test accuracy 0.723 ;IOU accuracy: 0.807 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.800 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 0.809 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.806 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 0.643 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 0.771 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 0.817 ;acc: 0.945 ;iou: 0.975 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.784 ;Train accuracy: 0.943 ;IOU accuracy: 0.966 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.174 ;acc: 0.750 ;iou_acc: 0.820 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.254 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.315 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.389 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.367 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.655 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.308 ;Test accuracy 0.724 ;IOU accuracy: 0.808 ;Time: 0:02:01\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.661 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 0.840 ;acc: 0.930 ;iou: 0.960 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.847 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 0.740 ;acc: 0.960 ;iou: 0.960 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.647 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 0.827 ;acc: 0.910 ;iou: 0.960 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 0.775 ;Train accuracy: 0.946 ;IOU accuracy: 0.968 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.188 ;acc: 0.755 ;iou_acc: 0.830 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.313 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.313 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.322 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.332 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.649 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.309 ;Test accuracy 0.724 ;IOU accuracy: 0.807 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.900 ;acc: 0.935 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 0.841 ;acc: 0.920 ;iou: 0.960 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 0.664 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 0.799 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 0.806 ;acc: 0.940 ;iou: 0.980 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 0.707 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.758 ;Train accuracy: 0.948 ;IOU accuracy: 0.969 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.176 ;acc: 0.740 ;iou_acc: 0.805 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.214 ;acc: 0.765 ;iou_acc: 0.830 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.369 ;acc: 0.745 ;iou_acc: 0.805 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.349 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.330 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.668 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.313 ;Test accuracy 0.724 ;IOU accuracy: 0.807 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 0.594 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.774 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 0.863 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 0.739 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 0.732 ;acc: 0.965 ;iou: 0.990 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 0.712 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.749 ;Train accuracy: 0.950 ;IOU accuracy: 0.971 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.147 ;acc: 0.760 ;iou_acc: 0.835 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.253 ;acc: 0.755 ;iou_acc: 0.815 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.387 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.370 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.363 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.662 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.315 ;Test accuracy 0.724 ;IOU accuracy: 0.808 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 50 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14851 ;lr: 0.0495 ;B loss: 0.658 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14901 ;lr: 0.0495 ;B loss: 0.855 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14951 ;lr: 0.0495 ;B loss: 0.590 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15001 ;lr: 0.0495 ;B loss: 0.761 ;acc: 0.950 ;iou: 0.975 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15051 ;lr: 0.0495 ;B loss: 0.645 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15101 ;lr: 0.0495 ;B loss: 0.952 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.743 ;Train accuracy: 0.952 ;IOU accuracy: 0.972 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 50\n",
      "batch: 0 ;B loss: 1.225 ;acc: 0.755 ;iou_acc: 0.815 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.268 ;acc: 0.760 ;iou_acc: 0.830 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.326 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.325 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.360 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.626 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.315 ;Test accuracy 0.726 ;IOU accuracy: 0.808 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 51 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15148 ;lr: 0.0495 ;B loss: 0.711 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15198 ;lr: 0.0495 ;B loss: 0.638 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15248 ;lr: 0.0495 ;B loss: 0.861 ;acc: 0.955 ;iou: 0.970 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15298 ;lr: 0.0495 ;B loss: 1.051 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15348 ;lr: 0.0495 ;B loss: 0.719 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15398 ;lr: 0.0495 ;B loss: 0.685 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.732 ;Train accuracy: 0.954 ;IOU accuracy: 0.972 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 51\n",
      "batch: 0 ;B loss: 1.228 ;acc: 0.755 ;iou_acc: 0.810 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.313 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.414 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.352 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.362 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.634 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 1.354 ;Test accuracy 0.720 ;IOU accuracy: 0.804 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 52 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15445 ;lr: 0.0495 ;B loss: 0.793 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15495 ;lr: 0.0495 ;B loss: 0.694 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15545 ;lr: 0.0495 ;B loss: 0.765 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15595 ;lr: 0.0495 ;B loss: 0.722 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15645 ;lr: 0.0495 ;B loss: 0.838 ;acc: 0.950 ;iou: 0.970 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15695 ;lr: 0.0495 ;B loss: 0.689 ;acc: 0.950 ;iou: 0.985 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.718 ;Train accuracy: 0.956 ;IOU accuracy: 0.974 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 52\n",
      "batch: 0 ;B loss: 1.188 ;acc: 0.740 ;iou_acc: 0.810 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.348 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.354 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.438 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.412 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.669 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.333 ;Test accuracy 0.722 ;IOU accuracy: 0.806 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 53 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15742 ;lr: 0.0495 ;B loss: 0.713 ;acc: 0.955 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15792 ;lr: 0.0495 ;B loss: 0.660 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15842 ;lr: 0.0495 ;B loss: 0.505 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15892 ;lr: 0.0495 ;B loss: 0.586 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15942 ;lr: 0.0495 ;B loss: 0.653 ;acc: 0.965 ;iou: 0.990 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15992 ;lr: 0.0495 ;B loss: 0.741 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.714 ;Train accuracy: 0.958 ;IOU accuracy: 0.976 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 53\n",
      "batch: 0 ;B loss: 1.203 ;acc: 0.750 ;iou_acc: 0.815 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.359 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.407 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.380 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.377 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.649 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.345 ;Test accuracy 0.723 ;IOU accuracy: 0.807 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 54 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16039 ;lr: 0.0495 ;B loss: 0.652 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16089 ;lr: 0.0495 ;B loss: 0.611 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16139 ;lr: 0.0495 ;B loss: 0.622 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16189 ;lr: 0.0495 ;B loss: 0.781 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16239 ;lr: 0.0495 ;B loss: 0.710 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16289 ;lr: 0.0495 ;B loss: 0.692 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:50\n",
      "\n",
      "*Training B: True ;B Train loss: 0.696 ;Train accuracy: 0.960 ;IOU accuracy: 0.977 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 54\n",
      "batch: 0 ;B loss: 1.166 ;acc: 0.755 ;iou_acc: 0.820 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.272 ;acc: 0.760 ;iou_acc: 0.830 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 1.390 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 1.366 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.352 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.608 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:46\n",
      "\n",
      "*BTrain: True ;Test loss: 1.331 ;Test accuracy 0.724 ;IOU accuracy: 0.809 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 55 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16336 ;lr: 0.0495 ;B loss: 0.701 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16386 ;lr: 0.0495 ;B loss: 0.567 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16436 ;lr: 0.0495 ;B loss: 0.698 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16486 ;lr: 0.0495 ;B loss: 0.599 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16536 ;lr: 0.0495 ;B loss: 0.664 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16586 ;lr: 0.0495 ;B loss: 0.593 ;acc: 0.935 ;iou: 0.965 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.690 ;Train accuracy: 0.961 ;IOU accuracy: 0.978 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 55\n",
      "batch: 0 ;B loss: 1.184 ;acc: 0.730 ;iou_acc: 0.785 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.347 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.397 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.363 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.376 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.641 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.345 ;Test accuracy 0.725 ;IOU accuracy: 0.809 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 56 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16633 ;lr: 0.0495 ;B loss: 0.767 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16683 ;lr: 0.0495 ;B loss: 0.527 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16733 ;lr: 0.0495 ;B loss: 0.558 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16783 ;lr: 0.0495 ;B loss: 0.718 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16833 ;lr: 0.0495 ;B loss: 0.562 ;acc: 0.985 ;iou: 0.985 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16883 ;lr: 0.0495 ;B loss: 0.637 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.687 ;Train accuracy: 0.963 ;IOU accuracy: 0.978 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 56\n",
      "batch: 0 ;B loss: 1.153 ;acc: 0.755 ;iou_acc: 0.830 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.341 ;acc: 0.745 ;iou_acc: 0.815 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.408 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.385 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.385 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.684 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.352 ;Test accuracy 0.722 ;IOU accuracy: 0.807 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 57 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16930 ;lr: 0.0495 ;B loss: 0.741 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16980 ;lr: 0.0495 ;B loss: 0.709 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17030 ;lr: 0.0495 ;B loss: 0.557 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17080 ;lr: 0.0495 ;B loss: 0.635 ;acc: 0.955 ;iou: 0.980 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17130 ;lr: 0.0495 ;B loss: 0.811 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17180 ;lr: 0.0495 ;B loss: 0.622 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.677 ;Train accuracy: 0.964 ;IOU accuracy: 0.979 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 57\n",
      "batch: 0 ;B loss: 1.143 ;acc: 0.775 ;iou_acc: 0.840 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.367 ;acc: 0.740 ;iou_acc: 0.825 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.395 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.438 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.373 ;acc: 0.735 ;iou_acc: 0.825 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.666 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.353 ;Test accuracy 0.725 ;IOU accuracy: 0.809 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 58 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17227 ;lr: 0.0495 ;B loss: 0.709 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17277 ;lr: 0.0495 ;B loss: 0.566 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17327 ;lr: 0.0495 ;B loss: 0.633 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17377 ;lr: 0.0495 ;B loss: 0.719 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17427 ;lr: 0.0495 ;B loss: 0.746 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17477 ;lr: 0.0495 ;B loss: 0.839 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.661 ;Train accuracy: 0.965 ;IOU accuracy: 0.980 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 58\n",
      "batch: 0 ;B loss: 1.148 ;acc: 0.750 ;iou_acc: 0.820 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.370 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.365 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.408 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.400 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.680 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.348 ;Test accuracy 0.725 ;IOU accuracy: 0.808 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 59 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17524 ;lr: 0.0495 ;B loss: 0.615 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17574 ;lr: 0.0495 ;B loss: 0.686 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17624 ;lr: 0.0495 ;B loss: 0.675 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17674 ;lr: 0.0495 ;B loss: 0.591 ;acc: 0.960 ;iou: 0.975 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17724 ;lr: 0.0495 ;B loss: 0.501 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17774 ;lr: 0.0495 ;B loss: 0.498 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.651 ;Train accuracy: 0.968 ;IOU accuracy: 0.981 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 59\n",
      "batch: 0 ;B loss: 1.184 ;acc: 0.750 ;iou_acc: 0.825 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.331 ;acc: 0.735 ;iou_acc: 0.810 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 1.398 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.482 ;acc: 0.705 ;iou_acc: 0.815 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.415 ;acc: 0.715 ;iou_acc: 0.825 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.694 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.355 ;Test accuracy 0.726 ;IOU accuracy: 0.809 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 60 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17821 ;lr: 0.0495 ;B loss: 0.588 ;acc: 0.960 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17871 ;lr: 0.0495 ;B loss: 0.670 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17921 ;lr: 0.0495 ;B loss: 0.733 ;acc: 0.955 ;iou: 0.975 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17971 ;lr: 0.0495 ;B loss: 0.668 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18021 ;lr: 0.0495 ;B loss: 0.622 ;acc: 0.965 ;iou: 0.980 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18071 ;lr: 0.0495 ;B loss: 0.666 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.640 ;Train accuracy: 0.968 ;IOU accuracy: 0.981 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 60\n",
      "batch: 0 ;B loss: 1.206 ;acc: 0.745 ;iou_acc: 0.815 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.375 ;acc: 0.745 ;iou_acc: 0.820 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.435 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.418 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.399 ;acc: 0.730 ;iou_acc: 0.825 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.728 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 1.373 ;Test accuracy 0.724 ;IOU accuracy: 0.808 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 61 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18118 ;lr: 0.0495 ;B loss: 0.534 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18168 ;lr: 0.0495 ;B loss: 0.735 ;acc: 0.970 ;iou: 0.975 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18218 ;lr: 0.0495 ;B loss: 0.677 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18268 ;lr: 0.0495 ;B loss: 0.757 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18318 ;lr: 0.0495 ;B loss: 0.575 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18368 ;lr: 0.0495 ;B loss: 0.583 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.634 ;Train accuracy: 0.970 ;IOU accuracy: 0.983 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 61\n",
      "batch: 0 ;B loss: 1.165 ;acc: 0.760 ;iou_acc: 0.820 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.416 ;acc: 0.740 ;iou_acc: 0.830 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 1.338 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.459 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.455 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.763 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.354 ;Test accuracy 0.727 ;IOU accuracy: 0.810 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 62 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18415 ;lr: 0.0495 ;B loss: 0.600 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18465 ;lr: 0.0495 ;B loss: 0.591 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18515 ;lr: 0.0495 ;B loss: 0.551 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18565 ;lr: 0.0495 ;B loss: 0.446 ;acc: 0.980 ;iou: 0.990 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18615 ;lr: 0.0495 ;B loss: 0.585 ;acc: 0.975 ;iou: 0.995 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18665 ;lr: 0.0495 ;B loss: 0.718 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.634 ;Train accuracy: 0.970 ;IOU accuracy: 0.983 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 62\n",
      "batch: 0 ;B loss: 1.211 ;acc: 0.745 ;iou_acc: 0.810 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.421 ;acc: 0.750 ;iou_acc: 0.815 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.386 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.438 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.429 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.720 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.374 ;Test accuracy 0.725 ;IOU accuracy: 0.807 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 63 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18712 ;lr: 0.0495 ;B loss: 0.492 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18762 ;lr: 0.0495 ;B loss: 0.589 ;acc: 0.975 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18812 ;lr: 0.0495 ;B loss: 0.511 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18862 ;lr: 0.0495 ;B loss: 0.646 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18912 ;lr: 0.0495 ;B loss: 0.628 ;acc: 0.965 ;iou: 0.975 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18962 ;lr: 0.0495 ;B loss: 0.600 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.617 ;Train accuracy: 0.971 ;IOU accuracy: 0.983 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 63\n",
      "batch: 0 ;B loss: 1.307 ;acc: 0.755 ;iou_acc: 0.795 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.376 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.396 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.448 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.419 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.777 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:47\n",
      "\n",
      "*BTrain: True ;Test loss: 1.384 ;Test accuracy 0.726 ;IOU accuracy: 0.809 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 64 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19009 ;lr: 0.0495 ;B loss: 0.553 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19059 ;lr: 0.0495 ;B loss: 0.523 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19109 ;lr: 0.0495 ;B loss: 0.616 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19159 ;lr: 0.0495 ;B loss: 0.489 ;acc: 0.965 ;iou: 0.985 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19209 ;lr: 0.0495 ;B loss: 0.661 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19259 ;lr: 0.0495 ;B loss: 0.808 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.613 ;Train accuracy: 0.973 ;IOU accuracy: 0.985 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 64\n",
      "batch: 0 ;B loss: 1.194 ;acc: 0.755 ;iou_acc: 0.815 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.403 ;acc: 0.750 ;iou_acc: 0.820 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.396 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.450 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.364 ;acc: 0.750 ;iou_acc: 0.825 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.678 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.379 ;Test accuracy 0.725 ;IOU accuracy: 0.808 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 65 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19306 ;lr: 0.0495 ;B loss: 0.439 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19356 ;lr: 0.0495 ;B loss: 0.427 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19406 ;lr: 0.0495 ;B loss: 0.527 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19456 ;lr: 0.0495 ;B loss: 0.574 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19506 ;lr: 0.0495 ;B loss: 0.745 ;acc: 0.955 ;iou: 0.965 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19556 ;lr: 0.0495 ;B loss: 0.643 ;acc: 0.960 ;iou: 0.980 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 0.604 ;Train accuracy: 0.974 ;IOU accuracy: 0.985 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 65\n",
      "batch: 0 ;B loss: 1.253 ;acc: 0.745 ;iou_acc: 0.800 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.383 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.358 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.502 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.433 ;acc: 0.730 ;iou_acc: 0.810 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.696 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.394 ;Test accuracy 0.723 ;IOU accuracy: 0.806 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 66 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19603 ;lr: 0.0495 ;B loss: 0.453 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19653 ;lr: 0.0495 ;B loss: 0.696 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19703 ;lr: 0.0495 ;B loss: 0.695 ;acc: 0.960 ;iou: 0.985 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19753 ;lr: 0.0495 ;B loss: 0.570 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19803 ;lr: 0.0495 ;B loss: 0.432 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19853 ;lr: 0.0495 ;B loss: 0.561 ;acc: 0.985 ;iou: 0.990 ;time: 0:00:51\n",
      "\n",
      "*Training B: True ;B Train loss: 0.588 ;Train accuracy: 0.976 ;IOU accuracy: 0.987 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 66\n",
      "batch: 0 ;B loss: 1.281 ;acc: 0.755 ;iou_acc: 0.805 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.409 ;acc: 0.740 ;iou_acc: 0.815 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.401 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.479 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.473 ;acc: 0.735 ;iou_acc: 0.825 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.716 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 1.394 ;Test accuracy 0.725 ;IOU accuracy: 0.807 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 67 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19900 ;lr: 0.0495 ;B loss: 0.571 ;acc: 0.975 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19950 ;lr: 0.0495 ;B loss: 0.578 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20000 ;lr: 0.0495 ;B loss: 0.438 ;acc: 0.995 ;iou: 0.995 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20050 ;lr: 0.0490 ;B loss: 0.646 ;acc: 0.975 ;iou: 0.975 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20100 ;lr: 0.0490 ;B loss: 0.498 ;acc: 0.970 ;iou: 0.980 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20150 ;lr: 0.0490 ;B loss: 0.686 ;acc: 0.980 ;iou: 0.980 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 0.577 ;Train accuracy: 0.977 ;IOU accuracy: 0.987 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 67\n",
      "batch: 0 ;B loss: 1.201 ;acc: 0.755 ;iou_acc: 0.805 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.489 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 1.433 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 1.488 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.493 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.801 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.413 ;Test accuracy 0.724 ;IOU accuracy: 0.806 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 68 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20197 ;lr: 0.0490 ;B loss: 0.513 ;acc: 0.980 ;iou: 0.995 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20247 ;lr: 0.0490 ;B loss: 0.520 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20297 ;lr: 0.0490 ;B loss: 0.608 ;acc: 0.965 ;iou: 0.990 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20347 ;lr: 0.0490 ;B loss: 0.456 ;acc: 0.985 ;iou: 0.995 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20397 ;lr: 0.0490 ;B loss: 0.466 ;acc: 0.990 ;iou: 0.990 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20447 ;lr: 0.0490 ;B loss: 0.483 ;acc: 0.985 ;iou: 1.000 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 0.568 ;Train accuracy: 0.977 ;IOU accuracy: 0.987 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 68\n",
      "batch: 0 ;B loss: 1.198 ;acc: 0.775 ;iou_acc: 0.825 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.348 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.471 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.432 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.481 ;acc: 0.745 ;iou_acc: 0.820 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.692 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.422 ;Test accuracy 0.724 ;IOU accuracy: 0.806 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 69 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20494 ;lr: 0.0490 ;B loss: 0.524 ;acc: 0.980 ;iou: 0.985 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20544 ;lr: 0.0490 ;B loss: 0.438 ;acc: 1.000 ;iou: 1.000 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20594 ;lr: 0.0490 ;B loss: 0.579 ;acc: 0.965 ;iou: 0.990 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20644 ;lr: 0.0490 ;B loss: 0.548 ;acc: 0.975 ;iou: 0.985 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20694 ;lr: 0.0490 ;B loss: 0.416 ;acc: 0.970 ;iou: 0.985 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20744 ;lr: 0.0490 ;B loss: 0.469 ;acc: 0.990 ;iou: 0.995 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 0.563 ;Train accuracy: 0.978 ;IOU accuracy: 0.988 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 69\n",
      "batch: 0 ;B loss: 1.258 ;acc: 0.770 ;iou_acc: 0.820 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.378 ;acc: 0.760 ;iou_acc: 0.830 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.378 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.446 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 1.462 ;acc: 0.755 ;iou_acc: 0.815 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.783 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:47\n",
      "\n",
      "*BTrain: True ;Test loss: 1.413 ;Test accuracy 0.724 ;IOU accuracy: 0.807 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n",
      "dropout_in 0.5\n",
      "dropout_out 0.5\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/img_drop_0.5,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 2.894 ;acc: 0.310 ;iou: 0.415 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.698 ;acc: 0.290 ;iou: 0.400 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.772 ;acc: 0.230 ;iou: 0.380 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.687 ;acc: 0.300 ;iou: 0.405 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.790 ;acc: 0.245 ;iou: 0.340 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.631 ;acc: 0.335 ;iou: 0.445 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 2.711 ;Train accuracy: 0.285 ;IOU accuracy: 0.386 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.619 ;acc: 0.260 ;iou_acc: 0.395 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 2.683 ;acc: 0.220 ;iou_acc: 0.345 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 2.687 ;acc: 0.225 ;iou_acc: 0.310 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 2.644 ;acc: 0.250 ;iou_acc: 0.385 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 2.582 ;acc: 0.310 ;iou_acc: 0.390 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.601 ;acc: 0.300 ;iou_acc: 0.430 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 2.593 ;Test accuracy 0.292 ;IOU accuracy: 0.406 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 298 ;lr: 0.0500 ;B loss: 2.682 ;acc: 0.330 ;iou: 0.415 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 348 ;lr: 0.0500 ;B loss: 2.436 ;acc: 0.415 ;iou: 0.525 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 398 ;lr: 0.0500 ;B loss: 2.466 ;acc: 0.400 ;iou: 0.505 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 448 ;lr: 0.0500 ;B loss: 2.495 ;acc: 0.395 ;iou: 0.510 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 498 ;lr: 0.0500 ;B loss: 2.399 ;acc: 0.380 ;iou: 0.490 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 548 ;lr: 0.0500 ;B loss: 2.313 ;acc: 0.450 ;iou: 0.510 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 2.473 ;Train accuracy: 0.388 ;IOU accuracy: 0.493 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.353 ;acc: 0.365 ;iou_acc: 0.475 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 2.417 ;acc: 0.350 ;iou_acc: 0.445 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 2.442 ;acc: 0.350 ;iou_acc: 0.455 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 2.393 ;acc: 0.315 ;iou_acc: 0.435 ;time: 0:01:29\n",
      "batch: 200 ;B loss: 2.315 ;acc: 0.405 ;iou_acc: 0.470 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 2.330 ;acc: 0.425 ;iou_acc: 0.570 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 2.333 ;Test accuracy 0.382 ;IOU accuracy: 0.493 ;Time: 0:01:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 595 ;lr: 0.0500 ;B loss: 2.471 ;acc: 0.420 ;iou: 0.555 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 645 ;lr: 0.0500 ;B loss: 2.336 ;acc: 0.440 ;iou: 0.555 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 695 ;lr: 0.0500 ;B loss: 2.358 ;acc: 0.450 ;iou: 0.565 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 745 ;lr: 0.0500 ;B loss: 2.361 ;acc: 0.485 ;iou: 0.580 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 795 ;lr: 0.0500 ;B loss: 2.280 ;acc: 0.425 ;iou: 0.535 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 845 ;lr: 0.0500 ;B loss: 2.167 ;acc: 0.490 ;iou: 0.555 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 2.298 ;Train accuracy: 0.460 ;IOU accuracy: 0.564 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.212 ;acc: 0.390 ;iou_acc: 0.495 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 2.254 ;acc: 0.430 ;iou_acc: 0.490 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 2.288 ;acc: 0.455 ;iou_acc: 0.530 ;time: 0:01:22\n",
      "batch: 150 ;B loss: 2.284 ;acc: 0.390 ;iou_acc: 0.490 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 2.228 ;acc: 0.420 ;iou_acc: 0.525 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.180 ;acc: 0.465 ;iou_acc: 0.585 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 2.175 ;Test accuracy 0.441 ;IOU accuracy: 0.546 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 892 ;lr: 0.0500 ;B loss: 2.147 ;acc: 0.505 ;iou: 0.590 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 942 ;lr: 0.0500 ;B loss: 2.219 ;acc: 0.505 ;iou: 0.605 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 992 ;lr: 0.0500 ;B loss: 2.058 ;acc: 0.535 ;iou: 0.625 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1042 ;lr: 0.0500 ;B loss: 2.060 ;acc: 0.540 ;iou: 0.630 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1092 ;lr: 0.0500 ;B loss: 2.066 ;acc: 0.530 ;iou: 0.610 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1142 ;lr: 0.0500 ;B loss: 2.079 ;acc: 0.565 ;iou: 0.670 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 2.163 ;Train accuracy: 0.510 ;IOU accuracy: 0.608 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 2.100 ;acc: 0.445 ;iou_acc: 0.565 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 2.093 ;acc: 0.485 ;iou_acc: 0.565 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 2.174 ;acc: 0.460 ;iou_acc: 0.555 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 2.142 ;acc: 0.420 ;iou_acc: 0.510 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 2.107 ;acc: 0.470 ;iou_acc: 0.580 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 2.055 ;acc: 0.495 ;iou_acc: 0.610 ;time: 0:01:49\n",
      "\n",
      "*BTrain: True ;Test loss: 2.045 ;Test accuracy 0.484 ;IOU accuracy: 0.585 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1189 ;lr: 0.0500 ;B loss: 2.023 ;acc: 0.565 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1239 ;lr: 0.0500 ;B loss: 2.058 ;acc: 0.570 ;iou: 0.650 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1289 ;lr: 0.0500 ;B loss: 2.040 ;acc: 0.535 ;iou: 0.590 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1339 ;lr: 0.0500 ;B loss: 1.963 ;acc: 0.600 ;iou: 0.675 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1389 ;lr: 0.0500 ;B loss: 1.988 ;acc: 0.515 ;iou: 0.605 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1439 ;lr: 0.0500 ;B loss: 2.136 ;acc: 0.530 ;iou: 0.625 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 2.059 ;Train accuracy: 0.545 ;IOU accuracy: 0.638 ;Time: 0:01:01 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 1.971 ;acc: 0.510 ;iou_acc: 0.585 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 2.033 ;acc: 0.490 ;iou_acc: 0.570 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 2.073 ;acc: 0.455 ;iou_acc: 0.565 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 2.058 ;acc: 0.465 ;iou_acc: 0.570 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 2.033 ;acc: 0.485 ;iou_acc: 0.600 ;time: 0:01:37\n",
      "batch: 250 ;B loss: 1.988 ;acc: 0.485 ;iou_acc: 0.600 ;time: 0:01:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.961 ;Test accuracy 0.508 ;IOU accuracy: 0.607 ;Time: 0:01:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1486 ;lr: 0.0500 ;B loss: 2.101 ;acc: 0.540 ;iou: 0.625 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1536 ;lr: 0.0500 ;B loss: 1.922 ;acc: 0.565 ;iou: 0.640 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1586 ;lr: 0.0500 ;B loss: 1.928 ;acc: 0.555 ;iou: 0.625 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1636 ;lr: 0.0500 ;B loss: 2.071 ;acc: 0.545 ;iou: 0.635 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1686 ;lr: 0.0500 ;B loss: 1.890 ;acc: 0.575 ;iou: 0.690 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1736 ;lr: 0.0500 ;B loss: 1.757 ;acc: 0.610 ;iou: 0.690 ;time: 0:00:52\n",
      "\n",
      "*Training B: False ;B Train loss: 1.981 ;Train accuracy: 0.569 ;IOU accuracy: 0.659 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 1.878 ;acc: 0.540 ;iou_acc: 0.620 ;time: 0:01:03\n",
      "batch: 50 ;B loss: 1.964 ;acc: 0.525 ;iou_acc: 0.605 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.992 ;acc: 0.490 ;iou_acc: 0.590 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.979 ;acc: 0.515 ;iou_acc: 0.625 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.979 ;acc: 0.515 ;iou_acc: 0.645 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.950 ;acc: 0.535 ;iou_acc: 0.635 ;time: 0:01:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.895 ;Test accuracy 0.527 ;IOU accuracy: 0.623 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1783 ;lr: 0.0500 ;B loss: 2.087 ;acc: 0.510 ;iou: 0.625 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1833 ;lr: 0.0500 ;B loss: 2.016 ;acc: 0.560 ;iou: 0.620 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1883 ;lr: 0.0500 ;B loss: 1.969 ;acc: 0.550 ;iou: 0.660 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1933 ;lr: 0.0500 ;B loss: 1.831 ;acc: 0.620 ;iou: 0.705 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1983 ;lr: 0.0500 ;B loss: 1.998 ;acc: 0.605 ;iou: 0.675 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2033 ;lr: 0.0500 ;B loss: 2.051 ;acc: 0.605 ;iou: 0.675 ;time: 0:00:52\n",
      "\n",
      "*Training B: True ;B Train loss: 1.923 ;Train accuracy: 0.591 ;IOU accuracy: 0.678 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 1.853 ;acc: 0.555 ;iou_acc: 0.635 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.887 ;acc: 0.540 ;iou_acc: 0.625 ;time: 0:01:11\n",
      "batch: 100 ;B loss: 1.985 ;acc: 0.480 ;iou_acc: 0.580 ;time: 0:01:20\n",
      "batch: 150 ;B loss: 1.913 ;acc: 0.530 ;iou_acc: 0.625 ;time: 0:01:30\n",
      "batch: 200 ;B loss: 1.934 ;acc: 0.510 ;iou_acc: 0.615 ;time: 0:01:39\n",
      "batch: 250 ;B loss: 1.875 ;acc: 0.555 ;iou_acc: 0.655 ;time: 0:01:48\n",
      "\n",
      "*BTrain: True ;Test loss: 1.841 ;Test accuracy 0.544 ;IOU accuracy: 0.637 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2080 ;lr: 0.0500 ;B loss: 1.797 ;acc: 0.570 ;iou: 0.680 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2130 ;lr: 0.0500 ;B loss: 1.835 ;acc: 0.605 ;iou: 0.705 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2180 ;lr: 0.0500 ;B loss: 1.917 ;acc: 0.590 ;iou: 0.690 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2230 ;lr: 0.0500 ;B loss: 1.760 ;acc: 0.615 ;iou: 0.675 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2280 ;lr: 0.0500 ;B loss: 1.994 ;acc: 0.610 ;iou: 0.695 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2330 ;lr: 0.0500 ;B loss: 1.971 ;acc: 0.595 ;iou: 0.715 ;time: 0:00:51\n",
      "\n",
      "*Training B: False ;B Train loss: 1.873 ;Train accuracy: 0.606 ;IOU accuracy: 0.690 ;Time: 0:01:00 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 1.795 ;acc: 0.560 ;iou_acc: 0.620 ;time: 0:01:01\n",
      "batch: 50 ;B loss: 1.873 ;acc: 0.555 ;iou_acc: 0.640 ;time: 0:01:10\n",
      "batch: 100 ;B loss: 1.912 ;acc: 0.545 ;iou_acc: 0.625 ;time: 0:01:19\n",
      "batch: 150 ;B loss: 1.846 ;acc: 0.550 ;iou_acc: 0.645 ;time: 0:01:28\n",
      "batch: 200 ;B loss: 1.889 ;acc: 0.515 ;iou_acc: 0.630 ;time: 0:01:38\n",
      "batch: 250 ;B loss: 1.812 ;acc: 0.515 ;iou_acc: 0.640 ;time: 0:01:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.796 ;Test accuracy 0.556 ;IOU accuracy: 0.650 ;Time: 0:01:56\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2377 ;lr: 0.0500 ;B loss: 1.811 ;acc: 0.605 ;iou: 0.715 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2427 ;lr: 0.0500 ;B loss: 1.928 ;acc: 0.605 ;iou: 0.665 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2477 ;lr: 0.0500 ;B loss: 1.752 ;acc: 0.610 ;iou: 0.705 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2527 ;lr: 0.0500 ;B loss: 1.720 ;acc: 0.655 ;iou: 0.700 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2577 ;lr: 0.0500 ;B loss: 1.775 ;acc: 0.655 ;iou: 0.730 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2627 ;lr: 0.0500 ;B loss: 1.880 ;acc: 0.600 ;iou: 0.680 ;time: 0:00:53\n",
      "\n",
      "*Training B: False ;B Train loss: 1.827 ;Train accuracy: 0.623 ;IOU accuracy: 0.706 ;Time: 0:01:02 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 1.768 ;acc: 0.530 ;iou_acc: 0.620 ;time: 0:01:02\n",
      "batch: 50 ;B loss: 1.777 ;acc: 0.580 ;iou_acc: 0.650 ;time: 0:01:12\n",
      "batch: 100 ;B loss: 1.941 ;acc: 0.510 ;iou_acc: 0.605 ;time: 0:01:21\n",
      "batch: 150 ;B loss: 1.783 ;acc: 0.515 ;iou_acc: 0.610 ;time: 0:01:31\n",
      "batch: 200 ;B loss: 1.845 ;acc: 0.505 ;iou_acc: 0.635 ;time: 0:01:40\n",
      "batch: 250 ;B loss: 1.781 ;acc: 0.530 ;iou_acc: 0.645 ;time: 0:01:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.769 ;Test accuracy 0.563 ;IOU accuracy: 0.655 ;Time: 0:01:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2674 ;lr: 0.0500 ;B loss: 1.731 ;acc: 0.625 ;iou: 0.730 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2724 ;lr: 0.0500 ;B loss: 1.864 ;acc: 0.625 ;iou: 0.735 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2774 ;lr: 0.0500 ;B loss: 1.772 ;acc: 0.685 ;iou: 0.740 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2824 ;lr: 0.0500 ;B loss: 1.968 ;acc: 0.600 ;iou: 0.680 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2874 ;lr: 0.0500 ;B loss: 1.799 ;acc: 0.660 ;iou: 0.710 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2924 ;lr: 0.0500 ;B loss: 1.886 ;acc: 0.620 ;iou: 0.695 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.785 ;Train accuracy: 0.637 ;IOU accuracy: 0.717 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 1.737 ;acc: 0.580 ;iou_acc: 0.660 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.754 ;acc: 0.585 ;iou_acc: 0.655 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.862 ;acc: 0.535 ;iou_acc: 0.630 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.760 ;acc: 0.570 ;iou_acc: 0.655 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.849 ;acc: 0.530 ;iou_acc: 0.635 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.753 ;acc: 0.575 ;iou_acc: 0.675 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.735 ;Test accuracy 0.575 ;IOU accuracy: 0.667 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2971 ;lr: 0.0500 ;B loss: 1.647 ;acc: 0.670 ;iou: 0.765 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3021 ;lr: 0.0500 ;B loss: 1.779 ;acc: 0.620 ;iou: 0.700 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3071 ;lr: 0.0500 ;B loss: 1.811 ;acc: 0.635 ;iou: 0.720 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3121 ;lr: 0.0500 ;B loss: 1.643 ;acc: 0.660 ;iou: 0.740 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3171 ;lr: 0.0500 ;B loss: 1.834 ;acc: 0.645 ;iou: 0.755 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3221 ;lr: 0.0500 ;B loss: 1.831 ;acc: 0.605 ;iou: 0.715 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.748 ;Train accuracy: 0.654 ;IOU accuracy: 0.733 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 1.685 ;acc: 0.580 ;iou_acc: 0.640 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.726 ;acc: 0.595 ;iou_acc: 0.650 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.827 ;acc: 0.535 ;iou_acc: 0.610 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.732 ;acc: 0.600 ;iou_acc: 0.705 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.786 ;acc: 0.540 ;iou_acc: 0.660 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.705 ;acc: 0.580 ;iou_acc: 0.685 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.695 ;Test accuracy 0.587 ;IOU accuracy: 0.679 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3268 ;lr: 0.0500 ;B loss: 1.795 ;acc: 0.650 ;iou: 0.715 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3318 ;lr: 0.0500 ;B loss: 1.584 ;acc: 0.670 ;iou: 0.755 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3368 ;lr: 0.0500 ;B loss: 1.665 ;acc: 0.700 ;iou: 0.765 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3418 ;lr: 0.0500 ;B loss: 1.854 ;acc: 0.605 ;iou: 0.705 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3468 ;lr: 0.0500 ;B loss: 1.698 ;acc: 0.705 ;iou: 0.775 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3518 ;lr: 0.0500 ;B loss: 1.598 ;acc: 0.690 ;iou: 0.780 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.705 ;Train accuracy: 0.672 ;IOU accuracy: 0.750 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 1.667 ;acc: 0.600 ;iou_acc: 0.660 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.638 ;acc: 0.585 ;iou_acc: 0.655 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.731 ;acc: 0.585 ;iou_acc: 0.650 ;time: 0:01:26\n",
      "batch: 150 ;B loss: 1.665 ;acc: 0.645 ;iou_acc: 0.745 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.738 ;acc: 0.560 ;iou_acc: 0.685 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.653 ;acc: 0.600 ;iou_acc: 0.705 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.646 ;Test accuracy 0.604 ;IOU accuracy: 0.697 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3565 ;lr: 0.0500 ;B loss: 1.721 ;acc: 0.700 ;iou: 0.760 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3615 ;lr: 0.0500 ;B loss: 1.721 ;acc: 0.700 ;iou: 0.755 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3665 ;lr: 0.0500 ;B loss: 1.716 ;acc: 0.700 ;iou: 0.750 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3715 ;lr: 0.0500 ;B loss: 1.759 ;acc: 0.705 ;iou: 0.770 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3765 ;lr: 0.0500 ;B loss: 1.609 ;acc: 0.680 ;iou: 0.760 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3815 ;lr: 0.0500 ;B loss: 1.778 ;acc: 0.665 ;iou: 0.745 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.656 ;Train accuracy: 0.694 ;IOU accuracy: 0.771 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 1.616 ;acc: 0.615 ;iou_acc: 0.685 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.587 ;acc: 0.595 ;iou_acc: 0.660 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.732 ;acc: 0.580 ;iou_acc: 0.660 ;time: 0:01:26\n",
      "batch: 150 ;B loss: 1.593 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.714 ;acc: 0.605 ;iou_acc: 0.705 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.604 ;acc: 0.620 ;iou_acc: 0.740 ;time: 0:01:55\n",
      "\n",
      "*BTrain: True ;Test loss: 1.592 ;Test accuracy 0.622 ;IOU accuracy: 0.716 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3862 ;lr: 0.0500 ;B loss: 1.574 ;acc: 0.675 ;iou: 0.740 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3912 ;lr: 0.0500 ;B loss: 1.449 ;acc: 0.755 ;iou: 0.815 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3962 ;lr: 0.0500 ;B loss: 1.535 ;acc: 0.710 ;iou: 0.835 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4012 ;lr: 0.0500 ;B loss: 1.496 ;acc: 0.750 ;iou: 0.855 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4062 ;lr: 0.0500 ;B loss: 1.560 ;acc: 0.720 ;iou: 0.780 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4112 ;lr: 0.0500 ;B loss: 1.478 ;acc: 0.750 ;iou: 0.800 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.603 ;Train accuracy: 0.718 ;IOU accuracy: 0.793 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 1.549 ;acc: 0.615 ;iou_acc: 0.705 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.515 ;acc: 0.630 ;iou_acc: 0.710 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.649 ;acc: 0.605 ;iou_acc: 0.685 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.537 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.647 ;acc: 0.610 ;iou_acc: 0.725 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.546 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.546 ;Test accuracy 0.637 ;IOU accuracy: 0.731 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4159 ;lr: 0.0500 ;B loss: 1.529 ;acc: 0.730 ;iou: 0.775 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4209 ;lr: 0.0500 ;B loss: 1.509 ;acc: 0.740 ;iou: 0.780 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4259 ;lr: 0.0500 ;B loss: 1.524 ;acc: 0.745 ;iou: 0.805 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4309 ;lr: 0.0500 ;B loss: 1.462 ;acc: 0.715 ;iou: 0.795 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4359 ;lr: 0.0500 ;B loss: 1.577 ;acc: 0.705 ;iou: 0.795 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4409 ;lr: 0.0500 ;B loss: 1.430 ;acc: 0.710 ;iou: 0.790 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.561 ;Train accuracy: 0.734 ;IOU accuracy: 0.808 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.567 ;acc: 0.620 ;iou_acc: 0.695 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.459 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.624 ;acc: 0.625 ;iou_acc: 0.700 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.522 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.570 ;acc: 0.645 ;iou_acc: 0.750 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.515 ;acc: 0.650 ;iou_acc: 0.755 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.516 ;Test accuracy 0.648 ;IOU accuracy: 0.740 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4456 ;lr: 0.0500 ;B loss: 1.667 ;acc: 0.695 ;iou: 0.775 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4506 ;lr: 0.0500 ;B loss: 1.491 ;acc: 0.755 ;iou: 0.835 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4556 ;lr: 0.0500 ;B loss: 1.618 ;acc: 0.715 ;iou: 0.785 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4606 ;lr: 0.0500 ;B loss: 1.490 ;acc: 0.745 ;iou: 0.805 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4656 ;lr: 0.0500 ;B loss: 1.545 ;acc: 0.755 ;iou: 0.865 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4706 ;lr: 0.0500 ;B loss: 1.401 ;acc: 0.775 ;iou: 0.845 ;time: 0:00:56\n",
      "\n",
      "*Training B: True ;B Train loss: 1.524 ;Train accuracy: 0.748 ;IOU accuracy: 0.821 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.513 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:01:07\n",
      "batch: 50 ;B loss: 1.394 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:01:17\n",
      "batch: 100 ;B loss: 1.623 ;acc: 0.625 ;iou_acc: 0.700 ;time: 0:01:26\n",
      "batch: 150 ;B loss: 1.471 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:36\n",
      "batch: 200 ;B loss: 1.539 ;acc: 0.630 ;iou_acc: 0.740 ;time: 0:01:46\n",
      "batch: 250 ;B loss: 1.515 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:55\n",
      "\n",
      "*BTrain: True ;Test loss: 1.473 ;Test accuracy 0.659 ;IOU accuracy: 0.752 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4753 ;lr: 0.0500 ;B loss: 1.646 ;acc: 0.715 ;iou: 0.815 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4803 ;lr: 0.0500 ;B loss: 1.386 ;acc: 0.770 ;iou: 0.850 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4853 ;lr: 0.0500 ;B loss: 1.335 ;acc: 0.775 ;iou: 0.865 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4903 ;lr: 0.0500 ;B loss: 1.500 ;acc: 0.760 ;iou: 0.830 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4953 ;lr: 0.0500 ;B loss: 1.435 ;acc: 0.740 ;iou: 0.845 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5003 ;lr: 0.0500 ;B loss: 1.395 ;acc: 0.740 ;iou: 0.800 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.487 ;Train accuracy: 0.761 ;IOU accuracy: 0.830 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.455 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.360 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.522 ;acc: 0.645 ;iou_acc: 0.710 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.476 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.527 ;acc: 0.630 ;iou_acc: 0.745 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.469 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.435 ;Test accuracy 0.669 ;IOU accuracy: 0.762 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5050 ;lr: 0.0500 ;B loss: 1.330 ;acc: 0.820 ;iou: 0.850 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5100 ;lr: 0.0500 ;B loss: 1.616 ;acc: 0.740 ;iou: 0.835 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5150 ;lr: 0.0500 ;B loss: 1.512 ;acc: 0.760 ;iou: 0.860 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5200 ;lr: 0.0500 ;B loss: 1.613 ;acc: 0.760 ;iou: 0.835 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5250 ;lr: 0.0500 ;B loss: 1.435 ;acc: 0.760 ;iou: 0.830 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5300 ;lr: 0.0500 ;B loss: 1.420 ;acc: 0.765 ;iou: 0.845 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.456 ;Train accuracy: 0.768 ;IOU accuracy: 0.837 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.458 ;acc: 0.650 ;iou_acc: 0.705 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.358 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.506 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.451 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.513 ;acc: 0.615 ;iou_acc: 0.720 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.455 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.423 ;Test accuracy 0.672 ;IOU accuracy: 0.764 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5347 ;lr: 0.0500 ;B loss: 1.631 ;acc: 0.710 ;iou: 0.805 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5397 ;lr: 0.0500 ;B loss: 1.434 ;acc: 0.760 ;iou: 0.830 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5447 ;lr: 0.0500 ;B loss: 1.355 ;acc: 0.800 ;iou: 0.860 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5497 ;lr: 0.0500 ;B loss: 1.548 ;acc: 0.790 ;iou: 0.855 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5547 ;lr: 0.0500 ;B loss: 1.507 ;acc: 0.735 ;iou: 0.805 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5597 ;lr: 0.0500 ;B loss: 1.486 ;acc: 0.775 ;iou: 0.820 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 1.434 ;Train accuracy: 0.775 ;IOU accuracy: 0.843 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.447 ;acc: 0.645 ;iou_acc: 0.725 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.346 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.487 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.404 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.443 ;acc: 0.635 ;iou_acc: 0.760 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.445 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.400 ;Test accuracy 0.678 ;IOU accuracy: 0.769 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5644 ;lr: 0.0500 ;B loss: 1.434 ;acc: 0.795 ;iou: 0.855 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5694 ;lr: 0.0500 ;B loss: 1.336 ;acc: 0.805 ;iou: 0.855 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5744 ;lr: 0.0500 ;B loss: 1.520 ;acc: 0.760 ;iou: 0.810 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5794 ;lr: 0.0500 ;B loss: 1.358 ;acc: 0.780 ;iou: 0.835 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5844 ;lr: 0.0500 ;B loss: 1.523 ;acc: 0.765 ;iou: 0.830 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5894 ;lr: 0.0500 ;B loss: 1.262 ;acc: 0.810 ;iou: 0.860 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.408 ;Train accuracy: 0.781 ;IOU accuracy: 0.847 ;Time: 0:01:06 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.372 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.313 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.456 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:01:26\n",
      "batch: 150 ;B loss: 1.392 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:36\n",
      "batch: 200 ;B loss: 1.422 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.420 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.372 ;Test accuracy 0.684 ;IOU accuracy: 0.775 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5941 ;lr: 0.0500 ;B loss: 1.242 ;acc: 0.795 ;iou: 0.875 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5991 ;lr: 0.0500 ;B loss: 1.473 ;acc: 0.855 ;iou: 0.905 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6041 ;lr: 0.0500 ;B loss: 1.124 ;acc: 0.815 ;iou: 0.905 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6091 ;lr: 0.0500 ;B loss: 1.361 ;acc: 0.785 ;iou: 0.855 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6141 ;lr: 0.0500 ;B loss: 1.528 ;acc: 0.785 ;iou: 0.865 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6191 ;lr: 0.0500 ;B loss: 1.403 ;acc: 0.825 ;iou: 0.890 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.388 ;Train accuracy: 0.789 ;IOU accuracy: 0.855 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.379 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.325 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.471 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.423 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.447 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.419 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.370 ;Test accuracy 0.686 ;IOU accuracy: 0.776 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6238 ;lr: 0.0500 ;B loss: 1.238 ;acc: 0.855 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6288 ;lr: 0.0500 ;B loss: 1.151 ;acc: 0.820 ;iou: 0.855 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6338 ;lr: 0.0500 ;B loss: 1.466 ;acc: 0.775 ;iou: 0.865 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6388 ;lr: 0.0500 ;B loss: 1.413 ;acc: 0.775 ;iou: 0.825 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6438 ;lr: 0.0500 ;B loss: 1.549 ;acc: 0.790 ;iou: 0.850 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6488 ;lr: 0.0500 ;B loss: 1.327 ;acc: 0.840 ;iou: 0.890 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.368 ;Train accuracy: 0.796 ;IOU accuracy: 0.859 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.427 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.299 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.463 ;acc: 0.655 ;iou_acc: 0.745 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.364 ;acc: 0.670 ;iou_acc: 0.765 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.387 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.433 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.353 ;Test accuracy 0.688 ;IOU accuracy: 0.779 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6535 ;lr: 0.0500 ;B loss: 1.507 ;acc: 0.765 ;iou: 0.820 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6585 ;lr: 0.0500 ;B loss: 1.604 ;acc: 0.760 ;iou: 0.830 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6635 ;lr: 0.0500 ;B loss: 1.399 ;acc: 0.795 ;iou: 0.840 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6685 ;lr: 0.0500 ;B loss: 1.270 ;acc: 0.820 ;iou: 0.845 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6735 ;lr: 0.0500 ;B loss: 1.304 ;acc: 0.795 ;iou: 0.860 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6785 ;lr: 0.0500 ;B loss: 1.229 ;acc: 0.830 ;iou: 0.900 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.343 ;Train accuracy: 0.800 ;IOU accuracy: 0.862 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.395 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.262 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.423 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.359 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.373 ;acc: 0.675 ;iou_acc: 0.795 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.412 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.329 ;Test accuracy 0.696 ;IOU accuracy: 0.785 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6832 ;lr: 0.0500 ;B loss: 1.510 ;acc: 0.775 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6882 ;lr: 0.0500 ;B loss: 1.434 ;acc: 0.790 ;iou: 0.865 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6932 ;lr: 0.0500 ;B loss: 1.253 ;acc: 0.835 ;iou: 0.880 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6982 ;lr: 0.0500 ;B loss: 1.341 ;acc: 0.740 ;iou: 0.815 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7032 ;lr: 0.0500 ;B loss: 1.234 ;acc: 0.840 ;iou: 0.900 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7082 ;lr: 0.0500 ;B loss: 1.260 ;acc: 0.795 ;iou: 0.870 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.327 ;Train accuracy: 0.806 ;IOU accuracy: 0.867 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.357 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.271 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.418 ;acc: 0.650 ;iou_acc: 0.730 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.367 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.356 ;acc: 0.655 ;iou_acc: 0.780 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.385 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.322 ;Test accuracy 0.696 ;IOU accuracy: 0.784 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7129 ;lr: 0.0500 ;B loss: 1.351 ;acc: 0.820 ;iou: 0.850 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7179 ;lr: 0.0500 ;B loss: 1.442 ;acc: 0.785 ;iou: 0.850 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7229 ;lr: 0.0500 ;B loss: 1.416 ;acc: 0.830 ;iou: 0.885 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7279 ;lr: 0.0500 ;B loss: 1.446 ;acc: 0.785 ;iou: 0.840 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7329 ;lr: 0.0500 ;B loss: 1.302 ;acc: 0.795 ;iou: 0.865 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7379 ;lr: 0.0500 ;B loss: 1.348 ;acc: 0.775 ;iou: 0.850 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.313 ;Train accuracy: 0.809 ;IOU accuracy: 0.869 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.337 ;acc: 0.670 ;iou_acc: 0.745 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.256 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.390 ;acc: 0.665 ;iou_acc: 0.740 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.329 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.354 ;acc: 0.665 ;iou_acc: 0.785 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.402 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.310 ;Test accuracy 0.700 ;IOU accuracy: 0.787 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7426 ;lr: 0.0500 ;B loss: 1.113 ;acc: 0.870 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7476 ;lr: 0.0500 ;B loss: 1.268 ;acc: 0.815 ;iou: 0.875 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7526 ;lr: 0.0500 ;B loss: 1.242 ;acc: 0.805 ;iou: 0.840 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7576 ;lr: 0.0500 ;B loss: 1.101 ;acc: 0.850 ;iou: 0.920 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7626 ;lr: 0.0500 ;B loss: 1.389 ;acc: 0.815 ;iou: 0.865 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7676 ;lr: 0.0500 ;B loss: 1.451 ;acc: 0.775 ;iou: 0.845 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.286 ;Train accuracy: 0.815 ;IOU accuracy: 0.874 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.338 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.243 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.365 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.336 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.353 ;acc: 0.655 ;iou_acc: 0.780 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.357 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.304 ;Test accuracy 0.702 ;IOU accuracy: 0.790 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7723 ;lr: 0.0500 ;B loss: 1.334 ;acc: 0.810 ;iou: 0.865 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7773 ;lr: 0.0500 ;B loss: 1.382 ;acc: 0.760 ;iou: 0.835 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7823 ;lr: 0.0500 ;B loss: 1.328 ;acc: 0.805 ;iou: 0.880 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7873 ;lr: 0.0500 ;B loss: 1.400 ;acc: 0.795 ;iou: 0.865 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7923 ;lr: 0.0500 ;B loss: 1.178 ;acc: 0.850 ;iou: 0.900 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7973 ;lr: 0.0500 ;B loss: 1.397 ;acc: 0.760 ;iou: 0.815 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.283 ;Train accuracy: 0.820 ;IOU accuracy: 0.877 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.338 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.231 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.444 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.325 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.361 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.362 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.289 ;Test accuracy 0.706 ;IOU accuracy: 0.792 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8020 ;lr: 0.0500 ;B loss: 1.209 ;acc: 0.835 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8070 ;lr: 0.0500 ;B loss: 1.168 ;acc: 0.870 ;iou: 0.920 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8120 ;lr: 0.0500 ;B loss: 1.186 ;acc: 0.830 ;iou: 0.870 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8170 ;lr: 0.0500 ;B loss: 1.279 ;acc: 0.835 ;iou: 0.900 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8220 ;lr: 0.0500 ;B loss: 1.260 ;acc: 0.825 ;iou: 0.890 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8270 ;lr: 0.0500 ;B loss: 1.183 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.262 ;Train accuracy: 0.824 ;IOU accuracy: 0.880 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.348 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.222 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.396 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.317 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.309 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.375 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.283 ;Test accuracy 0.707 ;IOU accuracy: 0.795 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8317 ;lr: 0.0500 ;B loss: 1.282 ;acc: 0.850 ;iou: 0.885 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8367 ;lr: 0.0500 ;B loss: 1.247 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8417 ;lr: 0.0500 ;B loss: 1.191 ;acc: 0.895 ;iou: 0.920 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8467 ;lr: 0.0500 ;B loss: 1.330 ;acc: 0.825 ;iou: 0.880 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8517 ;lr: 0.0500 ;B loss: 1.237 ;acc: 0.785 ;iou: 0.835 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8567 ;lr: 0.0500 ;B loss: 1.219 ;acc: 0.845 ;iou: 0.885 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.252 ;Train accuracy: 0.829 ;IOU accuracy: 0.885 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.324 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.246 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.402 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:26\n",
      "batch: 150 ;B loss: 1.294 ;acc: 0.700 ;iou_acc: 0.790 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.324 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.374 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.279 ;Test accuracy 0.709 ;IOU accuracy: 0.795 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8614 ;lr: 0.0500 ;B loss: 1.142 ;acc: 0.855 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8664 ;lr: 0.0500 ;B loss: 1.321 ;acc: 0.840 ;iou: 0.900 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8714 ;lr: 0.0500 ;B loss: 1.359 ;acc: 0.790 ;iou: 0.865 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8764 ;lr: 0.0500 ;B loss: 1.204 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8814 ;lr: 0.0500 ;B loss: 1.380 ;acc: 0.765 ;iou: 0.830 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8864 ;lr: 0.0500 ;B loss: 1.069 ;acc: 0.830 ;iou: 0.880 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.233 ;Train accuracy: 0.832 ;IOU accuracy: 0.887 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.301 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.214 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.366 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.299 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.333 ;acc: 0.650 ;iou_acc: 0.770 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.356 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.266 ;Test accuracy 0.711 ;IOU accuracy: 0.797 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8911 ;lr: 0.0500 ;B loss: 1.210 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8961 ;lr: 0.0500 ;B loss: 1.216 ;acc: 0.805 ;iou: 0.855 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9011 ;lr: 0.0500 ;B loss: 1.366 ;acc: 0.845 ;iou: 0.905 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9061 ;lr: 0.0500 ;B loss: 1.332 ;acc: 0.850 ;iou: 0.915 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9111 ;lr: 0.0500 ;B loss: 1.171 ;acc: 0.855 ;iou: 0.910 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9161 ;lr: 0.0500 ;B loss: 1.244 ;acc: 0.830 ;iou: 0.875 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.221 ;Train accuracy: 0.835 ;IOU accuracy: 0.889 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.303 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.222 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.367 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.266 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.295 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.358 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.255 ;Test accuracy 0.714 ;IOU accuracy: 0.799 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9208 ;lr: 0.0500 ;B loss: 1.236 ;acc: 0.815 ;iou: 0.875 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9258 ;lr: 0.0500 ;B loss: 1.236 ;acc: 0.855 ;iou: 0.885 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9308 ;lr: 0.0500 ;B loss: 1.277 ;acc: 0.800 ;iou: 0.860 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9358 ;lr: 0.0500 ;B loss: 1.135 ;acc: 0.815 ;iou: 0.890 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9408 ;lr: 0.0500 ;B loss: 1.260 ;acc: 0.830 ;iou: 0.895 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9458 ;lr: 0.0500 ;B loss: 1.257 ;acc: 0.835 ;iou: 0.870 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.205 ;Train accuracy: 0.840 ;IOU accuracy: 0.892 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.298 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.190 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.357 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.300 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.310 ;acc: 0.675 ;iou_acc: 0.790 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.345 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.258 ;Test accuracy 0.715 ;IOU accuracy: 0.800 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9505 ;lr: 0.0500 ;B loss: 1.050 ;acc: 0.895 ;iou: 0.905 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9555 ;lr: 0.0500 ;B loss: 1.077 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9605 ;lr: 0.0500 ;B loss: 1.111 ;acc: 0.855 ;iou: 0.920 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9655 ;lr: 0.0500 ;B loss: 1.154 ;acc: 0.825 ;iou: 0.880 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9705 ;lr: 0.0500 ;B loss: 1.409 ;acc: 0.770 ;iou: 0.850 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9755 ;lr: 0.0500 ;B loss: 1.092 ;acc: 0.840 ;iou: 0.885 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.190 ;Train accuracy: 0.842 ;IOU accuracy: 0.895 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.281 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.220 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.403 ;acc: 0.660 ;iou_acc: 0.750 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.309 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.283 ;acc: 0.685 ;iou_acc: 0.815 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.315 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.251 ;Test accuracy 0.716 ;IOU accuracy: 0.801 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9802 ;lr: 0.0500 ;B loss: 1.040 ;acc: 0.880 ;iou: 0.900 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9852 ;lr: 0.0500 ;B loss: 0.920 ;acc: 0.860 ;iou: 0.925 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9902 ;lr: 0.0500 ;B loss: 1.168 ;acc: 0.850 ;iou: 0.865 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9952 ;lr: 0.0500 ;B loss: 1.143 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10002 ;lr: 0.0495 ;B loss: 1.188 ;acc: 0.815 ;iou: 0.870 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10052 ;lr: 0.0495 ;B loss: 1.046 ;acc: 0.855 ;iou: 0.895 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.181 ;Train accuracy: 0.847 ;IOU accuracy: 0.898 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.308 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.222 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.346 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.286 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.298 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.335 ;acc: 0.695 ;iou_acc: 0.815 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.245 ;Test accuracy 0.717 ;IOU accuracy: 0.802 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10099 ;lr: 0.0495 ;B loss: 1.323 ;acc: 0.845 ;iou: 0.895 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10149 ;lr: 0.0495 ;B loss: 1.445 ;acc: 0.805 ;iou: 0.865 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10199 ;lr: 0.0495 ;B loss: 1.113 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10249 ;lr: 0.0495 ;B loss: 1.105 ;acc: 0.845 ;iou: 0.905 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10299 ;lr: 0.0495 ;B loss: 1.236 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10349 ;lr: 0.0495 ;B loss: 1.000 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.169 ;Train accuracy: 0.851 ;IOU accuracy: 0.900 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.269 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.155 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.306 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.268 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.327 ;acc: 0.640 ;iou_acc: 0.770 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.341 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.234 ;Test accuracy 0.721 ;IOU accuracy: 0.805 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10396 ;lr: 0.0495 ;B loss: 1.241 ;acc: 0.875 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10446 ;lr: 0.0495 ;B loss: 1.216 ;acc: 0.815 ;iou: 0.865 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10496 ;lr: 0.0495 ;B loss: 1.163 ;acc: 0.850 ;iou: 0.875 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10546 ;lr: 0.0495 ;B loss: 1.128 ;acc: 0.870 ;iou: 0.920 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10596 ;lr: 0.0495 ;B loss: 1.251 ;acc: 0.810 ;iou: 0.880 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10646 ;lr: 0.0495 ;B loss: 1.042 ;acc: 0.835 ;iou: 0.895 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.159 ;Train accuracy: 0.853 ;IOU accuracy: 0.902 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.243 ;acc: 0.705 ;iou_acc: 0.770 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.177 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.332 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.273 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.312 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.302 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.241 ;Test accuracy 0.717 ;IOU accuracy: 0.801 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10693 ;lr: 0.0495 ;B loss: 1.231 ;acc: 0.835 ;iou: 0.870 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10743 ;lr: 0.0495 ;B loss: 1.021 ;acc: 0.865 ;iou: 0.900 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10793 ;lr: 0.0495 ;B loss: 1.162 ;acc: 0.840 ;iou: 0.905 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10843 ;lr: 0.0495 ;B loss: 1.056 ;acc: 0.860 ;iou: 0.880 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10893 ;lr: 0.0495 ;B loss: 0.928 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10943 ;lr: 0.0495 ;B loss: 1.235 ;acc: 0.840 ;iou: 0.910 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.147 ;Train accuracy: 0.856 ;IOU accuracy: 0.904 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.259 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.218 ;acc: 0.680 ;iou_acc: 0.795 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.308 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.304 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.281 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.309 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.233 ;Test accuracy 0.720 ;IOU accuracy: 0.804 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10990 ;lr: 0.0495 ;B loss: 1.289 ;acc: 0.825 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11040 ;lr: 0.0495 ;B loss: 1.099 ;acc: 0.865 ;iou: 0.915 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11090 ;lr: 0.0495 ;B loss: 1.053 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11140 ;lr: 0.0495 ;B loss: 1.134 ;acc: 0.860 ;iou: 0.920 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11190 ;lr: 0.0495 ;B loss: 1.260 ;acc: 0.800 ;iou: 0.875 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11240 ;lr: 0.0495 ;B loss: 0.875 ;acc: 0.880 ;iou: 0.930 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.133 ;Train accuracy: 0.858 ;IOU accuracy: 0.906 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.242 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.209 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.325 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.334 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.273 ;acc: 0.670 ;iou_acc: 0.795 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.305 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.231 ;Test accuracy 0.721 ;IOU accuracy: 0.805 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11287 ;lr: 0.0495 ;B loss: 1.150 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11337 ;lr: 0.0495 ;B loss: 1.164 ;acc: 0.835 ;iou: 0.905 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11387 ;lr: 0.0495 ;B loss: 1.023 ;acc: 0.860 ;iou: 0.900 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11437 ;lr: 0.0495 ;B loss: 1.116 ;acc: 0.840 ;iou: 0.890 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11487 ;lr: 0.0495 ;B loss: 1.109 ;acc: 0.845 ;iou: 0.880 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11537 ;lr: 0.0495 ;B loss: 1.199 ;acc: 0.830 ;iou: 0.870 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.121 ;Train accuracy: 0.862 ;IOU accuracy: 0.909 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.252 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.187 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.310 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.287 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.284 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.316 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.227 ;Test accuracy 0.722 ;IOU accuracy: 0.807 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11584 ;lr: 0.0495 ;B loss: 1.113 ;acc: 0.840 ;iou: 0.900 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11634 ;lr: 0.0495 ;B loss: 1.123 ;acc: 0.855 ;iou: 0.900 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11684 ;lr: 0.0495 ;B loss: 1.099 ;acc: 0.880 ;iou: 0.925 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11734 ;lr: 0.0495 ;B loss: 1.279 ;acc: 0.810 ;iou: 0.885 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11784 ;lr: 0.0495 ;B loss: 1.070 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11834 ;lr: 0.0495 ;B loss: 1.062 ;acc: 0.865 ;iou: 0.895 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.119 ;Train accuracy: 0.863 ;IOU accuracy: 0.910 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.248 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.187 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.297 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.283 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.273 ;acc: 0.665 ;iou_acc: 0.780 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.293 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.223 ;Test accuracy 0.724 ;IOU accuracy: 0.807 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11881 ;lr: 0.0495 ;B loss: 1.113 ;acc: 0.865 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11931 ;lr: 0.0495 ;B loss: 1.110 ;acc: 0.855 ;iou: 0.885 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11981 ;lr: 0.0495 ;B loss: 1.115 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12031 ;lr: 0.0495 ;B loss: 1.188 ;acc: 0.865 ;iou: 0.915 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12081 ;lr: 0.0495 ;B loss: 1.139 ;acc: 0.855 ;iou: 0.915 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12131 ;lr: 0.0495 ;B loss: 1.176 ;acc: 0.850 ;iou: 0.875 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.103 ;Train accuracy: 0.867 ;IOU accuracy: 0.912 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.214 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.132 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.324 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.274 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.283 ;acc: 0.660 ;iou_acc: 0.805 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.280 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.217 ;Test accuracy 0.724 ;IOU accuracy: 0.808 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12178 ;lr: 0.0495 ;B loss: 1.046 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12228 ;lr: 0.0495 ;B loss: 0.958 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12278 ;lr: 0.0495 ;B loss: 1.189 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12328 ;lr: 0.0495 ;B loss: 1.217 ;acc: 0.840 ;iou: 0.890 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12378 ;lr: 0.0495 ;B loss: 1.049 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12428 ;lr: 0.0495 ;B loss: 0.953 ;acc: 0.900 ;iou: 0.925 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.096 ;Train accuracy: 0.871 ;IOU accuracy: 0.915 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.212 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.161 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.314 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.247 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.241 ;acc: 0.665 ;iou_acc: 0.800 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.299 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.212 ;Test accuracy 0.726 ;IOU accuracy: 0.809 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12475 ;lr: 0.0495 ;B loss: 1.002 ;acc: 0.915 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12525 ;lr: 0.0495 ;B loss: 1.129 ;acc: 0.880 ;iou: 0.935 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12575 ;lr: 0.0495 ;B loss: 1.050 ;acc: 0.900 ;iou: 0.925 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12625 ;lr: 0.0495 ;B loss: 1.079 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12675 ;lr: 0.0495 ;B loss: 1.079 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12725 ;lr: 0.0495 ;B loss: 1.006 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.084 ;Train accuracy: 0.872 ;IOU accuracy: 0.917 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.241 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.169 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.285 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.285 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.280 ;acc: 0.685 ;iou_acc: 0.805 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.306 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.209 ;Test accuracy 0.729 ;IOU accuracy: 0.811 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12772 ;lr: 0.0495 ;B loss: 1.029 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12822 ;lr: 0.0495 ;B loss: 1.235 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12872 ;lr: 0.0495 ;B loss: 0.977 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12922 ;lr: 0.0495 ;B loss: 1.018 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12972 ;lr: 0.0495 ;B loss: 1.047 ;acc: 0.885 ;iou: 0.910 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13022 ;lr: 0.0495 ;B loss: 1.083 ;acc: 0.860 ;iou: 0.910 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.070 ;Train accuracy: 0.876 ;IOU accuracy: 0.919 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.213 ;acc: 0.735 ;iou_acc: 0.810 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.157 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.298 ;acc: 0.700 ;iou_acc: 0.755 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.254 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.270 ;acc: 0.670 ;iou_acc: 0.800 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.304 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.205 ;Test accuracy 0.729 ;IOU accuracy: 0.812 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13069 ;lr: 0.0495 ;B loss: 0.923 ;acc: 0.900 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13119 ;lr: 0.0495 ;B loss: 1.057 ;acc: 0.885 ;iou: 0.920 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13169 ;lr: 0.0495 ;B loss: 0.809 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13219 ;lr: 0.0495 ;B loss: 1.008 ;acc: 0.890 ;iou: 0.915 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13269 ;lr: 0.0495 ;B loss: 1.263 ;acc: 0.840 ;iou: 0.910 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13319 ;lr: 0.0495 ;B loss: 1.098 ;acc: 0.875 ;iou: 0.925 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.067 ;Train accuracy: 0.877 ;IOU accuracy: 0.921 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.195 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.185 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.310 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.260 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.242 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.260 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.200 ;Test accuracy 0.731 ;IOU accuracy: 0.813 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13366 ;lr: 0.0495 ;B loss: 0.987 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13416 ;lr: 0.0495 ;B loss: 0.931 ;acc: 0.850 ;iou: 0.895 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13466 ;lr: 0.0495 ;B loss: 1.066 ;acc: 0.870 ;iou: 0.930 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13516 ;lr: 0.0495 ;B loss: 1.082 ;acc: 0.860 ;iou: 0.930 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13566 ;lr: 0.0495 ;B loss: 1.124 ;acc: 0.845 ;iou: 0.895 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13616 ;lr: 0.0495 ;B loss: 1.102 ;acc: 0.825 ;iou: 0.880 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.053 ;Train accuracy: 0.880 ;IOU accuracy: 0.922 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.187 ;acc: 0.750 ;iou_acc: 0.845 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.195 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.307 ;acc: 0.730 ;iou_acc: 0.795 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.270 ;acc: 0.730 ;iou_acc: 0.805 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.190 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.280 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:01:55\n",
      "\n",
      "*BTrain: True ;Test loss: 1.201 ;Test accuracy 0.731 ;IOU accuracy: 0.814 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13663 ;lr: 0.0495 ;B loss: 0.897 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13713 ;lr: 0.0495 ;B loss: 1.028 ;acc: 0.885 ;iou: 0.930 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13763 ;lr: 0.0495 ;B loss: 0.847 ;acc: 0.910 ;iou: 0.915 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13813 ;lr: 0.0495 ;B loss: 1.004 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13863 ;lr: 0.0495 ;B loss: 1.027 ;acc: 0.865 ;iou: 0.905 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13913 ;lr: 0.0495 ;B loss: 1.137 ;acc: 0.900 ;iou: 0.945 ;time: 0:00:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.044 ;Train accuracy: 0.882 ;IOU accuracy: 0.924 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.162 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.180 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.335 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:01:26\n",
      "batch: 150 ;B loss: 1.237 ;acc: 0.745 ;iou_acc: 0.810 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.248 ;acc: 0.685 ;iou_acc: 0.815 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.267 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.193 ;Test accuracy 0.732 ;IOU accuracy: 0.814 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13960 ;lr: 0.0495 ;B loss: 0.909 ;acc: 0.905 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14010 ;lr: 0.0495 ;B loss: 1.163 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14060 ;lr: 0.0495 ;B loss: 0.933 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14110 ;lr: 0.0495 ;B loss: 1.077 ;acc: 0.885 ;iou: 0.930 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14160 ;lr: 0.0495 ;B loss: 0.957 ;acc: 0.885 ;iou: 0.920 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14210 ;lr: 0.0495 ;B loss: 1.029 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.041 ;Train accuracy: 0.884 ;IOU accuracy: 0.926 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.200 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.148 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.293 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.276 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.209 ;acc: 0.705 ;iou_acc: 0.835 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.300 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.204 ;Test accuracy 0.731 ;IOU accuracy: 0.813 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14257 ;lr: 0.0495 ;B loss: 0.937 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14307 ;lr: 0.0495 ;B loss: 1.306 ;acc: 0.845 ;iou: 0.900 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14357 ;lr: 0.0495 ;B loss: 1.057 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14407 ;lr: 0.0495 ;B loss: 1.002 ;acc: 0.875 ;iou: 0.935 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14457 ;lr: 0.0495 ;B loss: 1.200 ;acc: 0.820 ;iou: 0.875 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14507 ;lr: 0.0495 ;B loss: 1.237 ;acc: 0.860 ;iou: 0.900 ;time: 0:00:53\n",
      "\n",
      "*Training B: True ;B Train loss: 1.034 ;Train accuracy: 0.886 ;IOU accuracy: 0.927 ;Time: 0:01:03 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.173 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.144 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:13\n",
      "batch: 100 ;B loss: 1.272 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:01:23\n",
      "batch: 150 ;B loss: 1.235 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 1.202 ;acc: 0.695 ;iou_acc: 0.830 ;time: 0:01:42\n",
      "batch: 250 ;B loss: 1.269 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:52\n",
      "\n",
      "*BTrain: True ;Test loss: 1.192 ;Test accuracy 0.732 ;IOU accuracy: 0.814 ;Time: 0:02:00\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14554 ;lr: 0.0495 ;B loss: 1.105 ;acc: 0.860 ;iou: 0.910 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14604 ;lr: 0.0495 ;B loss: 0.801 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14654 ;lr: 0.0495 ;B loss: 1.130 ;acc: 0.845 ;iou: 0.910 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14704 ;lr: 0.0495 ;B loss: 1.044 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14754 ;lr: 0.0495 ;B loss: 1.075 ;acc: 0.890 ;iou: 0.945 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14804 ;lr: 0.0495 ;B loss: 1.003 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.029 ;Train accuracy: 0.888 ;IOU accuracy: 0.929 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.159 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.154 ;acc: 0.725 ;iou_acc: 0.820 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.251 ;acc: 0.705 ;iou_acc: 0.765 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.253 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 1.217 ;acc: 0.695 ;iou_acc: 0.815 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.275 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.197 ;Test accuracy 0.732 ;IOU accuracy: 0.813 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 50 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14851 ;lr: 0.0495 ;B loss: 1.071 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14901 ;lr: 0.0495 ;B loss: 0.989 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14951 ;lr: 0.0495 ;B loss: 1.069 ;acc: 0.870 ;iou: 0.905 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15001 ;lr: 0.0495 ;B loss: 0.888 ;acc: 0.900 ;iou: 0.915 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15051 ;lr: 0.0495 ;B loss: 1.070 ;acc: 0.850 ;iou: 0.895 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15101 ;lr: 0.0495 ;B loss: 1.038 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.021 ;Train accuracy: 0.890 ;IOU accuracy: 0.928 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 50\n",
      "batch: 0 ;B loss: 1.171 ;acc: 0.720 ;iou_acc: 0.810 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.170 ;acc: 0.705 ;iou_acc: 0.805 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.238 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.260 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.193 ;acc: 0.705 ;iou_acc: 0.835 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.260 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.189 ;Test accuracy 0.734 ;IOU accuracy: 0.816 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 51 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15148 ;lr: 0.0495 ;B loss: 0.987 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15198 ;lr: 0.0495 ;B loss: 0.945 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15248 ;lr: 0.0495 ;B loss: 0.957 ;acc: 0.900 ;iou: 0.945 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15298 ;lr: 0.0495 ;B loss: 0.935 ;acc: 0.905 ;iou: 0.960 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15348 ;lr: 0.0495 ;B loss: 1.023 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15398 ;lr: 0.0495 ;B loss: 0.986 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.009 ;Train accuracy: 0.892 ;IOU accuracy: 0.930 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 51\n",
      "batch: 0 ;B loss: 1.164 ;acc: 0.745 ;iou_acc: 0.840 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.147 ;acc: 0.735 ;iou_acc: 0.820 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.285 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.275 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.236 ;acc: 0.680 ;iou_acc: 0.810 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.303 ;acc: 0.715 ;iou_acc: 0.810 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.186 ;Test accuracy 0.736 ;IOU accuracy: 0.817 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 52 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15445 ;lr: 0.0495 ;B loss: 0.873 ;acc: 0.895 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15495 ;lr: 0.0495 ;B loss: 0.892 ;acc: 0.895 ;iou: 0.945 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15545 ;lr: 0.0495 ;B loss: 1.067 ;acc: 0.865 ;iou: 0.930 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15595 ;lr: 0.0495 ;B loss: 1.149 ;acc: 0.850 ;iou: 0.910 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15645 ;lr: 0.0495 ;B loss: 0.957 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15695 ;lr: 0.0495 ;B loss: 0.997 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.996 ;Train accuracy: 0.895 ;IOU accuracy: 0.933 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 52\n",
      "batch: 0 ;B loss: 1.155 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.138 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.297 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.264 ;acc: 0.705 ;iou_acc: 0.770 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.155 ;acc: 0.705 ;iou_acc: 0.835 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.311 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.188 ;Test accuracy 0.735 ;IOU accuracy: 0.815 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 53 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15742 ;lr: 0.0495 ;B loss: 1.062 ;acc: 0.890 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15792 ;lr: 0.0495 ;B loss: 1.148 ;acc: 0.880 ;iou: 0.905 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15842 ;lr: 0.0495 ;B loss: 1.014 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15892 ;lr: 0.0495 ;B loss: 0.978 ;acc: 0.870 ;iou: 0.925 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15942 ;lr: 0.0495 ;B loss: 0.991 ;acc: 0.885 ;iou: 0.930 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15992 ;lr: 0.0495 ;B loss: 0.925 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.994 ;Train accuracy: 0.896 ;IOU accuracy: 0.934 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 53\n",
      "batch: 0 ;B loss: 1.149 ;acc: 0.745 ;iou_acc: 0.825 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.145 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.260 ;acc: 0.700 ;iou_acc: 0.775 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.279 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.162 ;acc: 0.700 ;iou_acc: 0.835 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.294 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.182 ;Test accuracy 0.737 ;IOU accuracy: 0.817 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 54 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16039 ;lr: 0.0495 ;B loss: 0.965 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16089 ;lr: 0.0495 ;B loss: 0.898 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16139 ;lr: 0.0495 ;B loss: 0.819 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16189 ;lr: 0.0495 ;B loss: 1.301 ;acc: 0.860 ;iou: 0.930 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16239 ;lr: 0.0495 ;B loss: 1.031 ;acc: 0.880 ;iou: 0.910 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16289 ;lr: 0.0495 ;B loss: 0.996 ;acc: 0.875 ;iou: 0.905 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.981 ;Train accuracy: 0.898 ;IOU accuracy: 0.935 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 54\n",
      "batch: 0 ;B loss: 1.120 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.136 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.279 ;acc: 0.710 ;iou_acc: 0.765 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.286 ;acc: 0.730 ;iou_acc: 0.795 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.176 ;acc: 0.690 ;iou_acc: 0.820 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.292 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.179 ;Test accuracy 0.738 ;IOU accuracy: 0.818 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 55 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16336 ;lr: 0.0495 ;B loss: 0.933 ;acc: 0.930 ;iou: 0.970 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16386 ;lr: 0.0495 ;B loss: 0.949 ;acc: 0.905 ;iou: 0.950 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16436 ;lr: 0.0495 ;B loss: 0.845 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16486 ;lr: 0.0495 ;B loss: 1.119 ;acc: 0.885 ;iou: 0.930 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16536 ;lr: 0.0495 ;B loss: 1.107 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16586 ;lr: 0.0495 ;B loss: 1.106 ;acc: 0.910 ;iou: 0.940 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.980 ;Train accuracy: 0.901 ;IOU accuracy: 0.937 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 55\n",
      "batch: 0 ;B loss: 1.120 ;acc: 0.745 ;iou_acc: 0.825 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.145 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.261 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.291 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 1.189 ;acc: 0.690 ;iou_acc: 0.810 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.299 ;acc: 0.745 ;iou_acc: 0.810 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.186 ;Test accuracy 0.736 ;IOU accuracy: 0.816 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 56 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16633 ;lr: 0.0495 ;B loss: 0.928 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16683 ;lr: 0.0495 ;B loss: 1.007 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16733 ;lr: 0.0495 ;B loss: 0.898 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16783 ;lr: 0.0495 ;B loss: 0.897 ;acc: 0.895 ;iou: 0.940 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16833 ;lr: 0.0495 ;B loss: 0.893 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16883 ;lr: 0.0495 ;B loss: 0.961 ;acc: 0.895 ;iou: 0.950 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.965 ;Train accuracy: 0.903 ;IOU accuracy: 0.939 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 56\n",
      "batch: 0 ;B loss: 1.098 ;acc: 0.755 ;iou_acc: 0.830 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.080 ;acc: 0.760 ;iou_acc: 0.830 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.320 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.280 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.217 ;acc: 0.690 ;iou_acc: 0.820 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.261 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.187 ;Test accuracy 0.735 ;IOU accuracy: 0.816 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 57 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16930 ;lr: 0.0495 ;B loss: 0.950 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16980 ;lr: 0.0495 ;B loss: 0.929 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17030 ;lr: 0.0495 ;B loss: 1.006 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17080 ;lr: 0.0495 ;B loss: 0.963 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17130 ;lr: 0.0495 ;B loss: 1.006 ;acc: 0.885 ;iou: 0.935 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17180 ;lr: 0.0495 ;B loss: 1.012 ;acc: 0.865 ;iou: 0.910 ;time: 0:00:55\n",
      "\n",
      "*Training B: True ;B Train loss: 0.962 ;Train accuracy: 0.904 ;IOU accuracy: 0.939 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 57\n",
      "batch: 0 ;B loss: 1.147 ;acc: 0.730 ;iou_acc: 0.810 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.115 ;acc: 0.745 ;iou_acc: 0.830 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.302 ;acc: 0.705 ;iou_acc: 0.770 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.275 ;acc: 0.735 ;iou_acc: 0.790 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.230 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.283 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:01:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.187 ;Test accuracy 0.737 ;IOU accuracy: 0.817 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 58 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17227 ;lr: 0.0495 ;B loss: 0.808 ;acc: 0.910 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17277 ;lr: 0.0495 ;B loss: 0.849 ;acc: 0.940 ;iou: 0.965 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17327 ;lr: 0.0495 ;B loss: 1.139 ;acc: 0.860 ;iou: 0.910 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17377 ;lr: 0.0495 ;B loss: 0.975 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17427 ;lr: 0.0495 ;B loss: 0.852 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17477 ;lr: 0.0495 ;B loss: 1.016 ;acc: 0.900 ;iou: 0.935 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.948 ;Train accuracy: 0.906 ;IOU accuracy: 0.941 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 58\n",
      "batch: 0 ;B loss: 1.134 ;acc: 0.755 ;iou_acc: 0.820 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.146 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.250 ;acc: 0.705 ;iou_acc: 0.765 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.249 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.191 ;acc: 0.685 ;iou_acc: 0.825 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.246 ;acc: 0.750 ;iou_acc: 0.825 ;time: 0:01:52\n",
      "\n",
      "*BTrain: False ;Test loss: 1.182 ;Test accuracy 0.738 ;IOU accuracy: 0.819 ;Time: 0:02:01\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 59 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17524 ;lr: 0.0495 ;B loss: 0.942 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17574 ;lr: 0.0495 ;B loss: 1.047 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17624 ;lr: 0.0495 ;B loss: 1.012 ;acc: 0.875 ;iou: 0.910 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17674 ;lr: 0.0495 ;B loss: 1.057 ;acc: 0.925 ;iou: 0.940 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17724 ;lr: 0.0495 ;B loss: 0.968 ;acc: 0.905 ;iou: 0.930 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17774 ;lr: 0.0495 ;B loss: 0.948 ;acc: 0.885 ;iou: 0.915 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 0.944 ;Train accuracy: 0.909 ;IOU accuracy: 0.943 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 59\n",
      "batch: 0 ;B loss: 1.093 ;acc: 0.780 ;iou_acc: 0.850 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.144 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:01:16\n",
      "batch: 100 ;B loss: 1.276 ;acc: 0.690 ;iou_acc: 0.750 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.272 ;acc: 0.735 ;iou_acc: 0.810 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.168 ;acc: 0.700 ;iou_acc: 0.820 ;time: 0:01:45\n",
      "batch: 250 ;B loss: 1.296 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.177 ;Test accuracy 0.739 ;IOU accuracy: 0.819 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 60 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17821 ;lr: 0.0495 ;B loss: 0.824 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17871 ;lr: 0.0495 ;B loss: 0.921 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17921 ;lr: 0.0495 ;B loss: 0.820 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17971 ;lr: 0.0495 ;B loss: 1.004 ;acc: 0.880 ;iou: 0.905 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18021 ;lr: 0.0495 ;B loss: 0.885 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18071 ;lr: 0.0495 ;B loss: 0.974 ;acc: 0.885 ;iou: 0.920 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.941 ;Train accuracy: 0.910 ;IOU accuracy: 0.944 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 60\n",
      "batch: 0 ;B loss: 1.108 ;acc: 0.760 ;iou_acc: 0.830 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.117 ;acc: 0.735 ;iou_acc: 0.820 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.267 ;acc: 0.695 ;iou_acc: 0.755 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.211 ;acc: 0.745 ;iou_acc: 0.815 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.140 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.327 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.180 ;Test accuracy 0.739 ;IOU accuracy: 0.819 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 61 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18118 ;lr: 0.0495 ;B loss: 0.833 ;acc: 0.920 ;iou: 0.955 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18168 ;lr: 0.0495 ;B loss: 0.978 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18218 ;lr: 0.0495 ;B loss: 1.133 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18268 ;lr: 0.0495 ;B loss: 0.856 ;acc: 0.950 ;iou: 0.965 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18318 ;lr: 0.0495 ;B loss: 1.016 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18368 ;lr: 0.0495 ;B loss: 0.913 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.929 ;Train accuracy: 0.911 ;IOU accuracy: 0.945 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 61\n",
      "batch: 0 ;B loss: 1.127 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.146 ;acc: 0.750 ;iou_acc: 0.840 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.252 ;acc: 0.725 ;iou_acc: 0.785 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.211 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 1.140 ;acc: 0.720 ;iou_acc: 0.835 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.325 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.178 ;Test accuracy 0.739 ;IOU accuracy: 0.820 ;Time: 0:02:01\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 62 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18415 ;lr: 0.0495 ;B loss: 0.918 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18465 ;lr: 0.0495 ;B loss: 0.963 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18515 ;lr: 0.0495 ;B loss: 0.765 ;acc: 0.935 ;iou: 0.960 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18565 ;lr: 0.0495 ;B loss: 0.844 ;acc: 0.925 ;iou: 0.965 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18615 ;lr: 0.0495 ;B loss: 1.040 ;acc: 0.915 ;iou: 0.930 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18665 ;lr: 0.0495 ;B loss: 0.928 ;acc: 0.890 ;iou: 0.925 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.924 ;Train accuracy: 0.914 ;IOU accuracy: 0.946 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 62\n",
      "batch: 0 ;B loss: 1.146 ;acc: 0.760 ;iou_acc: 0.825 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.114 ;acc: 0.745 ;iou_acc: 0.840 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.218 ;acc: 0.725 ;iou_acc: 0.775 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.285 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.169 ;acc: 0.705 ;iou_acc: 0.830 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.312 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.186 ;Test accuracy 0.738 ;IOU accuracy: 0.818 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 63 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18712 ;lr: 0.0495 ;B loss: 1.095 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18762 ;lr: 0.0495 ;B loss: 0.965 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18812 ;lr: 0.0495 ;B loss: 0.900 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18862 ;lr: 0.0495 ;B loss: 0.895 ;acc: 0.910 ;iou: 0.950 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18912 ;lr: 0.0495 ;B loss: 0.906 ;acc: 0.930 ;iou: 0.955 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18962 ;lr: 0.0495 ;B loss: 0.874 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.918 ;Train accuracy: 0.916 ;IOU accuracy: 0.948 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 63\n",
      "batch: 0 ;B loss: 1.120 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:04\n",
      "batch: 50 ;B loss: 1.114 ;acc: 0.750 ;iou_acc: 0.830 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.289 ;acc: 0.700 ;iou_acc: 0.760 ;time: 0:01:23\n",
      "batch: 150 ;B loss: 1.287 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:01:33\n",
      "batch: 200 ;B loss: 1.139 ;acc: 0.720 ;iou_acc: 0.845 ;time: 0:01:42\n",
      "batch: 250 ;B loss: 1.294 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:01:52\n",
      "\n",
      "*BTrain: True ;Test loss: 1.177 ;Test accuracy 0.741 ;IOU accuracy: 0.820 ;Time: 0:02:01\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 64 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19009 ;lr: 0.0495 ;B loss: 1.030 ;acc: 0.895 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19059 ;lr: 0.0495 ;B loss: 0.757 ;acc: 0.945 ;iou: 0.960 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19109 ;lr: 0.0495 ;B loss: 0.897 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19159 ;lr: 0.0495 ;B loss: 1.076 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19209 ;lr: 0.0495 ;B loss: 0.958 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19259 ;lr: 0.0495 ;B loss: 0.715 ;acc: 0.950 ;iou: 0.955 ;time: 0:00:55\n",
      "\n",
      "*Training B: False ;B Train loss: 0.919 ;Train accuracy: 0.916 ;IOU accuracy: 0.947 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 64\n",
      "batch: 0 ;B loss: 1.109 ;acc: 0.740 ;iou_acc: 0.805 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.110 ;acc: 0.740 ;iou_acc: 0.835 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.275 ;acc: 0.705 ;iou_acc: 0.765 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.333 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.205 ;acc: 0.705 ;iou_acc: 0.820 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.301 ;acc: 0.710 ;iou_acc: 0.805 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.182 ;Test accuracy 0.740 ;IOU accuracy: 0.819 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 65 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19306 ;lr: 0.0495 ;B loss: 0.882 ;acc: 0.920 ;iou: 0.965 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19356 ;lr: 0.0495 ;B loss: 0.783 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19406 ;lr: 0.0495 ;B loss: 1.068 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19456 ;lr: 0.0495 ;B loss: 0.969 ;acc: 0.885 ;iou: 0.925 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19506 ;lr: 0.0495 ;B loss: 0.809 ;acc: 0.925 ;iou: 0.950 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19556 ;lr: 0.0495 ;B loss: 0.873 ;acc: 0.940 ;iou: 0.970 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.905 ;Train accuracy: 0.919 ;IOU accuracy: 0.950 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 65\n",
      "batch: 0 ;B loss: 1.134 ;acc: 0.750 ;iou_acc: 0.825 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.131 ;acc: 0.725 ;iou_acc: 0.820 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.270 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.283 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.185 ;acc: 0.710 ;iou_acc: 0.830 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.308 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.177 ;Test accuracy 0.740 ;IOU accuracy: 0.820 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 66 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19603 ;lr: 0.0495 ;B loss: 0.950 ;acc: 0.905 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19653 ;lr: 0.0495 ;B loss: 0.960 ;acc: 0.920 ;iou: 0.950 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19703 ;lr: 0.0495 ;B loss: 0.982 ;acc: 0.920 ;iou: 0.935 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19753 ;lr: 0.0495 ;B loss: 0.989 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19803 ;lr: 0.0495 ;B loss: 0.729 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19853 ;lr: 0.0495 ;B loss: 0.970 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.906 ;Train accuracy: 0.919 ;IOU accuracy: 0.950 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 66\n",
      "batch: 0 ;B loss: 1.110 ;acc: 0.745 ;iou_acc: 0.815 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.124 ;acc: 0.730 ;iou_acc: 0.815 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.271 ;acc: 0.720 ;iou_acc: 0.780 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.309 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.177 ;acc: 0.715 ;iou_acc: 0.835 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.319 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.175 ;Test accuracy 0.741 ;IOU accuracy: 0.821 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 67 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19900 ;lr: 0.0495 ;B loss: 0.933 ;acc: 0.910 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19950 ;lr: 0.0495 ;B loss: 0.979 ;acc: 0.925 ;iou: 0.960 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20000 ;lr: 0.0495 ;B loss: 0.905 ;acc: 0.925 ;iou: 0.970 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20050 ;lr: 0.0490 ;B loss: 0.915 ;acc: 0.920 ;iou: 0.960 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20100 ;lr: 0.0490 ;B loss: 0.799 ;acc: 0.950 ;iou: 0.960 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20150 ;lr: 0.0490 ;B loss: 0.878 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.894 ;Train accuracy: 0.922 ;IOU accuracy: 0.951 ;Time: 0:01:05 \n",
      "\n",
      "Testing, ephoc: 67\n",
      "batch: 0 ;B loss: 1.080 ;acc: 0.750 ;iou_acc: 0.820 ;time: 0:01:06\n",
      "batch: 50 ;B loss: 1.098 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:01:15\n",
      "batch: 100 ;B loss: 1.323 ;acc: 0.715 ;iou_acc: 0.765 ;time: 0:01:25\n",
      "batch: 150 ;B loss: 1.238 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:01:35\n",
      "batch: 200 ;B loss: 1.169 ;acc: 0.700 ;iou_acc: 0.815 ;time: 0:01:44\n",
      "batch: 250 ;B loss: 1.274 ;acc: 0.735 ;iou_acc: 0.825 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.180 ;Test accuracy 0.740 ;IOU accuracy: 0.820 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 68 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20197 ;lr: 0.0490 ;B loss: 0.795 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20247 ;lr: 0.0490 ;B loss: 0.824 ;acc: 0.950 ;iou: 0.980 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20297 ;lr: 0.0490 ;B loss: 0.940 ;acc: 0.900 ;iou: 0.945 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20347 ;lr: 0.0490 ;B loss: 0.914 ;acc: 0.915 ;iou: 0.950 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20397 ;lr: 0.0490 ;B loss: 0.952 ;acc: 0.910 ;iou: 0.945 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20447 ;lr: 0.0490 ;B loss: 0.863 ;acc: 0.920 ;iou: 0.940 ;time: 0:00:54\n",
      "\n",
      "*Training B: False ;B Train loss: 0.893 ;Train accuracy: 0.924 ;IOU accuracy: 0.953 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 68\n",
      "batch: 0 ;B loss: 1.115 ;acc: 0.755 ;iou_acc: 0.815 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.153 ;acc: 0.745 ;iou_acc: 0.830 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.277 ;acc: 0.715 ;iou_acc: 0.775 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.308 ;acc: 0.720 ;iou_acc: 0.775 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.220 ;acc: 0.680 ;iou_acc: 0.810 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.305 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:01:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.194 ;Test accuracy 0.739 ;IOU accuracy: 0.819 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 69 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20494 ;lr: 0.0490 ;B loss: 0.808 ;acc: 0.940 ;iou: 0.980 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20544 ;lr: 0.0490 ;B loss: 0.810 ;acc: 0.970 ;iou: 0.990 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20594 ;lr: 0.0490 ;B loss: 0.965 ;acc: 0.915 ;iou: 0.930 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20644 ;lr: 0.0490 ;B loss: 1.088 ;acc: 0.920 ;iou: 0.960 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20694 ;lr: 0.0490 ;B loss: 0.874 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20744 ;lr: 0.0490 ;B loss: 0.818 ;acc: 0.940 ;iou: 0.955 ;time: 0:00:54\n",
      "\n",
      "*Training B: True ;B Train loss: 0.887 ;Train accuracy: 0.925 ;IOU accuracy: 0.954 ;Time: 0:01:04 \n",
      "\n",
      "Testing, ephoc: 69\n",
      "batch: 0 ;B loss: 1.069 ;acc: 0.770 ;iou_acc: 0.835 ;time: 0:01:05\n",
      "batch: 50 ;B loss: 1.120 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:01:14\n",
      "batch: 100 ;B loss: 1.279 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:01:24\n",
      "batch: 150 ;B loss: 1.263 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:01:34\n",
      "batch: 200 ;B loss: 1.172 ;acc: 0.705 ;iou_acc: 0.835 ;time: 0:01:43\n",
      "batch: 250 ;B loss: 1.316 ;acc: 0.750 ;iou_acc: 0.830 ;time: 0:01:53\n",
      "\n",
      "*BTrain: True ;Test loss: 1.186 ;Test accuracy 0.742 ;IOU accuracy: 0.820 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "**************************************************************************************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropout_in +  dropout_out + drop_img\n",
    "dimg_bnorm_test_res, dimg_bnorm_train_res = [], []\n",
    "num_hidden=200\n",
    "drpos_ratio = [[0.5, 1.], [1., 0.5], [.5,.5]]\n",
    "for drops in drpos_ratio:\n",
    "    dropout_in, dropout_out = drops\n",
    "    params_dir = params_dir_tmp+'bnorm_base/img_drop_'+str(dropout_in)+','+str(dropout_out)+'_hidden:'+str(num_hidden)\n",
    "    tf.reset_default_graph()\n",
    "    m = Model(\n",
    "        batch_size=200, \n",
    "        num_hidden=num_hidden,\n",
    "        embed_size=embed_vecs.shape[1],,\n",
    "        img_dims=trainset[0][0][1][0].shape[1], \n",
    "        bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "        lr=.05,\n",
    "        vocab=vocab, \n",
    "        decay_steps=10000, \n",
    "        decay_rate=0.99, \n",
    "        edit_reward=0.,\n",
    "        rnn_editProb=0.,\n",
    "        coefAlr=1,\n",
    "        bnorm=True)\n",
    "\n",
    "\n",
    "    # start comp\n",
    "    print('dropout_in', dropout_in)\n",
    "    print('dropout_out', dropout_out)\n",
    "    print('params_dir:', params_dir)\n",
    "    print('num_hidden:', m.num_hidden)\n",
    "    print('learning rate:', m.lr)\n",
    "    tst, trn = m.train(trainset, testset,\n",
    "            ephocs_num=70,\n",
    "            start_ephoc=0,\n",
    "            startA=71,\n",
    "            activation_ephoc=71,\n",
    "            muteB=0, \n",
    "            activateAProb=0,\n",
    "            max_activateAProb=0,\n",
    "            editProb=0,\n",
    "            edit_reward=0,\n",
    "            dropout_img=0.5,\n",
    "            dropout_in=dropout_in,\n",
    "            dropout_out=dropout_out)\n",
    "\n",
    "    dimg_bnorm_test_res.append(tst)\n",
    "    dimg_bnorm_train_res.append(trn)\n",
    "    print('\\n'+'*'*100)\n",
    "    print('*'*100)\n",
    "    print('*'*100,'\\n')                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Augmenting data\n",
    "<p>This is a mass </p>\n",
    "<p>Didn't really arange it proparly yet but you can see the results.</p>\n",
    "<p>The overfitting actually gets worse some how. The only difference is that the probability for the true bbox gets smaller so we get high IOU even for relative high loss.<br>\n",
    "Interestly, at some point I stoped the training on the Augmented data and start over again with the normal size data. We still have overfitting and the training IOU gets smaller while the testing IOU gets stucked, but the thing is that now the training learning rate gets smaller, i.e. we can see the loss gets smaller but in a very slow rate.</p>\n",
    "\n",
    "<p>Any way, might be a stupid idea</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59449\n",
      "89173\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 89173\n",
      "# Training batches: 445\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Initializing variables\n",
      "================================================== \n",
      "Train, ephoc: 0 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1 ;lr: 0.0500 ;B loss: 3.035 ;acc: 0.250 ;iou: 0.365 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 51 ;lr: 0.0500 ;B loss: 2.473 ;acc: 0.225 ;iou: 0.350 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 101 ;lr: 0.0500 ;B loss: 2.480 ;acc: 0.220 ;iou: 0.325 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 151 ;lr: 0.0500 ;B loss: 2.445 ;acc: 0.190 ;iou: 0.295 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 201 ;lr: 0.0500 ;B loss: 2.514 ;acc: 0.170 ;iou: 0.295 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 251 ;lr: 0.0500 ;B loss: 2.591 ;acc: 0.180 ;iou: 0.280 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 301 ;lr: 0.0500 ;B loss: 2.503 ;acc: 0.250 ;iou: 0.345 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 351 ;lr: 0.0500 ;B loss: 2.569 ;acc: 0.200 ;iou: 0.320 ;time: 0:01:03\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 401 ;lr: 0.0500 ;B loss: 2.476 ;acc: 0.230 ;iou: 0.270 ;time: 0:01:11\n",
      "\n",
      "*Training B: True ;B Train loss: 2.538 ;Train accuracy: 0.231 ;IOU accuracy: 0.331 ;Time: 0:01:19 \n",
      "\n",
      "Testing, ephoc: 0\n",
      "batch: 0 ;B loss: 2.412 ;acc: 0.230 ;iou_acc: 0.325 ;time: 0:01:20\n",
      "batch: 50 ;B loss: 2.439 ;acc: 0.220 ;iou_acc: 0.315 ;time: 0:01:28\n",
      "batch: 100 ;B loss: 2.405 ;acc: 0.225 ;iou_acc: 0.315 ;time: 0:01:35\n",
      "batch: 150 ;B loss: 2.435 ;acc: 0.230 ;iou_acc: 0.365 ;time: 0:01:42\n",
      "batch: 200 ;B loss: 2.401 ;acc: 0.230 ;iou_acc: 0.360 ;time: 0:01:50\n",
      "batch: 250 ;B loss: 2.468 ;acc: 0.215 ;iou_acc: 0.370 ;time: 0:01:58\n",
      "\n",
      "*BTrain: True ;Test loss: 2.429 ;Test accuracy 0.230 ;IOU accuracy: 0.340 ;Time: 0:02:05\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 1 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 446 ;lr: 0.0500 ;B loss: 2.504 ;acc: 0.255 ;iou: 0.350 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 496 ;lr: 0.0500 ;B loss: 2.508 ;acc: 0.240 ;iou: 0.325 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 546 ;lr: 0.0500 ;B loss: 2.516 ;acc: 0.260 ;iou: 0.350 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 596 ;lr: 0.0500 ;B loss: 2.471 ;acc: 0.265 ;iou: 0.345 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 646 ;lr: 0.0500 ;B loss: 2.530 ;acc: 0.255 ;iou: 0.360 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 696 ;lr: 0.0500 ;B loss: 2.450 ;acc: 0.305 ;iou: 0.400 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 746 ;lr: 0.0500 ;B loss: 2.450 ;acc: 0.295 ;iou: 0.450 ;time: 0:00:51\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 796 ;lr: 0.0500 ;B loss: 2.503 ;acc: 0.350 ;iou: 0.445 ;time: 0:01:00\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 846 ;lr: 0.0500 ;B loss: 2.483 ;acc: 0.255 ;iou: 0.315 ;time: 0:01:09\n",
      "\n",
      "*Training B: False ;B Train loss: 2.515 ;Train accuracy: 0.259 ;IOU accuracy: 0.362 ;Time: 0:01:16 \n",
      "\n",
      "Testing, ephoc: 1\n",
      "batch: 0 ;B loss: 2.358 ;acc: 0.290 ;iou_acc: 0.390 ;time: 0:01:17\n",
      "batch: 50 ;B loss: 2.386 ;acc: 0.245 ;iou_acc: 0.355 ;time: 0:01:24\n",
      "batch: 100 ;B loss: 2.397 ;acc: 0.205 ;iou_acc: 0.300 ;time: 0:01:32\n",
      "batch: 150 ;B loss: 2.400 ;acc: 0.300 ;iou_acc: 0.405 ;time: 0:01:39\n",
      "batch: 200 ;B loss: 2.359 ;acc: 0.265 ;iou_acc: 0.400 ;time: 0:01:46\n",
      "batch: 250 ;B loss: 2.431 ;acc: 0.265 ;iou_acc: 0.380 ;time: 0:01:54\n",
      "\n",
      "*BTrain: False ;Test loss: 2.379 ;Test accuracy 0.286 ;IOU accuracy: 0.398 ;Time: 0:02:01\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 2 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 891 ;lr: 0.0500 ;B loss: 2.405 ;acc: 0.295 ;iou: 0.390 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 941 ;lr: 0.0500 ;B loss: 2.496 ;acc: 0.285 ;iou: 0.350 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 991 ;lr: 0.0500 ;B loss: 2.375 ;acc: 0.300 ;iou: 0.420 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1041 ;lr: 0.0500 ;B loss: 2.517 ;acc: 0.270 ;iou: 0.360 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1091 ;lr: 0.0500 ;B loss: 2.499 ;acc: 0.280 ;iou: 0.385 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1141 ;lr: 0.0500 ;B loss: 2.429 ;acc: 0.290 ;iou: 0.360 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 1191 ;lr: 0.0500 ;B loss: 2.519 ;acc: 0.180 ;iou: 0.350 ;time: 0:00:56\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 1241 ;lr: 0.0500 ;B loss: 2.499 ;acc: 0.305 ;iou: 0.385 ;time: 0:01:05\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 1291 ;lr: 0.0500 ;B loss: 2.499 ;acc: 0.250 ;iou: 0.405 ;time: 0:01:14\n",
      "\n",
      "*Training B: False ;B Train loss: 2.484 ;Train accuracy: 0.297 ;IOU accuracy: 0.399 ;Time: 0:01:21 \n",
      "\n",
      "Testing, ephoc: 2\n",
      "batch: 0 ;B loss: 2.254 ;acc: 0.395 ;iou_acc: 0.475 ;time: 0:01:22\n",
      "batch: 50 ;B loss: 2.324 ;acc: 0.320 ;iou_acc: 0.430 ;time: 0:01:30\n",
      "batch: 100 ;B loss: 2.382 ;acc: 0.250 ;iou_acc: 0.315 ;time: 0:01:38\n",
      "batch: 150 ;B loss: 2.354 ;acc: 0.295 ;iou_acc: 0.390 ;time: 0:01:45\n",
      "batch: 200 ;B loss: 2.295 ;acc: 0.310 ;iou_acc: 0.425 ;time: 0:01:53\n",
      "batch: 250 ;B loss: 2.363 ;acc: 0.360 ;iou_acc: 0.510 ;time: 0:02:01\n",
      "\n",
      "*BTrain: False ;Test loss: 2.310 ;Test accuracy 0.341 ;IOU accuracy: 0.454 ;Time: 0:02:09\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 3 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1336 ;lr: 0.0500 ;B loss: 2.445 ;acc: 0.285 ;iou: 0.385 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1386 ;lr: 0.0500 ;B loss: 2.426 ;acc: 0.280 ;iou: 0.420 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1436 ;lr: 0.0500 ;B loss: 2.370 ;acc: 0.300 ;iou: 0.445 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1486 ;lr: 0.0500 ;B loss: 2.454 ;acc: 0.270 ;iou: 0.390 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1536 ;lr: 0.0500 ;B loss: 2.430 ;acc: 0.305 ;iou: 0.405 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 1586 ;lr: 0.0500 ;B loss: 2.443 ;acc: 0.355 ;iou: 0.490 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 1636 ;lr: 0.0500 ;B loss: 2.508 ;acc: 0.385 ;iou: 0.490 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 1686 ;lr: 0.0500 ;B loss: 2.476 ;acc: 0.335 ;iou: 0.410 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 1736 ;lr: 0.0500 ;B loss: 2.488 ;acc: 0.335 ;iou: 0.440 ;time: 0:01:11\n",
      "\n",
      "*Training B: True ;B Train loss: 2.461 ;Train accuracy: 0.322 ;IOU accuracy: 0.425 ;Time: 0:01:19 \n",
      "\n",
      "Testing, ephoc: 3\n",
      "batch: 0 ;B loss: 2.223 ;acc: 0.410 ;iou_acc: 0.520 ;time: 0:01:20\n",
      "batch: 50 ;B loss: 2.273 ;acc: 0.355 ;iou_acc: 0.485 ;time: 0:01:28\n",
      "batch: 100 ;B loss: 2.349 ;acc: 0.280 ;iou_acc: 0.395 ;time: 0:01:35\n",
      "batch: 150 ;B loss: 2.320 ;acc: 0.390 ;iou_acc: 0.500 ;time: 0:01:44\n",
      "batch: 200 ;B loss: 2.256 ;acc: 0.375 ;iou_acc: 0.495 ;time: 0:01:52\n",
      "batch: 250 ;B loss: 2.333 ;acc: 0.330 ;iou_acc: 0.490 ;time: 0:02:00\n",
      "\n",
      "*BTrain: True ;Test loss: 2.275 ;Test accuracy 0.374 ;IOU accuracy: 0.488 ;Time: 0:02:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 4 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 1781 ;lr: 0.0500 ;B loss: 2.540 ;acc: 0.345 ;iou: 0.405 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 1831 ;lr: 0.0500 ;B loss: 2.347 ;acc: 0.355 ;iou: 0.435 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 1881 ;lr: 0.0500 ;B loss: 2.498 ;acc: 0.320 ;iou: 0.420 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 1931 ;lr: 0.0500 ;B loss: 2.539 ;acc: 0.345 ;iou: 0.460 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 1981 ;lr: 0.0500 ;B loss: 2.440 ;acc: 0.345 ;iou: 0.450 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2031 ;lr: 0.0500 ;B loss: 2.396 ;acc: 0.380 ;iou: 0.450 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 2081 ;lr: 0.0500 ;B loss: 2.297 ;acc: 0.340 ;iou: 0.425 ;time: 0:00:52\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 2131 ;lr: 0.0500 ;B loss: 2.471 ;acc: 0.320 ;iou: 0.450 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 2181 ;lr: 0.0500 ;B loss: 2.312 ;acc: 0.390 ;iou: 0.485 ;time: 0:01:10\n",
      "\n",
      "*Training B: False ;B Train loss: 2.446 ;Train accuracy: 0.341 ;IOU accuracy: 0.444 ;Time: 0:01:18 \n",
      "\n",
      "Testing, ephoc: 4\n",
      "batch: 0 ;B loss: 2.215 ;acc: 0.410 ;iou_acc: 0.500 ;time: 0:01:19\n",
      "batch: 50 ;B loss: 2.230 ;acc: 0.375 ;iou_acc: 0.480 ;time: 0:01:26\n",
      "batch: 100 ;B loss: 2.321 ;acc: 0.305 ;iou_acc: 0.415 ;time: 0:01:33\n",
      "batch: 150 ;B loss: 2.290 ;acc: 0.360 ;iou_acc: 0.475 ;time: 0:01:41\n",
      "batch: 200 ;B loss: 2.224 ;acc: 0.390 ;iou_acc: 0.510 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 2.287 ;acc: 0.415 ;iou_acc: 0.590 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 2.241 ;Test accuracy 0.399 ;IOU accuracy: 0.512 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 5 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2226 ;lr: 0.0500 ;B loss: 2.455 ;acc: 0.335 ;iou: 0.400 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2276 ;lr: 0.0500 ;B loss: 2.465 ;acc: 0.360 ;iou: 0.445 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2326 ;lr: 0.0500 ;B loss: 2.619 ;acc: 0.310 ;iou: 0.425 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2376 ;lr: 0.0500 ;B loss: 2.385 ;acc: 0.400 ;iou: 0.480 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2426 ;lr: 0.0500 ;B loss: 2.409 ;acc: 0.405 ;iou: 0.510 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2476 ;lr: 0.0500 ;B loss: 2.424 ;acc: 0.380 ;iou: 0.450 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 2526 ;lr: 0.0500 ;B loss: 2.482 ;acc: 0.300 ;iou: 0.430 ;time: 0:00:50\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 2576 ;lr: 0.0500 ;B loss: 2.489 ;acc: 0.380 ;iou: 0.490 ;time: 0:00:59\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 2626 ;lr: 0.0500 ;B loss: 2.453 ;acc: 0.280 ;iou: 0.400 ;time: 0:01:09\n",
      "\n",
      "*Training B: False ;B Train loss: 2.431 ;Train accuracy: 0.361 ;IOU accuracy: 0.464 ;Time: 0:01:16 \n",
      "\n",
      "Testing, ephoc: 5\n",
      "batch: 0 ;B loss: 2.183 ;acc: 0.410 ;iou_acc: 0.505 ;time: 0:01:17\n",
      "batch: 50 ;B loss: 2.206 ;acc: 0.405 ;iou_acc: 0.525 ;time: 0:01:24\n",
      "batch: 100 ;B loss: 2.294 ;acc: 0.390 ;iou_acc: 0.475 ;time: 0:01:32\n",
      "batch: 150 ;B loss: 2.273 ;acc: 0.395 ;iou_acc: 0.510 ;time: 0:01:40\n",
      "batch: 200 ;B loss: 2.195 ;acc: 0.385 ;iou_acc: 0.530 ;time: 0:01:47\n",
      "batch: 250 ;B loss: 2.255 ;acc: 0.405 ;iou_acc: 0.565 ;time: 0:01:55\n",
      "\n",
      "*BTrain: False ;Test loss: 2.208 ;Test accuracy 0.429 ;IOU accuracy: 0.544 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 6 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 2671 ;lr: 0.0500 ;B loss: 2.377 ;acc: 0.425 ;iou: 0.540 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 2721 ;lr: 0.0500 ;B loss: 2.435 ;acc: 0.350 ;iou: 0.485 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 2771 ;lr: 0.0500 ;B loss: 2.455 ;acc: 0.380 ;iou: 0.500 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 2821 ;lr: 0.0500 ;B loss: 2.370 ;acc: 0.435 ;iou: 0.530 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 2871 ;lr: 0.0500 ;B loss: 2.474 ;acc: 0.340 ;iou: 0.440 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 2921 ;lr: 0.0500 ;B loss: 2.456 ;acc: 0.330 ;iou: 0.415 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 2971 ;lr: 0.0500 ;B loss: 2.483 ;acc: 0.375 ;iou: 0.490 ;time: 0:00:52\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 3021 ;lr: 0.0500 ;B loss: 2.480 ;acc: 0.425 ;iou: 0.530 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 3071 ;lr: 0.0500 ;B loss: 2.447 ;acc: 0.380 ;iou: 0.490 ;time: 0:01:09\n",
      "\n",
      "*Training B: True ;B Train loss: 2.413 ;Train accuracy: 0.381 ;IOU accuracy: 0.481 ;Time: 0:01:17 \n",
      "\n",
      "Testing, ephoc: 6\n",
      "batch: 0 ;B loss: 2.157 ;acc: 0.445 ;iou_acc: 0.550 ;time: 0:01:18\n",
      "batch: 50 ;B loss: 2.165 ;acc: 0.435 ;iou_acc: 0.550 ;time: 0:01:25\n",
      "batch: 100 ;B loss: 2.246 ;acc: 0.435 ;iou_acc: 0.535 ;time: 0:01:33\n",
      "batch: 150 ;B loss: 2.237 ;acc: 0.430 ;iou_acc: 0.535 ;time: 0:01:40\n",
      "batch: 200 ;B loss: 2.164 ;acc: 0.405 ;iou_acc: 0.560 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 2.211 ;acc: 0.485 ;iou_acc: 0.630 ;time: 0:01:55\n",
      "\n",
      "*BTrain: True ;Test loss: 2.175 ;Test accuracy 0.458 ;IOU accuracy: 0.567 ;Time: 0:02:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 7 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3116 ;lr: 0.0500 ;B loss: 2.470 ;acc: 0.395 ;iou: 0.525 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3166 ;lr: 0.0500 ;B loss: 2.409 ;acc: 0.385 ;iou: 0.485 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3216 ;lr: 0.0500 ;B loss: 2.426 ;acc: 0.410 ;iou: 0.465 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3266 ;lr: 0.0500 ;B loss: 2.344 ;acc: 0.390 ;iou: 0.465 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3316 ;lr: 0.0500 ;B loss: 2.389 ;acc: 0.375 ;iou: 0.475 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3366 ;lr: 0.0500 ;B loss: 2.284 ;acc: 0.395 ;iou: 0.485 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 3416 ;lr: 0.0500 ;B loss: 2.520 ;acc: 0.355 ;iou: 0.470 ;time: 0:00:54\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 3466 ;lr: 0.0500 ;B loss: 2.364 ;acc: 0.400 ;iou: 0.495 ;time: 0:01:03\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 3516 ;lr: 0.0500 ;B loss: 2.382 ;acc: 0.360 ;iou: 0.450 ;time: 0:01:12\n",
      "\n",
      "*Training B: False ;B Train loss: 2.397 ;Train accuracy: 0.396 ;IOU accuracy: 0.495 ;Time: 0:01:20 \n",
      "\n",
      "Testing, ephoc: 7\n",
      "batch: 0 ;B loss: 2.135 ;acc: 0.455 ;iou_acc: 0.565 ;time: 0:01:21\n",
      "batch: 50 ;B loss: 2.120 ;acc: 0.470 ;iou_acc: 0.565 ;time: 0:01:29\n",
      "batch: 100 ;B loss: 2.227 ;acc: 0.435 ;iou_acc: 0.540 ;time: 0:01:36\n",
      "batch: 150 ;B loss: 2.206 ;acc: 0.435 ;iou_acc: 0.550 ;time: 0:01:44\n",
      "batch: 200 ;B loss: 2.134 ;acc: 0.440 ;iou_acc: 0.575 ;time: 0:01:51\n",
      "batch: 250 ;B loss: 2.170 ;acc: 0.505 ;iou_acc: 0.645 ;time: 0:01:59\n",
      "\n",
      "*BTrain: False ;Test loss: 2.142 ;Test accuracy 0.475 ;IOU accuracy: 0.581 ;Time: 0:02:06\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 8 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 3561 ;lr: 0.0500 ;B loss: 2.371 ;acc: 0.440 ;iou: 0.525 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 3611 ;lr: 0.0500 ;B loss: 2.457 ;acc: 0.430 ;iou: 0.510 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 3661 ;lr: 0.0500 ;B loss: 2.290 ;acc: 0.410 ;iou: 0.525 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 3711 ;lr: 0.0500 ;B loss: 2.468 ;acc: 0.355 ;iou: 0.470 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 3761 ;lr: 0.0500 ;B loss: 2.321 ;acc: 0.475 ;iou: 0.585 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 3811 ;lr: 0.0500 ;B loss: 2.363 ;acc: 0.435 ;iou: 0.530 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 3861 ;lr: 0.0500 ;B loss: 2.290 ;acc: 0.375 ;iou: 0.485 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 3911 ;lr: 0.0500 ;B loss: 2.308 ;acc: 0.450 ;iou: 0.530 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 3961 ;lr: 0.0500 ;B loss: 2.405 ;acc: 0.405 ;iou: 0.485 ;time: 0:01:10\n",
      "\n",
      "*Training B: False ;B Train loss: 2.382 ;Train accuracy: 0.409 ;IOU accuracy: 0.507 ;Time: 0:01:17 \n",
      "\n",
      "Testing, ephoc: 8\n",
      "batch: 0 ;B loss: 2.102 ;acc: 0.490 ;iou_acc: 0.590 ;time: 0:01:18\n",
      "batch: 50 ;B loss: 2.086 ;acc: 0.505 ;iou_acc: 0.600 ;time: 0:01:25\n",
      "batch: 100 ;B loss: 2.201 ;acc: 0.440 ;iou_acc: 0.520 ;time: 0:01:33\n",
      "batch: 150 ;B loss: 2.179 ;acc: 0.480 ;iou_acc: 0.575 ;time: 0:01:41\n",
      "batch: 200 ;B loss: 2.101 ;acc: 0.470 ;iou_acc: 0.600 ;time: 0:01:48\n",
      "batch: 250 ;B loss: 2.130 ;acc: 0.515 ;iou_acc: 0.635 ;time: 0:01:56\n",
      "\n",
      "*BTrain: False ;Test loss: 2.116 ;Test accuracy 0.492 ;IOU accuracy: 0.595 ;Time: 0:02:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 9 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4006 ;lr: 0.0500 ;B loss: 2.363 ;acc: 0.440 ;iou: 0.545 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4056 ;lr: 0.0500 ;B loss: 2.557 ;acc: 0.380 ;iou: 0.510 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4106 ;lr: 0.0500 ;B loss: 2.301 ;acc: 0.400 ;iou: 0.495 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4156 ;lr: 0.0500 ;B loss: 2.302 ;acc: 0.435 ;iou: 0.505 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4206 ;lr: 0.0500 ;B loss: 2.301 ;acc: 0.450 ;iou: 0.550 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4256 ;lr: 0.0500 ;B loss: 2.299 ;acc: 0.460 ;iou: 0.555 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 4306 ;lr: 0.0500 ;B loss: 2.307 ;acc: 0.455 ;iou: 0.540 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 4356 ;lr: 0.0500 ;B loss: 2.292 ;acc: 0.380 ;iou: 0.470 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 4406 ;lr: 0.0500 ;B loss: 2.346 ;acc: 0.420 ;iou: 0.525 ;time: 0:01:11\n",
      "\n",
      "*Training B: True ;B Train loss: 2.371 ;Train accuracy: 0.418 ;IOU accuracy: 0.513 ;Time: 0:01:18 \n",
      "\n",
      "Testing, ephoc: 9\n",
      "batch: 0 ;B loss: 2.071 ;acc: 0.535 ;iou_acc: 0.625 ;time: 0:01:19\n",
      "batch: 50 ;B loss: 2.070 ;acc: 0.530 ;iou_acc: 0.595 ;time: 0:01:26\n",
      "batch: 100 ;B loss: 2.170 ;acc: 0.475 ;iou_acc: 0.560 ;time: 0:01:34\n",
      "batch: 150 ;B loss: 2.158 ;acc: 0.505 ;iou_acc: 0.600 ;time: 0:01:42\n",
      "batch: 200 ;B loss: 2.096 ;acc: 0.450 ;iou_acc: 0.605 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 2.105 ;acc: 0.525 ;iou_acc: 0.640 ;time: 0:01:57\n",
      "\n",
      "*BTrain: True ;Test loss: 2.097 ;Test accuracy 0.504 ;IOU accuracy: 0.606 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 10 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4451 ;lr: 0.0500 ;B loss: 2.427 ;acc: 0.370 ;iou: 0.525 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4501 ;lr: 0.0500 ;B loss: 2.290 ;acc: 0.470 ;iou: 0.545 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4551 ;lr: 0.0500 ;B loss: 2.291 ;acc: 0.375 ;iou: 0.525 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 4601 ;lr: 0.0500 ;B loss: 2.382 ;acc: 0.410 ;iou: 0.475 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 4651 ;lr: 0.0500 ;B loss: 2.497 ;acc: 0.435 ;iou: 0.555 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 4701 ;lr: 0.0500 ;B loss: 2.311 ;acc: 0.490 ;iou: 0.575 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 4751 ;lr: 0.0500 ;B loss: 2.359 ;acc: 0.435 ;iou: 0.525 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 4801 ;lr: 0.0500 ;B loss: 2.361 ;acc: 0.470 ;iou: 0.545 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 4851 ;lr: 0.0500 ;B loss: 2.339 ;acc: 0.495 ;iou: 0.595 ;time: 0:01:11\n",
      "\n",
      "*Training B: False ;B Train loss: 2.359 ;Train accuracy: 0.425 ;IOU accuracy: 0.520 ;Time: 0:01:19 \n",
      "\n",
      "Testing, ephoc: 10\n",
      "batch: 0 ;B loss: 2.054 ;acc: 0.530 ;iou_acc: 0.615 ;time: 0:01:19\n",
      "batch: 50 ;B loss: 2.040 ;acc: 0.520 ;iou_acc: 0.595 ;time: 0:01:27\n",
      "batch: 100 ;B loss: 2.153 ;acc: 0.455 ;iou_acc: 0.540 ;time: 0:01:34\n",
      "batch: 150 ;B loss: 2.140 ;acc: 0.500 ;iou_acc: 0.580 ;time: 0:01:41\n",
      "batch: 200 ;B loss: 2.059 ;acc: 0.490 ;iou_acc: 0.600 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 2.077 ;acc: 0.550 ;iou_acc: 0.655 ;time: 0:01:56\n",
      "\n",
      "*BTrain: False ;Test loss: 2.074 ;Test accuracy 0.512 ;IOU accuracy: 0.613 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 11 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 4896 ;lr: 0.0500 ;B loss: 2.384 ;acc: 0.430 ;iou: 0.520 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 4946 ;lr: 0.0500 ;B loss: 2.345 ;acc: 0.500 ;iou: 0.585 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 4996 ;lr: 0.0500 ;B loss: 2.426 ;acc: 0.385 ;iou: 0.485 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5046 ;lr: 0.0500 ;B loss: 2.358 ;acc: 0.400 ;iou: 0.515 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5096 ;lr: 0.0500 ;B loss: 2.399 ;acc: 0.430 ;iou: 0.545 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5146 ;lr: 0.0500 ;B loss: 2.444 ;acc: 0.360 ;iou: 0.445 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 5196 ;lr: 0.0500 ;B loss: 2.457 ;acc: 0.450 ;iou: 0.550 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 5246 ;lr: 0.0500 ;B loss: 2.425 ;acc: 0.435 ;iou: 0.520 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 5296 ;lr: 0.0500 ;B loss: 2.370 ;acc: 0.395 ;iou: 0.500 ;time: 0:01:11\n",
      "\n",
      "*Training B: False ;B Train loss: 2.348 ;Train accuracy: 0.432 ;IOU accuracy: 0.526 ;Time: 0:01:18 \n",
      "\n",
      "Testing, ephoc: 11\n",
      "batch: 0 ;B loss: 2.025 ;acc: 0.515 ;iou_acc: 0.620 ;time: 0:01:18\n",
      "batch: 50 ;B loss: 2.039 ;acc: 0.550 ;iou_acc: 0.630 ;time: 0:01:26\n",
      "batch: 100 ;B loss: 2.142 ;acc: 0.475 ;iou_acc: 0.550 ;time: 0:01:34\n",
      "batch: 150 ;B loss: 2.128 ;acc: 0.510 ;iou_acc: 0.605 ;time: 0:01:41\n",
      "batch: 200 ;B loss: 2.058 ;acc: 0.515 ;iou_acc: 0.635 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 2.069 ;acc: 0.550 ;iou_acc: 0.660 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 2.060 ;Test accuracy 0.522 ;IOU accuracy: 0.624 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 12 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5341 ;lr: 0.0500 ;B loss: 2.310 ;acc: 0.480 ;iou: 0.535 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5391 ;lr: 0.0500 ;B loss: 2.149 ;acc: 0.520 ;iou: 0.595 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5441 ;lr: 0.0500 ;B loss: 2.338 ;acc: 0.450 ;iou: 0.540 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5491 ;lr: 0.0500 ;B loss: 2.363 ;acc: 0.480 ;iou: 0.545 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5541 ;lr: 0.0500 ;B loss: 2.378 ;acc: 0.450 ;iou: 0.535 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 5591 ;lr: 0.0500 ;B loss: 2.336 ;acc: 0.455 ;iou: 0.510 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 5641 ;lr: 0.0500 ;B loss: 2.331 ;acc: 0.405 ;iou: 0.495 ;time: 0:00:52\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 5691 ;lr: 0.0500 ;B loss: 2.443 ;acc: 0.415 ;iou: 0.540 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 5741 ;lr: 0.0500 ;B loss: 2.405 ;acc: 0.400 ;iou: 0.520 ;time: 0:01:10\n",
      "\n",
      "*Training B: True ;B Train loss: 2.340 ;Train accuracy: 0.439 ;IOU accuracy: 0.532 ;Time: 0:01:17 \n",
      "\n",
      "Testing, ephoc: 12\n",
      "batch: 0 ;B loss: 2.018 ;acc: 0.530 ;iou_acc: 0.625 ;time: 0:01:18\n",
      "batch: 50 ;B loss: 2.024 ;acc: 0.530 ;iou_acc: 0.600 ;time: 0:01:25\n",
      "batch: 100 ;B loss: 2.129 ;acc: 0.465 ;iou_acc: 0.555 ;time: 0:01:33\n",
      "batch: 150 ;B loss: 2.114 ;acc: 0.495 ;iou_acc: 0.590 ;time: 0:01:40\n",
      "batch: 200 ;B loss: 2.046 ;acc: 0.525 ;iou_acc: 0.645 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 2.053 ;acc: 0.545 ;iou_acc: 0.650 ;time: 0:01:56\n",
      "\n",
      "*BTrain: True ;Test loss: 2.048 ;Test accuracy 0.531 ;IOU accuracy: 0.630 ;Time: 0:02:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 13 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 5786 ;lr: 0.0500 ;B loss: 2.408 ;acc: 0.480 ;iou: 0.570 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 5836 ;lr: 0.0500 ;B loss: 2.307 ;acc: 0.480 ;iou: 0.550 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 5886 ;lr: 0.0500 ;B loss: 2.347 ;acc: 0.410 ;iou: 0.525 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 5936 ;lr: 0.0500 ;B loss: 2.210 ;acc: 0.475 ;iou: 0.530 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 5986 ;lr: 0.0500 ;B loss: 2.411 ;acc: 0.365 ;iou: 0.465 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6036 ;lr: 0.0500 ;B loss: 2.398 ;acc: 0.415 ;iou: 0.525 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 6086 ;lr: 0.0500 ;B loss: 2.200 ;acc: 0.465 ;iou: 0.545 ;time: 0:00:52\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 6136 ;lr: 0.0500 ;B loss: 2.315 ;acc: 0.420 ;iou: 0.500 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 6186 ;lr: 0.0500 ;B loss: 2.425 ;acc: 0.435 ;iou: 0.545 ;time: 0:01:10\n",
      "\n",
      "*Training B: False ;B Train loss: 2.332 ;Train accuracy: 0.444 ;IOU accuracy: 0.536 ;Time: 0:01:18 \n",
      "\n",
      "Testing, ephoc: 13\n",
      "batch: 0 ;B loss: 2.003 ;acc: 0.545 ;iou_acc: 0.635 ;time: 0:01:18\n",
      "batch: 50 ;B loss: 2.017 ;acc: 0.565 ;iou_acc: 0.615 ;time: 0:01:26\n",
      "batch: 100 ;B loss: 2.105 ;acc: 0.495 ;iou_acc: 0.590 ;time: 0:01:34\n",
      "batch: 150 ;B loss: 2.097 ;acc: 0.535 ;iou_acc: 0.620 ;time: 0:01:41\n",
      "batch: 200 ;B loss: 2.037 ;acc: 0.505 ;iou_acc: 0.620 ;time: 0:01:49\n",
      "batch: 250 ;B loss: 2.045 ;acc: 0.555 ;iou_acc: 0.660 ;time: 0:01:57\n",
      "\n",
      "*BTrain: False ;Test loss: 2.036 ;Test accuracy 0.535 ;IOU accuracy: 0.634 ;Time: 0:02:05\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 14 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6231 ;lr: 0.0500 ;B loss: 2.214 ;acc: 0.405 ;iou: 0.505 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6281 ;lr: 0.0500 ;B loss: 2.374 ;acc: 0.400 ;iou: 0.490 ;time: 0:00:09\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6331 ;lr: 0.0500 ;B loss: 2.277 ;acc: 0.485 ;iou: 0.545 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6381 ;lr: 0.0500 ;B loss: 2.258 ;acc: 0.365 ;iou: 0.470 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6431 ;lr: 0.0500 ;B loss: 2.383 ;acc: 0.420 ;iou: 0.500 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6481 ;lr: 0.0500 ;B loss: 2.274 ;acc: 0.525 ;iou: 0.615 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 6531 ;lr: 0.0500 ;B loss: 2.398 ;acc: 0.440 ;iou: 0.525 ;time: 0:00:57\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 6581 ;lr: 0.0500 ;B loss: 2.408 ;acc: 0.425 ;iou: 0.495 ;time: 0:01:08\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 6631 ;lr: 0.0500 ;B loss: 2.349 ;acc: 0.465 ;iou: 0.525 ;time: 0:01:19\n",
      "\n",
      "*Training B: False ;B Train loss: 2.323 ;Train accuracy: 0.450 ;IOU accuracy: 0.541 ;Time: 0:01:29 \n",
      "\n",
      "Testing, ephoc: 14\n",
      "batch: 0 ;B loss: 1.986 ;acc: 0.555 ;iou_acc: 0.645 ;time: 0:01:30\n",
      "batch: 50 ;B loss: 1.995 ;acc: 0.545 ;iou_acc: 0.600 ;time: 0:01:41\n",
      "batch: 100 ;B loss: 2.092 ;acc: 0.490 ;iou_acc: 0.580 ;time: 0:01:53\n",
      "batch: 150 ;B loss: 2.088 ;acc: 0.500 ;iou_acc: 0.600 ;time: 0:02:04\n",
      "batch: 200 ;B loss: 2.020 ;acc: 0.515 ;iou_acc: 0.635 ;time: 0:02:15\n",
      "batch: 250 ;B loss: 2.030 ;acc: 0.530 ;iou_acc: 0.660 ;time: 0:02:26\n",
      "\n",
      "*BTrain: False ;Test loss: 2.020 ;Test accuracy 0.540 ;IOU accuracy: 0.638 ;Time: 0:02:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 15 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 6676 ;lr: 0.0500 ;B loss: 2.349 ;acc: 0.475 ;iou: 0.555 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 6726 ;lr: 0.0500 ;B loss: 2.291 ;acc: 0.475 ;iou: 0.630 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 6776 ;lr: 0.0500 ;B loss: 2.290 ;acc: 0.425 ;iou: 0.535 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 6826 ;lr: 0.0500 ;B loss: 2.483 ;acc: 0.395 ;iou: 0.485 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 6876 ;lr: 0.0500 ;B loss: 2.193 ;acc: 0.525 ;iou: 0.640 ;time: 0:00:51\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 6926 ;lr: 0.0500 ;B loss: 2.368 ;acc: 0.435 ;iou: 0.485 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 6976 ;lr: 0.0500 ;B loss: 2.233 ;acc: 0.445 ;iou: 0.565 ;time: 0:01:17\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 7026 ;lr: 0.0500 ;B loss: 2.387 ;acc: 0.415 ;iou: 0.490 ;time: 0:01:29\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 7076 ;lr: 0.0500 ;B loss: 2.332 ;acc: 0.415 ;iou: 0.505 ;time: 0:01:43\n",
      "\n",
      "*Training B: True ;B Train loss: 2.317 ;Train accuracy: 0.455 ;IOU accuracy: 0.546 ;Time: 0:01:53 \n",
      "\n",
      "Testing, ephoc: 15\n",
      "batch: 0 ;B loss: 1.979 ;acc: 0.575 ;iou_acc: 0.655 ;time: 0:01:54\n",
      "batch: 50 ;B loss: 1.983 ;acc: 0.565 ;iou_acc: 0.630 ;time: 0:02:06\n",
      "batch: 100 ;B loss: 2.083 ;acc: 0.480 ;iou_acc: 0.560 ;time: 0:02:17\n",
      "batch: 150 ;B loss: 2.079 ;acc: 0.535 ;iou_acc: 0.630 ;time: 0:02:26\n",
      "batch: 200 ;B loss: 2.010 ;acc: 0.520 ;iou_acc: 0.645 ;time: 0:02:33\n",
      "batch: 250 ;B loss: 2.018 ;acc: 0.540 ;iou_acc: 0.660 ;time: 0:02:41\n",
      "\n",
      "*BTrain: True ;Test loss: 2.013 ;Test accuracy 0.545 ;IOU accuracy: 0.642 ;Time: 0:02:48\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 16 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7121 ;lr: 0.0500 ;B loss: 2.387 ;acc: 0.435 ;iou: 0.525 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7171 ;lr: 0.0500 ;B loss: 2.254 ;acc: 0.540 ;iou: 0.605 ;time: 0:00:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7221 ;lr: 0.0500 ;B loss: 2.341 ;acc: 0.425 ;iou: 0.500 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7271 ;lr: 0.0500 ;B loss: 2.294 ;acc: 0.475 ;iou: 0.605 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7321 ;lr: 0.0500 ;B loss: 2.414 ;acc: 0.425 ;iou: 0.535 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7371 ;lr: 0.0500 ;B loss: 2.303 ;acc: 0.500 ;iou: 0.580 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 7421 ;lr: 0.0500 ;B loss: 2.214 ;acc: 0.450 ;iou: 0.535 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 7471 ;lr: 0.0500 ;B loss: 2.283 ;acc: 0.450 ;iou: 0.545 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 7521 ;lr: 0.0500 ;B loss: 2.538 ;acc: 0.360 ;iou: 0.510 ;time: 0:01:15\n",
      "\n",
      "*Training B: False ;B Train loss: 2.309 ;Train accuracy: 0.459 ;IOU accuracy: 0.550 ;Time: 0:01:24 \n",
      "\n",
      "Testing, ephoc: 16\n",
      "batch: 0 ;B loss: 1.961 ;acc: 0.535 ;iou_acc: 0.615 ;time: 0:01:25\n",
      "batch: 50 ;B loss: 1.974 ;acc: 0.570 ;iou_acc: 0.610 ;time: 0:01:35\n",
      "batch: 100 ;B loss: 2.072 ;acc: 0.510 ;iou_acc: 0.595 ;time: 0:01:45\n",
      "batch: 150 ;B loss: 2.066 ;acc: 0.565 ;iou_acc: 0.665 ;time: 0:01:57\n",
      "batch: 200 ;B loss: 2.002 ;acc: 0.540 ;iou_acc: 0.650 ;time: 0:02:07\n",
      "batch: 250 ;B loss: 2.003 ;acc: 0.545 ;iou_acc: 0.655 ;time: 0:02:18\n",
      "\n",
      "*BTrain: False ;Test loss: 1.998 ;Test accuracy 0.550 ;IOU accuracy: 0.647 ;Time: 0:02:29\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 17 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 7566 ;lr: 0.0500 ;B loss: 2.332 ;acc: 0.480 ;iou: 0.580 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 7616 ;lr: 0.0500 ;B loss: 2.309 ;acc: 0.480 ;iou: 0.580 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 7666 ;lr: 0.0500 ;B loss: 2.386 ;acc: 0.400 ;iou: 0.515 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 7716 ;lr: 0.0500 ;B loss: 2.153 ;acc: 0.530 ;iou: 0.605 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 7766 ;lr: 0.0500 ;B loss: 2.328 ;acc: 0.430 ;iou: 0.515 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 7816 ;lr: 0.0500 ;B loss: 2.289 ;acc: 0.475 ;iou: 0.575 ;time: 0:01:06\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 7866 ;lr: 0.0500 ;B loss: 2.366 ;acc: 0.505 ;iou: 0.575 ;time: 0:01:19\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 7916 ;lr: 0.0500 ;B loss: 2.273 ;acc: 0.405 ;iou: 0.495 ;time: 0:01:32\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 7966 ;lr: 0.0500 ;B loss: 2.187 ;acc: 0.495 ;iou: 0.565 ;time: 0:01:45\n",
      "\n",
      "*Training B: False ;B Train loss: 2.302 ;Train accuracy: 0.463 ;IOU accuracy: 0.552 ;Time: 0:01:56 \n",
      "\n",
      "Testing, ephoc: 17\n",
      "batch: 0 ;B loss: 1.949 ;acc: 0.600 ;iou_acc: 0.665 ;time: 0:01:57\n",
      "batch: 50 ;B loss: 1.967 ;acc: 0.555 ;iou_acc: 0.620 ;time: 0:02:09\n",
      "batch: 100 ;B loss: 2.063 ;acc: 0.515 ;iou_acc: 0.605 ;time: 0:02:21\n",
      "batch: 150 ;B loss: 2.055 ;acc: 0.535 ;iou_acc: 0.630 ;time: 0:02:33\n",
      "batch: 200 ;B loss: 1.996 ;acc: 0.540 ;iou_acc: 0.650 ;time: 0:02:45\n",
      "batch: 250 ;B loss: 2.003 ;acc: 0.565 ;iou_acc: 0.670 ;time: 0:02:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.989 ;Test accuracy 0.556 ;IOU accuracy: 0.652 ;Time: 0:03:09\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8011 ;lr: 0.0500 ;B loss: 2.314 ;acc: 0.475 ;iou: 0.580 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8061 ;lr: 0.0500 ;B loss: 2.280 ;acc: 0.435 ;iou: 0.530 ;time: 0:00:14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6409d7f20260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mdropout_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdropout_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         dropout_out=dropout_out)\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mnoise_bnorm_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, use_wordAttn, addNoise)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                         attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(trn_data, \n\u001b[0;32m--> 543\u001b[0;31m                                                                                             b*self.batch_size, (b+1)*self.batch_size, addNoise=addNoise)\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                         \u001b[0mreward_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dummy holder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mbuild_data\u001b[0;34m(self, data, start, end, addNoise)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             padded_im.append(np.concatenate([data[i][j][0] for j in range(1, len(data[i])-1)] + \n\u001b[0;32m--> 320\u001b[0;31m                                        [np.full((imlen-(len(data[i])-2), im_dim), vocab['<pad>'], dtype=np.float32)], axis=0))\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             padded_bbox.append(np.concatenate([data[i][j][1] for j in range(1, len(data[i])-1)] + \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Augmenting data\n",
    "# The accuracy and IOU of the trainin set includs data points \n",
    "# with no true groinding bbox so the true training's accuracy and IOU\n",
    "# is higher then we can see in the reults here (TODO: fix it)\n",
    "\n",
    "print(len(trainset))\n",
    "augment_data(trainset)\n",
    "print(len(trainset))\n",
    "\n",
    "\n",
    "aug_bnorm_test_res, aug_bnorm_train_res = [], []\n",
    "num_hidden = 200\n",
    "dropout_in=0.5\n",
    "dropout_out=1.\n",
    "dropout_img = 0.5\n",
    "params_dir = params_dir_tmp+'bnorm_base/augmented_'+str(dropout_in)+','+str(dropout_out)+','+str(dropout_img)+'_hidden:'+str(num_hidden)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=num_hidden,\n",
    "    img_dims=trainset[0][0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "    lr=.05,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.99, \n",
    "    edit_reward=0.,\n",
    "    rnn_editProb=0.,\n",
    "    coefAlr=1,\n",
    "    bnorm=True)\n",
    "\n",
    "\n",
    "# start comp\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=70,\n",
    "        start_ephoc=0,\n",
    "        startA=101,\n",
    "        activation_ephoc=101,\n",
    "        muteB=0, \n",
    "        activateAProb=0,\n",
    "        max_activateAProb=0,\n",
    "        editProb=0,\n",
    "        edit_reward=0,\n",
    "        dropout_img=dropout_img,\n",
    "        dropout_in=dropout_in,\n",
    "        dropout_out=dropout_out)\n",
    "\n",
    "aug_bnorm_test_res.append(tst)\n",
    "aug_bnorm_train_res.append(trn)\n",
    "print('\\n'+'*'*100)\n",
    "print('*'*100)\n",
    "print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.1\n",
      "# Train set size: 89173\n",
      "# Training batches: 445\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Loading parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-17\n",
      "INFO:tensorflow:Restoring parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-17\n",
      "================================================== \n",
      "Train, ephoc: 18 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8011 ;lr: 0.1000 ;B loss: 2.345 ;acc: 0.475 ;iou: 0.575 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8061 ;lr: 0.1000 ;B loss: 2.349 ;acc: 0.450 ;iou: 0.525 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8111 ;lr: 0.1000 ;B loss: 2.446 ;acc: 0.415 ;iou: 0.525 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8161 ;lr: 0.1000 ;B loss: 2.259 ;acc: 0.475 ;iou: 0.560 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8211 ;lr: 0.1000 ;B loss: 2.273 ;acc: 0.460 ;iou: 0.595 ;time: 0:00:52\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8261 ;lr: 0.1000 ;B loss: 2.281 ;acc: 0.520 ;iou: 0.595 ;time: 0:01:06\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 8311 ;lr: 0.1000 ;B loss: 2.276 ;acc: 0.440 ;iou: 0.510 ;time: 0:01:19\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 8361 ;lr: 0.1000 ;B loss: 2.263 ;acc: 0.540 ;iou: 0.585 ;time: 0:01:32\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 8411 ;lr: 0.1000 ;B loss: 2.260 ;acc: 0.490 ;iou: 0.545 ;time: 0:01:45\n",
      "\n",
      "*Training B: True ;B Train loss: 2.299 ;Train accuracy: 0.472 ;IOU accuracy: 0.561 ;Time: 0:01:57 \n",
      "\n",
      "Testing, ephoc: 18\n",
      "batch: 0 ;B loss: 1.936 ;acc: 0.585 ;iou_acc: 0.665 ;time: 0:01:58\n",
      "batch: 50 ;B loss: 1.961 ;acc: 0.535 ;iou_acc: 0.600 ;time: 0:02:10\n",
      "batch: 100 ;B loss: 2.047 ;acc: 0.535 ;iou_acc: 0.620 ;time: 0:02:23\n",
      "batch: 150 ;B loss: 2.031 ;acc: 0.555 ;iou_acc: 0.645 ;time: 0:02:35\n",
      "batch: 200 ;B loss: 1.978 ;acc: 0.540 ;iou_acc: 0.665 ;time: 0:02:46\n",
      "batch: 250 ;B loss: 1.989 ;acc: 0.555 ;iou_acc: 0.690 ;time: 0:02:58\n",
      "\n",
      "*BTrain: True ;Test loss: 1.979 ;Test accuracy 0.561 ;IOU accuracy: 0.658 ;Time: 0:03:09\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 19 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8456 ;lr: 0.1000 ;B loss: 2.260 ;acc: 0.485 ;iou: 0.535 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8506 ;lr: 0.1000 ;B loss: 2.329 ;acc: 0.480 ;iou: 0.565 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 8556 ;lr: 0.1000 ;B loss: 2.336 ;acc: 0.485 ;iou: 0.585 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 8606 ;lr: 0.1000 ;B loss: 2.340 ;acc: 0.475 ;iou: 0.550 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 8656 ;lr: 0.1000 ;B loss: 2.191 ;acc: 0.450 ;iou: 0.550 ;time: 0:00:56\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 8706 ;lr: 0.1000 ;B loss: 2.426 ;acc: 0.460 ;iou: 0.555 ;time: 0:01:10\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 8756 ;lr: 0.1000 ;B loss: 2.265 ;acc: 0.455 ;iou: 0.565 ;time: 0:01:23\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 8806 ;lr: 0.1000 ;B loss: 2.327 ;acc: 0.460 ;iou: 0.570 ;time: 0:01:36\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 8856 ;lr: 0.1000 ;B loss: 2.165 ;acc: 0.595 ;iou: 0.670 ;time: 0:01:51\n",
      "\n",
      "*Training B: False ;B Train loss: 2.289 ;Train accuracy: 0.481 ;IOU accuracy: 0.568 ;Time: 0:02:02 \n",
      "\n",
      "Testing, ephoc: 19\n",
      "batch: 0 ;B loss: 1.892 ;acc: 0.610 ;iou_acc: 0.690 ;time: 0:02:03\n",
      "batch: 50 ;B loss: 1.951 ;acc: 0.560 ;iou_acc: 0.635 ;time: 0:02:15\n",
      "batch: 100 ;B loss: 2.026 ;acc: 0.540 ;iou_acc: 0.625 ;time: 0:02:28\n",
      "batch: 150 ;B loss: 2.018 ;acc: 0.575 ;iou_acc: 0.665 ;time: 0:02:40\n",
      "batch: 200 ;B loss: 1.969 ;acc: 0.560 ;iou_acc: 0.670 ;time: 0:02:52\n",
      "batch: 250 ;B loss: 1.994 ;acc: 0.530 ;iou_acc: 0.665 ;time: 0:03:05\n",
      "\n",
      "*BTrain: False ;Test loss: 1.961 ;Test accuracy 0.569 ;IOU accuracy: 0.665 ;Time: 0:03:16\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 20 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 8901 ;lr: 0.1000 ;B loss: 2.219 ;acc: 0.530 ;iou: 0.610 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 8951 ;lr: 0.1000 ;B loss: 2.183 ;acc: 0.545 ;iou: 0.625 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9001 ;lr: 0.1000 ;B loss: 2.209 ;acc: 0.490 ;iou: 0.610 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9051 ;lr: 0.1000 ;B loss: 2.142 ;acc: 0.450 ;iou: 0.540 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9101 ;lr: 0.1000 ;B loss: 2.438 ;acc: 0.410 ;iou: 0.510 ;time: 0:01:15\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9151 ;lr: 0.1000 ;B loss: 2.225 ;acc: 0.485 ;iou: 0.560 ;time: 0:01:29\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 9201 ;lr: 0.1000 ;B loss: 2.298 ;acc: 0.465 ;iou: 0.580 ;time: 0:01:43\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 9251 ;lr: 0.1000 ;B loss: 2.178 ;acc: 0.525 ;iou: 0.575 ;time: 0:01:57\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 9301 ;lr: 0.1000 ;B loss: 2.209 ;acc: 0.530 ;iou: 0.610 ;time: 0:02:11\n",
      "\n",
      "*Training B: False ;B Train loss: 2.277 ;Train accuracy: 0.488 ;IOU accuracy: 0.575 ;Time: 0:02:23 \n",
      "\n",
      "Testing, ephoc: 20\n",
      "batch: 0 ;B loss: 1.881 ;acc: 0.605 ;iou_acc: 0.695 ;time: 0:02:23\n",
      "batch: 50 ;B loss: 1.934 ;acc: 0.570 ;iou_acc: 0.620 ;time: 0:02:35\n",
      "batch: 100 ;B loss: 2.007 ;acc: 0.580 ;iou_acc: 0.665 ;time: 0:02:47\n",
      "batch: 150 ;B loss: 2.016 ;acc: 0.580 ;iou_acc: 0.680 ;time: 0:02:59\n",
      "batch: 200 ;B loss: 1.964 ;acc: 0.565 ;iou_acc: 0.680 ;time: 0:03:11\n",
      "batch: 250 ;B loss: 1.974 ;acc: 0.530 ;iou_acc: 0.660 ;time: 0:03:23\n",
      "\n",
      "*BTrain: False ;Test loss: 1.948 ;Test accuracy 0.580 ;IOU accuracy: 0.674 ;Time: 0:03:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9346 ;lr: 0.1000 ;B loss: 2.333 ;acc: 0.505 ;iou: 0.550 ;time: 0:00:01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-63dec0758af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdropout_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdropout_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         dropout_out=dropout_out)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0maug_bnorm_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, use_wordAttn, addNoise)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                 \u001b[0mB_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m                             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misEdit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misEdit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m                             iou_acc = self.iou_accuracy(trn_data, b*self.batch_size, (b+1)*self.batch_size, \n\u001b[1;32m    669\u001b[0m                                                         sess=sess, feed_dict=feed_dict, isEdit=isEdit)\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, data, start, end, sess, feed_dict, isEdit)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Augmenting data\n",
    "# The accuracy and IOU of the trainin set includs data points \n",
    "# with no true groinding bbox so the true training's accuracy and IOU\n",
    "# is higher then we can see in the reults here (TODO: fix it)\n",
    "# increasing learning rate\n",
    "\n",
    "num_hidden = 200\n",
    "dropout_in=0.5\n",
    "dropout_out=1.\n",
    "dropout_img = 0.5\n",
    "params_dir = params_dir_tmp+'bnorm_base/augmented_'+str(dropout_in)+','+str(dropout_out)+','+str(dropout_img)+'_hidden:'+str(num_hidden)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=num_hidden,\n",
    "    img_dims=trainset[0][0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][0][1][1].shape[1], \n",
    "    lr=.1,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.99, \n",
    "    edit_reward=0.,\n",
    "    rnn_editProb=0.,\n",
    "    coefAlr=1,\n",
    "    bnorm=True)\n",
    "\n",
    "\n",
    "# start comp\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=100,\n",
    "        start_ephoc=18,\n",
    "        startA=101,\n",
    "        activation_ephoc=101,\n",
    "        muteB=0, \n",
    "        activateAProb=0,\n",
    "        max_activateAProb=0,\n",
    "        editProb=0,\n",
    "        edit_reward=0,\n",
    "        dropout_img=dropout_img,\n",
    "        dropout_in=dropout_in,\n",
    "        dropout_out=dropout_out)\n",
    "\n",
    "aug_bnorm_test_res.append(tst)\n",
    "aug_bnorm_train_res.append(trn)\n",
    "print('\\n'+'*'*100)\n",
    "print('*'*100)\n",
    "print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.2\n",
      "# Train set size: 89173\n",
      "# Training batches: 445\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Loading parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-20\n",
      "INFO:tensorflow:Restoring parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-20\n",
      "================================================== \n",
      "Train, ephoc: 21 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9346 ;lr: 0.2000 ;B loss: 2.260 ;acc: 0.500 ;iou: 0.570 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9396 ;lr: 0.2000 ;B loss: 2.262 ;acc: 0.485 ;iou: 0.575 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9446 ;lr: 0.2000 ;B loss: 2.252 ;acc: 0.470 ;iou: 0.575 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9496 ;lr: 0.2000 ;B loss: 2.292 ;acc: 0.480 ;iou: 0.565 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9546 ;lr: 0.2000 ;B loss: 2.240 ;acc: 0.500 ;iou: 0.595 ;time: 0:00:54\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 9596 ;lr: 0.2000 ;B loss: 2.271 ;acc: 0.550 ;iou: 0.640 ;time: 0:01:07\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 9646 ;lr: 0.2000 ;B loss: 2.163 ;acc: 0.550 ;iou: 0.630 ;time: 0:01:27\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 9696 ;lr: 0.2000 ;B loss: 2.384 ;acc: 0.515 ;iou: 0.605 ;time: 0:01:40\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 9746 ;lr: 0.2000 ;B loss: 2.288 ;acc: 0.545 ;iou: 0.615 ;time: 0:01:55\n",
      "\n",
      "*Training B: True ;B Train loss: 2.275 ;Train accuracy: 0.510 ;IOU accuracy: 0.595 ;Time: 0:02:06 \n",
      "\n",
      "Testing, ephoc: 21\n",
      "batch: 0 ;B loss: 1.858 ;acc: 0.595 ;iou_acc: 0.675 ;time: 0:02:07\n",
      "batch: 50 ;B loss: 1.886 ;acc: 0.585 ;iou_acc: 0.650 ;time: 0:02:19\n",
      "batch: 100 ;B loss: 1.990 ;acc: 0.540 ;iou_acc: 0.645 ;time: 0:02:31\n",
      "batch: 150 ;B loss: 1.965 ;acc: 0.615 ;iou_acc: 0.705 ;time: 0:02:43\n",
      "batch: 200 ;B loss: 1.917 ;acc: 0.590 ;iou_acc: 0.705 ;time: 0:02:54\n",
      "batch: 250 ;B loss: 1.940 ;acc: 0.595 ;iou_acc: 0.720 ;time: 0:03:05\n",
      "\n",
      "*BTrain: True ;Test loss: 1.907 ;Test accuracy 0.601 ;IOU accuracy: 0.699 ;Time: 0:03:16\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 22 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 9791 ;lr: 0.2000 ;B loss: 2.309 ;acc: 0.535 ;iou: 0.605 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 9841 ;lr: 0.2000 ;B loss: 2.190 ;acc: 0.575 ;iou: 0.645 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 9891 ;lr: 0.2000 ;B loss: 2.248 ;acc: 0.530 ;iou: 0.615 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 9941 ;lr: 0.2000 ;B loss: 2.222 ;acc: 0.505 ;iou: 0.600 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 9991 ;lr: 0.2000 ;B loss: 2.274 ;acc: 0.525 ;iou: 0.630 ;time: 0:00:54\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10041 ;lr: 0.1980 ;B loss: 2.236 ;acc: 0.525 ;iou: 0.600 ;time: 0:01:07\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 10091 ;lr: 0.1980 ;B loss: 2.207 ;acc: 0.550 ;iou: 0.645 ;time: 0:01:21\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 10141 ;lr: 0.1980 ;B loss: 2.229 ;acc: 0.560 ;iou: 0.620 ;time: 0:02:00\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 10191 ;lr: 0.1980 ;B loss: 2.239 ;acc: 0.540 ;iou: 0.610 ;time: 0:02:46\n",
      "\n",
      "*Training B: False ;B Train loss: 2.246 ;Train accuracy: 0.529 ;IOU accuracy: 0.614 ;Time: 0:03:19 \n",
      "\n",
      "Testing, ephoc: 22\n",
      "batch: 0 ;B loss: 1.849 ;acc: 0.625 ;iou_acc: 0.710 ;time: 0:03:20\n",
      "batch: 50 ;B loss: 1.820 ;acc: 0.625 ;iou_acc: 0.705 ;time: 0:03:50\n",
      "batch: 100 ;B loss: 1.945 ;acc: 0.555 ;iou_acc: 0.650 ;time: 0:04:22\n",
      "batch: 150 ;B loss: 1.911 ;acc: 0.645 ;iou_acc: 0.735 ;time: 0:04:57\n",
      "batch: 200 ;B loss: 1.862 ;acc: 0.620 ;iou_acc: 0.710 ;time: 0:05:33\n",
      "batch: 250 ;B loss: 1.886 ;acc: 0.635 ;iou_acc: 0.740 ;time: 0:06:09\n",
      "\n",
      "*BTrain: False ;Test loss: 1.868 ;Test accuracy 0.626 ;IOU accuracy: 0.725 ;Time: 0:06:47\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 23 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10236 ;lr: 0.1980 ;B loss: 2.222 ;acc: 0.580 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10286 ;lr: 0.1980 ;B loss: 2.244 ;acc: 0.545 ;iou: 0.620 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10336 ;lr: 0.1980 ;B loss: 2.230 ;acc: 0.555 ;iou: 0.640 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10386 ;lr: 0.1980 ;B loss: 2.296 ;acc: 0.560 ;iou: 0.630 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10436 ;lr: 0.1980 ;B loss: 2.060 ;acc: 0.595 ;iou: 0.665 ;time: 0:00:51\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10486 ;lr: 0.1980 ;B loss: 2.162 ;acc: 0.570 ;iou: 0.620 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 10536 ;lr: 0.1980 ;B loss: 2.001 ;acc: 0.585 ;iou: 0.655 ;time: 0:01:18\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 10586 ;lr: 0.1980 ;B loss: 2.179 ;acc: 0.540 ;iou: 0.635 ;time: 0:01:31\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 10636 ;lr: 0.1980 ;B loss: 2.391 ;acc: 0.515 ;iou: 0.615 ;time: 0:01:45\n",
      "\n",
      "*Training B: False ;B Train loss: 2.226 ;Train accuracy: 0.544 ;IOU accuracy: 0.627 ;Time: 0:01:57 \n",
      "\n",
      "Testing, ephoc: 23\n",
      "batch: 0 ;B loss: 1.798 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:01:58\n",
      "batch: 50 ;B loss: 1.802 ;acc: 0.640 ;iou_acc: 0.710 ;time: 0:02:11\n",
      "batch: 100 ;B loss: 1.928 ;acc: 0.595 ;iou_acc: 0.690 ;time: 0:02:24\n",
      "batch: 150 ;B loss: 1.892 ;acc: 0.650 ;iou_acc: 0.750 ;time: 0:02:37\n",
      "batch: 200 ;B loss: 1.825 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:02:50\n",
      "batch: 250 ;B loss: 1.856 ;acc: 0.610 ;iou_acc: 0.715 ;time: 0:03:02\n",
      "\n",
      "*BTrain: False ;Test loss: 1.839 ;Test accuracy 0.642 ;IOU accuracy: 0.740 ;Time: 0:03:13\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 24 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 10681 ;lr: 0.1980 ;B loss: 2.238 ;acc: 0.550 ;iou: 0.645 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 10731 ;lr: 0.1980 ;B loss: 2.015 ;acc: 0.640 ;iou: 0.700 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 10781 ;lr: 0.1980 ;B loss: 2.203 ;acc: 0.480 ;iou: 0.590 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 10831 ;lr: 0.1980 ;B loss: 2.138 ;acc: 0.590 ;iou: 0.650 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 10881 ;lr: 0.1980 ;B loss: 2.267 ;acc: 0.525 ;iou: 0.595 ;time: 0:00:55\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 10931 ;lr: 0.1980 ;B loss: 2.163 ;acc: 0.555 ;iou: 0.625 ;time: 0:01:08\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 10981 ;lr: 0.1980 ;B loss: 2.075 ;acc: 0.590 ;iou: 0.680 ;time: 0:01:21\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 11031 ;lr: 0.1980 ;B loss: 2.266 ;acc: 0.525 ;iou: 0.620 ;time: 0:01:41\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 11081 ;lr: 0.1980 ;B loss: 2.279 ;acc: 0.505 ;iou: 0.615 ;time: 0:01:54\n",
      "\n",
      "*Training B: True ;B Train loss: 2.208 ;Train accuracy: 0.555 ;IOU accuracy: 0.637 ;Time: 0:02:06 \n",
      "\n",
      "Testing, ephoc: 24\n",
      "batch: 0 ;B loss: 1.805 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:02:06\n",
      "batch: 50 ;B loss: 1.793 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:02:18\n",
      "batch: 100 ;B loss: 1.923 ;acc: 0.590 ;iou_acc: 0.680 ;time: 0:02:30\n",
      "batch: 150 ;B loss: 1.868 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:02:42\n",
      "batch: 200 ;B loss: 1.817 ;acc: 0.645 ;iou_acc: 0.765 ;time: 0:02:54\n",
      "batch: 250 ;B loss: 1.839 ;acc: 0.615 ;iou_acc: 0.715 ;time: 0:03:06\n",
      "\n",
      "*BTrain: True ;Test loss: 1.819 ;Test accuracy 0.650 ;IOU accuracy: 0.747 ;Time: 0:03:17\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 25 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11126 ;lr: 0.1980 ;B loss: 2.231 ;acc: 0.550 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11176 ;lr: 0.1980 ;B loss: 2.109 ;acc: 0.590 ;iou: 0.685 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11226 ;lr: 0.1980 ;B loss: 2.074 ;acc: 0.605 ;iou: 0.680 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11276 ;lr: 0.1980 ;B loss: 2.159 ;acc: 0.535 ;iou: 0.605 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11326 ;lr: 0.1980 ;B loss: 2.164 ;acc: 0.550 ;iou: 0.630 ;time: 0:00:57\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11376 ;lr: 0.1980 ;B loss: 2.409 ;acc: 0.405 ;iou: 0.510 ;time: 0:01:13\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 11426 ;lr: 0.1980 ;B loss: 2.180 ;acc: 0.595 ;iou: 0.650 ;time: 0:01:29\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 11476 ;lr: 0.1980 ;B loss: 2.276 ;acc: 0.505 ;iou: 0.565 ;time: 0:01:45\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 11526 ;lr: 0.1980 ;B loss: 2.210 ;acc: 0.580 ;iou: 0.640 ;time: 0:02:01\n",
      "\n",
      "*Training B: False ;B Train loss: 2.195 ;Train accuracy: 0.561 ;IOU accuracy: 0.642 ;Time: 0:02:15 \n",
      "\n",
      "Testing, ephoc: 25\n",
      "batch: 0 ;B loss: 1.767 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:02:16\n",
      "batch: 50 ;B loss: 1.794 ;acc: 0.665 ;iou_acc: 0.720 ;time: 0:02:30\n",
      "batch: 100 ;B loss: 1.897 ;acc: 0.615 ;iou_acc: 0.710 ;time: 0:02:44\n",
      "batch: 150 ;B loss: 1.859 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:02:59\n",
      "batch: 200 ;B loss: 1.832 ;acc: 0.625 ;iou_acc: 0.750 ;time: 0:03:14\n",
      "batch: 250 ;B loss: 1.821 ;acc: 0.615 ;iou_acc: 0.735 ;time: 0:03:29\n",
      "\n",
      "*BTrain: False ;Test loss: 1.802 ;Test accuracy 0.661 ;IOU accuracy: 0.758 ;Time: 0:03:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 26 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 11571 ;lr: 0.1980 ;B loss: 2.126 ;acc: 0.555 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 11621 ;lr: 0.1980 ;B loss: 2.251 ;acc: 0.590 ;iou: 0.640 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 11671 ;lr: 0.1980 ;B loss: 2.110 ;acc: 0.550 ;iou: 0.635 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 11721 ;lr: 0.1980 ;B loss: 2.133 ;acc: 0.590 ;iou: 0.665 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 11771 ;lr: 0.1980 ;B loss: 2.044 ;acc: 0.590 ;iou: 0.670 ;time: 0:01:11\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 11821 ;lr: 0.1980 ;B loss: 2.215 ;acc: 0.575 ;iou: 0.630 ;time: 0:01:28\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 11871 ;lr: 0.1980 ;B loss: 2.097 ;acc: 0.615 ;iou: 0.685 ;time: 0:01:44\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 11921 ;lr: 0.1980 ;B loss: 2.122 ;acc: 0.565 ;iou: 0.645 ;time: 0:02:00\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 11971 ;lr: 0.1980 ;B loss: 2.117 ;acc: 0.550 ;iou: 0.610 ;time: 0:02:17\n",
      "\n",
      "*Training B: False ;B Train loss: 2.182 ;Train accuracy: 0.567 ;IOU accuracy: 0.647 ;Time: 0:02:31 \n",
      "\n",
      "Testing, ephoc: 26\n",
      "batch: 0 ;B loss: 1.756 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:02:32\n",
      "batch: 50 ;B loss: 1.766 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:02:47\n",
      "batch: 100 ;B loss: 1.875 ;acc: 0.610 ;iou_acc: 0.700 ;time: 0:03:02\n",
      "batch: 150 ;B loss: 1.828 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:03:21\n",
      "batch: 200 ;B loss: 1.813 ;acc: 0.645 ;iou_acc: 0.775 ;time: 0:03:36\n",
      "batch: 250 ;B loss: 1.802 ;acc: 0.620 ;iou_acc: 0.760 ;time: 0:03:51\n",
      "\n",
      "*BTrain: False ;Test loss: 1.784 ;Test accuracy 0.666 ;IOU accuracy: 0.761 ;Time: 0:04:05\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 27 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12016 ;lr: 0.1980 ;B loss: 2.182 ;acc: 0.610 ;iou: 0.670 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12066 ;lr: 0.1980 ;B loss: 2.193 ;acc: 0.580 ;iou: 0.660 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12116 ;lr: 0.1980 ;B loss: 2.321 ;acc: 0.470 ;iou: 0.585 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12166 ;lr: 0.1980 ;B loss: 2.171 ;acc: 0.580 ;iou: 0.660 ;time: 0:00:48\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12216 ;lr: 0.1980 ;B loss: 2.156 ;acc: 0.530 ;iou: 0.600 ;time: 0:01:05\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12266 ;lr: 0.1980 ;B loss: 2.158 ;acc: 0.560 ;iou: 0.660 ;time: 0:01:19\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 12316 ;lr: 0.1980 ;B loss: 2.130 ;acc: 0.560 ;iou: 0.635 ;time: 0:01:34\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 12366 ;lr: 0.1980 ;B loss: 2.191 ;acc: 0.530 ;iou: 0.645 ;time: 0:01:49\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 12416 ;lr: 0.1980 ;B loss: 2.168 ;acc: 0.570 ;iou: 0.650 ;time: 0:02:04\n",
      "\n",
      "*Training B: True ;B Train loss: 2.168 ;Train accuracy: 0.572 ;IOU accuracy: 0.651 ;Time: 0:02:19 \n",
      "\n",
      "Testing, ephoc: 27\n",
      "batch: 0 ;B loss: 1.746 ;acc: 0.650 ;iou_acc: 0.740 ;time: 0:02:20\n",
      "batch: 50 ;B loss: 1.731 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:02:34\n",
      "batch: 100 ;B loss: 1.860 ;acc: 0.605 ;iou_acc: 0.685 ;time: 0:02:48\n",
      "batch: 150 ;B loss: 1.820 ;acc: 0.670 ;iou_acc: 0.790 ;time: 0:03:03\n",
      "batch: 200 ;B loss: 1.783 ;acc: 0.645 ;iou_acc: 0.760 ;time: 0:03:16\n",
      "batch: 250 ;B loss: 1.784 ;acc: 0.620 ;iou_acc: 0.730 ;time: 0:03:28\n",
      "\n",
      "*BTrain: True ;Test loss: 1.766 ;Test accuracy 0.674 ;IOU accuracy: 0.770 ;Time: 0:03:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 28 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12461 ;lr: 0.1980 ;B loss: 2.288 ;acc: 0.540 ;iou: 0.625 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12511 ;lr: 0.1980 ;B loss: 2.179 ;acc: 0.565 ;iou: 0.650 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 12561 ;lr: 0.1980 ;B loss: 2.248 ;acc: 0.580 ;iou: 0.665 ;time: 0:01:17\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 12611 ;lr: 0.1980 ;B loss: 2.132 ;acc: 0.560 ;iou: 0.645 ;time: 0:01:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 12661 ;lr: 0.1980 ;B loss: 2.206 ;acc: 0.545 ;iou: 0.635 ;time: 0:01:49\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 12711 ;lr: 0.1980 ;B loss: 2.259 ;acc: 0.560 ;iou: 0.665 ;time: 0:02:04\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 12761 ;lr: 0.1980 ;B loss: 2.129 ;acc: 0.645 ;iou: 0.715 ;time: 0:02:19\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 12811 ;lr: 0.1980 ;B loss: 2.168 ;acc: 0.555 ;iou: 0.645 ;time: 0:02:35\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 12861 ;lr: 0.1980 ;B loss: 2.292 ;acc: 0.530 ;iou: 0.605 ;time: 0:02:52\n",
      "\n",
      "*Training B: False ;B Train loss: 2.160 ;Train accuracy: 0.575 ;IOU accuracy: 0.653 ;Time: 0:03:06 \n",
      "\n",
      "Testing, ephoc: 28\n",
      "batch: 0 ;B loss: 1.725 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:03:07\n",
      "batch: 50 ;B loss: 1.740 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:03:21\n",
      "batch: 100 ;B loss: 1.848 ;acc: 0.625 ;iou_acc: 0.695 ;time: 0:03:36\n",
      "batch: 150 ;B loss: 1.837 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:03:51\n",
      "batch: 200 ;B loss: 1.778 ;acc: 0.690 ;iou_acc: 0.795 ;time: 0:04:05\n",
      "batch: 250 ;B loss: 1.767 ;acc: 0.620 ;iou_acc: 0.730 ;time: 0:04:19\n",
      "\n",
      "*BTrain: False ;Test loss: 1.760 ;Test accuracy 0.673 ;IOU accuracy: 0.768 ;Time: 0:04:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12906 ;lr: 0.1980 ;B loss: 2.165 ;acc: 0.600 ;iou: 0.660 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12956 ;lr: 0.1980 ;B loss: 2.264 ;acc: 0.510 ;iou: 0.600 ;time: 0:00:15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-53bb2b0a6767>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdropout_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdropout_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         dropout_out=dropout_out)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0maug_bnorm_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, use_wordAttn, addNoise)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                         attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(trn_data, \n\u001b[0;32m--> 543\u001b[0;31m                                                                                             b*self.batch_size, (b+1)*self.batch_size, addNoise=addNoise)\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                         \u001b[0mreward_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dummy holder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mbuild_data\u001b[0;34m(self, data, start, end, addNoise)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mpadded_im\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mpadded_im\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Augmenting data\n",
    "# The accuracy and IOU of the trainin set includs data points \n",
    "# with no true groinding bbox so the true training's accuracy and IOU\n",
    "# is higher then we can see in the reults here (TODO: fix it)\n",
    "# increasing learning rate even more\n",
    "\n",
    "num_hidden = 200\n",
    "dropout_in=0.5\n",
    "dropout_out=1.\n",
    "dropout_img = 0.5\n",
    "params_dir = params_dir_tmp+'bnorm_base/augmented_'+str(dropout_in)+','+str(dropout_out)+','+str(dropout_img)+'_hidden:'+str(num_hidden)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=num_hidden,\n",
    "    img_dims=trainset[0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][1][1].shape[1], \n",
    "    lr=.2,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.99, \n",
    "    edit_reward=0.,\n",
    "    rnn_editProb=0.,\n",
    "    coefAlr=1,\n",
    "    bnorm=True)\n",
    "\n",
    "\n",
    "# start comp\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=100,\n",
    "        start_ephoc=21,\n",
    "        startA=101,\n",
    "        activation_ephoc=101,\n",
    "        muteB=0, \n",
    "        activateAProb=0,\n",
    "        max_activateAProb=0,\n",
    "        editProb=0,\n",
    "        edit_reward=0,\n",
    "        dropout_img=dropout_img,\n",
    "        dropout_in=dropout_in,\n",
    "        dropout_out=dropout_out)\n",
    "\n",
    "aug_bnorm_test_res.append(tst)\n",
    "aug_bnorm_train_res.append(trn)\n",
    "print('\\n'+'*'*100)\n",
    "print('*'*100)\n",
    "print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.1\n",
      "# Train set size: 89173\n",
      "# Training batches: 445\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Loading parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-28\n",
      "INFO:tensorflow:Restoring parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-28\n",
      "================================================== \n",
      "Train, ephoc: 29 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 12906 ;lr: 0.0990 ;B loss: 2.098 ;acc: 0.525 ;iou: 0.645 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 12956 ;lr: 0.0990 ;B loss: 2.029 ;acc: 0.600 ;iou: 0.690 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13006 ;lr: 0.0990 ;B loss: 2.156 ;acc: 0.585 ;iou: 0.635 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13056 ;lr: 0.0990 ;B loss: 2.068 ;acc: 0.555 ;iou: 0.615 ;time: 0:00:50\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13106 ;lr: 0.0990 ;B loss: 2.097 ;acc: 0.565 ;iou: 0.645 ;time: 0:01:06\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13156 ;lr: 0.0990 ;B loss: 2.243 ;acc: 0.565 ;iou: 0.625 ;time: 0:01:23\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 13206 ;lr: 0.0990 ;B loss: 2.213 ;acc: 0.560 ;iou: 0.635 ;time: 0:01:41\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 13256 ;lr: 0.0990 ;B loss: 2.128 ;acc: 0.570 ;iou: 0.660 ;time: 0:01:58\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 13306 ;lr: 0.0990 ;B loss: 2.125 ;acc: 0.545 ;iou: 0.670 ;time: 0:02:15\n",
      "\n",
      "*Training B: False ;B Train loss: 2.136 ;Train accuracy: 0.575 ;IOU accuracy: 0.653 ;Time: 0:02:29 \n",
      "\n",
      "Testing, ephoc: 29\n",
      "batch: 0 ;B loss: 1.705 ;acc: 0.710 ;iou_acc: 0.770 ;time: 0:02:30\n",
      "batch: 50 ;B loss: 1.700 ;acc: 0.640 ;iou_acc: 0.735 ;time: 0:02:44\n",
      "batch: 100 ;B loss: 1.817 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:02:58\n",
      "batch: 150 ;B loss: 1.799 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:03:13\n",
      "batch: 200 ;B loss: 1.744 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:03:27\n",
      "batch: 250 ;B loss: 1.741 ;acc: 0.660 ;iou_acc: 0.760 ;time: 0:03:42\n",
      "\n",
      "*BTrain: False ;Test loss: 1.736 ;Test accuracy 0.682 ;IOU accuracy: 0.775 ;Time: 0:03:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 30 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13351 ;lr: 0.0990 ;B loss: 2.090 ;acc: 0.610 ;iou: 0.640 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13401 ;lr: 0.0990 ;B loss: 2.192 ;acc: 0.595 ;iou: 0.655 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13451 ;lr: 0.0990 ;B loss: 2.185 ;acc: 0.575 ;iou: 0.700 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13501 ;lr: 0.0990 ;B loss: 2.301 ;acc: 0.520 ;iou: 0.615 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13551 ;lr: 0.0990 ;B loss: 1.931 ;acc: 0.630 ;iou: 0.740 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 13601 ;lr: 0.0990 ;B loss: 2.201 ;acc: 0.555 ;iou: 0.635 ;time: 0:01:20\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 13651 ;lr: 0.0990 ;B loss: 2.190 ;acc: 0.560 ;iou: 0.630 ;time: 0:01:37\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 13701 ;lr: 0.0990 ;B loss: 2.014 ;acc: 0.585 ;iou: 0.645 ;time: 0:01:53\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 13751 ;lr: 0.0990 ;B loss: 2.147 ;acc: 0.560 ;iou: 0.685 ;time: 0:02:16\n",
      "\n",
      "*Training B: True ;B Train loss: 2.129 ;Train accuracy: 0.578 ;IOU accuracy: 0.655 ;Time: 0:02:31 \n",
      "\n",
      "Testing, ephoc: 30\n",
      "batch: 0 ;B loss: 1.716 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:02:32\n",
      "batch: 50 ;B loss: 1.686 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:02:46\n",
      "batch: 100 ;B loss: 1.806 ;acc: 0.635 ;iou_acc: 0.710 ;time: 0:03:01\n",
      "batch: 150 ;B loss: 1.790 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:03:16\n",
      "batch: 200 ;B loss: 1.738 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:03:30\n",
      "batch: 250 ;B loss: 1.738 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:03:45\n",
      "\n",
      "*BTrain: True ;Test loss: 1.727 ;Test accuracy 0.686 ;IOU accuracy: 0.779 ;Time: 0:03:58\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 31 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 13796 ;lr: 0.0990 ;B loss: 2.034 ;acc: 0.620 ;iou: 0.710 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 13846 ;lr: 0.0990 ;B loss: 2.042 ;acc: 0.650 ;iou: 0.720 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 13896 ;lr: 0.0990 ;B loss: 2.193 ;acc: 0.570 ;iou: 0.640 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 13946 ;lr: 0.0990 ;B loss: 2.181 ;acc: 0.560 ;iou: 0.645 ;time: 0:00:51\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 13996 ;lr: 0.0990 ;B loss: 2.153 ;acc: 0.610 ;iou: 0.690 ;time: 0:01:08\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14046 ;lr: 0.0990 ;B loss: 2.129 ;acc: 0.585 ;iou: 0.685 ;time: 0:01:25\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 14096 ;lr: 0.0990 ;B loss: 2.202 ;acc: 0.600 ;iou: 0.670 ;time: 0:01:41\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 14146 ;lr: 0.0990 ;B loss: 2.193 ;acc: 0.535 ;iou: 0.615 ;time: 0:02:13\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 14196 ;lr: 0.0990 ;B loss: 2.098 ;acc: 0.575 ;iou: 0.645 ;time: 0:02:31\n",
      "\n",
      "*Training B: False ;B Train loss: 2.122 ;Train accuracy: 0.581 ;IOU accuracy: 0.658 ;Time: 0:02:46 \n",
      "\n",
      "Testing, ephoc: 31\n",
      "batch: 0 ;B loss: 1.693 ;acc: 0.705 ;iou_acc: 0.755 ;time: 0:02:46\n",
      "batch: 50 ;B loss: 1.686 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:03:01\n",
      "batch: 100 ;B loss: 1.795 ;acc: 0.630 ;iou_acc: 0.700 ;time: 0:03:14\n",
      "batch: 150 ;B loss: 1.789 ;acc: 0.645 ;iou_acc: 0.740 ;time: 0:03:29\n",
      "batch: 200 ;B loss: 1.727 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:03:43\n",
      "batch: 250 ;B loss: 1.716 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:03:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.717 ;Test accuracy 0.685 ;IOU accuracy: 0.778 ;Time: 0:04:10\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14241 ;lr: 0.0990 ;B loss: 2.094 ;acc: 0.635 ;iou: 0.695 ;time: 0:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0b54a750c262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdropout_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdropout_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         dropout_out=dropout_out)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0maug_bnorm_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, use_wordAttn, addNoise)\u001b[0m\n\u001b[1;32m    667\u001b[0m                             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misEdit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misEdit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                             iou_acc = self.iou_accuracy(trn_data, b*self.batch_size, (b+1)*self.batch_size, \n\u001b[0;32m--> 669\u001b[0;31m                                                         sess=sess, feed_dict=feed_dict, isEdit=isEdit)\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                             \u001b[0mtrn_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrn_nbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36miou_accuracy\u001b[0;34m(self, data, start, end, sess, feed_dict, threshold, test, isEdit)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misEdit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misEdit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misEdit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misEdit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mground\u001b[0;34m(self, data, start, end, sess, feed_dict, isEdit)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get score for each bbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Augmenting data\n",
    "# The accuracy and IOU of the trainin set includs data points \n",
    "# with no true groinding bbox so the true training's accuracy and IOU\n",
    "# is higher then we can see in the reults here (TODO: fix it)\n",
    "# decreasing learning rate even more\n",
    "\n",
    "num_hidden = 200\n",
    "dropout_in=0.5\n",
    "dropout_out=1.\n",
    "dropout_img = 0.5\n",
    "params_dir = params_dir_tmp+'bnorm_base/augmented_'+str(dropout_in)+','+str(dropout_out)+','+str(dropout_img)+'_hidden:'+str(num_hidden)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=num_hidden,\n",
    "    img_dims=trainset[0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][1][1].shape[1], \n",
    "    lr=.1,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.99, \n",
    "    edit_reward=0.,\n",
    "    rnn_editProb=0.,\n",
    "    coefAlr=1,\n",
    "    bnorm=True)\n",
    "\n",
    "\n",
    "# start comp\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=100,\n",
    "        start_ephoc=29,\n",
    "        startA=101,\n",
    "        activation_ephoc=101,\n",
    "        muteB=0, \n",
    "        activateAProb=0,\n",
    "        max_activateAProb=0,\n",
    "        editProb=0,\n",
    "        edit_reward=0,\n",
    "        dropout_img=dropout_img,\n",
    "        dropout_in=dropout_in,\n",
    "        dropout_out=dropout_out)\n",
    "\n",
    "aug_bnorm_test_res.append(tst)\n",
    "aug_bnorm_train_res.append(trn)\n",
    "print('\\n'+'*'*100)\n",
    "print('*'*100)\n",
    "print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 89173\n",
      "# Training batches: 445\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Loading parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-31\n",
      "INFO:tensorflow:Restoring parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-31\n",
      "================================================== \n",
      "Train, ephoc: 32 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14241 ;lr: 0.0495 ;B loss: 2.237 ;acc: 0.535 ;iou: 0.620 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14291 ;lr: 0.0495 ;B loss: 2.164 ;acc: 0.560 ;iou: 0.640 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14341 ;lr: 0.0495 ;B loss: 2.208 ;acc: 0.465 ;iou: 0.560 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14391 ;lr: 0.0495 ;B loss: 2.006 ;acc: 0.595 ;iou: 0.660 ;time: 0:00:49\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14441 ;lr: 0.0495 ;B loss: 2.150 ;acc: 0.545 ;iou: 0.650 ;time: 0:01:07\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14491 ;lr: 0.0495 ;B loss: 2.076 ;acc: 0.610 ;iou: 0.660 ;time: 0:01:24\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 14541 ;lr: 0.0495 ;B loss: 2.250 ;acc: 0.570 ;iou: 0.650 ;time: 0:02:04\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 14591 ;lr: 0.0495 ;B loss: 2.123 ;acc: 0.585 ;iou: 0.705 ;time: 0:03:04\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 14641 ;lr: 0.0495 ;B loss: 2.120 ;acc: 0.620 ;iou: 0.665 ;time: 0:04:06\n",
      "\n",
      "*Training B: False ;B Train loss: 2.110 ;Train accuracy: 0.581 ;IOU accuracy: 0.658 ;Time: 0:04:21 \n",
      "\n",
      "Testing, ephoc: 32\n",
      "batch: 0 ;B loss: 1.687 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:04:22\n",
      "batch: 50 ;B loss: 1.672 ;acc: 0.670 ;iou_acc: 0.735 ;time: 0:04:35\n",
      "batch: 100 ;B loss: 1.806 ;acc: 0.635 ;iou_acc: 0.710 ;time: 0:04:48\n",
      "batch: 150 ;B loss: 1.780 ;acc: 0.650 ;iou_acc: 0.765 ;time: 0:05:02\n",
      "batch: 200 ;B loss: 1.718 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:05:16\n",
      "batch: 250 ;B loss: 1.712 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:05:30\n",
      "\n",
      "*BTrain: False ;Test loss: 1.709 ;Test accuracy 0.689 ;IOU accuracy: 0.782 ;Time: 0:05:44\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 33 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 14686 ;lr: 0.0495 ;B loss: 2.090 ;acc: 0.565 ;iou: 0.640 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 14736 ;lr: 0.0495 ;B loss: 2.167 ;acc: 0.560 ;iou: 0.620 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 14786 ;lr: 0.0495 ;B loss: 2.201 ;acc: 0.565 ;iou: 0.635 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 14836 ;lr: 0.0495 ;B loss: 2.103 ;acc: 0.595 ;iou: 0.665 ;time: 0:00:48\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 14886 ;lr: 0.0495 ;B loss: 2.171 ;acc: 0.540 ;iou: 0.645 ;time: 0:01:05\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 14936 ;lr: 0.0495 ;B loss: 2.083 ;acc: 0.570 ;iou: 0.635 ;time: 0:01:21\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 14986 ;lr: 0.0495 ;B loss: 2.030 ;acc: 0.650 ;iou: 0.730 ;time: 0:01:38\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 15036 ;lr: 0.0495 ;B loss: 2.204 ;acc: 0.545 ;iou: 0.620 ;time: 0:02:41\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 15086 ;lr: 0.0495 ;B loss: 2.085 ;acc: 0.525 ;iou: 0.605 ;time: 0:03:57\n",
      "\n",
      "*Training B: True ;B Train loss: 2.107 ;Train accuracy: 0.583 ;IOU accuracy: 0.659 ;Time: 0:04:55 \n",
      "\n",
      "Testing, ephoc: 33\n",
      "batch: 0 ;B loss: 1.674 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:04:57\n",
      "batch: 50 ;B loss: 1.677 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:06:04\n",
      "batch: 100 ;B loss: 1.796 ;acc: 0.640 ;iou_acc: 0.715 ;time: 0:07:02\n",
      "batch: 150 ;B loss: 1.775 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:08:04\n",
      "batch: 200 ;B loss: 1.717 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:09:05\n",
      "batch: 250 ;B loss: 1.702 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:10:05\n",
      "\n",
      "*BTrain: True ;Test loss: 1.699 ;Test accuracy 0.692 ;IOU accuracy: 0.784 ;Time: 0:11:08\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 34 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15131 ;lr: 0.0495 ;B loss: 1.970 ;acc: 0.615 ;iou: 0.710 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15181 ;lr: 0.0495 ;B loss: 2.136 ;acc: 0.585 ;iou: 0.660 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15231 ;lr: 0.0495 ;B loss: 2.128 ;acc: 0.595 ;iou: 0.665 ;time: 0:02:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15281 ;lr: 0.0495 ;B loss: 2.102 ;acc: 0.625 ;iou: 0.685 ;time: 0:03:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15331 ;lr: 0.0495 ;B loss: 2.058 ;acc: 0.640 ;iou: 0.715 ;time: 0:04:26\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15381 ;lr: 0.0495 ;B loss: 1.919 ;acc: 0.655 ;iou: 0.720 ;time: 0:04:40\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 15431 ;lr: 0.0495 ;B loss: 2.256 ;acc: 0.550 ;iou: 0.630 ;time: 0:04:55\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 15481 ;lr: 0.0495 ;B loss: 2.158 ;acc: 0.550 ;iou: 0.630 ;time: 0:05:10\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 15531 ;lr: 0.0495 ;B loss: 2.115 ;acc: 0.595 ;iou: 0.675 ;time: 0:05:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.104 ;Train accuracy: 0.583 ;IOU accuracy: 0.660 ;Time: 0:05:40 \n",
      "\n",
      "Testing, ephoc: 34\n",
      "batch: 0 ;B loss: 1.685 ;acc: 0.695 ;iou_acc: 0.755 ;time: 0:05:40\n",
      "batch: 50 ;B loss: 1.682 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:05:55\n",
      "batch: 100 ;B loss: 1.795 ;acc: 0.640 ;iou_acc: 0.710 ;time: 0:06:10\n",
      "batch: 150 ;B loss: 1.773 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:06:24\n",
      "batch: 200 ;B loss: 1.710 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:06:38\n",
      "batch: 250 ;B loss: 1.698 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:06:53\n",
      "\n",
      "*BTrain: False ;Test loss: 1.704 ;Test accuracy 0.691 ;IOU accuracy: 0.784 ;Time: 0:07:18\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 35 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 15576 ;lr: 0.0495 ;B loss: 2.099 ;acc: 0.560 ;iou: 0.640 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 15626 ;lr: 0.0495 ;B loss: 2.116 ;acc: 0.580 ;iou: 0.660 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 15676 ;lr: 0.0495 ;B loss: 2.036 ;acc: 0.670 ;iou: 0.710 ;time: 0:00:56\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 15726 ;lr: 0.0495 ;B loss: 2.037 ;acc: 0.570 ;iou: 0.635 ;time: 0:01:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 15776 ;lr: 0.0495 ;B loss: 2.134 ;acc: 0.555 ;iou: 0.630 ;time: 0:01:51\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 15826 ;lr: 0.0495 ;B loss: 2.224 ;acc: 0.565 ;iou: 0.640 ;time: 0:02:20\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 15876 ;lr: 0.0495 ;B loss: 2.085 ;acc: 0.570 ;iou: 0.645 ;time: 0:02:48\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 15926 ;lr: 0.0495 ;B loss: 2.100 ;acc: 0.570 ;iou: 0.680 ;time: 0:03:46\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 15976 ;lr: 0.0495 ;B loss: 2.044 ;acc: 0.575 ;iou: 0.635 ;time: 0:04:26\n",
      "\n",
      "*Training B: False ;B Train loss: 2.098 ;Train accuracy: 0.585 ;IOU accuracy: 0.661 ;Time: 0:04:52 \n",
      "\n",
      "Testing, ephoc: 35\n",
      "batch: 0 ;B loss: 1.680 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:04:53\n",
      "batch: 50 ;B loss: 1.665 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:05:19\n",
      "batch: 100 ;B loss: 1.788 ;acc: 0.635 ;iou_acc: 0.705 ;time: 0:05:44\n",
      "batch: 150 ;B loss: 1.772 ;acc: 0.655 ;iou_acc: 0.765 ;time: 0:06:10\n",
      "batch: 200 ;B loss: 1.700 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:06:36\n",
      "batch: 250 ;B loss: 1.693 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:07:40\n",
      "\n",
      "*BTrain: False ;Test loss: 1.696 ;Test accuracy 0.693 ;IOU accuracy: 0.785 ;Time: 0:08:45\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 36 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16021 ;lr: 0.0495 ;B loss: 2.141 ;acc: 0.560 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16071 ;lr: 0.0495 ;B loss: 2.105 ;acc: 0.580 ;iou: 0.675 ;time: 0:01:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16121 ;lr: 0.0495 ;B loss: 2.131 ;acc: 0.575 ;iou: 0.660 ;time: 0:02:24\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16171 ;lr: 0.0495 ;B loss: 2.154 ;acc: 0.560 ;iou: 0.640 ;time: 0:03:38\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16221 ;lr: 0.0495 ;B loss: 2.134 ;acc: 0.570 ;iou: 0.645 ;time: 0:05:00\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16271 ;lr: 0.0495 ;B loss: 1.958 ;acc: 0.640 ;iou: 0.715 ;time: 0:06:25\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 16321 ;lr: 0.0495 ;B loss: 2.049 ;acc: 0.600 ;iou: 0.660 ;time: 0:07:09\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 16371 ;lr: 0.0495 ;B loss: 2.099 ;acc: 0.575 ;iou: 0.650 ;time: 0:07:35\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 16421 ;lr: 0.0495 ;B loss: 2.168 ;acc: 0.615 ;iou: 0.675 ;time: 0:08:01\n",
      "\n",
      "*Training B: True ;B Train loss: 2.096 ;Train accuracy: 0.586 ;IOU accuracy: 0.663 ;Time: 0:08:26 \n",
      "\n",
      "Testing, ephoc: 36\n",
      "batch: 0 ;B loss: 1.681 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:08:27\n",
      "batch: 50 ;B loss: 1.668 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:08:52\n",
      "batch: 100 ;B loss: 1.789 ;acc: 0.640 ;iou_acc: 0.710 ;time: 0:09:18\n",
      "batch: 150 ;B loss: 1.774 ;acc: 0.665 ;iou_acc: 0.775 ;time: 0:10:16\n",
      "batch: 200 ;B loss: 1.703 ;acc: 0.695 ;iou_acc: 0.800 ;time: 0:11:30\n",
      "batch: 250 ;B loss: 1.702 ;acc: 0.655 ;iou_acc: 0.765 ;time: 0:12:33\n",
      "\n",
      "*BTrain: True ;Test loss: 1.699 ;Test accuracy 0.692 ;IOU accuracy: 0.784 ;Time: 0:13:28\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16466 ;lr: 0.0495 ;B loss: 2.151 ;acc: 0.560 ;iou: 0.645 ;time: 0:00:02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5bbd5bc734c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdropout_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdropout_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         dropout_out=dropout_out)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0maug_bnorm_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, use_wordAttn, addNoise)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                         attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(trn_data, \n\u001b[0;32m--> 543\u001b[0;31m                                                                                             b*self.batch_size, (b+1)*self.batch_size, addNoise=addNoise)\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                         \u001b[0mreward_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dummy holder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mbuild_data\u001b[0;34m(self, data, start, end, addNoise)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mpadded_im\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mpadded_im\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Augmenting data\n",
    "# The accuracy and IOU of the trainin set includs data points \n",
    "# with no true groinding bbox so the true training's accuracy and IOU\n",
    "# is higher then we can see in the reults here (TODO: fix it)\n",
    "# decreasing learning rate even more\n",
    "\n",
    "num_hidden = 200\n",
    "dropout_in=0.5\n",
    "dropout_out=1.\n",
    "dropout_img = 0.5\n",
    "params_dir = params_dir_tmp+'bnorm_base/augmented_'+str(dropout_in)+','+str(dropout_out)+','+str(dropout_img)+'_hidden:'+str(num_hidden)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=num_hidden,\n",
    "    img_dims=trainset[0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][1][1].shape[1], \n",
    "    lr=.05,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.99, \n",
    "    edit_reward=0.,\n",
    "    rnn_editProb=0.,\n",
    "    coefAlr=1,\n",
    "    bnorm=True)\n",
    "\n",
    "\n",
    "# start comp\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=100,\n",
    "        start_ephoc=32,\n",
    "        startA=101,\n",
    "        activation_ephoc=101,\n",
    "        muteB=0, \n",
    "        activateAProb=0,\n",
    "        max_activateAProb=0,\n",
    "        editProb=0,\n",
    "        edit_reward=0,\n",
    "        dropout_img=dropout_img,\n",
    "        dropout_in=dropout_in,\n",
    "        dropout_out=dropout_out)\n",
    "\n",
    "aug_bnorm_test_res.append(tst)\n",
    "aug_bnorm_train_res.append(trn)\n",
    "print('\\n'+'*'*100)\n",
    "print('*'*100)\n",
    "print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.005\n",
      "# Train set size: 89173\n",
      "# Training batches: 445\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Loading parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-36\n",
      "INFO:tensorflow:Restoring parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-36\n",
      "================================================== \n",
      "Train, ephoc: 37 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16466 ;lr: 0.0049 ;B loss: 2.067 ;acc: 0.590 ;iou: 0.685 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16516 ;lr: 0.0049 ;B loss: 2.090 ;acc: 0.585 ;iou: 0.640 ;time: 0:01:06\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 16566 ;lr: 0.0049 ;B loss: 2.112 ;acc: 0.595 ;iou: 0.620 ;time: 0:02:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 16616 ;lr: 0.0049 ;B loss: 2.139 ;acc: 0.540 ;iou: 0.630 ;time: 0:03:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 16666 ;lr: 0.0049 ;B loss: 1.980 ;acc: 0.625 ;iou: 0.695 ;time: 0:04:52\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 16716 ;lr: 0.0049 ;B loss: 2.122 ;acc: 0.545 ;iou: 0.630 ;time: 0:06:05\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 16766 ;lr: 0.0049 ;B loss: 2.116 ;acc: 0.555 ;iou: 0.630 ;time: 0:07:17\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 16816 ;lr: 0.0049 ;B loss: 2.092 ;acc: 0.590 ;iou: 0.665 ;time: 0:08:27\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 16866 ;lr: 0.0049 ;B loss: 1.949 ;acc: 0.640 ;iou: 0.725 ;time: 0:09:48\n",
      "\n",
      "*Training B: False ;B Train loss: 2.087 ;Train accuracy: 0.583 ;IOU accuracy: 0.659 ;Time: 0:10:45 \n",
      "\n",
      "Testing, ephoc: 37\n",
      "batch: 0 ;B loss: 1.677 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:10:46\n",
      "batch: 50 ;B loss: 1.664 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:11:52\n",
      "batch: 100 ;B loss: 1.780 ;acc: 0.640 ;iou_acc: 0.710 ;time: 0:12:55\n",
      "batch: 150 ;B loss: 1.767 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:14:02\n",
      "batch: 200 ;B loss: 1.697 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:15:07\n",
      "batch: 250 ;B loss: 1.695 ;acc: 0.660 ;iou_acc: 0.765 ;time: 0:16:17\n",
      "\n",
      "*BTrain: False ;Test loss: 1.694 ;Test accuracy 0.694 ;IOU accuracy: 0.786 ;Time: 0:17:20\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16911 ;lr: 0.0049 ;B loss: 2.181 ;acc: 0.555 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16961 ;lr: 0.0049 ;B loss: 2.232 ;acc: 0.515 ;iou: 0.595 ;time: 0:01:11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-77ea251605c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdropout_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdropout_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         dropout_out=dropout_out)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0maug_bnorm_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, use_wordAttn, addNoise)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                         attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(trn_data, \n\u001b[0;32m--> 543\u001b[0;31m                                                                                             b*self.batch_size, (b+1)*self.batch_size, addNoise=addNoise)\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                         \u001b[0mreward_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dummy holder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-142af79a318b>\u001b[0m in \u001b[0;36mbuild_data\u001b[0;34m(self, data, start, end, addNoise)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mpadded_im\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mpadded_im\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Augmenting data\n",
    "# The accuracy and IOU of the trainin set includs data points \n",
    "# with no true groinding bbox so the true training's accuracy and IOU\n",
    "# is higher then we can see in the reults here (TODO: fix it)\n",
    "# decreasing learning rate even more\n",
    "\n",
    "num_hidden = 200\n",
    "dropout_in=0.5\n",
    "dropout_out=1.\n",
    "dropout_img = 0.5\n",
    "params_dir = params_dir_tmp+'bnorm_base/augmented_'+str(dropout_in)+','+str(dropout_out)+','+str(dropout_img)+'_hidden:'+str(num_hidden)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=num_hidden,\n",
    "    img_dims=trainset[0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][1][1].shape[1], \n",
    "    lr=.005,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.99, \n",
    "    edit_reward=0.,\n",
    "    rnn_editProb=0.,\n",
    "    coefAlr=1,\n",
    "    bnorm=True)\n",
    "\n",
    "\n",
    "# start comp\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=100,\n",
    "        start_ephoc=37,\n",
    "        startA=101,\n",
    "        activation_ephoc=101,\n",
    "        muteB=0, \n",
    "        activateAProb=0,\n",
    "        max_activateAProb=0,\n",
    "        editProb=0,\n",
    "        edit_reward=0,\n",
    "        dropout_img=dropout_img,\n",
    "        dropout_in=dropout_in,\n",
    "        dropout_out=dropout_out)\n",
    "\n",
    "aug_bnorm_test_res.append(tst)\n",
    "aug_bnorm_train_res.append(trn)\n",
    "print('\\n'+'*'*100)\n",
    "print('*'*100)\n",
    "print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59449\n",
      "89173\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 89173\n",
      "# Training batches: 445\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Loading parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-37\n",
      "INFO:tensorflow:Restoring parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-37\n",
      "================================================== \n",
      "Train, ephoc: 38 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 16911 ;lr: 0.0495 ;B loss: 2.077 ;acc: 0.565 ;iou: 0.650 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 16961 ;lr: 0.0495 ;B loss: 2.238 ;acc: 0.595 ;iou: 0.665 ;time: 0:00:10\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17011 ;lr: 0.0495 ;B loss: 2.048 ;acc: 0.580 ;iou: 0.650 ;time: 0:00:20\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17061 ;lr: 0.0495 ;B loss: 2.077 ;acc: 0.535 ;iou: 0.625 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17111 ;lr: 0.0495 ;B loss: 2.195 ;acc: 0.575 ;iou: 0.645 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17161 ;lr: 0.0495 ;B loss: 2.108 ;acc: 0.580 ;iou: 0.625 ;time: 0:00:51\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 17211 ;lr: 0.0495 ;B loss: 2.021 ;acc: 0.580 ;iou: 0.660 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 17261 ;lr: 0.0495 ;B loss: 2.117 ;acc: 0.625 ;iou: 0.675 ;time: 0:01:12\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 17311 ;lr: 0.0495 ;B loss: 2.219 ;acc: 0.540 ;iou: 0.610 ;time: 0:01:23\n",
      "\n",
      "*Training B: False ;B Train loss: 2.104 ;Train accuracy: 0.588 ;IOU accuracy: 0.664 ;Time: 0:01:33 \n",
      "\n",
      "Testing, ephoc: 38\n",
      "batch: 0 ;B loss: 1.689 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:01:34\n",
      "batch: 50 ;B loss: 1.674 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:01:42\n",
      "batch: 100 ;B loss: 1.779 ;acc: 0.655 ;iou_acc: 0.730 ;time: 0:01:51\n",
      "batch: 150 ;B loss: 1.767 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:02:00\n",
      "batch: 200 ;B loss: 1.708 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:02:10\n",
      "batch: 250 ;B loss: 1.705 ;acc: 0.665 ;iou_acc: 0.765 ;time: 0:02:19\n",
      "\n",
      "*BTrain: False ;Test loss: 1.701 ;Test accuracy 0.695 ;IOU accuracy: 0.787 ;Time: 0:02:28\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 39 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17356 ;lr: 0.0495 ;B loss: 2.168 ;acc: 0.575 ;iou: 0.655 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17406 ;lr: 0.0495 ;B loss: 2.215 ;acc: 0.540 ;iou: 0.605 ;time: 0:00:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17456 ;lr: 0.0495 ;B loss: 2.095 ;acc: 0.565 ;iou: 0.645 ;time: 0:00:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17506 ;lr: 0.0495 ;B loss: 2.030 ;acc: 0.560 ;iou: 0.650 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 17556 ;lr: 0.0495 ;B loss: 2.100 ;acc: 0.590 ;iou: 0.670 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 17606 ;lr: 0.0495 ;B loss: 2.096 ;acc: 0.610 ;iou: 0.670 ;time: 0:00:55\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 17656 ;lr: 0.0495 ;B loss: 2.136 ;acc: 0.610 ;iou: 0.675 ;time: 0:01:06\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 17706 ;lr: 0.0495 ;B loss: 1.965 ;acc: 0.635 ;iou: 0.710 ;time: 0:01:16\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 17756 ;lr: 0.0495 ;B loss: 2.201 ;acc: 0.550 ;iou: 0.645 ;time: 0:01:27\n",
      "\n",
      "*Training B: True ;B Train loss: 2.100 ;Train accuracy: 0.590 ;IOU accuracy: 0.665 ;Time: 0:01:37 \n",
      "\n",
      "Testing, ephoc: 39\n",
      "batch: 0 ;B loss: 1.688 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:01:38\n",
      "batch: 50 ;B loss: 1.665 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:01:48\n",
      "batch: 100 ;B loss: 1.781 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:01:57\n",
      "batch: 150 ;B loss: 1.764 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:02:07\n",
      "batch: 200 ;B loss: 1.703 ;acc: 0.695 ;iou_acc: 0.805 ;time: 0:02:16\n",
      "batch: 250 ;B loss: 1.698 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:02:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.697 ;Test accuracy 0.696 ;IOU accuracy: 0.788 ;Time: 0:02:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 40 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 17801 ;lr: 0.0495 ;B loss: 2.133 ;acc: 0.630 ;iou: 0.710 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 17851 ;lr: 0.0495 ;B loss: 2.064 ;acc: 0.580 ;iou: 0.645 ;time: 0:00:12\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 17901 ;lr: 0.0495 ;B loss: 2.173 ;acc: 0.565 ;iou: 0.645 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 17951 ;lr: 0.0495 ;B loss: 2.069 ;acc: 0.595 ;iou: 0.680 ;time: 0:00:38\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18001 ;lr: 0.0495 ;B loss: 2.025 ;acc: 0.645 ;iou: 0.680 ;time: 0:00:50\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18051 ;lr: 0.0495 ;B loss: 2.016 ;acc: 0.620 ;iou: 0.685 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 18101 ;lr: 0.0495 ;B loss: 2.055 ;acc: 0.585 ;iou: 0.655 ;time: 0:01:14\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 18151 ;lr: 0.0495 ;B loss: 2.079 ;acc: 0.560 ;iou: 0.645 ;time: 0:01:25\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 18201 ;lr: 0.0495 ;B loss: 2.115 ;acc: 0.570 ;iou: 0.670 ;time: 0:01:38\n",
      "\n",
      "*Training B: False ;B Train loss: 2.097 ;Train accuracy: 0.592 ;IOU accuracy: 0.666 ;Time: 0:01:49 \n",
      "\n",
      "Testing, ephoc: 40\n",
      "batch: 0 ;B loss: 1.696 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:49\n",
      "batch: 50 ;B loss: 1.659 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:02:00\n",
      "batch: 100 ;B loss: 1.797 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:02:12\n",
      "batch: 150 ;B loss: 1.769 ;acc: 0.645 ;iou_acc: 0.740 ;time: 0:02:23\n",
      "batch: 200 ;B loss: 1.699 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:02:35\n",
      "batch: 250 ;B loss: 1.693 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:02:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.694 ;Test accuracy 0.697 ;IOU accuracy: 0.789 ;Time: 0:02:57\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 41 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18246 ;lr: 0.0495 ;B loss: 2.037 ;acc: 0.595 ;iou: 0.695 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18296 ;lr: 0.0495 ;B loss: 2.144 ;acc: 0.605 ;iou: 0.690 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18346 ;lr: 0.0495 ;B loss: 2.137 ;acc: 0.670 ;iou: 0.720 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18396 ;lr: 0.0495 ;B loss: 2.062 ;acc: 0.555 ;iou: 0.635 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18446 ;lr: 0.0495 ;B loss: 2.024 ;acc: 0.690 ;iou: 0.745 ;time: 0:00:54\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18496 ;lr: 0.0495 ;B loss: 2.143 ;acc: 0.580 ;iou: 0.625 ;time: 0:01:08\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 18546 ;lr: 0.0495 ;B loss: 2.060 ;acc: 0.620 ;iou: 0.685 ;time: 0:01:21\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 18596 ;lr: 0.0495 ;B loss: 2.005 ;acc: 0.630 ;iou: 0.695 ;time: 0:01:35\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 18646 ;lr: 0.0495 ;B loss: 2.113 ;acc: 0.565 ;iou: 0.670 ;time: 0:01:49\n",
      "\n",
      "*Training B: False ;B Train loss: 2.092 ;Train accuracy: 0.592 ;IOU accuracy: 0.667 ;Time: 0:02:01 \n",
      "\n",
      "Testing, ephoc: 41\n",
      "batch: 0 ;B loss: 1.680 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:02:01\n",
      "batch: 50 ;B loss: 1.665 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:02:14\n",
      "batch: 100 ;B loss: 1.781 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:02:27\n",
      "batch: 150 ;B loss: 1.748 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:02:39\n",
      "batch: 200 ;B loss: 1.697 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:02:51\n",
      "batch: 250 ;B loss: 1.684 ;acc: 0.655 ;iou_acc: 0.760 ;time: 0:03:04\n",
      "\n",
      "*BTrain: False ;Test loss: 1.692 ;Test accuracy 0.698 ;IOU accuracy: 0.789 ;Time: 0:03:15\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 42 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 18691 ;lr: 0.0495 ;B loss: 1.973 ;acc: 0.680 ;iou: 0.725 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 18741 ;lr: 0.0495 ;B loss: 2.049 ;acc: 0.605 ;iou: 0.660 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 18791 ;lr: 0.0495 ;B loss: 2.079 ;acc: 0.640 ;iou: 0.705 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 18841 ;lr: 0.0495 ;B loss: 2.025 ;acc: 0.595 ;iou: 0.665 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 18891 ;lr: 0.0495 ;B loss: 2.063 ;acc: 0.610 ;iou: 0.710 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 18941 ;lr: 0.0495 ;B loss: 2.102 ;acc: 0.600 ;iou: 0.700 ;time: 0:01:18\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 18991 ;lr: 0.0495 ;B loss: 2.042 ;acc: 0.575 ;iou: 0.670 ;time: 0:01:34\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 19041 ;lr: 0.0495 ;B loss: 2.074 ;acc: 0.570 ;iou: 0.665 ;time: 0:01:51\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 19091 ;lr: 0.0495 ;B loss: 2.098 ;acc: 0.580 ;iou: 0.650 ;time: 0:02:07\n",
      "\n",
      "*Training B: True ;B Train loss: 2.088 ;Train accuracy: 0.594 ;IOU accuracy: 0.669 ;Time: 0:02:21 \n",
      "\n",
      "Testing, ephoc: 42\n",
      "batch: 0 ;B loss: 1.683 ;acc: 0.710 ;iou_acc: 0.770 ;time: 0:02:21\n",
      "batch: 50 ;B loss: 1.660 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:02:36\n",
      "batch: 100 ;B loss: 1.764 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:02:52\n",
      "batch: 150 ;B loss: 1.754 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:03:07\n",
      "batch: 200 ;B loss: 1.690 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:03:22\n",
      "batch: 250 ;B loss: 1.685 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:03:36\n",
      "\n",
      "*BTrain: True ;Test loss: 1.687 ;Test accuracy 0.699 ;IOU accuracy: 0.791 ;Time: 0:03:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 43 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19136 ;lr: 0.0495 ;B loss: 2.108 ;acc: 0.640 ;iou: 0.725 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19186 ;lr: 0.0495 ;B loss: 2.006 ;acc: 0.645 ;iou: 0.715 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19236 ;lr: 0.0495 ;B loss: 2.102 ;acc: 0.640 ;iou: 0.665 ;time: 0:00:35\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19286 ;lr: 0.0495 ;B loss: 2.035 ;acc: 0.615 ;iou: 0.665 ;time: 0:00:52\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19336 ;lr: 0.0495 ;B loss: 2.166 ;acc: 0.595 ;iou: 0.670 ;time: 0:01:09\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19386 ;lr: 0.0495 ;B loss: 2.162 ;acc: 0.615 ;iou: 0.695 ;time: 0:01:26\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 19436 ;lr: 0.0495 ;B loss: 2.177 ;acc: 0.575 ;iou: 0.640 ;time: 0:01:43\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 19486 ;lr: 0.0495 ;B loss: 2.052 ;acc: 0.655 ;iou: 0.720 ;time: 0:02:01\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 19536 ;lr: 0.0495 ;B loss: 2.000 ;acc: 0.570 ;iou: 0.690 ;time: 0:02:17\n",
      "\n",
      "*Training B: False ;B Train loss: 2.086 ;Train accuracy: 0.595 ;IOU accuracy: 0.670 ;Time: 0:02:32 \n",
      "\n",
      "Testing, ephoc: 43\n",
      "batch: 0 ;B loss: 1.684 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:02:33\n",
      "batch: 50 ;B loss: 1.655 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:02:47\n",
      "batch: 100 ;B loss: 1.770 ;acc: 0.650 ;iou_acc: 0.720 ;time: 0:03:02\n",
      "batch: 150 ;B loss: 1.758 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:03:17\n",
      "batch: 200 ;B loss: 1.692 ;acc: 0.710 ;iou_acc: 0.830 ;time: 0:03:31\n",
      "batch: 250 ;B loss: 1.672 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:03:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.686 ;Test accuracy 0.699 ;IOU accuracy: 0.790 ;Time: 0:04:00\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 44 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 19581 ;lr: 0.0495 ;B loss: 2.070 ;acc: 0.635 ;iou: 0.710 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 19631 ;lr: 0.0495 ;B loss: 1.911 ;acc: 0.635 ;iou: 0.715 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 19681 ;lr: 0.0495 ;B loss: 2.150 ;acc: 0.590 ;iou: 0.665 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 19731 ;lr: 0.0495 ;B loss: 2.009 ;acc: 0.565 ;iou: 0.645 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 19781 ;lr: 0.0495 ;B loss: 2.037 ;acc: 0.605 ;iou: 0.670 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 19831 ;lr: 0.0495 ;B loss: 2.131 ;acc: 0.620 ;iou: 0.640 ;time: 0:01:22\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 19881 ;lr: 0.0495 ;B loss: 2.157 ;acc: 0.595 ;iou: 0.680 ;time: 0:01:40\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 19931 ;lr: 0.0495 ;B loss: 2.115 ;acc: 0.570 ;iou: 0.650 ;time: 0:02:02\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 19981 ;lr: 0.0495 ;B loss: 1.983 ;acc: 0.620 ;iou: 0.690 ;time: 0:02:38\n",
      "\n",
      "*Training B: False ;B Train loss: 2.081 ;Train accuracy: 0.596 ;IOU accuracy: 0.670 ;Time: 0:02:53 \n",
      "\n",
      "Testing, ephoc: 44\n",
      "batch: 0 ;B loss: 1.665 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:02:54\n",
      "batch: 50 ;B loss: 1.656 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:03:09\n",
      "batch: 100 ;B loss: 1.770 ;acc: 0.645 ;iou_acc: 0.720 ;time: 0:03:23\n",
      "batch: 150 ;B loss: 1.749 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:03:38\n",
      "batch: 200 ;B loss: 1.679 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:03:52\n",
      "batch: 250 ;B loss: 1.664 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:04:05\n",
      "\n",
      "*BTrain: False ;Test loss: 1.680 ;Test accuracy 0.700 ;IOU accuracy: 0.791 ;Time: 0:04:22\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 45 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20026 ;lr: 0.0490 ;B loss: 2.096 ;acc: 0.585 ;iou: 0.655 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20076 ;lr: 0.0490 ;B loss: 2.015 ;acc: 0.665 ;iou: 0.720 ;time: 0:00:26\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20126 ;lr: 0.0490 ;B loss: 2.113 ;acc: 0.605 ;iou: 0.680 ;time: 0:00:52\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20176 ;lr: 0.0490 ;B loss: 1.969 ;acc: 0.640 ;iou: 0.740 ;time: 0:01:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20226 ;lr: 0.0490 ;B loss: 2.086 ;acc: 0.605 ;iou: 0.670 ;time: 0:01:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20276 ;lr: 0.0490 ;B loss: 2.042 ;acc: 0.610 ;iou: 0.680 ;time: 0:02:08\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 20326 ;lr: 0.0490 ;B loss: 2.168 ;acc: 0.605 ;iou: 0.655 ;time: 0:02:34\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 20376 ;lr: 0.0490 ;B loss: 1.990 ;acc: 0.590 ;iou: 0.670 ;time: 0:02:51\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 20426 ;lr: 0.0490 ;B loss: 2.088 ;acc: 0.590 ;iou: 0.675 ;time: 0:03:08\n",
      "\n",
      "*Training B: True ;B Train loss: 2.080 ;Train accuracy: 0.597 ;IOU accuracy: 0.670 ;Time: 0:04:02 \n",
      "\n",
      "Testing, ephoc: 45\n",
      "batch: 0 ;B loss: 1.670 ;acc: 0.720 ;iou_acc: 0.775 ;time: 0:04:04\n",
      "batch: 50 ;B loss: 1.649 ;acc: 0.685 ;iou_acc: 0.755 ;time: 0:04:49\n",
      "batch: 100 ;B loss: 1.743 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:05:03\n",
      "batch: 150 ;B loss: 1.747 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:05:18\n",
      "batch: 200 ;B loss: 1.672 ;acc: 0.680 ;iou_acc: 0.805 ;time: 0:05:33\n",
      "batch: 250 ;B loss: 1.671 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:05:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.678 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:06:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 46 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20471 ;lr: 0.0490 ;B loss: 2.003 ;acc: 0.640 ;iou: 0.680 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20521 ;lr: 0.0490 ;B loss: 2.149 ;acc: 0.595 ;iou: 0.665 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 20571 ;lr: 0.0490 ;B loss: 1.965 ;acc: 0.630 ;iou: 0.715 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 20621 ;lr: 0.0490 ;B loss: 2.153 ;acc: 0.620 ;iou: 0.650 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 20671 ;lr: 0.0490 ;B loss: 2.108 ;acc: 0.590 ;iou: 0.690 ;time: 0:01:28\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 20721 ;lr: 0.0490 ;B loss: 1.964 ;acc: 0.585 ;iou: 0.675 ;time: 0:02:07\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 20771 ;lr: 0.0490 ;B loss: 2.169 ;acc: 0.555 ;iou: 0.650 ;time: 0:03:32\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 20821 ;lr: 0.0490 ;B loss: 2.066 ;acc: 0.600 ;iou: 0.665 ;time: 0:04:42\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 20871 ;lr: 0.0490 ;B loss: 2.251 ;acc: 0.590 ;iou: 0.660 ;time: 0:05:52\n",
      "\n",
      "*Training B: False ;B Train loss: 2.076 ;Train accuracy: 0.598 ;IOU accuracy: 0.671 ;Time: 0:06:53 \n",
      "\n",
      "Testing, ephoc: 46\n",
      "batch: 0 ;B loss: 1.679 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:06:55\n",
      "batch: 50 ;B loss: 1.656 ;acc: 0.655 ;iou_acc: 0.750 ;time: 0:08:12\n",
      "batch: 100 ;B loss: 1.755 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:08:48\n",
      "batch: 150 ;B loss: 1.748 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:09:01\n",
      "batch: 200 ;B loss: 1.676 ;acc: 0.685 ;iou_acc: 0.815 ;time: 0:09:15\n",
      "batch: 250 ;B loss: 1.668 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:09:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.681 ;Test accuracy 0.701 ;IOU accuracy: 0.793 ;Time: 0:09:46\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 47 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 20916 ;lr: 0.0490 ;B loss: 2.105 ;acc: 0.575 ;iou: 0.635 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 20966 ;lr: 0.0490 ;B loss: 1.997 ;acc: 0.640 ;iou: 0.690 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21016 ;lr: 0.0490 ;B loss: 2.068 ;acc: 0.570 ;iou: 0.640 ;time: 0:00:34\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21066 ;lr: 0.0490 ;B loss: 2.134 ;acc: 0.590 ;iou: 0.665 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21116 ;lr: 0.0490 ;B loss: 2.038 ;acc: 0.645 ;iou: 0.750 ;time: 0:01:10\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21166 ;lr: 0.0490 ;B loss: 1.975 ;acc: 0.600 ;iou: 0.685 ;time: 0:01:26\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 21216 ;lr: 0.0490 ;B loss: 2.082 ;acc: 0.555 ;iou: 0.640 ;time: 0:01:42\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 21266 ;lr: 0.0490 ;B loss: 1.932 ;acc: 0.640 ;iou: 0.725 ;time: 0:01:58\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 21316 ;lr: 0.0490 ;B loss: 1.980 ;acc: 0.635 ;iou: 0.675 ;time: 0:02:15\n",
      "\n",
      "*Training B: False ;B Train loss: 2.075 ;Train accuracy: 0.600 ;IOU accuracy: 0.674 ;Time: 0:02:29 \n",
      "\n",
      "Testing, ephoc: 47\n",
      "batch: 0 ;B loss: 1.674 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:02:30\n",
      "batch: 50 ;B loss: 1.646 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:02:46\n",
      "batch: 100 ;B loss: 1.756 ;acc: 0.675 ;iou_acc: 0.745 ;time: 0:03:01\n",
      "batch: 150 ;B loss: 1.750 ;acc: 0.670 ;iou_acc: 0.750 ;time: 0:03:17\n",
      "batch: 200 ;B loss: 1.679 ;acc: 0.690 ;iou_acc: 0.805 ;time: 0:03:32\n",
      "batch: 250 ;B loss: 1.659 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:03:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.675 ;Test accuracy 0.701 ;IOU accuracy: 0.792 ;Time: 0:04:00\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 48 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21361 ;lr: 0.0490 ;B loss: 1.875 ;acc: 0.655 ;iou: 0.715 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21411 ;lr: 0.0490 ;B loss: 2.023 ;acc: 0.635 ;iou: 0.715 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21461 ;lr: 0.0490 ;B loss: 1.940 ;acc: 0.610 ;iou: 0.670 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21511 ;lr: 0.0490 ;B loss: 2.194 ;acc: 0.590 ;iou: 0.635 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 21561 ;lr: 0.0490 ;B loss: 2.073 ;acc: 0.605 ;iou: 0.680 ;time: 0:01:09\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 21611 ;lr: 0.0490 ;B loss: 2.079 ;acc: 0.545 ;iou: 0.630 ;time: 0:01:25\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 21661 ;lr: 0.0490 ;B loss: 1.948 ;acc: 0.610 ;iou: 0.675 ;time: 0:01:45\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 21711 ;lr: 0.0490 ;B loss: 2.026 ;acc: 0.545 ;iou: 0.615 ;time: 0:02:04\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 21761 ;lr: 0.0490 ;B loss: 1.931 ;acc: 0.670 ;iou: 0.750 ;time: 0:02:22\n",
      "\n",
      "*Training B: True ;B Train loss: 2.069 ;Train accuracy: 0.599 ;IOU accuracy: 0.673 ;Time: 0:02:35 \n",
      "\n",
      "Testing, ephoc: 48\n",
      "batch: 0 ;B loss: 1.668 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:02:36\n",
      "batch: 50 ;B loss: 1.647 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:02:51\n",
      "batch: 100 ;B loss: 1.763 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:03:05\n",
      "batch: 150 ;B loss: 1.748 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:03:21\n",
      "batch: 200 ;B loss: 1.674 ;acc: 0.710 ;iou_acc: 0.815 ;time: 0:03:36\n",
      "batch: 250 ;B loss: 1.661 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:03:51\n",
      "\n",
      "*BTrain: True ;Test loss: 1.673 ;Test accuracy 0.703 ;IOU accuracy: 0.793 ;Time: 0:04:04\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 49 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 21806 ;lr: 0.0490 ;B loss: 2.069 ;acc: 0.530 ;iou: 0.605 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 21856 ;lr: 0.0490 ;B loss: 1.992 ;acc: 0.605 ;iou: 0.665 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 21906 ;lr: 0.0490 ;B loss: 2.159 ;acc: 0.550 ;iou: 0.640 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 21956 ;lr: 0.0490 ;B loss: 2.068 ;acc: 0.600 ;iou: 0.655 ;time: 0:00:59\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22006 ;lr: 0.0490 ;B loss: 2.115 ;acc: 0.570 ;iou: 0.655 ;time: 0:01:13\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22056 ;lr: 0.0490 ;B loss: 2.139 ;acc: 0.590 ;iou: 0.690 ;time: 0:01:28\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 22106 ;lr: 0.0490 ;B loss: 2.034 ;acc: 0.560 ;iou: 0.625 ;time: 0:01:43\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 22156 ;lr: 0.0490 ;B loss: 2.027 ;acc: 0.565 ;iou: 0.640 ;time: 0:01:59\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 22206 ;lr: 0.0490 ;B loss: 2.164 ;acc: 0.550 ;iou: 0.635 ;time: 0:02:13\n",
      "\n",
      "*Training B: False ;B Train loss: 2.067 ;Train accuracy: 0.601 ;IOU accuracy: 0.674 ;Time: 0:02:28 \n",
      "\n",
      "Testing, ephoc: 49\n",
      "batch: 0 ;B loss: 1.670 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:02:29\n",
      "batch: 50 ;B loss: 1.645 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:02:42\n",
      "batch: 100 ;B loss: 1.753 ;acc: 0.650 ;iou_acc: 0.710 ;time: 0:02:56\n",
      "batch: 150 ;B loss: 1.738 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:03:10\n",
      "batch: 200 ;B loss: 1.672 ;acc: 0.705 ;iou_acc: 0.825 ;time: 0:03:25\n",
      "batch: 250 ;B loss: 1.654 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:03:40\n",
      "\n",
      "*BTrain: False ;Test loss: 1.673 ;Test accuracy 0.703 ;IOU accuracy: 0.794 ;Time: 0:03:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 50 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22251 ;lr: 0.0490 ;B loss: 2.199 ;acc: 0.565 ;iou: 0.655 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22301 ;lr: 0.0490 ;B loss: 2.133 ;acc: 0.550 ;iou: 0.660 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22351 ;lr: 0.0490 ;B loss: 2.018 ;acc: 0.655 ;iou: 0.735 ;time: 0:00:32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-914f9dbf6ea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdropout_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mdropout_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         dropout_out=dropout_out)\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0maug_bnorm_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-142af79a318b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, use_wordAttn, addNoise)\u001b[0m\n\u001b[1;32m    667\u001b[0m                             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misEdit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misEdit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                             iou_acc = self.iou_accuracy(trn_data, b*self.batch_size, (b+1)*self.batch_size, \n\u001b[0;32m--> 669\u001b[0;31m                                                         sess=sess, feed_dict=feed_dict, isEdit=isEdit)\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                             \u001b[0mtrn_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtrn_nbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-142af79a318b>\u001b[0m in \u001b[0;36miou_accuracy\u001b[0;34m(self, data, start, end, sess, feed_dict, threshold, test, isEdit)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgt_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# ground truth bbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mcrops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Model chosen bbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#IOU for the i sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/Desktop/nanoRep/er/q2i_new/fastAlg/SARNN11/my_code/retriever.py\u001b[0m in \u001b[0;36mcompute_iou\u001b[0;34m(boxes, target)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mI_y1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mI_x2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mI_y2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mA_I\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_x2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mI_x1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_y2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mI_y1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mIoUs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_I\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mA_boxes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mA_target\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA_I\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Augmenting data\n",
    "# The accuracy and IOU of the trainin set includs data points \n",
    "# with no true groinding bbox so the true training's accuracy and IOU\n",
    "# is higher then we can see in the reults here (TODO: fix it)\n",
    "# decreasing learning rate even more\n",
    "\n",
    "print(len(trainset))\n",
    "augment_data(trainset)\n",
    "print(len(trainset))\n",
    "\n",
    "num_hidden = 200\n",
    "dropout_in=0.5\n",
    "dropout_out=1.\n",
    "dropout_img = 0.5\n",
    "params_dir = params_dir_tmp+'bnorm_base/augmented_'+str(dropout_in)+','+str(dropout_out)+','+str(dropout_img)+'_hidden:'+str(num_hidden)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=num_hidden,\n",
    "    img_dims=trainset[0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][1][1].shape[1], \n",
    "    lr=.05,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.99, \n",
    "    edit_reward=0.,\n",
    "    rnn_editProb=0.,\n",
    "    coefAlr=1,\n",
    "    bnorm=True)\n",
    "\n",
    "\n",
    "# start comp\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=100,\n",
    "        start_ephoc=38,\n",
    "        startA=101,\n",
    "        activation_ephoc=101,\n",
    "        muteB=0, \n",
    "        activateAProb=0,\n",
    "        max_activateAProb=0,\n",
    "        editProb=0,\n",
    "        edit_reward=0,\n",
    "        dropout_img=dropout_img,\n",
    "        dropout_in=dropout_in,\n",
    "        dropout_out=dropout_out)\n",
    "\n",
    "aug_bnorm_test_res.append(tst)\n",
    "aug_bnorm_train_res.append(trn)\n",
    "print('\\n'+'*'*100)\n",
    "print('*'*100)\n",
    "print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This is where remove the artificially added points</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset length: 59449\n"
     ]
    }
   ],
   "source": [
    "trainset = np.load(open(trainset_file, 'rb'))\n",
    "trainset = [item for item in trainset if len(item)>2 and len(item[0])>0]\n",
    "print('trainset length:', len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Loading parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-49\n",
      "INFO:tensorflow:Restoring parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-49\n",
      "================================================== \n",
      "Train, ephoc: 50 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22251 ;lr: 0.0490 ;B loss: 1.572 ;acc: 0.790 ;iou: 0.865 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22301 ;lr: 0.0490 ;B loss: 1.603 ;acc: 0.815 ;iou: 0.895 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22351 ;lr: 0.0490 ;B loss: 1.410 ;acc: 0.820 ;iou: 0.890 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22401 ;lr: 0.0490 ;B loss: 1.638 ;acc: 0.800 ;iou: 0.880 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22451 ;lr: 0.0490 ;B loss: 1.482 ;acc: 0.770 ;iou: 0.820 ;time: 0:00:55\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22501 ;lr: 0.0490 ;B loss: 1.572 ;acc: 0.815 ;iou: 0.855 ;time: 0:01:07\n",
      "\n",
      "*Training B: False ;B Train loss: 1.485 ;Train accuracy: 0.812 ;IOU accuracy: 0.874 ;Time: 0:01:20 \n",
      "\n",
      "Testing, ephoc: 50\n",
      "batch: 0 ;B loss: 1.572 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:01:21\n",
      "batch: 50 ;B loss: 1.533 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:01:33\n",
      "batch: 100 ;B loss: 1.740 ;acc: 0.655 ;iou_acc: 0.735 ;time: 0:01:46\n",
      "batch: 150 ;B loss: 1.690 ;acc: 0.690 ;iou_acc: 0.800 ;time: 0:01:57\n",
      "batch: 200 ;B loss: 1.601 ;acc: 0.720 ;iou_acc: 0.835 ;time: 0:02:09\n",
      "batch: 250 ;B loss: 1.552 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:02:21\n",
      "\n",
      "*BTrain: False ;Test loss: 1.603 ;Test accuracy 0.710 ;IOU accuracy: 0.800 ;Time: 0:02:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 51 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22548 ;lr: 0.0490 ;B loss: 1.375 ;acc: 0.830 ;iou: 0.895 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22598 ;lr: 0.0490 ;B loss: 1.396 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22648 ;lr: 0.0490 ;B loss: 1.476 ;acc: 0.810 ;iou: 0.870 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22698 ;lr: 0.0490 ;B loss: 1.496 ;acc: 0.800 ;iou: 0.890 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 22748 ;lr: 0.0490 ;B loss: 1.451 ;acc: 0.800 ;iou: 0.875 ;time: 0:00:55\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 22798 ;lr: 0.0490 ;B loss: 1.490 ;acc: 0.790 ;iou: 0.845 ;time: 0:01:10\n",
      "\n",
      "*Training B: True ;B Train loss: 1.460 ;Train accuracy: 0.819 ;IOU accuracy: 0.880 ;Time: 0:01:22 \n",
      "\n",
      "Testing, ephoc: 51\n",
      "batch: 0 ;B loss: 1.570 ;acc: 0.725 ;iou_acc: 0.780 ;time: 0:01:23\n",
      "batch: 50 ;B loss: 1.507 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:35\n",
      "batch: 100 ;B loss: 1.719 ;acc: 0.635 ;iou_acc: 0.715 ;time: 0:01:46\n",
      "batch: 150 ;B loss: 1.693 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:01:58\n",
      "batch: 200 ;B loss: 1.597 ;acc: 0.710 ;iou_acc: 0.825 ;time: 0:02:10\n",
      "batch: 250 ;B loss: 1.545 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:02:22\n",
      "\n",
      "*BTrain: True ;Test loss: 1.604 ;Test accuracy 0.708 ;IOU accuracy: 0.798 ;Time: 0:02:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 52 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 22845 ;lr: 0.0490 ;B loss: 1.438 ;acc: 0.805 ;iou: 0.865 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 22895 ;lr: 0.0490 ;B loss: 1.430 ;acc: 0.825 ;iou: 0.865 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 22945 ;lr: 0.0490 ;B loss: 1.440 ;acc: 0.800 ;iou: 0.870 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 22995 ;lr: 0.0490 ;B loss: 1.485 ;acc: 0.800 ;iou: 0.865 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23045 ;lr: 0.0490 ;B loss: 1.352 ;acc: 0.860 ;iou: 0.925 ;time: 0:00:57\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23095 ;lr: 0.0490 ;B loss: 1.490 ;acc: 0.830 ;iou: 0.870 ;time: 0:01:10\n",
      "\n",
      "*Training B: False ;B Train loss: 1.450 ;Train accuracy: 0.822 ;IOU accuracy: 0.882 ;Time: 0:01:21 \n",
      "\n",
      "Testing, ephoc: 52\n",
      "batch: 0 ;B loss: 1.578 ;acc: 0.735 ;iou_acc: 0.790 ;time: 0:01:21\n",
      "batch: 50 ;B loss: 1.513 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:01:33\n",
      "batch: 100 ;B loss: 1.712 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:01:45\n",
      "batch: 150 ;B loss: 1.711 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:01:57\n",
      "batch: 200 ;B loss: 1.600 ;acc: 0.725 ;iou_acc: 0.815 ;time: 0:02:09\n",
      "batch: 250 ;B loss: 1.537 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:02:22\n",
      "\n",
      "*BTrain: False ;Test loss: 1.602 ;Test accuracy 0.709 ;IOU accuracy: 0.799 ;Time: 0:02:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 53 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23142 ;lr: 0.0490 ;B loss: 1.534 ;acc: 0.840 ;iou: 0.925 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23192 ;lr: 0.0490 ;B loss: 1.427 ;acc: 0.835 ;iou: 0.860 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23242 ;lr: 0.0490 ;B loss: 1.434 ;acc: 0.820 ;iou: 0.860 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23292 ;lr: 0.0490 ;B loss: 1.399 ;acc: 0.830 ;iou: 0.900 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23342 ;lr: 0.0490 ;B loss: 1.569 ;acc: 0.805 ;iou: 0.865 ;time: 0:01:00\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23392 ;lr: 0.0490 ;B loss: 1.404 ;acc: 0.805 ;iou: 0.875 ;time: 0:01:14\n",
      "\n",
      "*Training B: False ;B Train loss: 1.444 ;Train accuracy: 0.823 ;IOU accuracy: 0.882 ;Time: 0:02:19 \n",
      "\n",
      "Testing, ephoc: 53\n",
      "batch: 0 ;B loss: 1.566 ;acc: 0.730 ;iou_acc: 0.790 ;time: 0:02:20\n",
      "batch: 50 ;B loss: 1.527 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:03:43\n",
      "batch: 100 ;B loss: 1.731 ;acc: 0.655 ;iou_acc: 0.720 ;time: 0:05:15\n",
      "batch: 150 ;B loss: 1.679 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:06:50\n",
      "batch: 200 ;B loss: 1.589 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:08:18\n",
      "batch: 250 ;B loss: 1.516 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:09:31\n",
      "\n",
      "*BTrain: False ;Test loss: 1.602 ;Test accuracy 0.709 ;IOU accuracy: 0.799 ;Time: 0:10:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 54 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23439 ;lr: 0.0490 ;B loss: 1.364 ;acc: 0.825 ;iou: 0.905 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23489 ;lr: 0.0490 ;B loss: 1.355 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23539 ;lr: 0.0490 ;B loss: 1.466 ;acc: 0.860 ;iou: 0.900 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23589 ;lr: 0.0490 ;B loss: 1.537 ;acc: 0.830 ;iou: 0.885 ;time: 0:01:23\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23639 ;lr: 0.0490 ;B loss: 1.412 ;acc: 0.860 ;iou: 0.890 ;time: 0:01:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23689 ;lr: 0.0490 ;B loss: 1.270 ;acc: 0.910 ;iou: 0.930 ;time: 0:02:04\n",
      "\n",
      "*Training B: True ;B Train loss: 1.438 ;Train accuracy: 0.827 ;IOU accuracy: 0.885 ;Time: 0:02:24 \n",
      "\n",
      "Testing, ephoc: 54\n",
      "batch: 0 ;B loss: 1.567 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:02:25\n",
      "batch: 50 ;B loss: 1.536 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:02:46\n",
      "batch: 100 ;B loss: 1.715 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:03:08\n",
      "batch: 150 ;B loss: 1.678 ;acc: 0.670 ;iou_acc: 0.770 ;time: 0:03:27\n",
      "batch: 200 ;B loss: 1.598 ;acc: 0.735 ;iou_acc: 0.820 ;time: 0:03:46\n",
      "batch: 250 ;B loss: 1.515 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:04:03\n",
      "\n",
      "*BTrain: True ;Test loss: 1.600 ;Test accuracy 0.709 ;IOU accuracy: 0.800 ;Time: 0:04:16\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 55 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 23736 ;lr: 0.0490 ;B loss: 1.494 ;acc: 0.875 ;iou: 0.915 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 23786 ;lr: 0.0490 ;B loss: 1.540 ;acc: 0.820 ;iou: 0.890 ;time: 0:00:13\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 23836 ;lr: 0.0490 ;B loss: 1.347 ;acc: 0.845 ;iou: 0.880 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 23886 ;lr: 0.0490 ;B loss: 1.471 ;acc: 0.840 ;iou: 0.875 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 23936 ;lr: 0.0490 ;B loss: 1.286 ;acc: 0.865 ;iou: 0.930 ;time: 0:00:58\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 23986 ;lr: 0.0490 ;B loss: 1.533 ;acc: 0.795 ;iou: 0.865 ;time: 0:01:34\n",
      "\n",
      "*Training B: False ;B Train loss: 1.425 ;Train accuracy: 0.830 ;IOU accuracy: 0.889 ;Time: 0:02:54 \n",
      "\n",
      "Testing, ephoc: 55\n",
      "batch: 0 ;B loss: 1.592 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:02:57\n",
      "batch: 50 ;B loss: 1.518 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:04:23\n",
      "batch: 100 ;B loss: 1.715 ;acc: 0.675 ;iou_acc: 0.730 ;time: 0:05:24\n",
      "batch: 150 ;B loss: 1.664 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:05:44\n",
      "batch: 200 ;B loss: 1.606 ;acc: 0.720 ;iou_acc: 0.820 ;time: 0:06:00\n",
      "batch: 250 ;B loss: 1.551 ;acc: 0.710 ;iou_acc: 0.810 ;time: 0:06:14\n",
      "\n",
      "*BTrain: False ;Test loss: 1.602 ;Test accuracy 0.710 ;IOU accuracy: 0.800 ;Time: 0:06:27\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 56 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24033 ;lr: 0.0490 ;B loss: 1.485 ;acc: 0.820 ;iou: 0.890 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24083 ;lr: 0.0490 ;B loss: 1.352 ;acc: 0.825 ;iou: 0.905 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24133 ;lr: 0.0490 ;B loss: 1.319 ;acc: 0.825 ;iou: 0.900 ;time: 0:00:39\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24183 ;lr: 0.0490 ;B loss: 1.471 ;acc: 0.815 ;iou: 0.855 ;time: 0:00:58\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24233 ;lr: 0.0490 ;B loss: 1.479 ;acc: 0.835 ;iou: 0.865 ;time: 0:01:16\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24283 ;lr: 0.0490 ;B loss: 1.472 ;acc: 0.825 ;iou: 0.885 ;time: 0:01:34\n",
      "\n",
      "*Training B: False ;B Train loss: 1.424 ;Train accuracy: 0.833 ;IOU accuracy: 0.890 ;Time: 0:01:51 \n",
      "\n",
      "Testing, ephoc: 56\n",
      "batch: 0 ;B loss: 1.594 ;acc: 0.710 ;iou_acc: 0.770 ;time: 0:01:52\n",
      "batch: 50 ;B loss: 1.538 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:02:49\n",
      "batch: 100 ;B loss: 1.699 ;acc: 0.675 ;iou_acc: 0.725 ;time: 0:04:13\n",
      "batch: 150 ;B loss: 1.683 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:05:28\n",
      "batch: 200 ;B loss: 1.619 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:06:54\n",
      "batch: 250 ;B loss: 1.514 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:08:16\n",
      "\n",
      "*BTrain: False ;Test loss: 1.601 ;Test accuracy 0.709 ;IOU accuracy: 0.800 ;Time: 0:09:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 57 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24330 ;lr: 0.0490 ;B loss: 1.391 ;acc: 0.840 ;iou: 0.875 ;time: 0:00:03\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24380 ;lr: 0.0490 ;B loss: 1.324 ;acc: 0.850 ;iou: 0.920 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24430 ;lr: 0.0490 ;B loss: 1.380 ;acc: 0.835 ;iou: 0.870 ;time: 0:01:07\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24480 ;lr: 0.0490 ;B loss: 1.618 ;acc: 0.825 ;iou: 0.900 ;time: 0:01:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24530 ;lr: 0.0490 ;B loss: 1.433 ;acc: 0.855 ;iou: 0.900 ;time: 0:01:51\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24580 ;lr: 0.0490 ;B loss: 1.378 ;acc: 0.840 ;iou: 0.910 ;time: 0:02:12\n",
      "\n",
      "*Training B: True ;B Train loss: 1.416 ;Train accuracy: 0.835 ;IOU accuracy: 0.892 ;Time: 0:02:30 \n",
      "\n",
      "Testing, ephoc: 57\n",
      "batch: 0 ;B loss: 1.580 ;acc: 0.705 ;iou_acc: 0.765 ;time: 0:02:31\n",
      "batch: 50 ;B loss: 1.531 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:02:47\n",
      "batch: 100 ;B loss: 1.729 ;acc: 0.650 ;iou_acc: 0.725 ;time: 0:03:01\n",
      "batch: 150 ;B loss: 1.699 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:03:17\n",
      "batch: 200 ;B loss: 1.596 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:03:30\n",
      "batch: 250 ;B loss: 1.528 ;acc: 0.725 ;iou_acc: 0.785 ;time: 0:03:45\n",
      "\n",
      "*BTrain: True ;Test loss: 1.604 ;Test accuracy 0.708 ;IOU accuracy: 0.800 ;Time: 0:04:03\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 58 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24627 ;lr: 0.0490 ;B loss: 1.363 ;acc: 0.840 ;iou: 0.905 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24677 ;lr: 0.0490 ;B loss: 1.427 ;acc: 0.885 ;iou: 0.935 ;time: 0:01:45\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 24727 ;lr: 0.0490 ;B loss: 1.401 ;acc: 0.835 ;iou: 0.885 ;time: 0:02:13\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 24777 ;lr: 0.0490 ;B loss: 1.302 ;acc: 0.875 ;iou: 0.910 ;time: 0:02:43\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 24827 ;lr: 0.0490 ;B loss: 1.398 ;acc: 0.880 ;iou: 0.925 ;time: 0:03:09\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 24877 ;lr: 0.0490 ;B loss: 1.448 ;acc: 0.850 ;iou: 0.900 ;time: 0:03:39\n",
      "\n",
      "*Training B: False ;B Train loss: 1.408 ;Train accuracy: 0.836 ;IOU accuracy: 0.892 ;Time: 0:04:06 \n",
      "\n",
      "Testing, ephoc: 58\n",
      "batch: 0 ;B loss: 1.562 ;acc: 0.720 ;iou_acc: 0.775 ;time: 0:04:07\n",
      "batch: 50 ;B loss: 1.525 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:04:35\n",
      "batch: 100 ;B loss: 1.695 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:05:45\n",
      "batch: 150 ;B loss: 1.719 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:07:23\n",
      "batch: 200 ;B loss: 1.609 ;acc: 0.735 ;iou_acc: 0.825 ;time: 0:09:03\n",
      "batch: 250 ;B loss: 1.517 ;acc: 0.705 ;iou_acc: 0.810 ;time: 0:10:37\n",
      "\n",
      "*BTrain: False ;Test loss: 1.600 ;Test accuracy 0.710 ;IOU accuracy: 0.800 ;Time: 0:12:12\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 59 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 24924 ;lr: 0.0490 ;B loss: 1.387 ;acc: 0.860 ;iou: 0.915 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 24974 ;lr: 0.0490 ;B loss: 1.338 ;acc: 0.845 ;iou: 0.895 ;time: 0:01:44\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25024 ;lr: 0.0490 ;B loss: 1.493 ;acc: 0.820 ;iou: 0.890 ;time: 0:03:29\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25074 ;lr: 0.0490 ;B loss: 1.388 ;acc: 0.830 ;iou: 0.905 ;time: 0:05:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25124 ;lr: 0.0490 ;B loss: 1.266 ;acc: 0.870 ;iou: 0.910 ;time: 0:07:01\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25174 ;lr: 0.0490 ;B loss: 1.284 ;acc: 0.860 ;iou: 0.900 ;time: 0:08:53\n",
      "\n",
      "*Training B: False ;B Train loss: 1.404 ;Train accuracy: 0.838 ;IOU accuracy: 0.892 ;Time: 0:10:27 \n",
      "\n",
      "Testing, ephoc: 59\n",
      "batch: 0 ;B loss: 1.593 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:10:30\n",
      "batch: 50 ;B loss: 1.515 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:12:11\n",
      "batch: 100 ;B loss: 1.700 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:13:45\n",
      "batch: 150 ;B loss: 1.705 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:15:26\n",
      "batch: 200 ;B loss: 1.598 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:17:02\n",
      "batch: 250 ;B loss: 1.526 ;acc: 0.725 ;iou_acc: 0.800 ;time: 0:18:39\n",
      "\n",
      "*BTrain: False ;Test loss: 1.602 ;Test accuracy 0.710 ;IOU accuracy: 0.800 ;Time: 0:20:13\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 60 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25221 ;lr: 0.0490 ;B loss: 1.350 ;acc: 0.810 ;iou: 0.865 ;time: 0:00:03\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25271 ;lr: 0.0490 ;B loss: 1.373 ;acc: 0.855 ;iou: 0.915 ;time: 0:01:45\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25321 ;lr: 0.0490 ;B loss: 1.292 ;acc: 0.885 ;iou: 0.910 ;time: 0:03:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25371 ;lr: 0.0490 ;B loss: 1.431 ;acc: 0.845 ;iou: 0.885 ;time: 0:05:19\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25421 ;lr: 0.0490 ;B loss: 1.353 ;acc: 0.880 ;iou: 0.935 ;time: 0:07:04\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25471 ;lr: 0.0490 ;B loss: 1.503 ;acc: 0.830 ;iou: 0.860 ;time: 0:08:39\n",
      "\n",
      "*Training B: True ;B Train loss: 1.400 ;Train accuracy: 0.840 ;IOU accuracy: 0.895 ;Time: 0:10:20 \n",
      "\n",
      "Testing, ephoc: 60\n",
      "batch: 0 ;B loss: 1.582 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:10:23\n",
      "batch: 50 ;B loss: 1.521 ;acc: 0.680 ;iou_acc: 0.755 ;time: 0:12:00\n",
      "batch: 100 ;B loss: 1.681 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:13:38\n",
      "batch: 150 ;B loss: 1.704 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:15:19\n",
      "batch: 200 ;B loss: 1.605 ;acc: 0.730 ;iou_acc: 0.840 ;time: 0:16:53\n",
      "batch: 250 ;B loss: 1.504 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:18:32\n",
      "\n",
      "*BTrain: True ;Test loss: 1.603 ;Test accuracy 0.710 ;IOU accuracy: 0.800 ;Time: 0:20:05\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 61 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25518 ;lr: 0.0490 ;B loss: 1.459 ;acc: 0.845 ;iou: 0.900 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25568 ;lr: 0.0490 ;B loss: 1.356 ;acc: 0.865 ;iou: 0.920 ;time: 0:01:46\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25618 ;lr: 0.0490 ;B loss: 1.392 ;acc: 0.830 ;iou: 0.865 ;time: 0:03:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25668 ;lr: 0.0490 ;B loss: 1.415 ;acc: 0.805 ;iou: 0.890 ;time: 0:05:11\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 25718 ;lr: 0.0490 ;B loss: 1.416 ;acc: 0.850 ;iou: 0.900 ;time: 0:06:58\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 25768 ;lr: 0.0490 ;B loss: 1.373 ;acc: 0.835 ;iou: 0.905 ;time: 0:08:37\n",
      "\n",
      "*Training B: False ;B Train loss: 1.394 ;Train accuracy: 0.842 ;IOU accuracy: 0.896 ;Time: 0:10:13 \n",
      "\n",
      "Testing, ephoc: 61\n",
      "batch: 0 ;B loss: 1.578 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:10:15\n",
      "batch: 50 ;B loss: 1.511 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:11:52\n",
      "batch: 100 ;B loss: 1.684 ;acc: 0.660 ;iou_acc: 0.730 ;time: 0:13:29\n",
      "batch: 150 ;B loss: 1.717 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:15:09\n",
      "batch: 200 ;B loss: 1.604 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:16:42\n",
      "batch: 250 ;B loss: 1.530 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:18:21\n",
      "\n",
      "*BTrain: False ;Test loss: 1.599 ;Test accuracy 0.712 ;IOU accuracy: 0.801 ;Time: 0:19:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 62 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 25815 ;lr: 0.0490 ;B loss: 1.348 ;acc: 0.875 ;iou: 0.935 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 25865 ;lr: 0.0490 ;B loss: 1.395 ;acc: 0.885 ;iou: 0.930 ;time: 0:01:44\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 25915 ;lr: 0.0490 ;B loss: 1.315 ;acc: 0.860 ;iou: 0.925 ;time: 0:03:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 25965 ;lr: 0.0490 ;B loss: 1.356 ;acc: 0.810 ;iou: 0.865 ;time: 0:05:09\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26015 ;lr: 0.0490 ;B loss: 1.302 ;acc: 0.860 ;iou: 0.915 ;time: 0:06:52\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26065 ;lr: 0.0490 ;B loss: 1.369 ;acc: 0.790 ;iou: 0.845 ;time: 0:08:34\n",
      "\n",
      "*Training B: False ;B Train loss: 1.390 ;Train accuracy: 0.842 ;IOU accuracy: 0.897 ;Time: 0:10:10 \n",
      "\n",
      "Testing, ephoc: 62\n",
      "batch: 0 ;B loss: 1.587 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:10:12\n",
      "batch: 50 ;B loss: 1.551 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:11:34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c54bbb44b50c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mdropout_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdropout_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         dropout_out=dropout_out)\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0maug_bnorm_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-142af79a318b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, use_wordAttn, addNoise)\u001b[0m\n\u001b[1;32m    698\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst_nbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m                         attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(tst_data,\n\u001b[0;32m--> 700\u001b[0;31m                                                                                     b*self.batch_size, (b+1)*self.batch_size)\n\u001b[0m\u001b[1;32m    701\u001b[0m                         \u001b[0mrewards_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                         feed_dict = {\n",
      "\u001b[0;32m<ipython-input-10-142af79a318b>\u001b[0m in \u001b[0;36mbuild_data\u001b[0;34m(self, data, start, end, addNoise)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mpadded_im\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mpadded_im\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_hidden = 200\n",
    "dropout_in=0.5\n",
    "dropout_out=1.\n",
    "dropout_img = 0.5\n",
    "params_dir = params_dir_tmp+'bnorm_base/augmented_'+str(dropout_in)+','+str(dropout_out)+','+str(dropout_img)+'_hidden:'+str(num_hidden)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=num_hidden,\n",
    "    img_dims=trainset[0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][1][1].shape[1], \n",
    "    lr=.05,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.99, \n",
    "    edit_reward=0.,\n",
    "    rnn_editProb=0.,\n",
    "    coefAlr=1,\n",
    "    bnorm=True)\n",
    "\n",
    "\n",
    "# start comp\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=100,\n",
    "        start_ephoc=50,\n",
    "        startA=101,\n",
    "        activation_ephoc=101,\n",
    "        muteB=0, \n",
    "        activateAProb=0,\n",
    "        max_activateAProb=0,\n",
    "        editProb=0,\n",
    "        edit_reward=0,\n",
    "        dropout_img=dropout_img,\n",
    "        dropout_in=dropout_in,\n",
    "        dropout_out=dropout_out)\n",
    "\n",
    "aug_bnorm_test_res.append(tst)\n",
    "aug_bnorm_train_res.append(trn)\n",
    "print('\\n'+'*'*100)\n",
    "print('*'*100)\n",
    "print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59449\n",
      "95118\n",
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 95118\n",
      "# Training batches: 475\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Loading parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-62\n",
      "INFO:tensorflow:Restoring parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-62\n",
      "================================================== \n",
      "Train, ephoc: 63 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26112 ;lr: 0.0490 ;B loss: 2.353 ;acc: 0.590 ;iou: 0.680 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26162 ;lr: 0.0490 ;B loss: 2.266 ;acc: 0.590 ;iou: 0.685 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26212 ;lr: 0.0490 ;B loss: 2.173 ;acc: 0.600 ;iou: 0.650 ;time: 0:00:28\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26262 ;lr: 0.0490 ;B loss: 2.133 ;acc: 0.640 ;iou: 0.725 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26312 ;lr: 0.0490 ;B loss: 2.207 ;acc: 0.555 ;iou: 0.615 ;time: 0:00:56\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26362 ;lr: 0.0490 ;B loss: 2.091 ;acc: 0.555 ;iou: 0.645 ;time: 0:01:10\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 26412 ;lr: 0.0490 ;B loss: 1.918 ;acc: 0.640 ;iou: 0.710 ;time: 0:01:24\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 26462 ;lr: 0.0490 ;B loss: 2.167 ;acc: 0.555 ;iou: 0.655 ;time: 0:01:38\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 26512 ;lr: 0.0490 ;B loss: 2.191 ;acc: 0.570 ;iou: 0.680 ;time: 0:01:52\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 26562 ;lr: 0.0490 ;B loss: 2.148 ;acc: 0.560 ;iou: 0.635 ;time: 0:02:06\n",
      "\n",
      "*Training B: True ;B Train loss: 2.151 ;Train accuracy: 0.587 ;IOU accuracy: 0.659 ;Time: 0:02:13 \n",
      "\n",
      "Testing, ephoc: 63\n",
      "batch: 0 ;B loss: 1.690 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:02:14\n",
      "batch: 50 ;B loss: 1.638 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:02:26\n",
      "batch: 100 ;B loss: 1.708 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:02:38\n",
      "batch: 150 ;B loss: 1.761 ;acc: 0.650 ;iou_acc: 0.740 ;time: 0:02:51\n",
      "batch: 200 ;B loss: 1.669 ;acc: 0.725 ;iou_acc: 0.820 ;time: 0:03:03\n",
      "batch: 250 ;B loss: 1.638 ;acc: 0.665 ;iou_acc: 0.790 ;time: 0:03:18\n",
      "\n",
      "*BTrain: True ;Test loss: 1.669 ;Test accuracy 0.699 ;IOU accuracy: 0.790 ;Time: 0:03:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 64 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 26587 ;lr: 0.0490 ;B loss: 2.125 ;acc: 0.535 ;iou: 0.605 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 26637 ;lr: 0.0490 ;B loss: 2.197 ;acc: 0.545 ;iou: 0.630 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 26687 ;lr: 0.0490 ;B loss: 2.197 ;acc: 0.545 ;iou: 0.630 ;time: 0:00:33\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 26737 ;lr: 0.0490 ;B loss: 2.073 ;acc: 0.615 ;iou: 0.660 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 26787 ;lr: 0.0490 ;B loss: 2.242 ;acc: 0.530 ;iou: 0.605 ;time: 0:01:00\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 26837 ;lr: 0.0490 ;B loss: 2.061 ;acc: 0.635 ;iou: 0.700 ;time: 0:01:14\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 26887 ;lr: 0.0490 ;B loss: 2.123 ;acc: 0.600 ;iou: 0.670 ;time: 0:01:27\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 26937 ;lr: 0.0490 ;B loss: 2.117 ;acc: 0.555 ;iou: 0.630 ;time: 0:01:40\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 26987 ;lr: 0.0490 ;B loss: 2.051 ;acc: 0.600 ;iou: 0.680 ;time: 0:01:53\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 27037 ;lr: 0.0490 ;B loss: 2.065 ;acc: 0.640 ;iou: 0.695 ;time: 0:02:06\n",
      "\n",
      "*Training B: False ;B Train loss: 2.115 ;Train accuracy: 0.588 ;IOU accuracy: 0.659 ;Time: 0:02:13 \n",
      "\n",
      "Testing, ephoc: 64\n",
      "batch: 0 ;B loss: 1.671 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:02:14\n",
      "batch: 50 ;B loss: 1.645 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:02:27\n",
      "batch: 100 ;B loss: 1.710 ;acc: 0.660 ;iou_acc: 0.740 ;time: 0:02:39\n",
      "batch: 150 ;B loss: 1.743 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:02:52\n",
      "batch: 200 ;B loss: 1.676 ;acc: 0.720 ;iou_acc: 0.830 ;time: 0:03:05\n",
      "batch: 250 ;B loss: 1.646 ;acc: 0.660 ;iou_acc: 0.755 ;time: 0:03:19\n",
      "\n",
      "*BTrain: False ;Test loss: 1.670 ;Test accuracy 0.701 ;IOU accuracy: 0.791 ;Time: 0:03:32\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 65 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27062 ;lr: 0.0490 ;B loss: 2.135 ;acc: 0.585 ;iou: 0.645 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27112 ;lr: 0.0490 ;B loss: 1.944 ;acc: 0.610 ;iou: 0.655 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27162 ;lr: 0.0490 ;B loss: 2.059 ;acc: 0.620 ;iou: 0.690 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27212 ;lr: 0.0490 ;B loss: 1.947 ;acc: 0.655 ;iou: 0.735 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27262 ;lr: 0.0490 ;B loss: 2.144 ;acc: 0.575 ;iou: 0.670 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27312 ;lr: 0.0490 ;B loss: 2.099 ;acc: 0.610 ;iou: 0.685 ;time: 0:01:18\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 27362 ;lr: 0.0490 ;B loss: 2.221 ;acc: 0.545 ;iou: 0.620 ;time: 0:01:32\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 27412 ;lr: 0.0490 ;B loss: 2.230 ;acc: 0.540 ;iou: 0.635 ;time: 0:01:49\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 27462 ;lr: 0.0490 ;B loss: 2.133 ;acc: 0.590 ;iou: 0.655 ;time: 0:02:03\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 27512 ;lr: 0.0490 ;B loss: 2.150 ;acc: 0.570 ;iou: 0.640 ;time: 0:02:19\n",
      "\n",
      "*Training B: False ;B Train loss: 2.108 ;Train accuracy: 0.590 ;IOU accuracy: 0.661 ;Time: 0:02:27 \n",
      "\n",
      "Testing, ephoc: 65\n",
      "batch: 0 ;B loss: 1.681 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:02:28\n",
      "batch: 50 ;B loss: 1.651 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:02:41\n",
      "batch: 100 ;B loss: 1.718 ;acc: 0.665 ;iou_acc: 0.750 ;time: 0:02:55\n",
      "batch: 150 ;B loss: 1.757 ;acc: 0.655 ;iou_acc: 0.740 ;time: 0:03:10\n",
      "batch: 200 ;B loss: 1.673 ;acc: 0.720 ;iou_acc: 0.815 ;time: 0:03:24\n",
      "batch: 250 ;B loss: 1.664 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:03:38\n",
      "\n",
      "*BTrain: False ;Test loss: 1.673 ;Test accuracy 0.704 ;IOU accuracy: 0.794 ;Time: 0:03:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 66 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 27537 ;lr: 0.0490 ;B loss: 2.127 ;acc: 0.615 ;iou: 0.695 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 27587 ;lr: 0.0490 ;B loss: 1.990 ;acc: 0.585 ;iou: 0.665 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 27637 ;lr: 0.0490 ;B loss: 2.114 ;acc: 0.605 ;iou: 0.690 ;time: 0:00:41\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 27687 ;lr: 0.0490 ;B loss: 2.098 ;acc: 0.540 ;iou: 0.630 ;time: 0:00:57\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 27737 ;lr: 0.0490 ;B loss: 2.073 ;acc: 0.600 ;iou: 0.655 ;time: 0:01:12\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 27787 ;lr: 0.0490 ;B loss: 2.072 ;acc: 0.580 ;iou: 0.655 ;time: 0:01:27\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 27837 ;lr: 0.0490 ;B loss: 2.113 ;acc: 0.625 ;iou: 0.675 ;time: 0:01:43\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 27887 ;lr: 0.0490 ;B loss: 1.901 ;acc: 0.650 ;iou: 0.710 ;time: 0:01:59\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 27937 ;lr: 0.0490 ;B loss: 2.185 ;acc: 0.555 ;iou: 0.630 ;time: 0:02:14\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 27987 ;lr: 0.0490 ;B loss: 2.072 ;acc: 0.555 ;iou: 0.630 ;time: 0:02:29\n",
      "\n",
      "*Training B: True ;B Train loss: 2.101 ;Train accuracy: 0.590 ;IOU accuracy: 0.661 ;Time: 0:02:37 \n",
      "\n",
      "Testing, ephoc: 66\n",
      "batch: 0 ;B loss: 1.668 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:02:38\n",
      "batch: 50 ;B loss: 1.653 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:02:51\n",
      "batch: 100 ;B loss: 1.715 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:03:04\n",
      "batch: 150 ;B loss: 1.756 ;acc: 0.650 ;iou_acc: 0.745 ;time: 0:03:17\n",
      "batch: 200 ;B loss: 1.669 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:03:30\n",
      "batch: 250 ;B loss: 1.661 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:03:43\n",
      "\n",
      "*BTrain: True ;Test loss: 1.671 ;Test accuracy 0.706 ;IOU accuracy: 0.796 ;Time: 0:03:54\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 67 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28012 ;lr: 0.0490 ;B loss: 2.079 ;acc: 0.620 ;iou: 0.695 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28062 ;lr: 0.0490 ;B loss: 2.133 ;acc: 0.630 ;iou: 0.680 ;time: 0:00:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28112 ;lr: 0.0490 ;B loss: 2.095 ;acc: 0.620 ;iou: 0.710 ;time: 0:00:43\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28162 ;lr: 0.0490 ;B loss: 2.168 ;acc: 0.560 ;iou: 0.635 ;time: 0:00:58\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28212 ;lr: 0.0490 ;B loss: 2.155 ;acc: 0.610 ;iou: 0.670 ;time: 0:01:14\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28262 ;lr: 0.0490 ;B loss: 2.031 ;acc: 0.645 ;iou: 0.695 ;time: 0:01:30\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 28312 ;lr: 0.0490 ;B loss: 2.137 ;acc: 0.620 ;iou: 0.710 ;time: 0:01:46\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 28362 ;lr: 0.0490 ;B loss: 1.971 ;acc: 0.645 ;iou: 0.715 ;time: 0:02:03\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 28412 ;lr: 0.0490 ;B loss: 2.184 ;acc: 0.595 ;iou: 0.635 ;time: 0:02:20\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 28462 ;lr: 0.0490 ;B loss: 2.070 ;acc: 0.580 ;iou: 0.645 ;time: 0:02:37\n",
      "\n",
      "*Training B: False ;B Train loss: 2.099 ;Train accuracy: 0.593 ;IOU accuracy: 0.663 ;Time: 0:02:46 \n",
      "\n",
      "Testing, ephoc: 67\n",
      "batch: 0 ;B loss: 1.666 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:02:46\n",
      "batch: 50 ;B loss: 1.645 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:03:01\n",
      "batch: 100 ;B loss: 1.712 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:03:15\n",
      "batch: 150 ;B loss: 1.745 ;acc: 0.660 ;iou_acc: 0.745 ;time: 0:03:29\n",
      "batch: 200 ;B loss: 1.658 ;acc: 0.715 ;iou_acc: 0.815 ;time: 0:03:43\n",
      "batch: 250 ;B loss: 1.657 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:03:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.661 ;Test accuracy 0.707 ;IOU accuracy: 0.797 ;Time: 0:04:11\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 68 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28487 ;lr: 0.0490 ;B loss: 2.123 ;acc: 0.525 ;iou: 0.620 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 28537 ;lr: 0.0490 ;B loss: 2.107 ;acc: 0.595 ;iou: 0.685 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 28587 ;lr: 0.0490 ;B loss: 2.081 ;acc: 0.615 ;iou: 0.695 ;time: 0:01:09\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 28637 ;lr: 0.0490 ;B loss: 2.093 ;acc: 0.575 ;iou: 0.650 ;time: 0:02:49\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 28687 ;lr: 0.0490 ;B loss: 1.969 ;acc: 0.630 ;iou: 0.705 ;time: 0:04:30\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 28737 ;lr: 0.0490 ;B loss: 2.175 ;acc: 0.510 ;iou: 0.600 ;time: 0:05:08\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 28787 ;lr: 0.0490 ;B loss: 2.149 ;acc: 0.545 ;iou: 0.675 ;time: 0:05:22\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 28837 ;lr: 0.0490 ;B loss: 2.063 ;acc: 0.550 ;iou: 0.615 ;time: 0:05:38\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 28887 ;lr: 0.0490 ;B loss: 2.139 ;acc: 0.605 ;iou: 0.680 ;time: 0:05:54\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 28937 ;lr: 0.0490 ;B loss: 2.093 ;acc: 0.600 ;iou: 0.665 ;time: 0:06:11\n",
      "\n",
      "*Training B: False ;B Train loss: 2.094 ;Train accuracy: 0.594 ;IOU accuracy: 0.664 ;Time: 0:06:18 \n",
      "\n",
      "Testing, ephoc: 68\n",
      "batch: 0 ;B loss: 1.671 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:06:19\n",
      "batch: 50 ;B loss: 1.640 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:06:33\n",
      "batch: 100 ;B loss: 1.714 ;acc: 0.690 ;iou_acc: 0.760 ;time: 0:06:46\n",
      "batch: 150 ;B loss: 1.743 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:07:00\n",
      "batch: 200 ;B loss: 1.668 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:07:15\n",
      "batch: 250 ;B loss: 1.653 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:07:28\n",
      "\n",
      "*BTrain: False ;Test loss: 1.664 ;Test accuracy 0.707 ;IOU accuracy: 0.797 ;Time: 0:07:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 69 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 28962 ;lr: 0.0490 ;B loss: 2.116 ;acc: 0.610 ;iou: 0.675 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29012 ;lr: 0.0490 ;B loss: 2.184 ;acc: 0.635 ;iou: 0.680 ;time: 0:00:17\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 29062 ;lr: 0.0490 ;B loss: 2.105 ;acc: 0.585 ;iou: 0.645 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 29112 ;lr: 0.0490 ;B loss: 2.160 ;acc: 0.535 ;iou: 0.605 ;time: 0:00:49\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29162 ;lr: 0.0490 ;B loss: 2.240 ;acc: 0.510 ;iou: 0.600 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29212 ;lr: 0.0490 ;B loss: 1.970 ;acc: 0.630 ;iou: 0.695 ;time: 0:01:19\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 29262 ;lr: 0.0490 ;B loss: 2.148 ;acc: 0.570 ;iou: 0.645 ;time: 0:01:35\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 29312 ;lr: 0.0490 ;B loss: 2.202 ;acc: 0.530 ;iou: 0.625 ;time: 0:01:50\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 29362 ;lr: 0.0490 ;B loss: 2.269 ;acc: 0.550 ;iou: 0.645 ;time: 0:03:16\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 29412 ;lr: 0.0490 ;B loss: 2.111 ;acc: 0.555 ;iou: 0.650 ;time: 0:04:53\n",
      "\n",
      "*Training B: True ;B Train loss: 2.091 ;Train accuracy: 0.595 ;IOU accuracy: 0.663 ;Time: 0:05:41 \n",
      "\n",
      "Testing, ephoc: 69\n",
      "batch: 0 ;B loss: 1.653 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:05:43\n",
      "batch: 50 ;B loss: 1.632 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:07:21\n",
      "batch: 100 ;B loss: 1.720 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:08:55\n",
      "batch: 150 ;B loss: 1.740 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:10:29\n",
      "batch: 200 ;B loss: 1.657 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:12:06\n",
      "batch: 250 ;B loss: 1.648 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:13:40\n",
      "\n",
      "*BTrain: True ;Test loss: 1.661 ;Test accuracy 0.708 ;IOU accuracy: 0.797 ;Time: 0:15:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 70 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 29437 ;lr: 0.0490 ;B loss: 2.071 ;acc: 0.520 ;iou: 0.610 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29487 ;lr: 0.0490 ;B loss: 2.095 ;acc: 0.660 ;iou: 0.700 ;time: 0:01:41\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 29537 ;lr: 0.0490 ;B loss: 2.076 ;acc: 0.620 ;iou: 0.650 ;time: 0:03:18\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 29587 ;lr: 0.0490 ;B loss: 2.022 ;acc: 0.640 ;iou: 0.690 ;time: 0:05:06\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 29637 ;lr: 0.0490 ;B loss: 2.093 ;acc: 0.605 ;iou: 0.690 ;time: 0:06:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 29687 ;lr: 0.0490 ;B loss: 2.091 ;acc: 0.585 ;iou: 0.665 ;time: 0:08:27\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 29737 ;lr: 0.0490 ;B loss: 2.139 ;acc: 0.585 ;iou: 0.645 ;time: 0:10:07\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 29787 ;lr: 0.0490 ;B loss: 2.015 ;acc: 0.650 ;iou: 0.715 ;time: 0:11:46\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 29837 ;lr: 0.0490 ;B loss: 2.106 ;acc: 0.600 ;iou: 0.680 ;time: 0:13:22\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 29887 ;lr: 0.0490 ;B loss: 2.048 ;acc: 0.630 ;iou: 0.680 ;time: 0:15:00\n",
      "\n",
      "*Training B: False ;B Train loss: 2.089 ;Train accuracy: 0.594 ;IOU accuracy: 0.664 ;Time: 0:15:48 \n",
      "\n",
      "Testing, ephoc: 70\n",
      "batch: 0 ;B loss: 1.643 ;acc: 0.735 ;iou_acc: 0.805 ;time: 0:15:51\n",
      "batch: 50 ;B loss: 1.633 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:17:21\n",
      "batch: 100 ;B loss: 1.710 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:18:57\n",
      "batch: 150 ;B loss: 1.741 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:20:35\n",
      "batch: 200 ;B loss: 1.654 ;acc: 0.730 ;iou_acc: 0.840 ;time: 0:22:01\n",
      "batch: 250 ;B loss: 1.657 ;acc: 0.665 ;iou_acc: 0.755 ;time: 0:23:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.663 ;Test accuracy 0.707 ;IOU accuracy: 0.797 ;Time: 0:25:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 71 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 29912 ;lr: 0.0490 ;B loss: 2.038 ;acc: 0.600 ;iou: 0.710 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 29962 ;lr: 0.0490 ;B loss: 1.909 ;acc: 0.645 ;iou: 0.705 ;time: 0:01:39\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 30012 ;lr: 0.0485 ;B loss: 2.132 ;acc: 0.580 ;iou: 0.625 ;time: 0:03:24\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 30062 ;lr: 0.0485 ;B loss: 2.080 ;acc: 0.605 ;iou: 0.675 ;time: 0:05:02\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 30112 ;lr: 0.0485 ;B loss: 2.012 ;acc: 0.630 ;iou: 0.680 ;time: 0:06:46\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 30162 ;lr: 0.0485 ;B loss: 2.077 ;acc: 0.605 ;iou: 0.655 ;time: 0:08:30\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 30212 ;lr: 0.0485 ;B loss: 2.055 ;acc: 0.615 ;iou: 0.680 ;time: 0:10:11\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 30262 ;lr: 0.0485 ;B loss: 2.121 ;acc: 0.580 ;iou: 0.660 ;time: 0:11:53\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 30312 ;lr: 0.0485 ;B loss: 2.108 ;acc: 0.585 ;iou: 0.655 ;time: 0:13:31\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 30362 ;lr: 0.0485 ;B loss: 2.114 ;acc: 0.580 ;iou: 0.655 ;time: 0:15:17\n",
      "\n",
      "*Training B: False ;B Train loss: 2.087 ;Train accuracy: 0.596 ;IOU accuracy: 0.666 ;Time: 0:16:04 \n",
      "\n",
      "Testing, ephoc: 71\n",
      "batch: 0 ;B loss: 1.665 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:16:06\n",
      "batch: 50 ;B loss: 1.624 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:17:44\n",
      "batch: 100 ;B loss: 1.720 ;acc: 0.660 ;iou_acc: 0.735 ;time: 0:19:17\n",
      "batch: 150 ;B loss: 1.743 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:20:56\n",
      "batch: 200 ;B loss: 1.660 ;acc: 0.720 ;iou_acc: 0.835 ;time: 0:22:30\n",
      "batch: 250 ;B loss: 1.656 ;acc: 0.675 ;iou_acc: 0.770 ;time: 0:24:04\n",
      "\n",
      "*BTrain: False ;Test loss: 1.660 ;Test accuracy 0.707 ;IOU accuracy: 0.796 ;Time: 0:25:35\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 72 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 30387 ;lr: 0.0485 ;B loss: 2.028 ;acc: 0.605 ;iou: 0.660 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 30437 ;lr: 0.0485 ;B loss: 2.072 ;acc: 0.580 ;iou: 0.640 ;time: 0:01:41\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 30487 ;lr: 0.0485 ;B loss: 2.212 ;acc: 0.580 ;iou: 0.645 ;time: 0:03:25\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 30537 ;lr: 0.0485 ;B loss: 2.087 ;acc: 0.585 ;iou: 0.645 ;time: 0:05:10\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 30587 ;lr: 0.0485 ;B loss: 2.083 ;acc: 0.610 ;iou: 0.680 ;time: 0:06:51\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 30637 ;lr: 0.0485 ;B loss: 2.025 ;acc: 0.625 ;iou: 0.670 ;time: 0:08:28\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 30687 ;lr: 0.0485 ;B loss: 2.023 ;acc: 0.645 ;iou: 0.695 ;time: 0:10:03\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 30737 ;lr: 0.0485 ;B loss: 2.153 ;acc: 0.595 ;iou: 0.675 ;time: 0:11:54\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 30787 ;lr: 0.0485 ;B loss: 2.117 ;acc: 0.650 ;iou: 0.720 ;time: 0:13:33\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 30837 ;lr: 0.0485 ;B loss: 2.019 ;acc: 0.600 ;iou: 0.680 ;time: 0:15:25\n",
      "\n",
      "*Training B: True ;B Train loss: 2.083 ;Train accuracy: 0.596 ;IOU accuracy: 0.665 ;Time: 0:15:47 \n",
      "\n",
      "Testing, ephoc: 72\n",
      "batch: 0 ;B loss: 1.651 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:15:48\n",
      "batch: 50 ;B loss: 1.634 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:16:02\n",
      "batch: 100 ;B loss: 1.717 ;acc: 0.665 ;iou_acc: 0.735 ;time: 0:16:16\n",
      "batch: 150 ;B loss: 1.753 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:16:31\n",
      "batch: 200 ;B loss: 1.661 ;acc: 0.725 ;iou_acc: 0.840 ;time: 0:16:44\n",
      "batch: 250 ;B loss: 1.651 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:16:58\n",
      "\n",
      "*BTrain: True ;Test loss: 1.662 ;Test accuracy 0.706 ;IOU accuracy: 0.797 ;Time: 0:17:11\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 73 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 30862 ;lr: 0.0485 ;B loss: 2.061 ;acc: 0.600 ;iou: 0.635 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 30912 ;lr: 0.0485 ;B loss: 1.913 ;acc: 0.630 ;iou: 0.710 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 30962 ;lr: 0.0485 ;B loss: 2.100 ;acc: 0.555 ;iou: 0.640 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 31012 ;lr: 0.0485 ;B loss: 2.040 ;acc: 0.605 ;iou: 0.705 ;time: 0:00:47\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 31062 ;lr: 0.0485 ;B loss: 2.186 ;acc: 0.575 ;iou: 0.640 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 31112 ;lr: 0.0485 ;B loss: 2.037 ;acc: 0.585 ;iou: 0.650 ;time: 0:01:20\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 31162 ;lr: 0.0485 ;B loss: 2.082 ;acc: 0.600 ;iou: 0.695 ;time: 0:01:36\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 31212 ;lr: 0.0485 ;B loss: 2.233 ;acc: 0.565 ;iou: 0.670 ;time: 0:01:51\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 31262 ;lr: 0.0485 ;B loss: 2.157 ;acc: 0.580 ;iou: 0.660 ;time: 0:03:28\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 31312 ;lr: 0.0485 ;B loss: 2.047 ;acc: 0.575 ;iou: 0.640 ;time: 0:05:14\n",
      "\n",
      "*Training B: False ;B Train loss: 2.082 ;Train accuracy: 0.596 ;IOU accuracy: 0.665 ;Time: 0:06:04 \n",
      "\n",
      "Testing, ephoc: 73\n",
      "batch: 0 ;B loss: 1.644 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:06:06\n",
      "batch: 50 ;B loss: 1.630 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:07:43\n",
      "batch: 100 ;B loss: 1.714 ;acc: 0.660 ;iou_acc: 0.725 ;time: 0:09:15\n",
      "batch: 150 ;B loss: 1.758 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:10:53\n",
      "batch: 200 ;B loss: 1.660 ;acc: 0.715 ;iou_acc: 0.820 ;time: 0:12:27\n",
      "batch: 250 ;B loss: 1.651 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:14:02\n",
      "\n",
      "*BTrain: False ;Test loss: 1.661 ;Test accuracy 0.707 ;IOU accuracy: 0.797 ;Time: 0:15:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 74 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 31337 ;lr: 0.0485 ;B loss: 1.965 ;acc: 0.620 ;iou: 0.700 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 31387 ;lr: 0.0485 ;B loss: 2.029 ;acc: 0.635 ;iou: 0.695 ;time: 0:01:47\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 31437 ;lr: 0.0485 ;B loss: 1.965 ;acc: 0.630 ;iou: 0.670 ;time: 0:03:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 31487 ;lr: 0.0485 ;B loss: 2.030 ;acc: 0.650 ;iou: 0.710 ;time: 0:05:10\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 31537 ;lr: 0.0485 ;B loss: 2.146 ;acc: 0.580 ;iou: 0.660 ;time: 0:06:54\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 31587 ;lr: 0.0485 ;B loss: 2.055 ;acc: 0.640 ;iou: 0.685 ;time: 0:08:38\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 31637 ;lr: 0.0485 ;B loss: 1.943 ;acc: 0.615 ;iou: 0.690 ;time: 0:10:15\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 31687 ;lr: 0.0485 ;B loss: 2.020 ;acc: 0.590 ;iou: 0.635 ;time: 0:11:59\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 31737 ;lr: 0.0485 ;B loss: 2.146 ;acc: 0.620 ;iou: 0.690 ;time: 0:13:38\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 31787 ;lr: 0.0485 ;B loss: 2.066 ;acc: 0.590 ;iou: 0.645 ;time: 0:15:19\n",
      "\n",
      "*Training B: False ;B Train loss: 2.082 ;Train accuracy: 0.597 ;IOU accuracy: 0.666 ;Time: 0:16:07 \n",
      "\n",
      "Testing, ephoc: 74\n",
      "batch: 0 ;B loss: 1.669 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:16:09\n",
      "batch: 50 ;B loss: 1.638 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:17:47\n",
      "batch: 100 ;B loss: 1.714 ;acc: 0.665 ;iou_acc: 0.730 ;time: 0:19:19\n",
      "batch: 150 ;B loss: 1.747 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:20:58\n",
      "batch: 200 ;B loss: 1.653 ;acc: 0.720 ;iou_acc: 0.835 ;time: 0:22:34\n",
      "batch: 250 ;B loss: 1.657 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:24:05\n",
      "\n",
      "*BTrain: False ;Test loss: 1.660 ;Test accuracy 0.707 ;IOU accuracy: 0.796 ;Time: 0:25:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 75 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 31812 ;lr: 0.0485 ;B loss: 2.018 ;acc: 0.565 ;iou: 0.635 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 31862 ;lr: 0.0485 ;B loss: 1.974 ;acc: 0.625 ;iou: 0.705 ;time: 0:01:39\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 31912 ;lr: 0.0485 ;B loss: 2.109 ;acc: 0.630 ;iou: 0.680 ;time: 0:03:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 31962 ;lr: 0.0485 ;B loss: 2.098 ;acc: 0.625 ;iou: 0.695 ;time: 0:05:01\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 32012 ;lr: 0.0485 ;B loss: 2.080 ;acc: 0.545 ;iou: 0.635 ;time: 0:06:30\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 32062 ;lr: 0.0485 ;B loss: 2.119 ;acc: 0.600 ;iou: 0.635 ;time: 0:08:18\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 32112 ;lr: 0.0485 ;B loss: 2.001 ;acc: 0.620 ;iou: 0.675 ;time: 0:09:53\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 32162 ;lr: 0.0485 ;B loss: 2.020 ;acc: 0.600 ;iou: 0.685 ;time: 0:11:38\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 32212 ;lr: 0.0485 ;B loss: 2.127 ;acc: 0.565 ;iou: 0.625 ;time: 0:13:20\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 32262 ;lr: 0.0485 ;B loss: 2.099 ;acc: 0.610 ;iou: 0.675 ;time: 0:15:09\n",
      "\n",
      "*Training B: True ;B Train loss: 2.078 ;Train accuracy: 0.597 ;IOU accuracy: 0.666 ;Time: 0:15:53 \n",
      "\n",
      "Testing, ephoc: 75\n",
      "batch: 0 ;B loss: 1.634 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:15:55\n",
      "batch: 50 ;B loss: 1.624 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:17:35\n",
      "batch: 100 ;B loss: 1.703 ;acc: 0.665 ;iou_acc: 0.745 ;time: 0:19:11\n",
      "batch: 150 ;B loss: 1.741 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:19:53\n",
      "batch: 200 ;B loss: 1.638 ;acc: 0.730 ;iou_acc: 0.835 ;time: 0:20:08\n",
      "batch: 250 ;B loss: 1.642 ;acc: 0.660 ;iou_acc: 0.775 ;time: 0:20:23\n",
      "\n",
      "*BTrain: True ;Test loss: 1.651 ;Test accuracy 0.709 ;IOU accuracy: 0.797 ;Time: 0:20:39\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 76 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 32287 ;lr: 0.0485 ;B loss: 2.098 ;acc: 0.640 ;iou: 0.680 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 32337 ;lr: 0.0485 ;B loss: 2.251 ;acc: 0.540 ;iou: 0.595 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 32387 ;lr: 0.0485 ;B loss: 2.119 ;acc: 0.575 ;iou: 0.655 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 32437 ;lr: 0.0485 ;B loss: 2.097 ;acc: 0.640 ;iou: 0.690 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 32487 ;lr: 0.0485 ;B loss: 2.127 ;acc: 0.585 ;iou: 0.645 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 32537 ;lr: 0.0485 ;B loss: 1.991 ;acc: 0.615 ;iou: 0.690 ;time: 0:01:16\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 32587 ;lr: 0.0485 ;B loss: 2.093 ;acc: 0.625 ;iou: 0.680 ;time: 0:01:33\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 32637 ;lr: 0.0485 ;B loss: 2.151 ;acc: 0.570 ;iou: 0.660 ;time: 0:01:51\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 32687 ;lr: 0.0485 ;B loss: 2.125 ;acc: 0.575 ;iou: 0.690 ;time: 0:02:10\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 32737 ;lr: 0.0485 ;B loss: 1.986 ;acc: 0.600 ;iou: 0.685 ;time: 0:02:27\n",
      "\n",
      "*Training B: False ;B Train loss: 2.077 ;Train accuracy: 0.599 ;IOU accuracy: 0.667 ;Time: 0:02:36 \n",
      "\n",
      "Testing, ephoc: 76\n",
      "batch: 0 ;B loss: 1.643 ;acc: 0.725 ;iou_acc: 0.810 ;time: 0:02:36\n",
      "batch: 50 ;B loss: 1.619 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:02:51\n",
      "batch: 100 ;B loss: 1.696 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:03:05\n",
      "batch: 150 ;B loss: 1.728 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:03:20\n",
      "batch: 200 ;B loss: 1.638 ;acc: 0.720 ;iou_acc: 0.840 ;time: 0:03:34\n",
      "batch: 250 ;B loss: 1.638 ;acc: 0.655 ;iou_acc: 0.770 ;time: 0:03:48\n",
      "\n",
      "*BTrain: False ;Test loss: 1.651 ;Test accuracy 0.708 ;IOU accuracy: 0.797 ;Time: 0:04:00\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 77 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 32762 ;lr: 0.0485 ;B loss: 2.164 ;acc: 0.565 ;iou: 0.675 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 32812 ;lr: 0.0485 ;B loss: 2.083 ;acc: 0.600 ;iou: 0.670 ;time: 0:00:16\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 32862 ;lr: 0.0485 ;B loss: 2.198 ;acc: 0.550 ;iou: 0.620 ;time: 0:00:29\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 32912 ;lr: 0.0485 ;B loss: 2.064 ;acc: 0.625 ;iou: 0.700 ;time: 0:00:42\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 32962 ;lr: 0.0485 ;B loss: 1.947 ;acc: 0.620 ;iou: 0.690 ;time: 0:00:56\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 33012 ;lr: 0.0485 ;B loss: 2.081 ;acc: 0.605 ;iou: 0.665 ;time: 0:01:10\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 33062 ;lr: 0.0485 ;B loss: 1.820 ;acc: 0.665 ;iou: 0.735 ;time: 0:01:25\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 33112 ;lr: 0.0485 ;B loss: 2.053 ;acc: 0.610 ;iou: 0.685 ;time: 0:01:41\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 33162 ;lr: 0.0485 ;B loss: 2.097 ;acc: 0.605 ;iou: 0.690 ;time: 0:01:55\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 33212 ;lr: 0.0485 ;B loss: 2.196 ;acc: 0.620 ;iou: 0.695 ;time: 0:02:11\n",
      "\n",
      "*Training B: False ;B Train loss: 2.072 ;Train accuracy: 0.598 ;IOU accuracy: 0.667 ;Time: 0:02:17 \n",
      "\n",
      "Testing, ephoc: 77\n",
      "batch: 0 ;B loss: 1.657 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:02:18\n",
      "batch: 50 ;B loss: 1.617 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:02:32\n",
      "batch: 100 ;B loss: 1.709 ;acc: 0.660 ;iou_acc: 0.720 ;time: 0:02:44\n",
      "batch: 150 ;B loss: 1.730 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:02:57\n",
      "batch: 200 ;B loss: 1.641 ;acc: 0.730 ;iou_acc: 0.840 ;time: 0:03:09\n",
      "batch: 250 ;B loss: 1.649 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:03:21\n",
      "\n",
      "*BTrain: False ;Test loss: 1.655 ;Test accuracy 0.709 ;IOU accuracy: 0.798 ;Time: 0:03:33\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 78 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 33237 ;lr: 0.0485 ;B loss: 2.093 ;acc: 0.585 ;iou: 0.640 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 33287 ;lr: 0.0485 ;B loss: 2.114 ;acc: 0.585 ;iou: 0.645 ;time: 0:00:15\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 33337 ;lr: 0.0485 ;B loss: 2.116 ;acc: 0.570 ;iou: 0.650 ;time: 0:00:30\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 33387 ;lr: 0.0485 ;B loss: 2.036 ;acc: 0.635 ;iou: 0.710 ;time: 0:00:45\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 33437 ;lr: 0.0485 ;B loss: 2.160 ;acc: 0.525 ;iou: 0.610 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 33487 ;lr: 0.0485 ;B loss: 2.053 ;acc: 0.605 ;iou: 0.650 ;time: 0:01:17\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 33537 ;lr: 0.0485 ;B loss: 2.194 ;acc: 0.560 ;iou: 0.620 ;time: 0:01:33\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 33587 ;lr: 0.0485 ;B loss: 2.224 ;acc: 0.550 ;iou: 0.620 ;time: 0:01:49\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 33637 ;lr: 0.0485 ;B loss: 2.109 ;acc: 0.595 ;iou: 0.645 ;time: 0:02:04\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 33687 ;lr: 0.0485 ;B loss: 2.060 ;acc: 0.605 ;iou: 0.680 ;time: 0:02:19\n",
      "\n",
      "*Training B: True ;B Train loss: 2.072 ;Train accuracy: 0.599 ;IOU accuracy: 0.667 ;Time: 0:02:27 \n",
      "\n",
      "Testing, ephoc: 78\n",
      "batch: 0 ;B loss: 1.636 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:02:28\n",
      "batch: 50 ;B loss: 1.615 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:02:43\n",
      "batch: 100 ;B loss: 1.705 ;acc: 0.670 ;iou_acc: 0.740 ;time: 0:03:05\n",
      "batch: 150 ;B loss: 1.726 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:03:31\n",
      "batch: 200 ;B loss: 1.649 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:03:57\n",
      "batch: 250 ;B loss: 1.652 ;acc: 0.665 ;iou_acc: 0.760 ;time: 0:04:24\n",
      "\n",
      "*BTrain: True ;Test loss: 1.653 ;Test accuracy 0.708 ;IOU accuracy: 0.797 ;Time: 0:04:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 79 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 33712 ;lr: 0.0485 ;B loss: 2.014 ;acc: 0.640 ;iou: 0.680 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 33762 ;lr: 0.0485 ;B loss: 2.109 ;acc: 0.590 ;iou: 0.650 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 33812 ;lr: 0.0485 ;B loss: 2.000 ;acc: 0.530 ;iou: 0.655 ;time: 0:01:01\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 33862 ;lr: 0.0485 ;B loss: 2.107 ;acc: 0.550 ;iou: 0.655 ;time: 0:01:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 33912 ;lr: 0.0485 ;B loss: 2.028 ;acc: 0.620 ;iou: 0.650 ;time: 0:02:05\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 33962 ;lr: 0.0485 ;B loss: 2.030 ;acc: 0.595 ;iou: 0.635 ;time: 0:02:36\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 34012 ;lr: 0.0485 ;B loss: 2.094 ;acc: 0.550 ;iou: 0.620 ;time: 0:03:07\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 34062 ;lr: 0.0485 ;B loss: 2.085 ;acc: 0.615 ;iou: 0.705 ;time: 0:03:36\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 34112 ;lr: 0.0485 ;B loss: 2.090 ;acc: 0.615 ;iou: 0.690 ;time: 0:04:06\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 34162 ;lr: 0.0485 ;B loss: 2.129 ;acc: 0.540 ;iou: 0.595 ;time: 0:04:36\n",
      "\n",
      "*Training B: False ;B Train loss: 2.069 ;Train accuracy: 0.600 ;IOU accuracy: 0.669 ;Time: 0:04:50 \n",
      "\n",
      "Testing, ephoc: 79\n",
      "batch: 0 ;B loss: 1.648 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:04:50\n",
      "batch: 50 ;B loss: 1.605 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:05:25\n",
      "batch: 100 ;B loss: 1.712 ;acc: 0.660 ;iou_acc: 0.720 ;time: 0:05:53\n",
      "batch: 150 ;B loss: 1.726 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:06:21\n",
      "batch: 200 ;B loss: 1.640 ;acc: 0.725 ;iou_acc: 0.835 ;time: 0:06:48\n",
      "batch: 250 ;B loss: 1.660 ;acc: 0.660 ;iou_acc: 0.770 ;time: 0:07:16\n",
      "\n",
      "*BTrain: False ;Test loss: 1.652 ;Test accuracy 0.709 ;IOU accuracy: 0.798 ;Time: 0:07:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 80 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 34187 ;lr: 0.0485 ;B loss: 2.117 ;acc: 0.595 ;iou: 0.670 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 34237 ;lr: 0.0485 ;B loss: 2.029 ;acc: 0.625 ;iou: 0.685 ;time: 0:00:31\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 34287 ;lr: 0.0485 ;B loss: 2.114 ;acc: 0.555 ;iou: 0.630 ;time: 0:01:36\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 34337 ;lr: 0.0485 ;B loss: 2.122 ;acc: 0.595 ;iou: 0.685 ;time: 0:03:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 34387 ;lr: 0.0485 ;B loss: 2.122 ;acc: 0.610 ;iou: 0.695 ;time: 0:04:58\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 34437 ;lr: 0.0485 ;B loss: 2.048 ;acc: 0.595 ;iou: 0.665 ;time: 0:06:39\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 34487 ;lr: 0.0485 ;B loss: 2.066 ;acc: 0.625 ;iou: 0.665 ;time: 0:08:21\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 34537 ;lr: 0.0485 ;B loss: 1.914 ;acc: 0.640 ;iou: 0.725 ;time: 0:10:01\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 34587 ;lr: 0.0485 ;B loss: 2.092 ;acc: 0.580 ;iou: 0.640 ;time: 0:11:43\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 34637 ;lr: 0.0485 ;B loss: 2.067 ;acc: 0.575 ;iou: 0.680 ;time: 0:13:24\n",
      "\n",
      "*Training B: False ;B Train loss: 2.069 ;Train accuracy: 0.599 ;IOU accuracy: 0.668 ;Time: 0:14:08 \n",
      "\n",
      "Testing, ephoc: 80\n",
      "batch: 0 ;B loss: 1.647 ;acc: 0.715 ;iou_acc: 0.790 ;time: 0:14:10\n",
      "batch: 50 ;B loss: 1.608 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:15:46\n",
      "batch: 100 ;B loss: 1.717 ;acc: 0.655 ;iou_acc: 0.720 ;time: 0:17:15\n",
      "batch: 150 ;B loss: 1.722 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:18:50\n",
      "batch: 200 ;B loss: 1.635 ;acc: 0.745 ;iou_acc: 0.845 ;time: 0:20:24\n",
      "batch: 250 ;B loss: 1.645 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:21:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.653 ;Test accuracy 0.710 ;IOU accuracy: 0.799 ;Time: 0:22:13\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 81 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 34662 ;lr: 0.0485 ;B loss: 1.962 ;acc: 0.630 ;iou: 0.690 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 34712 ;lr: 0.0485 ;B loss: 1.976 ;acc: 0.640 ;iou: 0.695 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 34762 ;lr: 0.0485 ;B loss: 2.011 ;acc: 0.560 ;iou: 0.665 ;time: 0:01:03\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 34812 ;lr: 0.0485 ;B loss: 2.009 ;acc: 0.630 ;iou: 0.685 ;time: 0:01:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 34862 ;lr: 0.0485 ;B loss: 2.019 ;acc: 0.615 ;iou: 0.695 ;time: 0:02:21\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 34912 ;lr: 0.0485 ;B loss: 2.034 ;acc: 0.595 ;iou: 0.695 ;time: 0:04:09\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 34962 ;lr: 0.0485 ;B loss: 2.038 ;acc: 0.575 ;iou: 0.680 ;time: 0:05:42\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 35012 ;lr: 0.0485 ;B loss: 2.089 ;acc: 0.575 ;iou: 0.640 ;time: 0:07:35\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 35062 ;lr: 0.0485 ;B loss: 2.233 ;acc: 0.550 ;iou: 0.640 ;time: 0:09:16\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 35112 ;lr: 0.0485 ;B loss: 2.082 ;acc: 0.545 ;iou: 0.645 ;time: 0:11:04\n",
      "\n",
      "*Training B: True ;B Train loss: 2.066 ;Train accuracy: 0.600 ;IOU accuracy: 0.669 ;Time: 0:11:55 \n",
      "\n",
      "Testing, ephoc: 81\n",
      "batch: 0 ;B loss: 1.637 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:11:58\n",
      "batch: 50 ;B loss: 1.610 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:13:36\n",
      "batch: 100 ;B loss: 1.704 ;acc: 0.685 ;iou_acc: 0.740 ;time: 0:15:14\n",
      "batch: 150 ;B loss: 1.728 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:16:55\n",
      "batch: 200 ;B loss: 1.643 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:18:29\n",
      "batch: 250 ;B loss: 1.655 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:20:09\n",
      "\n",
      "*BTrain: True ;Test loss: 1.650 ;Test accuracy 0.710 ;IOU accuracy: 0.799 ;Time: 0:21:41\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 82 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 35137 ;lr: 0.0485 ;B loss: 1.948 ;acc: 0.610 ;iou: 0.690 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 35187 ;lr: 0.0485 ;B loss: 2.154 ;acc: 0.560 ;iou: 0.675 ;time: 0:01:46\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 35237 ;lr: 0.0485 ;B loss: 2.096 ;acc: 0.585 ;iou: 0.675 ;time: 0:03:34\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 35287 ;lr: 0.0485 ;B loss: 2.099 ;acc: 0.610 ;iou: 0.665 ;time: 0:05:11\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 35337 ;lr: 0.0485 ;B loss: 2.119 ;acc: 0.590 ;iou: 0.665 ;time: 0:06:54\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 35387 ;lr: 0.0485 ;B loss: 2.096 ;acc: 0.610 ;iou: 0.660 ;time: 0:08:28\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 35437 ;lr: 0.0485 ;B loss: 2.097 ;acc: 0.545 ;iou: 0.620 ;time: 0:10:24\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 35487 ;lr: 0.0485 ;B loss: 2.121 ;acc: 0.605 ;iou: 0.655 ;time: 0:12:02\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 35537 ;lr: 0.0485 ;B loss: 1.856 ;acc: 0.655 ;iou: 0.695 ;time: 0:13:53\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 35587 ;lr: 0.0485 ;B loss: 2.043 ;acc: 0.615 ;iou: 0.665 ;time: 0:15:31\n",
      "\n",
      "*Training B: False ;B Train loss: 2.064 ;Train accuracy: 0.601 ;IOU accuracy: 0.669 ;Time: 0:16:22 \n",
      "\n",
      "Testing, ephoc: 82\n",
      "batch: 0 ;B loss: 1.657 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:16:23\n",
      "batch: 50 ;B loss: 1.613 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:18:00\n",
      "batch: 100 ;B loss: 1.700 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:19:40\n",
      "batch: 150 ;B loss: 1.733 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:21:16\n",
      "batch: 200 ;B loss: 1.638 ;acc: 0.715 ;iou_acc: 0.820 ;time: 0:22:56\n",
      "batch: 250 ;B loss: 1.646 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:24:34\n",
      "\n",
      "*BTrain: False ;Test loss: 1.654 ;Test accuracy 0.709 ;IOU accuracy: 0.798 ;Time: 0:26:02\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 83 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 35612 ;lr: 0.0485 ;B loss: 2.121 ;acc: 0.590 ;iou: 0.695 ;time: 0:00:03\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 35662 ;lr: 0.0485 ;B loss: 1.952 ;acc: 0.650 ;iou: 0.700 ;time: 0:01:57\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 35712 ;lr: 0.0485 ;B loss: 2.023 ;acc: 0.595 ;iou: 0.675 ;time: 0:03:36\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 35762 ;lr: 0.0485 ;B loss: 2.128 ;acc: 0.610 ;iou: 0.655 ;time: 0:05:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 35812 ;lr: 0.0485 ;B loss: 2.099 ;acc: 0.600 ;iou: 0.650 ;time: 0:07:11\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 35862 ;lr: 0.0485 ;B loss: 1.983 ;acc: 0.645 ;iou: 0.710 ;time: 0:08:53\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 35912 ;lr: 0.0485 ;B loss: 2.016 ;acc: 0.675 ;iou: 0.700 ;time: 0:10:33\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 35962 ;lr: 0.0485 ;B loss: 2.015 ;acc: 0.615 ;iou: 0.695 ;time: 0:12:16\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 36012 ;lr: 0.0485 ;B loss: 2.113 ;acc: 0.575 ;iou: 0.630 ;time: 0:13:59\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 36062 ;lr: 0.0485 ;B loss: 2.186 ;acc: 0.515 ;iou: 0.595 ;time: 0:15:45\n",
      "\n",
      "*Training B: False ;B Train loss: 2.062 ;Train accuracy: 0.602 ;IOU accuracy: 0.669 ;Time: 0:16:36 \n",
      "\n",
      "Testing, ephoc: 83\n",
      "batch: 0 ;B loss: 1.637 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:16:38\n",
      "batch: 50 ;B loss: 1.605 ;acc: 0.725 ;iou_acc: 0.795 ;time: 0:18:20\n",
      "batch: 100 ;B loss: 1.709 ;acc: 0.645 ;iou_acc: 0.720 ;time: 0:19:54\n",
      "batch: 150 ;B loss: 1.714 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:21:34\n",
      "batch: 200 ;B loss: 1.641 ;acc: 0.735 ;iou_acc: 0.845 ;time: 0:23:11\n",
      "batch: 250 ;B loss: 1.641 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:24:47\n",
      "\n",
      "*BTrain: False ;Test loss: 1.648 ;Test accuracy 0.709 ;IOU accuracy: 0.797 ;Time: 0:26:21\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 84 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 36087 ;lr: 0.0485 ;B loss: 2.032 ;acc: 0.570 ;iou: 0.645 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 36137 ;lr: 0.0485 ;B loss: 2.054 ;acc: 0.640 ;iou: 0.715 ;time: 0:01:46\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 36187 ;lr: 0.0485 ;B loss: 2.075 ;acc: 0.615 ;iou: 0.655 ;time: 0:03:37\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 36237 ;lr: 0.0485 ;B loss: 2.131 ;acc: 0.590 ;iou: 0.680 ;time: 0:05:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 36287 ;lr: 0.0485 ;B loss: 2.009 ;acc: 0.595 ;iou: 0.650 ;time: 0:06:59\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 36337 ;lr: 0.0485 ;B loss: 1.938 ;acc: 0.655 ;iou: 0.705 ;time: 0:08:45\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 36387 ;lr: 0.0485 ;B loss: 2.072 ;acc: 0.610 ;iou: 0.665 ;time: 0:10:28\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 36437 ;lr: 0.0485 ;B loss: 1.999 ;acc: 0.620 ;iou: 0.655 ;time: 0:12:09\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 36487 ;lr: 0.0485 ;B loss: 1.994 ;acc: 0.595 ;iou: 0.680 ;time: 0:13:58\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 36537 ;lr: 0.0485 ;B loss: 2.237 ;acc: 0.540 ;iou: 0.590 ;time: 0:15:42\n",
      "\n",
      "*Training B: True ;B Train loss: 2.062 ;Train accuracy: 0.602 ;IOU accuracy: 0.670 ;Time: 0:16:37 \n",
      "\n",
      "Testing, ephoc: 84\n",
      "batch: 0 ;B loss: 1.655 ;acc: 0.735 ;iou_acc: 0.815 ;time: 0:16:38\n",
      "batch: 50 ;B loss: 1.600 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:18:14\n",
      "batch: 100 ;B loss: 1.712 ;acc: 0.655 ;iou_acc: 0.720 ;time: 0:19:55\n",
      "batch: 150 ;B loss: 1.741 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:21:30\n",
      "batch: 200 ;B loss: 1.636 ;acc: 0.725 ;iou_acc: 0.835 ;time: 0:23:07\n",
      "batch: 250 ;B loss: 1.633 ;acc: 0.670 ;iou_acc: 0.775 ;time: 0:24:47\n",
      "\n",
      "*BTrain: True ;Test loss: 1.650 ;Test accuracy 0.709 ;IOU accuracy: 0.798 ;Time: 0:26:14\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 85 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 36562 ;lr: 0.0485 ;B loss: 1.980 ;acc: 0.645 ;iou: 0.700 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 36612 ;lr: 0.0485 ;B loss: 2.121 ;acc: 0.600 ;iou: 0.670 ;time: 0:01:50\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 36662 ;lr: 0.0485 ;B loss: 1.998 ;acc: 0.620 ;iou: 0.670 ;time: 0:03:26\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 36712 ;lr: 0.0485 ;B loss: 2.014 ;acc: 0.575 ;iou: 0.655 ;time: 0:05:18\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 36762 ;lr: 0.0485 ;B loss: 2.076 ;acc: 0.605 ;iou: 0.650 ;time: 0:07:02\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 36812 ;lr: 0.0485 ;B loss: 2.124 ;acc: 0.540 ;iou: 0.620 ;time: 0:08:49\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 36862 ;lr: 0.0485 ;B loss: 2.112 ;acc: 0.625 ;iou: 0.685 ;time: 0:10:36\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 36912 ;lr: 0.0485 ;B loss: 1.908 ;acc: 0.635 ;iou: 0.715 ;time: 0:12:23\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 36962 ;lr: 0.0485 ;B loss: 1.964 ;acc: 0.620 ;iou: 0.680 ;time: 0:14:09\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 37012 ;lr: 0.0485 ;B loss: 2.086 ;acc: 0.655 ;iou: 0.700 ;time: 0:15:53\n",
      "\n",
      "*Training B: False ;B Train loss: 2.059 ;Train accuracy: 0.602 ;IOU accuracy: 0.670 ;Time: 0:16:44 \n",
      "\n",
      "Testing, ephoc: 85\n",
      "batch: 0 ;B loss: 1.644 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:16:46\n",
      "batch: 50 ;B loss: 1.601 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:18:27\n",
      "batch: 100 ;B loss: 1.698 ;acc: 0.680 ;iou_acc: 0.740 ;time: 0:20:02\n",
      "batch: 150 ;B loss: 1.729 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:21:44\n",
      "batch: 200 ;B loss: 1.631 ;acc: 0.735 ;iou_acc: 0.845 ;time: 0:23:18\n",
      "batch: 250 ;B loss: 1.634 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:24:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.647 ;Test accuracy 0.710 ;IOU accuracy: 0.799 ;Time: 0:26:31\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 86 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 37037 ;lr: 0.0485 ;B loss: 1.883 ;acc: 0.610 ;iou: 0.655 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 37087 ;lr: 0.0485 ;B loss: 1.987 ;acc: 0.595 ;iou: 0.650 ;time: 0:01:42\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 37137 ;lr: 0.0485 ;B loss: 2.226 ;acc: 0.570 ;iou: 0.635 ;time: 0:03:30\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 37187 ;lr: 0.0485 ;B loss: 2.094 ;acc: 0.580 ;iou: 0.645 ;time: 0:05:14\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 37237 ;lr: 0.0485 ;B loss: 2.103 ;acc: 0.595 ;iou: 0.655 ;time: 0:07:02\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 37287 ;lr: 0.0485 ;B loss: 2.040 ;acc: 0.585 ;iou: 0.655 ;time: 0:08:43\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 37337 ;lr: 0.0485 ;B loss: 1.892 ;acc: 0.625 ;iou: 0.690 ;time: 0:10:28\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 37387 ;lr: 0.0485 ;B loss: 1.985 ;acc: 0.640 ;iou: 0.700 ;time: 0:12:10\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 37437 ;lr: 0.0485 ;B loss: 2.037 ;acc: 0.610 ;iou: 0.685 ;time: 0:13:54\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 37487 ;lr: 0.0485 ;B loss: 2.190 ;acc: 0.575 ;iou: 0.680 ;time: 0:15:46\n",
      "\n",
      "*Training B: False ;B Train loss: 2.058 ;Train accuracy: 0.604 ;IOU accuracy: 0.671 ;Time: 0:16:38 \n",
      "\n",
      "Testing, ephoc: 86\n",
      "batch: 0 ;B loss: 1.651 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:16:39\n",
      "batch: 50 ;B loss: 1.613 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:18:18\n",
      "batch: 100 ;B loss: 1.707 ;acc: 0.665 ;iou_acc: 0.725 ;time: 0:19:59\n",
      "batch: 150 ;B loss: 1.723 ;acc: 0.680 ;iou_acc: 0.760 ;time: 0:21:35\n",
      "batch: 200 ;B loss: 1.640 ;acc: 0.730 ;iou_acc: 0.830 ;time: 0:23:15\n",
      "batch: 250 ;B loss: 1.635 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:24:51\n",
      "\n",
      "*BTrain: False ;Test loss: 1.648 ;Test accuracy 0.711 ;IOU accuracy: 0.799 ;Time: 0:26:21\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 87 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 37512 ;lr: 0.0485 ;B loss: 2.028 ;acc: 0.580 ;iou: 0.665 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 37562 ;lr: 0.0485 ;B loss: 2.002 ;acc: 0.655 ;iou: 0.695 ;time: 0:01:50\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 37612 ;lr: 0.0485 ;B loss: 1.901 ;acc: 0.645 ;iou: 0.725 ;time: 0:03:35\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 37662 ;lr: 0.0485 ;B loss: 1.973 ;acc: 0.595 ;iou: 0.670 ;time: 0:05:19\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 37712 ;lr: 0.0485 ;B loss: 2.044 ;acc: 0.615 ;iou: 0.690 ;time: 0:07:00\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 37762 ;lr: 0.0485 ;B loss: 2.037 ;acc: 0.585 ;iou: 0.665 ;time: 0:08:45\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 37812 ;lr: 0.0485 ;B loss: 1.987 ;acc: 0.605 ;iou: 0.660 ;time: 0:10:30\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 37862 ;lr: 0.0485 ;B loss: 2.184 ;acc: 0.590 ;iou: 0.645 ;time: 0:12:22\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 37912 ;lr: 0.0485 ;B loss: 2.066 ;acc: 0.585 ;iou: 0.655 ;time: 0:14:09\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 37962 ;lr: 0.0485 ;B loss: 2.077 ;acc: 0.585 ;iou: 0.635 ;time: 0:15:53\n",
      "\n",
      "*Training B: True ;B Train loss: 2.055 ;Train accuracy: 0.603 ;IOU accuracy: 0.670 ;Time: 0:16:39 \n",
      "\n",
      "Testing, ephoc: 87\n",
      "batch: 0 ;B loss: 1.659 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:16:42\n",
      "batch: 50 ;B loss: 1.620 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:18:20\n",
      "batch: 100 ;B loss: 1.718 ;acc: 0.675 ;iou_acc: 0.725 ;time: 0:19:58\n",
      "batch: 150 ;B loss: 1.725 ;acc: 0.670 ;iou_acc: 0.760 ;time: 0:21:39\n",
      "batch: 200 ;B loss: 1.648 ;acc: 0.725 ;iou_acc: 0.835 ;time: 0:23:11\n",
      "batch: 250 ;B loss: 1.635 ;acc: 0.690 ;iou_acc: 0.790 ;time: 0:24:51\n",
      "\n",
      "*BTrain: True ;Test loss: 1.650 ;Test accuracy 0.709 ;IOU accuracy: 0.798 ;Time: 0:26:22\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 88 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 37987 ;lr: 0.0485 ;B loss: 2.150 ;acc: 0.625 ;iou: 0.700 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 38037 ;lr: 0.0485 ;B loss: 2.112 ;acc: 0.600 ;iou: 0.655 ;time: 0:01:42\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 38087 ;lr: 0.0485 ;B loss: 1.945 ;acc: 0.610 ;iou: 0.645 ;time: 0:03:27\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 38137 ;lr: 0.0485 ;B loss: 2.052 ;acc: 0.535 ;iou: 0.625 ;time: 0:05:03\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 38187 ;lr: 0.0485 ;B loss: 2.099 ;acc: 0.620 ;iou: 0.680 ;time: 0:06:49\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 38237 ;lr: 0.0485 ;B loss: 1.959 ;acc: 0.655 ;iou: 0.715 ;time: 0:08:31\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 38287 ;lr: 0.0485 ;B loss: 2.099 ;acc: 0.590 ;iou: 0.690 ;time: 0:10:22\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 38337 ;lr: 0.0485 ;B loss: 2.080 ;acc: 0.585 ;iou: 0.655 ;time: 0:12:13\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 38387 ;lr: 0.0485 ;B loss: 1.962 ;acc: 0.595 ;iou: 0.680 ;time: 0:14:03\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 38437 ;lr: 0.0485 ;B loss: 2.031 ;acc: 0.590 ;iou: 0.660 ;time: 0:15:47\n",
      "\n",
      "*Training B: False ;B Train loss: 2.055 ;Train accuracy: 0.604 ;IOU accuracy: 0.672 ;Time: 0:16:37 \n",
      "\n",
      "Testing, ephoc: 88\n",
      "batch: 0 ;B loss: 1.641 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:16:40\n",
      "batch: 50 ;B loss: 1.597 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:18:21\n",
      "batch: 100 ;B loss: 1.709 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:19:59\n",
      "batch: 150 ;B loss: 1.725 ;acc: 0.685 ;iou_acc: 0.770 ;time: 0:21:39\n",
      "batch: 200 ;B loss: 1.642 ;acc: 0.740 ;iou_acc: 0.835 ;time: 0:23:19\n",
      "batch: 250 ;B loss: 1.641 ;acc: 0.680 ;iou_acc: 0.780 ;time: 0:24:51\n",
      "\n",
      "*BTrain: False ;Test loss: 1.644 ;Test accuracy 0.710 ;IOU accuracy: 0.798 ;Time: 0:26:24\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 89 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 38462 ;lr: 0.0485 ;B loss: 2.062 ;acc: 0.575 ;iou: 0.640 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 38512 ;lr: 0.0485 ;B loss: 2.065 ;acc: 0.590 ;iou: 0.660 ;time: 0:01:52\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 38562 ;lr: 0.0485 ;B loss: 2.175 ;acc: 0.575 ;iou: 0.685 ;time: 0:03:41\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 38612 ;lr: 0.0485 ;B loss: 2.080 ;acc: 0.660 ;iou: 0.715 ;time: 0:05:24\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 38662 ;lr: 0.0485 ;B loss: 1.997 ;acc: 0.650 ;iou: 0.700 ;time: 0:07:11\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 38712 ;lr: 0.0485 ;B loss: 2.049 ;acc: 0.635 ;iou: 0.705 ;time: 0:08:48\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 38762 ;lr: 0.0485 ;B loss: 2.098 ;acc: 0.560 ;iou: 0.635 ;time: 0:10:28\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 38812 ;lr: 0.0485 ;B loss: 2.038 ;acc: 0.625 ;iou: 0.710 ;time: 0:12:13\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 38862 ;lr: 0.0485 ;B loss: 2.070 ;acc: 0.585 ;iou: 0.655 ;time: 0:14:01\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 38912 ;lr: 0.0485 ;B loss: 2.039 ;acc: 0.630 ;iou: 0.710 ;time: 0:15:54\n",
      "\n",
      "*Training B: False ;B Train loss: 2.052 ;Train accuracy: 0.604 ;IOU accuracy: 0.671 ;Time: 0:16:45 \n",
      "\n",
      "Testing, ephoc: 89\n",
      "batch: 0 ;B loss: 1.637 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:16:47\n",
      "batch: 50 ;B loss: 1.609 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:18:21\n",
      "batch: 100 ;B loss: 1.699 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:20:02\n",
      "batch: 150 ;B loss: 1.726 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:21:41\n",
      "batch: 200 ;B loss: 1.642 ;acc: 0.735 ;iou_acc: 0.840 ;time: 0:23:16\n",
      "batch: 250 ;B loss: 1.643 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:24:55\n",
      "\n",
      "*BTrain: False ;Test loss: 1.644 ;Test accuracy 0.709 ;IOU accuracy: 0.798 ;Time: 0:26:25\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 90 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 38937 ;lr: 0.0485 ;B loss: 2.011 ;acc: 0.615 ;iou: 0.680 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 38987 ;lr: 0.0485 ;B loss: 2.116 ;acc: 0.610 ;iou: 0.690 ;time: 0:01:50\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 39037 ;lr: 0.0485 ;B loss: 2.048 ;acc: 0.600 ;iou: 0.670 ;time: 0:03:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 39087 ;lr: 0.0485 ;B loss: 1.806 ;acc: 0.655 ;iou: 0.730 ;time: 0:05:19\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 39137 ;lr: 0.0485 ;B loss: 2.150 ;acc: 0.600 ;iou: 0.655 ;time: 0:07:07\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 39187 ;lr: 0.0485 ;B loss: 1.996 ;acc: 0.660 ;iou: 0.705 ;time: 0:08:50\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 39237 ;lr: 0.0485 ;B loss: 1.970 ;acc: 0.700 ;iou: 0.730 ;time: 0:10:33\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 39287 ;lr: 0.0485 ;B loss: 2.101 ;acc: 0.610 ;iou: 0.690 ;time: 0:12:19\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 39337 ;lr: 0.0485 ;B loss: 2.129 ;acc: 0.550 ;iou: 0.650 ;time: 0:13:58\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 39387 ;lr: 0.0485 ;B loss: 2.044 ;acc: 0.595 ;iou: 0.655 ;time: 0:15:40\n",
      "\n",
      "*Training B: True ;B Train loss: 2.049 ;Train accuracy: 0.605 ;IOU accuracy: 0.672 ;Time: 0:16:32 \n",
      "\n",
      "Testing, ephoc: 90\n",
      "batch: 0 ;B loss: 1.642 ;acc: 0.730 ;iou_acc: 0.810 ;time: 0:16:34\n",
      "batch: 50 ;B loss: 1.610 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:18:14\n",
      "batch: 100 ;B loss: 1.702 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:19:52\n",
      "batch: 150 ;B loss: 1.727 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:21:30\n",
      "batch: 200 ;B loss: 1.651 ;acc: 0.730 ;iou_acc: 0.845 ;time: 0:23:08\n",
      "batch: 250 ;B loss: 1.642 ;acc: 0.675 ;iou_acc: 0.785 ;time: 0:24:41\n",
      "\n",
      "*BTrain: True ;Test loss: 1.648 ;Test accuracy 0.710 ;IOU accuracy: 0.798 ;Time: 0:26:13\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 91 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 39412 ;lr: 0.0485 ;B loss: 1.997 ;acc: 0.655 ;iou: 0.715 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 39462 ;lr: 0.0485 ;B loss: 2.081 ;acc: 0.600 ;iou: 0.680 ;time: 0:01:46\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 39512 ;lr: 0.0485 ;B loss: 2.066 ;acc: 0.585 ;iou: 0.650 ;time: 0:03:35\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 39562 ;lr: 0.0485 ;B loss: 1.991 ;acc: 0.615 ;iou: 0.680 ;time: 0:05:17\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 39612 ;lr: 0.0485 ;B loss: 1.968 ;acc: 0.625 ;iou: 0.665 ;time: 0:07:04\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 39662 ;lr: 0.0485 ;B loss: 2.008 ;acc: 0.660 ;iou: 0.725 ;time: 0:08:46\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 39712 ;lr: 0.0485 ;B loss: 2.046 ;acc: 0.570 ;iou: 0.635 ;time: 0:10:32\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 39762 ;lr: 0.0485 ;B loss: 2.071 ;acc: 0.650 ;iou: 0.725 ;time: 0:12:22\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 39812 ;lr: 0.0485 ;B loss: 2.051 ;acc: 0.575 ;iou: 0.625 ;time: 0:14:06\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 39862 ;lr: 0.0485 ;B loss: 2.008 ;acc: 0.660 ;iou: 0.720 ;time: 0:15:50\n",
      "\n",
      "*Training B: False ;B Train loss: 2.049 ;Train accuracy: 0.604 ;IOU accuracy: 0.672 ;Time: 0:16:39 \n",
      "\n",
      "Testing, ephoc: 91\n",
      "batch: 0 ;B loss: 1.665 ;acc: 0.740 ;iou_acc: 0.820 ;time: 0:16:41\n",
      "batch: 50 ;B loss: 1.607 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:18:17\n",
      "batch: 100 ;B loss: 1.718 ;acc: 0.675 ;iou_acc: 0.730 ;time: 0:19:57\n",
      "batch: 150 ;B loss: 1.716 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:21:35\n",
      "batch: 200 ;B loss: 1.641 ;acc: 0.745 ;iou_acc: 0.845 ;time: 0:23:09\n",
      "batch: 250 ;B loss: 1.636 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:24:50\n",
      "\n",
      "*BTrain: False ;Test loss: 1.647 ;Test accuracy 0.710 ;IOU accuracy: 0.798 ;Time: 0:26:19\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 92 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 39887 ;lr: 0.0485 ;B loss: 2.163 ;acc: 0.530 ;iou: 0.585 ;time: 0:00:03\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 39937 ;lr: 0.0485 ;B loss: 2.087 ;acc: 0.630 ;iou: 0.675 ;time: 0:01:52\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 39987 ;lr: 0.0485 ;B loss: 2.152 ;acc: 0.575 ;iou: 0.665 ;time: 0:03:31\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 40037 ;lr: 0.0480 ;B loss: 2.019 ;acc: 0.610 ;iou: 0.645 ;time: 0:05:22\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 40087 ;lr: 0.0480 ;B loss: 2.152 ;acc: 0.570 ;iou: 0.680 ;time: 0:07:07\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 40137 ;lr: 0.0480 ;B loss: 2.174 ;acc: 0.585 ;iou: 0.655 ;time: 0:08:45\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 40187 ;lr: 0.0480 ;B loss: 2.139 ;acc: 0.575 ;iou: 0.640 ;time: 0:10:28\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 40237 ;lr: 0.0480 ;B loss: 2.175 ;acc: 0.575 ;iou: 0.630 ;time: 0:12:13\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 40287 ;lr: 0.0480 ;B loss: 2.070 ;acc: 0.600 ;iou: 0.695 ;time: 0:14:04\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 40337 ;lr: 0.0480 ;B loss: 2.056 ;acc: 0.600 ;iou: 0.645 ;time: 0:15:50\n",
      "\n",
      "*Training B: False ;B Train loss: 2.049 ;Train accuracy: 0.605 ;IOU accuracy: 0.672 ;Time: 0:16:40 \n",
      "\n",
      "Testing, ephoc: 92\n",
      "batch: 0 ;B loss: 1.637 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:16:42\n",
      "batch: 50 ;B loss: 1.611 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:18:22\n",
      "batch: 100 ;B loss: 1.703 ;acc: 0.695 ;iou_acc: 0.760 ;time: 0:20:00\n",
      "batch: 150 ;B loss: 1.724 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:21:14\n",
      "batch: 200 ;B loss: 1.639 ;acc: 0.735 ;iou_acc: 0.845 ;time: 0:21:43\n",
      "batch: 250 ;B loss: 1.619 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:22:11\n",
      "\n",
      "*BTrain: False ;Test loss: 1.643 ;Test accuracy 0.710 ;IOU accuracy: 0.798 ;Time: 0:22:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 93 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 40362 ;lr: 0.0480 ;B loss: 1.847 ;acc: 0.680 ;iou: 0.745 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 40412 ;lr: 0.0480 ;B loss: 1.920 ;acc: 0.635 ;iou: 0.680 ;time: 0:00:32\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 40462 ;lr: 0.0480 ;B loss: 2.015 ;acc: 0.615 ;iou: 0.695 ;time: 0:01:03\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 40512 ;lr: 0.0480 ;B loss: 1.960 ;acc: 0.660 ;iou: 0.740 ;time: 0:01:35\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 40562 ;lr: 0.0480 ;B loss: 1.929 ;acc: 0.625 ;iou: 0.695 ;time: 0:02:35\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 40612 ;lr: 0.0480 ;B loss: 2.019 ;acc: 0.595 ;iou: 0.645 ;time: 0:04:23\n",
      "Edit: False ;A: False ;batch: 300 ;gs: 40662 ;lr: 0.0480 ;B loss: 2.093 ;acc: 0.625 ;iou: 0.685 ;time: 0:06:05\n",
      "Edit: False ;A: False ;batch: 350 ;gs: 40712 ;lr: 0.0480 ;B loss: 1.993 ;acc: 0.605 ;iou: 0.695 ;time: 0:07:51\n",
      "Edit: False ;A: False ;batch: 400 ;gs: 40762 ;lr: 0.0480 ;B loss: 2.097 ;acc: 0.565 ;iou: 0.655 ;time: 0:09:35\n",
      "Edit: False ;A: False ;batch: 450 ;gs: 40812 ;lr: 0.0480 ;B loss: 2.084 ;acc: 0.625 ;iou: 0.680 ;time: 0:11:18\n",
      "\n",
      "*Training B: True ;B Train loss: 2.043 ;Train accuracy: 0.606 ;IOU accuracy: 0.673 ;Time: 0:12:08 \n",
      "\n",
      "Testing, ephoc: 93\n",
      "batch: 0 ;B loss: 1.646 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:12:11\n",
      "batch: 50 ;B loss: 1.599 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:13:46\n",
      "batch: 100 ;B loss: 1.707 ;acc: 0.685 ;iou_acc: 0.730 ;time: 0:15:26\n",
      "batch: 150 ;B loss: 1.728 ;acc: 0.680 ;iou_acc: 0.770 ;time: 0:17:05\n",
      "batch: 200 ;B loss: 1.640 ;acc: 0.735 ;iou_acc: 0.845 ;time: 0:18:39\n",
      "batch: 250 ;B loss: 1.631 ;acc: 0.670 ;iou_acc: 0.785 ;time: 0:20:18\n",
      "\n",
      "*BTrain: True ;Test loss: 1.644 ;Test accuracy 0.708 ;IOU accuracy: 0.797 ;Time: 0:21:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 94 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 40837 ;lr: 0.0480 ;B loss: 2.073 ;acc: 0.590 ;iou: 0.625 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 40887 ;lr: 0.0480 ;B loss: 2.036 ;acc: 0.610 ;iou: 0.670 ;time: 0:01:35\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 40937 ;lr: 0.0480 ;B loss: 1.971 ;acc: 0.620 ;iou: 0.695 ;time: 0:02:04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b69fb04df125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdropout_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mdropout_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         dropout_out=dropout_out)\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0maug_bnorm_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-142af79a318b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, use_wordAttn, addNoise)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                         attn_idx, padded_queries, padded_im, padded_bbox, labels = self.build_data(trn_data, \n\u001b[0;32m--> 543\u001b[0;31m                                                                                             b*self.batch_size, (b+1)*self.batch_size, addNoise=addNoise)\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                         \u001b[0mreward_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# dummy holder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-142af79a318b>\u001b[0m in \u001b[0;36mbuild_data\u001b[0;34m(self, data, start, end, addNoise)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mpadded_im\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mpadded_im\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Augmenting data\n",
    "# The accuracy and IOU of the trainin set includs data points \n",
    "# with no true groinding bbox so the true training's accuracy and IOU\n",
    "# is higher then we can see in the reults here (TODO: fix it)\n",
    "# decreasing learning rate even more\n",
    "\n",
    "print(len(trainset))\n",
    "augment_data(trainset, ratio=0.6)\n",
    "print(len(trainset))\n",
    "\n",
    "num_hidden = 200\n",
    "dropout_in=0.5\n",
    "dropout_out=1.\n",
    "dropout_img = 0.5\n",
    "params_dir = params_dir_tmp+'bnorm_base/augmented_'+str(dropout_in)+','+str(dropout_out)+','+str(dropout_img)+'_hidden:'+str(num_hidden)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=num_hidden,\n",
    "    img_dims=trainset[0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][1][1].shape[1], \n",
    "    lr=.05,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.99, \n",
    "    edit_reward=0.,\n",
    "    rnn_editProb=0.,\n",
    "    coefAlr=1,\n",
    "    bnorm=True)\n",
    "\n",
    "\n",
    "# start comp\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=100,\n",
    "        start_ephoc=63,\n",
    "        startA=101,\n",
    "        activation_ephoc=101,\n",
    "        muteB=0, \n",
    "        activateAProb=0,\n",
    "        max_activateAProb=0,\n",
    "        editProb=0,\n",
    "        edit_reward=0,\n",
    "        dropout_img=dropout_img,\n",
    "        dropout_in=dropout_in,\n",
    "        dropout_out=dropout_out)\n",
    "\n",
    "aug_bnorm_test_res.append(tst)\n",
    "aug_bnorm_train_res.append(trn)\n",
    "print('\\n'+'*'*100)\n",
    "print('*'*100)\n",
    "print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset length: 59449\n"
     ]
    }
   ],
   "source": [
    "trainset = np.load(open(trainset_file, 'rb'))\n",
    "trainset = [item for item in trainset if len(item)>2 and len(item[0])>0]\n",
    "print('trainset length:', len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dir: ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200\n",
      "num_hidden: 200\n",
      "learning rate: 0.05\n",
      "# Train set size: 59449\n",
      "# Training batches: 297\n",
      "# Test set size: 59507\n",
      "# Testing batches: 297\n",
      "Loading parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-93\n",
      "INFO:tensorflow:Restoring parameters from ../data/training/models/RGAB5/All/bnorm_base/augmented_0.5,1.0,0.5_hidden:200/model.ckpt-93\n",
      "================================================== \n",
      "Train, ephoc: 94 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 40837 ;lr: 0.0480 ;B loss: 1.438 ;acc: 0.865 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 40887 ;lr: 0.0480 ;B loss: 1.350 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:18\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 40937 ;lr: 0.0480 ;B loss: 1.292 ;acc: 0.845 ;iou: 0.900 ;time: 0:00:36\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 40987 ;lr: 0.0480 ;B loss: 1.214 ;acc: 0.875 ;iou: 0.935 ;time: 0:00:55\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 41037 ;lr: 0.0480 ;B loss: 1.313 ;acc: 0.875 ;iou: 0.930 ;time: 0:01:13\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 41087 ;lr: 0.0480 ;B loss: 1.419 ;acc: 0.860 ;iou: 0.920 ;time: 0:01:35\n",
      "\n",
      "*Training B: False ;B Train loss: 1.338 ;Train accuracy: 0.862 ;IOU accuracy: 0.910 ;Time: 0:01:54 \n",
      "\n",
      "Testing, ephoc: 94\n",
      "batch: 0 ;B loss: 1.562 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:01:55\n",
      "batch: 50 ;B loss: 1.494 ;acc: 0.715 ;iou_acc: 0.775 ;time: 0:02:11\n",
      "batch: 100 ;B loss: 1.661 ;acc: 0.685 ;iou_acc: 0.730 ;time: 0:02:27\n",
      "batch: 150 ;B loss: 1.681 ;acc: 0.710 ;iou_acc: 0.780 ;time: 0:02:42\n",
      "batch: 200 ;B loss: 1.577 ;acc: 0.725 ;iou_acc: 0.840 ;time: 0:02:57\n",
      "batch: 250 ;B loss: 1.526 ;acc: 0.725 ;iou_acc: 0.805 ;time: 0:03:14\n",
      "\n",
      "*BTrain: False ;Test loss: 1.581 ;Test accuracy 0.719 ;IOU accuracy: 0.807 ;Time: 0:03:29\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 95 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 41134 ;lr: 0.0480 ;B loss: 1.380 ;acc: 0.865 ;iou: 0.915 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 41184 ;lr: 0.0480 ;B loss: 1.280 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 41234 ;lr: 0.0480 ;B loss: 1.219 ;acc: 0.905 ;iou: 0.920 ;time: 0:00:40\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 41284 ;lr: 0.0480 ;B loss: 1.324 ;acc: 0.860 ;iou: 0.900 ;time: 0:01:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 41334 ;lr: 0.0480 ;B loss: 1.285 ;acc: 0.865 ;iou: 0.920 ;time: 0:02:28\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 41384 ;lr: 0.0480 ;B loss: 1.324 ;acc: 0.885 ;iou: 0.915 ;time: 0:03:35\n",
      "\n",
      "*Training B: False ;B Train loss: 1.309 ;Train accuracy: 0.867 ;IOU accuracy: 0.913 ;Time: 0:04:34 \n",
      "\n",
      "Testing, ephoc: 95\n",
      "batch: 0 ;B loss: 1.545 ;acc: 0.730 ;iou_acc: 0.800 ;time: 0:04:35\n",
      "batch: 50 ;B loss: 1.467 ;acc: 0.720 ;iou_acc: 0.775 ;time: 0:05:35\n",
      "batch: 100 ;B loss: 1.670 ;acc: 0.670 ;iou_acc: 0.715 ;time: 0:06:34\n",
      "batch: 150 ;B loss: 1.672 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:07:33\n",
      "batch: 200 ;B loss: 1.586 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:08:26\n",
      "batch: 250 ;B loss: 1.525 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:09:22\n",
      "\n",
      "*BTrain: False ;Test loss: 1.583 ;Test accuracy 0.720 ;IOU accuracy: 0.808 ;Time: 0:10:17\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 96 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 41431 ;lr: 0.0480 ;B loss: 1.247 ;acc: 0.890 ;iou: 0.940 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 41481 ;lr: 0.0480 ;B loss: 1.272 ;acc: 0.905 ;iou: 0.945 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 41531 ;lr: 0.0480 ;B loss: 1.311 ;acc: 0.865 ;iou: 0.905 ;time: 0:02:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 41581 ;lr: 0.0480 ;B loss: 1.390 ;acc: 0.850 ;iou: 0.910 ;time: 0:03:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 41631 ;lr: 0.0480 ;B loss: 1.190 ;acc: 0.865 ;iou: 0.905 ;time: 0:04:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 41681 ;lr: 0.0480 ;B loss: 1.375 ;acc: 0.835 ;iou: 0.915 ;time: 0:05:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.295 ;Train accuracy: 0.869 ;IOU accuracy: 0.916 ;Time: 0:07:05 \n",
      "\n",
      "Testing, ephoc: 96\n",
      "batch: 0 ;B loss: 1.549 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:07:07\n",
      "batch: 50 ;B loss: 1.470 ;acc: 0.750 ;iou_acc: 0.800 ;time: 0:08:06\n",
      "batch: 100 ;B loss: 1.651 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:09:06\n",
      "batch: 150 ;B loss: 1.703 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:10:04\n",
      "batch: 200 ;B loss: 1.570 ;acc: 0.730 ;iou_acc: 0.825 ;time: 0:10:58\n",
      "batch: 250 ;B loss: 1.517 ;acc: 0.700 ;iou_acc: 0.785 ;time: 0:11:54\n",
      "\n",
      "*BTrain: True ;Test loss: 1.589 ;Test accuracy 0.720 ;IOU accuracy: 0.807 ;Time: 0:12:47\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 97 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 41728 ;lr: 0.0480 ;B loss: 1.312 ;acc: 0.880 ;iou: 0.920 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 41778 ;lr: 0.0480 ;B loss: 1.136 ;acc: 0.895 ;iou: 0.925 ;time: 0:01:13\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 41828 ;lr: 0.0480 ;B loss: 1.321 ;acc: 0.880 ;iou: 0.925 ;time: 0:02:27\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 41878 ;lr: 0.0480 ;B loss: 1.264 ;acc: 0.875 ;iou: 0.905 ;time: 0:03:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 41928 ;lr: 0.0480 ;B loss: 1.341 ;acc: 0.805 ;iou: 0.890 ;time: 0:04:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 41978 ;lr: 0.0480 ;B loss: 1.307 ;acc: 0.870 ;iou: 0.910 ;time: 0:05:54\n",
      "\n",
      "*Training B: False ;B Train loss: 1.287 ;Train accuracy: 0.869 ;IOU accuracy: 0.916 ;Time: 0:07:05 \n",
      "\n",
      "Testing, ephoc: 97\n",
      "batch: 0 ;B loss: 1.545 ;acc: 0.705 ;iou_acc: 0.780 ;time: 0:07:07\n",
      "batch: 50 ;B loss: 1.489 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:08:03\n",
      "batch: 100 ;B loss: 1.673 ;acc: 0.680 ;iou_acc: 0.730 ;time: 0:09:05\n",
      "batch: 150 ;B loss: 1.705 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:10:03\n",
      "batch: 200 ;B loss: 1.595 ;acc: 0.730 ;iou_acc: 0.820 ;time: 0:11:00\n",
      "batch: 250 ;B loss: 1.514 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:11:57\n",
      "\n",
      "*BTrain: False ;Test loss: 1.590 ;Test accuracy 0.718 ;IOU accuracy: 0.806 ;Time: 0:12:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 98 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 42025 ;lr: 0.0480 ;B loss: 1.234 ;acc: 0.930 ;iou: 0.945 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 42075 ;lr: 0.0480 ;B loss: 1.339 ;acc: 0.850 ;iou: 0.895 ;time: 0:01:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 42125 ;lr: 0.0480 ;B loss: 1.190 ;acc: 0.895 ;iou: 0.915 ;time: 0:01:58\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 42175 ;lr: 0.0480 ;B loss: 1.218 ;acc: 0.870 ;iou: 0.925 ;time: 0:02:19\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 42225 ;lr: 0.0480 ;B loss: 1.163 ;acc: 0.875 ;iou: 0.915 ;time: 0:02:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 42275 ;lr: 0.0480 ;B loss: 1.242 ;acc: 0.890 ;iou: 0.930 ;time: 0:02:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.279 ;Train accuracy: 0.871 ;IOU accuracy: 0.916 ;Time: 0:03:13 \n",
      "\n",
      "Testing, ephoc: 98\n",
      "batch: 0 ;B loss: 1.554 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:03:14\n",
      "batch: 50 ;B loss: 1.455 ;acc: 0.700 ;iou_acc: 0.770 ;time: 0:03:31\n",
      "batch: 100 ;B loss: 1.663 ;acc: 0.690 ;iou_acc: 0.740 ;time: 0:03:48\n",
      "batch: 150 ;B loss: 1.726 ;acc: 0.685 ;iou_acc: 0.765 ;time: 0:04:06\n",
      "batch: 200 ;B loss: 1.565 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:04:25\n",
      "batch: 250 ;B loss: 1.523 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:04:46\n",
      "\n",
      "*BTrain: False ;Test loss: 1.598 ;Test accuracy 0.717 ;IOU accuracy: 0.806 ;Time: 0:05:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 99 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 42322 ;lr: 0.0480 ;B loss: 1.360 ;acc: 0.860 ;iou: 0.915 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 42372 ;lr: 0.0480 ;B loss: 1.199 ;acc: 0.905 ;iou: 0.950 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 42422 ;lr: 0.0480 ;B loss: 1.293 ;acc: 0.875 ;iou: 0.900 ;time: 0:02:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 42472 ;lr: 0.0480 ;B loss: 1.259 ;acc: 0.880 ;iou: 0.920 ;time: 0:03:27\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 42522 ;lr: 0.0480 ;B loss: 1.216 ;acc: 0.900 ;iou: 0.940 ;time: 0:04:45\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 42572 ;lr: 0.0480 ;B loss: 1.341 ;acc: 0.870 ;iou: 0.915 ;time: 0:05:55\n",
      "\n",
      "*Training B: True ;B Train loss: 1.274 ;Train accuracy: 0.874 ;IOU accuracy: 0.919 ;Time: 0:07:01 \n",
      "\n",
      "Testing, ephoc: 99\n",
      "batch: 0 ;B loss: 1.563 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:07:01\n",
      "batch: 50 ;B loss: 1.467 ;acc: 0.725 ;iou_acc: 0.780 ;time: 0:08:00\n",
      "batch: 100 ;B loss: 1.657 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:08:59\n",
      "batch: 150 ;B loss: 1.737 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:09:56\n",
      "batch: 200 ;B loss: 1.585 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:10:49\n",
      "batch: 250 ;B loss: 1.523 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:11:49\n",
      "\n",
      "*BTrain: True ;Test loss: 1.593 ;Test accuracy 0.719 ;IOU accuracy: 0.808 ;Time: 0:12:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 100 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 42619 ;lr: 0.0480 ;B loss: 1.329 ;acc: 0.825 ;iou: 0.875 ;time: 0:00:03\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 42669 ;lr: 0.0480 ;B loss: 1.287 ;acc: 0.900 ;iou: 0.930 ;time: 0:01:21\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 42719 ;lr: 0.0480 ;B loss: 1.192 ;acc: 0.875 ;iou: 0.930 ;time: 0:02:26\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 42769 ;lr: 0.0480 ;B loss: 1.309 ;acc: 0.885 ;iou: 0.940 ;time: 0:03:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 42819 ;lr: 0.0480 ;B loss: 1.112 ;acc: 0.925 ;iou: 0.950 ;time: 0:04:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 42869 ;lr: 0.0480 ;B loss: 1.357 ;acc: 0.855 ;iou: 0.920 ;time: 0:05:51\n",
      "\n",
      "*Training B: False ;B Train loss: 1.271 ;Train accuracy: 0.875 ;IOU accuracy: 0.920 ;Time: 0:06:57 \n",
      "\n",
      "Testing, ephoc: 100\n",
      "batch: 0 ;B loss: 1.555 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:06:59\n",
      "batch: 50 ;B loss: 1.474 ;acc: 0.715 ;iou_acc: 0.785 ;time: 0:07:56\n",
      "batch: 100 ;B loss: 1.665 ;acc: 0.680 ;iou_acc: 0.745 ;time: 0:08:55\n",
      "batch: 150 ;B loss: 1.739 ;acc: 0.655 ;iou_acc: 0.755 ;time: 0:09:52\n",
      "batch: 200 ;B loss: 1.573 ;acc: 0.725 ;iou_acc: 0.820 ;time: 0:10:50\n",
      "batch: 250 ;B loss: 1.547 ;acc: 0.685 ;iou_acc: 0.775 ;time: 0:11:50\n",
      "\n",
      "*BTrain: False ;Test loss: 1.597 ;Test accuracy 0.716 ;IOU accuracy: 0.804 ;Time: 0:12:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 101 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 42916 ;lr: 0.0480 ;B loss: 1.184 ;acc: 0.865 ;iou: 0.930 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 42966 ;lr: 0.0480 ;B loss: 1.285 ;acc: 0.835 ;iou: 0.870 ;time: 0:01:13\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 43016 ;lr: 0.0480 ;B loss: 1.278 ;acc: 0.855 ;iou: 0.910 ;time: 0:02:27\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 43066 ;lr: 0.0480 ;B loss: 1.232 ;acc: 0.850 ;iou: 0.915 ;time: 0:03:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 43116 ;lr: 0.0480 ;B loss: 1.296 ;acc: 0.875 ;iou: 0.930 ;time: 0:04:42\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 43166 ;lr: 0.0480 ;B loss: 1.385 ;acc: 0.875 ;iou: 0.900 ;time: 0:05:45\n",
      "\n",
      "*Training B: False ;B Train loss: 1.264 ;Train accuracy: 0.876 ;IOU accuracy: 0.920 ;Time: 0:06:49 \n",
      "\n",
      "Testing, ephoc: 101\n",
      "batch: 0 ;B loss: 1.541 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:06:50\n",
      "batch: 50 ;B loss: 1.493 ;acc: 0.710 ;iou_acc: 0.770 ;time: 0:07:50\n",
      "batch: 100 ;B loss: 1.667 ;acc: 0.670 ;iou_acc: 0.730 ;time: 0:08:50\n",
      "batch: 150 ;B loss: 1.730 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:09:49\n",
      "batch: 200 ;B loss: 1.595 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:10:47\n",
      "batch: 250 ;B loss: 1.535 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:11:44\n",
      "\n",
      "*BTrain: False ;Test loss: 1.600 ;Test accuracy 0.717 ;IOU accuracy: 0.806 ;Time: 0:12:36\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 102 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 43213 ;lr: 0.0480 ;B loss: 1.234 ;acc: 0.845 ;iou: 0.890 ;time: 0:00:03\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 43263 ;lr: 0.0480 ;B loss: 1.287 ;acc: 0.860 ;iou: 0.900 ;time: 0:01:17\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 43313 ;lr: 0.0480 ;B loss: 1.343 ;acc: 0.880 ;iou: 0.895 ;time: 0:02:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 43363 ;lr: 0.0480 ;B loss: 1.375 ;acc: 0.845 ;iou: 0.885 ;time: 0:03:41\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 43413 ;lr: 0.0480 ;B loss: 1.315 ;acc: 0.905 ;iou: 0.950 ;time: 0:04:56\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 43463 ;lr: 0.0480 ;B loss: 1.204 ;acc: 0.860 ;iou: 0.895 ;time: 0:06:06\n",
      "\n",
      "*Training B: True ;B Train loss: 1.259 ;Train accuracy: 0.876 ;IOU accuracy: 0.920 ;Time: 0:07:11 \n",
      "\n",
      "Testing, ephoc: 102\n",
      "batch: 0 ;B loss: 1.580 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:07:12\n",
      "batch: 50 ;B loss: 1.470 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:08:11\n",
      "batch: 100 ;B loss: 1.663 ;acc: 0.700 ;iou_acc: 0.750 ;time: 0:09:11\n",
      "batch: 150 ;B loss: 1.732 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:10:08\n",
      "batch: 200 ;B loss: 1.592 ;acc: 0.735 ;iou_acc: 0.825 ;time: 0:11:04\n",
      "batch: 250 ;B loss: 1.499 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:12:04\n",
      "\n",
      "*BTrain: True ;Test loss: 1.606 ;Test accuracy 0.717 ;IOU accuracy: 0.805 ;Time: 0:12:55\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 103 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 43510 ;lr: 0.0480 ;B loss: 1.351 ;acc: 0.835 ;iou: 0.915 ;time: 0:00:03\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 43560 ;lr: 0.0480 ;B loss: 1.308 ;acc: 0.890 ;iou: 0.920 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 43610 ;lr: 0.0480 ;B loss: 1.196 ;acc: 0.870 ;iou: 0.925 ;time: 0:02:14\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 43660 ;lr: 0.0480 ;B loss: 1.256 ;acc: 0.885 ;iou: 0.915 ;time: 0:03:19\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 43710 ;lr: 0.0480 ;B loss: 1.207 ;acc: 0.905 ;iou: 0.940 ;time: 0:04:29\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 43760 ;lr: 0.0480 ;B loss: 1.250 ;acc: 0.850 ;iou: 0.925 ;time: 0:05:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.260 ;Train accuracy: 0.879 ;IOU accuracy: 0.922 ;Time: 0:07:01 \n",
      "\n",
      "Testing, ephoc: 103\n",
      "batch: 0 ;B loss: 1.559 ;acc: 0.720 ;iou_acc: 0.795 ;time: 0:07:03\n",
      "batch: 50 ;B loss: 1.460 ;acc: 0.710 ;iou_acc: 0.770 ;time: 0:07:58\n",
      "batch: 100 ;B loss: 1.656 ;acc: 0.675 ;iou_acc: 0.735 ;time: 0:08:59\n",
      "batch: 150 ;B loss: 1.728 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:09:59\n",
      "batch: 200 ;B loss: 1.625 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:10:54\n",
      "batch: 250 ;B loss: 1.504 ;acc: 0.720 ;iou_acc: 0.805 ;time: 0:11:50\n",
      "\n",
      "*BTrain: False ;Test loss: 1.607 ;Test accuracy 0.715 ;IOU accuracy: 0.804 ;Time: 0:12:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 104 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 43807 ;lr: 0.0480 ;B loss: 1.207 ;acc: 0.845 ;iou: 0.895 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 43857 ;lr: 0.0480 ;B loss: 1.239 ;acc: 0.865 ;iou: 0.900 ;time: 0:01:07\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 43907 ;lr: 0.0480 ;B loss: 1.330 ;acc: 0.850 ;iou: 0.920 ;time: 0:02:11\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 43957 ;lr: 0.0480 ;B loss: 1.286 ;acc: 0.900 ;iou: 0.920 ;time: 0:03:28\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 44007 ;lr: 0.0480 ;B loss: 1.205 ;acc: 0.905 ;iou: 0.945 ;time: 0:04:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 44057 ;lr: 0.0480 ;B loss: 1.202 ;acc: 0.875 ;iou: 0.925 ;time: 0:04:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.250 ;Train accuracy: 0.877 ;IOU accuracy: 0.922 ;Time: 0:05:13 \n",
      "\n",
      "Testing, ephoc: 104\n",
      "batch: 0 ;B loss: 1.597 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:05:14\n",
      "batch: 50 ;B loss: 1.478 ;acc: 0.720 ;iou_acc: 0.785 ;time: 0:05:28\n",
      "batch: 100 ;B loss: 1.676 ;acc: 0.690 ;iou_acc: 0.750 ;time: 0:05:45\n",
      "batch: 150 ;B loss: 1.734 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:06:02\n",
      "batch: 200 ;B loss: 1.612 ;acc: 0.720 ;iou_acc: 0.825 ;time: 0:06:19\n",
      "batch: 250 ;B loss: 1.559 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:06:36\n",
      "\n",
      "*BTrain: False ;Test loss: 1.611 ;Test accuracy 0.713 ;IOU accuracy: 0.803 ;Time: 0:06:52\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 105 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 44104 ;lr: 0.0480 ;B loss: 1.250 ;acc: 0.880 ;iou: 0.915 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 44154 ;lr: 0.0480 ;B loss: 1.248 ;acc: 0.890 ;iou: 0.940 ;time: 0:00:19\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 44204 ;lr: 0.0480 ;B loss: 1.278 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:37\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 44254 ;lr: 0.0480 ;B loss: 1.315 ;acc: 0.855 ;iou: 0.905 ;time: 0:00:56\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 44304 ;lr: 0.0480 ;B loss: 1.310 ;acc: 0.860 ;iou: 0.910 ;time: 0:01:32\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 44354 ;lr: 0.0480 ;B loss: 1.241 ;acc: 0.865 ;iou: 0.890 ;time: 0:02:42\n",
      "\n",
      "*Training B: True ;B Train loss: 1.246 ;Train accuracy: 0.880 ;IOU accuracy: 0.923 ;Time: 0:03:33 \n",
      "\n",
      "Testing, ephoc: 105\n",
      "batch: 0 ;B loss: 1.573 ;acc: 0.720 ;iou_acc: 0.800 ;time: 0:03:34\n",
      "batch: 50 ;B loss: 1.506 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:04:34\n",
      "batch: 100 ;B loss: 1.680 ;acc: 0.675 ;iou_acc: 0.740 ;time: 0:05:37\n",
      "batch: 150 ;B loss: 1.747 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:06:34\n",
      "batch: 200 ;B loss: 1.604 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:07:29\n",
      "batch: 250 ;B loss: 1.571 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:08:26\n",
      "\n",
      "*BTrain: True ;Test loss: 1.616 ;Test accuracy 0.711 ;IOU accuracy: 0.801 ;Time: 0:09:18\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 106 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 44401 ;lr: 0.0480 ;B loss: 1.182 ;acc: 0.900 ;iou: 0.950 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 44451 ;lr: 0.0480 ;B loss: 1.214 ;acc: 0.880 ;iou: 0.920 ;time: 0:01:02\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 44501 ;lr: 0.0480 ;B loss: 1.287 ;acc: 0.845 ;iou: 0.895 ;time: 0:02:16\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 44551 ;lr: 0.0480 ;B loss: 1.259 ;acc: 0.870 ;iou: 0.920 ;time: 0:03:16\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 44601 ;lr: 0.0480 ;B loss: 1.273 ;acc: 0.805 ;iou: 0.860 ;time: 0:04:34\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 44651 ;lr: 0.0480 ;B loss: 1.271 ;acc: 0.890 ;iou: 0.945 ;time: 0:05:42\n",
      "\n",
      "*Training B: False ;B Train loss: 1.239 ;Train accuracy: 0.881 ;IOU accuracy: 0.924 ;Time: 0:07:01 \n",
      "\n",
      "Testing, ephoc: 106\n",
      "batch: 0 ;B loss: 1.604 ;acc: 0.715 ;iou_acc: 0.795 ;time: 0:07:01\n",
      "batch: 50 ;B loss: 1.501 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:08:01\n",
      "batch: 100 ;B loss: 1.673 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:09:03\n",
      "batch: 150 ;B loss: 1.736 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:10:00\n",
      "batch: 200 ;B loss: 1.600 ;acc: 0.755 ;iou_acc: 0.850 ;time: 0:10:54\n",
      "batch: 250 ;B loss: 1.511 ;acc: 0.705 ;iou_acc: 0.800 ;time: 0:11:49\n",
      "\n",
      "*BTrain: False ;Test loss: 1.609 ;Test accuracy 0.715 ;IOU accuracy: 0.803 ;Time: 0:12:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 107 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 44698 ;lr: 0.0480 ;B loss: 1.147 ;acc: 0.885 ;iou: 0.930 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 44748 ;lr: 0.0480 ;B loss: 1.238 ;acc: 0.885 ;iou: 0.920 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 44798 ;lr: 0.0480 ;B loss: 1.303 ;acc: 0.865 ;iou: 0.920 ;time: 0:02:13\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 44848 ;lr: 0.0480 ;B loss: 1.225 ;acc: 0.870 ;iou: 0.925 ;time: 0:03:29\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 44898 ;lr: 0.0480 ;B loss: 1.160 ;acc: 0.875 ;iou: 0.915 ;time: 0:04:40\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 44948 ;lr: 0.0480 ;B loss: 1.351 ;acc: 0.845 ;iou: 0.895 ;time: 0:05:56\n",
      "\n",
      "*Training B: False ;B Train loss: 1.237 ;Train accuracy: 0.882 ;IOU accuracy: 0.924 ;Time: 0:07:08 \n",
      "\n",
      "Testing, ephoc: 107\n",
      "batch: 0 ;B loss: 1.614 ;acc: 0.705 ;iou_acc: 0.795 ;time: 0:07:10\n",
      "batch: 50 ;B loss: 1.507 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:08:10\n",
      "batch: 100 ;B loss: 1.669 ;acc: 0.685 ;iou_acc: 0.750 ;time: 0:09:10\n",
      "batch: 150 ;B loss: 1.733 ;acc: 0.695 ;iou_acc: 0.795 ;time: 0:10:07\n",
      "batch: 200 ;B loss: 1.602 ;acc: 0.740 ;iou_acc: 0.845 ;time: 0:10:59\n",
      "batch: 250 ;B loss: 1.543 ;acc: 0.710 ;iou_acc: 0.795 ;time: 0:11:56\n",
      "\n",
      "*BTrain: False ;Test loss: 1.620 ;Test accuracy 0.710 ;IOU accuracy: 0.800 ;Time: 0:12:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 108 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 44995 ;lr: 0.0480 ;B loss: 1.226 ;acc: 0.930 ;iou: 0.950 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 45045 ;lr: 0.0480 ;B loss: 1.218 ;acc: 0.880 ;iou: 0.910 ;time: 0:01:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 45095 ;lr: 0.0480 ;B loss: 1.188 ;acc: 0.885 ;iou: 0.930 ;time: 0:02:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 45145 ;lr: 0.0480 ;B loss: 1.220 ;acc: 0.900 ;iou: 0.920 ;time: 0:03:25\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 45195 ;lr: 0.0480 ;B loss: 1.294 ;acc: 0.845 ;iou: 0.900 ;time: 0:04:39\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 45245 ;lr: 0.0480 ;B loss: 1.197 ;acc: 0.895 ;iou: 0.935 ;time: 0:05:52\n",
      "\n",
      "*Training B: True ;B Train loss: 1.235 ;Train accuracy: 0.883 ;IOU accuracy: 0.925 ;Time: 0:06:57 \n",
      "\n",
      "Testing, ephoc: 108\n",
      "batch: 0 ;B loss: 1.598 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:06:58\n",
      "batch: 50 ;B loss: 1.522 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:07:55\n",
      "batch: 100 ;B loss: 1.655 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:08:54\n",
      "batch: 150 ;B loss: 1.738 ;acc: 0.695 ;iou_acc: 0.775 ;time: 0:09:51\n",
      "batch: 200 ;B loss: 1.606 ;acc: 0.750 ;iou_acc: 0.845 ;time: 0:10:46\n",
      "batch: 250 ;B loss: 1.519 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:11:46\n",
      "\n",
      "*BTrain: True ;Test loss: 1.616 ;Test accuracy 0.713 ;IOU accuracy: 0.802 ;Time: 0:12:40\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 109 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 45292 ;lr: 0.0480 ;B loss: 1.134 ;acc: 0.915 ;iou: 0.940 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 45342 ;lr: 0.0480 ;B loss: 1.244 ;acc: 0.910 ;iou: 0.960 ;time: 0:01:08\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 45392 ;lr: 0.0480 ;B loss: 1.123 ;acc: 0.890 ;iou: 0.930 ;time: 0:02:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 45442 ;lr: 0.0480 ;B loss: 1.110 ;acc: 0.895 ;iou: 0.935 ;time: 0:03:32\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 45492 ;lr: 0.0480 ;B loss: 1.237 ;acc: 0.925 ;iou: 0.955 ;time: 0:04:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 45542 ;lr: 0.0480 ;B loss: 1.189 ;acc: 0.840 ;iou: 0.900 ;time: 0:05:58\n",
      "\n",
      "*Training B: False ;B Train loss: 1.231 ;Train accuracy: 0.884 ;IOU accuracy: 0.925 ;Time: 0:06:59 \n",
      "\n",
      "Testing, ephoc: 109\n",
      "batch: 0 ;B loss: 1.582 ;acc: 0.720 ;iou_acc: 0.790 ;time: 0:07:01\n",
      "batch: 50 ;B loss: 1.497 ;acc: 0.715 ;iou_acc: 0.800 ;time: 0:07:57\n",
      "batch: 100 ;B loss: 1.660 ;acc: 0.690 ;iou_acc: 0.725 ;time: 0:08:57\n",
      "batch: 150 ;B loss: 1.758 ;acc: 0.675 ;iou_acc: 0.760 ;time: 0:09:54\n",
      "batch: 200 ;B loss: 1.611 ;acc: 0.735 ;iou_acc: 0.840 ;time: 0:10:51\n",
      "batch: 250 ;B loss: 1.523 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:11:52\n",
      "\n",
      "*BTrain: False ;Test loss: 1.618 ;Test accuracy 0.714 ;IOU accuracy: 0.802 ;Time: 0:12:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 110 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 45589 ;lr: 0.0480 ;B loss: 1.157 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 45639 ;lr: 0.0480 ;B loss: 1.220 ;acc: 0.890 ;iou: 0.925 ;time: 0:01:07\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 45689 ;lr: 0.0480 ;B loss: 1.398 ;acc: 0.855 ;iou: 0.905 ;time: 0:01:28\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 45739 ;lr: 0.0480 ;B loss: 1.179 ;acc: 0.875 ;iou: 0.925 ;time: 0:01:50\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 45789 ;lr: 0.0480 ;B loss: 1.238 ;acc: 0.880 ;iou: 0.935 ;time: 0:02:10\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 45839 ;lr: 0.0480 ;B loss: 1.166 ;acc: 0.920 ;iou: 0.960 ;time: 0:02:33\n",
      "\n",
      "*Training B: False ;B Train loss: 1.228 ;Train accuracy: 0.884 ;IOU accuracy: 0.925 ;Time: 0:02:51 \n",
      "\n",
      "Testing, ephoc: 110\n",
      "batch: 0 ;B loss: 1.592 ;acc: 0.675 ;iou_acc: 0.775 ;time: 0:02:52\n",
      "batch: 50 ;B loss: 1.484 ;acc: 0.715 ;iou_acc: 0.805 ;time: 0:03:09\n",
      "batch: 100 ;B loss: 1.700 ;acc: 0.655 ;iou_acc: 0.710 ;time: 0:03:27\n",
      "batch: 150 ;B loss: 1.742 ;acc: 0.685 ;iou_acc: 0.780 ;time: 0:03:44\n",
      "batch: 200 ;B loss: 1.618 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:04:00\n",
      "batch: 250 ;B loss: 1.529 ;acc: 0.680 ;iou_acc: 0.775 ;time: 0:04:19\n",
      "\n",
      "*BTrain: False ;Test loss: 1.616 ;Test accuracy 0.714 ;IOU accuracy: 0.803 ;Time: 0:04:37\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 111 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 45886 ;lr: 0.0480 ;B loss: 1.126 ;acc: 0.905 ;iou: 0.940 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 45936 ;lr: 0.0480 ;B loss: 1.264 ;acc: 0.865 ;iou: 0.925 ;time: 0:00:25\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 45986 ;lr: 0.0480 ;B loss: 1.150 ;acc: 0.870 ;iou: 0.930 ;time: 0:00:46\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 46036 ;lr: 0.0480 ;B loss: 1.190 ;acc: 0.875 ;iou: 0.930 ;time: 0:01:09\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 46086 ;lr: 0.0480 ;B loss: 1.234 ;acc: 0.860 ;iou: 0.905 ;time: 0:01:31\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 46136 ;lr: 0.0480 ;B loss: 1.250 ;acc: 0.900 ;iou: 0.945 ;time: 0:01:54\n",
      "\n",
      "*Training B: True ;B Train loss: 1.223 ;Train accuracy: 0.886 ;IOU accuracy: 0.927 ;Time: 0:02:15 \n",
      "\n",
      "Testing, ephoc: 111\n",
      "batch: 0 ;B loss: 1.589 ;acc: 0.680 ;iou_acc: 0.785 ;time: 0:02:17\n",
      "batch: 50 ;B loss: 1.534 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:02:35\n",
      "batch: 100 ;B loss: 1.699 ;acc: 0.705 ;iou_acc: 0.760 ;time: 0:02:54\n",
      "batch: 150 ;B loss: 1.722 ;acc: 0.675 ;iou_acc: 0.765 ;time: 0:03:14\n",
      "batch: 200 ;B loss: 1.584 ;acc: 0.740 ;iou_acc: 0.850 ;time: 0:03:33\n",
      "batch: 250 ;B loss: 1.512 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:03:52\n",
      "\n",
      "*BTrain: True ;Test loss: 1.618 ;Test accuracy 0.715 ;IOU accuracy: 0.804 ;Time: 0:04:10\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 112 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 46183 ;lr: 0.0480 ;B loss: 1.220 ;acc: 0.875 ;iou: 0.935 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 46233 ;lr: 0.0480 ;B loss: 1.242 ;acc: 0.895 ;iou: 0.935 ;time: 0:00:23\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 46283 ;lr: 0.0480 ;B loss: 1.122 ;acc: 0.945 ;iou: 0.965 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 46333 ;lr: 0.0480 ;B loss: 1.134 ;acc: 0.890 ;iou: 0.915 ;time: 0:01:06\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 46383 ;lr: 0.0480 ;B loss: 1.272 ;acc: 0.885 ;iou: 0.920 ;time: 0:01:28\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 46433 ;lr: 0.0480 ;B loss: 1.168 ;acc: 0.895 ;iou: 0.930 ;time: 0:01:53\n",
      "\n",
      "*Training B: False ;B Train loss: 1.216 ;Train accuracy: 0.886 ;IOU accuracy: 0.926 ;Time: 0:02:13 \n",
      "\n",
      "Testing, ephoc: 112\n",
      "batch: 0 ;B loss: 1.595 ;acc: 0.690 ;iou_acc: 0.785 ;time: 0:02:14\n",
      "batch: 50 ;B loss: 1.525 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:02:51\n",
      "batch: 100 ;B loss: 1.669 ;acc: 0.675 ;iou_acc: 0.750 ;time: 0:03:16\n",
      "batch: 150 ;B loss: 1.736 ;acc: 0.675 ;iou_acc: 0.800 ;time: 0:03:33\n",
      "batch: 200 ;B loss: 1.623 ;acc: 0.735 ;iou_acc: 0.840 ;time: 0:03:49\n",
      "batch: 250 ;B loss: 1.544 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:04:07\n",
      "\n",
      "*BTrain: False ;Test loss: 1.628 ;Test accuracy 0.712 ;IOU accuracy: 0.800 ;Time: 0:04:23\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 113 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 46480 ;lr: 0.0480 ;B loss: 1.167 ;acc: 0.890 ;iou: 0.930 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 46530 ;lr: 0.0480 ;B loss: 1.125 ;acc: 0.865 ;iou: 0.900 ;time: 0:00:21\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 46580 ;lr: 0.0480 ;B loss: 1.224 ;acc: 0.850 ;iou: 0.925 ;time: 0:00:44\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 46630 ;lr: 0.0480 ;B loss: 1.075 ;acc: 0.875 ;iou: 0.925 ;time: 0:01:06\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 46680 ;lr: 0.0480 ;B loss: 1.209 ;acc: 0.880 ;iou: 0.910 ;time: 0:01:29\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 46730 ;lr: 0.0480 ;B loss: 1.249 ;acc: 0.870 ;iou: 0.905 ;time: 0:02:34\n",
      "\n",
      "*Training B: False ;B Train loss: 1.216 ;Train accuracy: 0.886 ;IOU accuracy: 0.926 ;Time: 0:03:42 \n",
      "\n",
      "Testing, ephoc: 113\n",
      "batch: 0 ;B loss: 1.631 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:03:42\n",
      "batch: 50 ;B loss: 1.525 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:04:41\n",
      "batch: 100 ;B loss: 1.713 ;acc: 0.690 ;iou_acc: 0.740 ;time: 0:05:42\n",
      "batch: 150 ;B loss: 1.754 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:06:40\n",
      "batch: 200 ;B loss: 1.598 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:07:35\n",
      "batch: 250 ;B loss: 1.544 ;acc: 0.685 ;iou_acc: 0.785 ;time: 0:08:33\n",
      "\n",
      "*BTrain: False ;Test loss: 1.626 ;Test accuracy 0.712 ;IOU accuracy: 0.801 ;Time: 0:09:30\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 114 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 46777 ;lr: 0.0480 ;B loss: 1.297 ;acc: 0.865 ;iou: 0.925 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 46827 ;lr: 0.0480 ;B loss: 1.328 ;acc: 0.865 ;iou: 0.940 ;time: 0:01:05\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 46877 ;lr: 0.0480 ;B loss: 1.272 ;acc: 0.865 ;iou: 0.930 ;time: 0:02:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 46927 ;lr: 0.0480 ;B loss: 1.217 ;acc: 0.835 ;iou: 0.870 ;time: 0:03:33\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 46977 ;lr: 0.0480 ;B loss: 1.217 ;acc: 0.865 ;iou: 0.900 ;time: 0:04:44\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 47027 ;lr: 0.0480 ;B loss: 1.250 ;acc: 0.885 ;iou: 0.915 ;time: 0:05:51\n",
      "\n",
      "*Training B: True ;B Train loss: 1.214 ;Train accuracy: 0.888 ;IOU accuracy: 0.928 ;Time: 0:06:53 \n",
      "\n",
      "Testing, ephoc: 114\n",
      "batch: 0 ;B loss: 1.591 ;acc: 0.700 ;iou_acc: 0.800 ;time: 0:06:55\n",
      "batch: 50 ;B loss: 1.512 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:07:53\n",
      "batch: 100 ;B loss: 1.688 ;acc: 0.710 ;iou_acc: 0.770 ;time: 0:08:54\n",
      "batch: 150 ;B loss: 1.737 ;acc: 0.675 ;iou_acc: 0.780 ;time: 0:09:51\n",
      "batch: 200 ;B loss: 1.624 ;acc: 0.735 ;iou_acc: 0.830 ;time: 0:10:46\n",
      "batch: 250 ;B loss: 1.520 ;acc: 0.685 ;iou_acc: 0.790 ;time: 0:11:47\n",
      "\n",
      "*BTrain: True ;Test loss: 1.625 ;Test accuracy 0.713 ;IOU accuracy: 0.802 ;Time: 0:12:43\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 115 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 47074 ;lr: 0.0480 ;B loss: 1.126 ;acc: 0.895 ;iou: 0.945 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 47124 ;lr: 0.0480 ;B loss: 1.231 ;acc: 0.920 ;iou: 0.950 ;time: 0:01:11\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 47174 ;lr: 0.0480 ;B loss: 1.344 ;acc: 0.865 ;iou: 0.905 ;time: 0:02:23\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 47224 ;lr: 0.0480 ;B loss: 1.063 ;acc: 0.900 ;iou: 0.960 ;time: 0:03:34\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 47274 ;lr: 0.0480 ;B loss: 1.148 ;acc: 0.885 ;iou: 0.930 ;time: 0:04:50\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 47324 ;lr: 0.0480 ;B loss: 1.333 ;acc: 0.870 ;iou: 0.925 ;time: 0:06:02\n",
      "\n",
      "*Training B: False ;B Train loss: 1.208 ;Train accuracy: 0.888 ;IOU accuracy: 0.928 ;Time: 0:07:03 \n",
      "\n",
      "Testing, ephoc: 115\n",
      "batch: 0 ;B loss: 1.590 ;acc: 0.690 ;iou_acc: 0.775 ;time: 0:07:06\n",
      "batch: 50 ;B loss: 1.505 ;acc: 0.740 ;iou_acc: 0.805 ;time: 0:08:03\n",
      "batch: 100 ;B loss: 1.684 ;acc: 0.695 ;iou_acc: 0.765 ;time: 0:09:04\n",
      "batch: 150 ;B loss: 1.738 ;acc: 0.680 ;iou_acc: 0.790 ;time: 0:10:01\n",
      "batch: 200 ;B loss: 1.633 ;acc: 0.740 ;iou_acc: 0.835 ;time: 0:10:55\n",
      "batch: 250 ;B loss: 1.555 ;acc: 0.700 ;iou_acc: 0.795 ;time: 0:11:56\n",
      "\n",
      "*BTrain: False ;Test loss: 1.632 ;Test accuracy 0.712 ;IOU accuracy: 0.801 ;Time: 0:12:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 116 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 47371 ;lr: 0.0480 ;B loss: 1.147 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 47421 ;lr: 0.0480 ;B loss: 1.282 ;acc: 0.870 ;iou: 0.910 ;time: 0:00:59\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 47471 ;lr: 0.0480 ;B loss: 1.099 ;acc: 0.830 ;iou: 0.905 ;time: 0:02:21\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 47521 ;lr: 0.0480 ;B loss: 1.275 ;acc: 0.840 ;iou: 0.895 ;time: 0:03:26\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 47571 ;lr: 0.0480 ;B loss: 1.346 ;acc: 0.875 ;iou: 0.940 ;time: 0:04:41\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 47621 ;lr: 0.0480 ;B loss: 1.353 ;acc: 0.875 ;iou: 0.930 ;time: 0:05:55\n",
      "\n",
      "*Training B: False ;B Train loss: 1.202 ;Train accuracy: 0.888 ;IOU accuracy: 0.928 ;Time: 0:07:04 \n",
      "\n",
      "Testing, ephoc: 116\n",
      "batch: 0 ;B loss: 1.639 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:07:05\n",
      "batch: 50 ;B loss: 1.508 ;acc: 0.710 ;iou_acc: 0.770 ;time: 0:08:05\n",
      "batch: 100 ;B loss: 1.689 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:09:06\n",
      "batch: 150 ;B loss: 1.716 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:10:03\n",
      "batch: 200 ;B loss: 1.660 ;acc: 0.725 ;iou_acc: 0.825 ;time: 0:10:58\n",
      "batch: 250 ;B loss: 1.586 ;acc: 0.700 ;iou_acc: 0.805 ;time: 0:11:58\n",
      "\n",
      "*BTrain: False ;Test loss: 1.632 ;Test accuracy 0.712 ;IOU accuracy: 0.800 ;Time: 0:12:53\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 117 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 47668 ;lr: 0.0480 ;B loss: 1.153 ;acc: 0.910 ;iou: 0.955 ;time: 0:00:03\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 47718 ;lr: 0.0480 ;B loss: 1.280 ;acc: 0.880 ;iou: 0.920 ;time: 0:01:17\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 47768 ;lr: 0.0480 ;B loss: 1.286 ;acc: 0.895 ;iou: 0.935 ;time: 0:02:27\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 47818 ;lr: 0.0480 ;B loss: 1.183 ;acc: 0.900 ;iou: 0.940 ;time: 0:03:31\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 47868 ;lr: 0.0480 ;B loss: 1.077 ;acc: 0.930 ;iou: 0.965 ;time: 0:04:04\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 47918 ;lr: 0.0480 ;B loss: 1.226 ;acc: 0.895 ;iou: 0.925 ;time: 0:04:27\n",
      "\n",
      "*Training B: True ;B Train loss: 1.203 ;Train accuracy: 0.889 ;IOU accuracy: 0.929 ;Time: 0:04:48 \n",
      "\n",
      "Testing, ephoc: 117\n",
      "batch: 0 ;B loss: 1.586 ;acc: 0.710 ;iou_acc: 0.785 ;time: 0:04:49\n",
      "batch: 50 ;B loss: 1.518 ;acc: 0.710 ;iou_acc: 0.790 ;time: 0:05:08\n",
      "batch: 100 ;B loss: 1.702 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:05:28\n",
      "batch: 150 ;B loss: 1.718 ;acc: 0.670 ;iou_acc: 0.780 ;time: 0:05:47\n",
      "batch: 200 ;B loss: 1.648 ;acc: 0.700 ;iou_acc: 0.810 ;time: 0:06:06\n",
      "batch: 250 ;B loss: 1.575 ;acc: 0.685 ;iou_acc: 0.800 ;time: 0:06:25\n",
      "\n",
      "*BTrain: True ;Test loss: 1.629 ;Test accuracy 0.712 ;IOU accuracy: 0.801 ;Time: 0:06:42\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 118 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 47965 ;lr: 0.0480 ;B loss: 1.267 ;acc: 0.865 ;iou: 0.915 ;time: 0:00:01\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 48015 ;lr: 0.0480 ;B loss: 1.266 ;acc: 0.875 ;iou: 0.920 ;time: 0:00:24\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 48065 ;lr: 0.0480 ;B loss: 1.064 ;acc: 0.895 ;iou: 0.935 ;time: 0:01:22\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 48115 ;lr: 0.0480 ;B loss: 1.169 ;acc: 0.880 ;iou: 0.910 ;time: 0:02:09\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 48165 ;lr: 0.0480 ;B loss: 1.206 ;acc: 0.900 ;iou: 0.935 ;time: 0:02:31\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 48215 ;lr: 0.0480 ;B loss: 1.116 ;acc: 0.920 ;iou: 0.945 ;time: 0:02:53\n",
      "\n",
      "*Training B: False ;B Train loss: 1.201 ;Train accuracy: 0.890 ;IOU accuracy: 0.929 ;Time: 0:03:14 \n",
      "\n",
      "Testing, ephoc: 118\n",
      "batch: 0 ;B loss: 1.591 ;acc: 0.705 ;iou_acc: 0.775 ;time: 0:03:15\n",
      "batch: 50 ;B loss: 1.537 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:03:34\n",
      "batch: 100 ;B loss: 1.693 ;acc: 0.685 ;iou_acc: 0.760 ;time: 0:03:54\n",
      "batch: 150 ;B loss: 1.718 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:04:13\n",
      "batch: 200 ;B loss: 1.640 ;acc: 0.725 ;iou_acc: 0.840 ;time: 0:04:31\n",
      "batch: 250 ;B loss: 1.583 ;acc: 0.705 ;iou_acc: 0.790 ;time: 0:04:50\n",
      "\n",
      "*BTrain: False ;Test loss: 1.632 ;Test accuracy 0.711 ;IOU accuracy: 0.800 ;Time: 0:05:08\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 119 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 48262 ;lr: 0.0480 ;B loss: 1.215 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:00\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 48312 ;lr: 0.0480 ;B loss: 1.167 ;acc: 0.895 ;iou: 0.925 ;time: 0:00:27\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 48362 ;lr: 0.0480 ;B loss: 1.327 ;acc: 0.860 ;iou: 0.895 ;time: 0:00:53\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 48412 ;lr: 0.0480 ;B loss: 1.135 ;acc: 0.895 ;iou: 0.935 ;time: 0:01:15\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 48462 ;lr: 0.0480 ;B loss: 1.099 ;acc: 0.910 ;iou: 0.945 ;time: 0:01:36\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 48512 ;lr: 0.0480 ;B loss: 1.233 ;acc: 0.890 ;iou: 0.920 ;time: 0:02:01\n",
      "\n",
      "*Training B: False ;B Train loss: 1.195 ;Train accuracy: 0.892 ;IOU accuracy: 0.930 ;Time: 0:02:23 \n",
      "\n",
      "Testing, ephoc: 119\n",
      "batch: 0 ;B loss: 1.648 ;acc: 0.705 ;iou_acc: 0.785 ;time: 0:02:24\n",
      "batch: 50 ;B loss: 1.530 ;acc: 0.725 ;iou_acc: 0.780 ;time: 0:02:43\n",
      "batch: 100 ;B loss: 1.739 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:03:03\n",
      "batch: 150 ;B loss: 1.743 ;acc: 0.680 ;iou_acc: 0.765 ;time: 0:03:23\n",
      "batch: 200 ;B loss: 1.646 ;acc: 0.710 ;iou_acc: 0.820 ;time: 0:03:42\n",
      "batch: 250 ;B loss: 1.593 ;acc: 0.680 ;iou_acc: 0.750 ;time: 0:04:42\n",
      "\n",
      "*BTrain: False ;Test loss: 1.638 ;Test accuracy 0.711 ;IOU accuracy: 0.800 ;Time: 0:05:34\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 120 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 48559 ;lr: 0.0480 ;B loss: 1.135 ;acc: 0.930 ;iou: 0.965 ;time: 0:00:04\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 48609 ;lr: 0.0480 ;B loss: 1.225 ;acc: 0.930 ;iou: 0.955 ;time: 0:01:36\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 48659 ;lr: 0.0480 ;B loss: 1.200 ;acc: 0.910 ;iou: 0.940 ;time: 0:02:38\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 48709 ;lr: 0.0480 ;B loss: 1.178 ;acc: 0.875 ;iou: 0.910 ;time: 0:03:42\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 48759 ;lr: 0.0480 ;B loss: 1.031 ;acc: 0.890 ;iou: 0.925 ;time: 0:04:59\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 48809 ;lr: 0.0480 ;B loss: 1.159 ;acc: 0.920 ;iou: 0.945 ;time: 0:06:09\n",
      "\n",
      "*Training B: True ;B Train loss: 1.189 ;Train accuracy: 0.892 ;IOU accuracy: 0.930 ;Time: 0:07:16 \n",
      "\n",
      "Testing, ephoc: 120\n",
      "batch: 0 ;B loss: 1.615 ;acc: 0.695 ;iou_acc: 0.780 ;time: 0:07:16\n",
      "batch: 50 ;B loss: 1.512 ;acc: 0.715 ;iou_acc: 0.780 ;time: 0:08:16\n",
      "batch: 100 ;B loss: 1.730 ;acc: 0.705 ;iou_acc: 0.760 ;time: 0:09:17\n",
      "batch: 150 ;B loss: 1.721 ;acc: 0.700 ;iou_acc: 0.765 ;time: 0:10:15\n",
      "batch: 200 ;B loss: 1.615 ;acc: 0.740 ;iou_acc: 0.845 ;time: 0:11:10\n",
      "batch: 250 ;B loss: 1.589 ;acc: 0.690 ;iou_acc: 0.780 ;time: 0:12:10\n",
      "\n",
      "*BTrain: True ;Test loss: 1.639 ;Test accuracy 0.710 ;IOU accuracy: 0.799 ;Time: 0:13:07\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 121 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 48856 ;lr: 0.0480 ;B loss: 1.124 ;acc: 0.905 ;iou: 0.935 ;time: 0:00:03\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 48906 ;lr: 0.0480 ;B loss: 1.114 ;acc: 0.915 ;iou: 0.950 ;time: 0:01:04\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 48956 ;lr: 0.0480 ;B loss: 1.182 ;acc: 0.880 ;iou: 0.920 ;time: 0:02:19\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 49006 ;lr: 0.0480 ;B loss: 1.125 ;acc: 0.920 ;iou: 0.960 ;time: 0:03:30\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 49056 ;lr: 0.0480 ;B loss: 1.206 ;acc: 0.895 ;iou: 0.935 ;time: 0:04:43\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 49106 ;lr: 0.0480 ;B loss: 1.231 ;acc: 0.885 ;iou: 0.915 ;time: 0:05:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.184 ;Train accuracy: 0.892 ;IOU accuracy: 0.930 ;Time: 0:07:01 \n",
      "\n",
      "Testing, ephoc: 121\n",
      "batch: 0 ;B loss: 1.597 ;acc: 0.710 ;iou_acc: 0.800 ;time: 0:07:02\n",
      "batch: 50 ;B loss: 1.542 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:08:02\n",
      "batch: 100 ;B loss: 1.688 ;acc: 0.685 ;iou_acc: 0.745 ;time: 0:09:03\n",
      "batch: 150 ;B loss: 1.722 ;acc: 0.690 ;iou_acc: 0.770 ;time: 0:10:01\n",
      "batch: 200 ;B loss: 1.636 ;acc: 0.725 ;iou_acc: 0.830 ;time: 0:10:56\n",
      "batch: 250 ;B loss: 1.585 ;acc: 0.700 ;iou_acc: 0.780 ;time: 0:11:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.633 ;Test accuracy 0.712 ;IOU accuracy: 0.801 ;Time: 0:12:51\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 122 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 49153 ;lr: 0.0480 ;B loss: 1.200 ;acc: 0.880 ;iou: 0.935 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 49203 ;lr: 0.0480 ;B loss: 1.218 ;acc: 0.885 ;iou: 0.925 ;time: 0:01:14\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 49253 ;lr: 0.0480 ;B loss: 1.169 ;acc: 0.915 ;iou: 0.935 ;time: 0:02:34\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 49303 ;lr: 0.0480 ;B loss: 1.161 ;acc: 0.880 ;iou: 0.915 ;time: 0:03:42\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 49353 ;lr: 0.0480 ;B loss: 1.137 ;acc: 0.900 ;iou: 0.920 ;time: 0:04:49\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 49403 ;lr: 0.0480 ;B loss: 1.271 ;acc: 0.910 ;iou: 0.940 ;time: 0:05:57\n",
      "\n",
      "*Training B: False ;B Train loss: 1.181 ;Train accuracy: 0.893 ;IOU accuracy: 0.930 ;Time: 0:07:04 \n",
      "\n",
      "Testing, ephoc: 122\n",
      "batch: 0 ;B loss: 1.598 ;acc: 0.695 ;iou_acc: 0.790 ;time: 0:07:05\n",
      "batch: 50 ;B loss: 1.534 ;acc: 0.710 ;iou_acc: 0.775 ;time: 0:08:03\n",
      "batch: 100 ;B loss: 1.714 ;acc: 0.690 ;iou_acc: 0.755 ;time: 0:09:02\n",
      "batch: 150 ;B loss: 1.732 ;acc: 0.665 ;iou_acc: 0.770 ;time: 0:10:00\n",
      "batch: 200 ;B loss: 1.631 ;acc: 0.735 ;iou_acc: 0.835 ;time: 0:10:55\n",
      "batch: 250 ;B loss: 1.564 ;acc: 0.670 ;iou_acc: 0.755 ;time: 0:11:54\n",
      "\n",
      "*BTrain: False ;Test loss: 1.633 ;Test accuracy 0.710 ;IOU accuracy: 0.799 ;Time: 0:12:49\n",
      "================================================== \n",
      "\n",
      "================================================== \n",
      "Train, ephoc: 123 ; Training B: True\n",
      "Edit: False ;A: False ;batch: 0 ;gs: 49450 ;lr: 0.0480 ;B loss: 1.117 ;acc: 0.940 ;iou: 0.960 ;time: 0:00:02\n",
      "Edit: False ;A: False ;batch: 50 ;gs: 49500 ;lr: 0.0480 ;B loss: 1.338 ;acc: 0.855 ;iou: 0.910 ;time: 0:01:21\n",
      "Edit: False ;A: False ;batch: 100 ;gs: 49550 ;lr: 0.0480 ;B loss: 1.219 ;acc: 0.925 ;iou: 0.940 ;time: 0:02:30\n",
      "Edit: False ;A: False ;batch: 150 ;gs: 49600 ;lr: 0.0480 ;B loss: 1.178 ;acc: 0.915 ;iou: 0.950 ;time: 0:03:44\n",
      "Edit: False ;A: False ;batch: 200 ;gs: 49650 ;lr: 0.0480 ;B loss: 1.188 ;acc: 0.910 ;iou: 0.950 ;time: 0:04:54\n",
      "Edit: False ;A: False ;batch: 250 ;gs: 49700 ;lr: 0.0480 ;B loss: 1.135 ;acc: 0.875 ;iou: 0.910 ;time: 0:06:05\n",
      "\n",
      "*Training B: True ;B Train loss: 1.175 ;Train accuracy: 0.894 ;IOU accuracy: 0.932 ;Time: 0:06:35 \n",
      "\n",
      "Testing, ephoc: 123\n",
      "batch: 0 ;B loss: 1.609 ;acc: 0.695 ;iou_acc: 0.785 ;time: 0:06:36\n",
      "batch: 50 ;B loss: 1.559 ;acc: 0.690 ;iou_acc: 0.765 ;time: 0:06:56\n",
      "batch: 100 ;B loss: 1.725 ;acc: 0.695 ;iou_acc: 0.770 ;time: 0:07:15\n",
      "batch: 150 ;B loss: 1.750 ;acc: 0.675 ;iou_acc: 0.755 ;time: 0:07:33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f808e3344508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdropout_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mdropout_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         dropout_out=dropout_out)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0maug_bnorm_test_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-142af79a318b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trn_data, tst_data, ephocs_num, edit_reward, startA, activation_ephoc, muteB, start_ephoc, dropout_in, dropout_out, dropout_img, editProb, max_activateAProb, activateAProb, use_wordAttn, addNoise)\u001b[0m\n\u001b[1;32m    718\u001b[0m                         \u001b[0mB_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misEdit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m                         iou_acc = self.iou_accuracy(\n\u001b[1;32m    722\u001b[0m                             tst_data, b*self.batch_size, (b+1)*self.batch_size, sess=sess, feed_dict=feed_dict, isEdit=False)\n",
      "\u001b[0;32m<ipython-input-8-142af79a318b>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, data, start, end, sess, feed_dict, isEdit)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_img\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asi/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Augmenting data\n",
    "# The accuracy and IOU of the trainin set includs data points \n",
    "# with no true groinding bbox so the true training's accuracy and IOU\n",
    "# is higher then we can see in the reults here (TODO: fix it)\n",
    "# decreasing learning rate even more\n",
    "\n",
    "\n",
    "num_hidden = 200\n",
    "dropout_in=0.5\n",
    "dropout_out=1.\n",
    "dropout_img = 0.5\n",
    "params_dir = params_dir_tmp+'bnorm_base/augmented_'+str(dropout_in)+','+str(dropout_out)+','+str(dropout_img)+'_hidden:'+str(num_hidden)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "m = Model(\n",
    "    batch_size=200, \n",
    "    num_hidden=num_hidden,\n",
    "    embed_size=num_hidden,\n",
    "    img_dims=trainset[0][1][0].shape[1], \n",
    "    bbox_dims=trainset[0][1][1].shape[1], \n",
    "    lr=.05,\n",
    "    vocab=vocab, \n",
    "    decay_steps=10000, \n",
    "    decay_rate=0.99, \n",
    "    edit_reward=0.,\n",
    "    rnn_editProb=0.,\n",
    "    coefAlr=1,\n",
    "    bnorm=True)\n",
    "\n",
    "\n",
    "# start comp\n",
    "print('params_dir:', params_dir)\n",
    "print('num_hidden:', m.num_hidden)\n",
    "print('learning rate:', m.lr)\n",
    "tst, trn = m.train(trainset, testset,\n",
    "        ephocs_num=200,\n",
    "        start_ephoc=94,\n",
    "        startA=101,\n",
    "        activation_ephoc=101,\n",
    "        muteB=0, \n",
    "        activateAProb=0,\n",
    "        max_activateAProb=0,\n",
    "        editProb=0,\n",
    "        edit_reward=0,\n",
    "        dropout_img=dropout_img,\n",
    "        dropout_in=dropout_in,\n",
    "        dropout_out=dropout_out)\n",
    "\n",
    "aug_bnorm_test_res.append(tst)\n",
    "aug_bnorm_train_res.append(trn)\n",
    "print('\\n'+'*'*100)\n",
    "print('*'*100)\n",
    "print('*'*100,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
